{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 457,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002188183807439825,
      "grad_norm": 21.92169952392578,
      "learning_rate": 1.0869565217391305e-07,
      "loss": 4.23,
      "step": 1
    },
    {
      "epoch": 0.00437636761487965,
      "grad_norm": 26.026044845581055,
      "learning_rate": 2.173913043478261e-07,
      "loss": 4.3188,
      "step": 2
    },
    {
      "epoch": 0.006564551422319475,
      "grad_norm": 23.51215934753418,
      "learning_rate": 3.2608695652173915e-07,
      "loss": 4.4454,
      "step": 3
    },
    {
      "epoch": 0.0087527352297593,
      "grad_norm": 23.570011138916016,
      "learning_rate": 4.347826086956522e-07,
      "loss": 4.7674,
      "step": 4
    },
    {
      "epoch": 0.010940919037199124,
      "grad_norm": 21.65768051147461,
      "learning_rate": 5.434782608695653e-07,
      "loss": 4.3347,
      "step": 5
    },
    {
      "epoch": 0.01312910284463895,
      "grad_norm": 25.191184997558594,
      "learning_rate": 6.521739130434783e-07,
      "loss": 4.3871,
      "step": 6
    },
    {
      "epoch": 0.015317286652078774,
      "grad_norm": 29.510009765625,
      "learning_rate": 7.608695652173914e-07,
      "loss": 4.3269,
      "step": 7
    },
    {
      "epoch": 0.0175054704595186,
      "grad_norm": 26.61124610900879,
      "learning_rate": 8.695652173913044e-07,
      "loss": 4.2808,
      "step": 8
    },
    {
      "epoch": 0.019693654266958426,
      "grad_norm": 28.173067092895508,
      "learning_rate": 9.782608695652175e-07,
      "loss": 3.9001,
      "step": 9
    },
    {
      "epoch": 0.02188183807439825,
      "grad_norm": 24.299726486206055,
      "learning_rate": 1.0869565217391306e-06,
      "loss": 3.8161,
      "step": 10
    },
    {
      "epoch": 0.024070021881838075,
      "grad_norm": 24.23542022705078,
      "learning_rate": 1.1956521739130436e-06,
      "loss": 3.6201,
      "step": 11
    },
    {
      "epoch": 0.0262582056892779,
      "grad_norm": 25.652372360229492,
      "learning_rate": 1.3043478260869566e-06,
      "loss": 3.633,
      "step": 12
    },
    {
      "epoch": 0.028446389496717725,
      "grad_norm": 30.208736419677734,
      "learning_rate": 1.4130434782608697e-06,
      "loss": 3.7734,
      "step": 13
    },
    {
      "epoch": 0.030634573304157548,
      "grad_norm": 28.77434730529785,
      "learning_rate": 1.521739130434783e-06,
      "loss": 3.9839,
      "step": 14
    },
    {
      "epoch": 0.03282275711159737,
      "grad_norm": 37.542110443115234,
      "learning_rate": 1.6304347826086957e-06,
      "loss": 3.4631,
      "step": 15
    },
    {
      "epoch": 0.0350109409190372,
      "grad_norm": 29.25891876220703,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 2.805,
      "step": 16
    },
    {
      "epoch": 0.037199124726477024,
      "grad_norm": 24.443220138549805,
      "learning_rate": 1.8478260869565218e-06,
      "loss": 3.1836,
      "step": 17
    },
    {
      "epoch": 0.03938730853391685,
      "grad_norm": 28.21834373474121,
      "learning_rate": 1.956521739130435e-06,
      "loss": 2.83,
      "step": 18
    },
    {
      "epoch": 0.04157549234135667,
      "grad_norm": 25.189159393310547,
      "learning_rate": 2.065217391304348e-06,
      "loss": 1.7317,
      "step": 19
    },
    {
      "epoch": 0.0437636761487965,
      "grad_norm": 18.42010498046875,
      "learning_rate": 2.173913043478261e-06,
      "loss": 2.2329,
      "step": 20
    },
    {
      "epoch": 0.045951859956236324,
      "grad_norm": 19.25421905517578,
      "learning_rate": 2.282608695652174e-06,
      "loss": 1.4282,
      "step": 21
    },
    {
      "epoch": 0.04814004376367615,
      "grad_norm": 18.170705795288086,
      "learning_rate": 2.391304347826087e-06,
      "loss": 1.2439,
      "step": 22
    },
    {
      "epoch": 0.05032822757111598,
      "grad_norm": 15.09523868560791,
      "learning_rate": 2.5e-06,
      "loss": 1.7597,
      "step": 23
    },
    {
      "epoch": 0.0525164113785558,
      "grad_norm": 13.439866065979004,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 1.2792,
      "step": 24
    },
    {
      "epoch": 0.05470459518599562,
      "grad_norm": 12.3915376663208,
      "learning_rate": 2.7173913043478263e-06,
      "loss": 0.8122,
      "step": 25
    },
    {
      "epoch": 0.05689277899343545,
      "grad_norm": 11.340263366699219,
      "learning_rate": 2.8260869565217393e-06,
      "loss": 0.8843,
      "step": 26
    },
    {
      "epoch": 0.05908096280087528,
      "grad_norm": 14.174553871154785,
      "learning_rate": 2.9347826086956528e-06,
      "loss": 0.8225,
      "step": 27
    },
    {
      "epoch": 0.061269146608315096,
      "grad_norm": 12.220551490783691,
      "learning_rate": 3.043478260869566e-06,
      "loss": 0.7445,
      "step": 28
    },
    {
      "epoch": 0.06345733041575492,
      "grad_norm": 11.536544799804688,
      "learning_rate": 3.152173913043479e-06,
      "loss": 0.8399,
      "step": 29
    },
    {
      "epoch": 0.06564551422319474,
      "grad_norm": 8.447307586669922,
      "learning_rate": 3.2608695652173914e-06,
      "loss": 0.324,
      "step": 30
    },
    {
      "epoch": 0.06783369803063458,
      "grad_norm": 7.784756660461426,
      "learning_rate": 3.3695652173913045e-06,
      "loss": 0.403,
      "step": 31
    },
    {
      "epoch": 0.0700218818380744,
      "grad_norm": 7.731598377227783,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.2715,
      "step": 32
    },
    {
      "epoch": 0.07221006564551423,
      "grad_norm": 2.521393299102783,
      "learning_rate": 3.5869565217391305e-06,
      "loss": 0.0793,
      "step": 33
    },
    {
      "epoch": 0.07439824945295405,
      "grad_norm": 4.356139183044434,
      "learning_rate": 3.6956521739130436e-06,
      "loss": 0.1297,
      "step": 34
    },
    {
      "epoch": 0.07658643326039387,
      "grad_norm": 7.290046215057373,
      "learning_rate": 3.804347826086957e-06,
      "loss": 0.7816,
      "step": 35
    },
    {
      "epoch": 0.0787746170678337,
      "grad_norm": 4.509263515472412,
      "learning_rate": 3.91304347826087e-06,
      "loss": 0.1902,
      "step": 36
    },
    {
      "epoch": 0.08096280087527352,
      "grad_norm": 4.0476884841918945,
      "learning_rate": 4.021739130434783e-06,
      "loss": 0.094,
      "step": 37
    },
    {
      "epoch": 0.08315098468271334,
      "grad_norm": 0.1850305050611496,
      "learning_rate": 4.130434782608696e-06,
      "loss": 0.0053,
      "step": 38
    },
    {
      "epoch": 0.08533916849015317,
      "grad_norm": 0.7134180068969727,
      "learning_rate": 4.239130434782609e-06,
      "loss": 0.0118,
      "step": 39
    },
    {
      "epoch": 0.087527352297593,
      "grad_norm": 3.846184253692627,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.4469,
      "step": 40
    },
    {
      "epoch": 0.08971553610503283,
      "grad_norm": 3.582517623901367,
      "learning_rate": 4.456521739130435e-06,
      "loss": 0.0058,
      "step": 41
    },
    {
      "epoch": 0.09190371991247265,
      "grad_norm": 0.02784961834549904,
      "learning_rate": 4.565217391304348e-06,
      "loss": 0.0007,
      "step": 42
    },
    {
      "epoch": 0.09409190371991247,
      "grad_norm": 4.695168495178223,
      "learning_rate": 4.673913043478261e-06,
      "loss": 0.1076,
      "step": 43
    },
    {
      "epoch": 0.0962800875273523,
      "grad_norm": 8.55430793762207,
      "learning_rate": 4.782608695652174e-06,
      "loss": 0.219,
      "step": 44
    },
    {
      "epoch": 0.09846827133479212,
      "grad_norm": 0.02668142132461071,
      "learning_rate": 4.891304347826087e-06,
      "loss": 0.0003,
      "step": 45
    },
    {
      "epoch": 0.10065645514223195,
      "grad_norm": 1.1315202713012695,
      "learning_rate": 5e-06,
      "loss": 0.0179,
      "step": 46
    },
    {
      "epoch": 0.10284463894967177,
      "grad_norm": 6.05073356628418,
      "learning_rate": 5.108695652173914e-06,
      "loss": 0.0283,
      "step": 47
    },
    {
      "epoch": 0.1050328227571116,
      "grad_norm": 0.02583625540137291,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.0006,
      "step": 48
    },
    {
      "epoch": 0.10722100656455143,
      "grad_norm": 0.00762923713773489,
      "learning_rate": 5.3260869565217395e-06,
      "loss": 0.0003,
      "step": 49
    },
    {
      "epoch": 0.10940919037199125,
      "grad_norm": 3.0636379718780518,
      "learning_rate": 5.4347826086956525e-06,
      "loss": 0.1377,
      "step": 50
    },
    {
      "epoch": 0.11159737417943107,
      "grad_norm": 0.008876768872141838,
      "learning_rate": 5.543478260869566e-06,
      "loss": 0.0003,
      "step": 51
    },
    {
      "epoch": 0.1137855579868709,
      "grad_norm": 1.1159427165985107,
      "learning_rate": 5.652173913043479e-06,
      "loss": 0.008,
      "step": 52
    },
    {
      "epoch": 0.11597374179431072,
      "grad_norm": 5.815639019012451,
      "learning_rate": 5.760869565217392e-06,
      "loss": 0.0304,
      "step": 53
    },
    {
      "epoch": 0.11816192560175055,
      "grad_norm": 5.290447235107422,
      "learning_rate": 5.8695652173913055e-06,
      "loss": 0.2619,
      "step": 54
    },
    {
      "epoch": 0.12035010940919037,
      "grad_norm": 4.20110559463501,
      "learning_rate": 5.978260869565218e-06,
      "loss": 0.1499,
      "step": 55
    },
    {
      "epoch": 0.12253829321663019,
      "grad_norm": 4.0314202308654785,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.2574,
      "step": 56
    },
    {
      "epoch": 0.12472647702407003,
      "grad_norm": 1.4957077503204346,
      "learning_rate": 6.195652173913044e-06,
      "loss": 0.0234,
      "step": 57
    },
    {
      "epoch": 0.12691466083150985,
      "grad_norm": 6.073808193206787,
      "learning_rate": 6.304347826086958e-06,
      "loss": 0.4651,
      "step": 58
    },
    {
      "epoch": 0.12910284463894967,
      "grad_norm": 3.75553560256958,
      "learning_rate": 6.41304347826087e-06,
      "loss": 0.2945,
      "step": 59
    },
    {
      "epoch": 0.13129102844638948,
      "grad_norm": 2.4902987480163574,
      "learning_rate": 6.521739130434783e-06,
      "loss": 0.2868,
      "step": 60
    },
    {
      "epoch": 0.13347921225382933,
      "grad_norm": 3.71418833732605,
      "learning_rate": 6.630434782608696e-06,
      "loss": 0.2579,
      "step": 61
    },
    {
      "epoch": 0.13566739606126915,
      "grad_norm": 0.03424016758799553,
      "learning_rate": 6.739130434782609e-06,
      "loss": 0.0007,
      "step": 62
    },
    {
      "epoch": 0.13785557986870897,
      "grad_norm": 2.8738279342651367,
      "learning_rate": 6.847826086956523e-06,
      "loss": 0.2375,
      "step": 63
    },
    {
      "epoch": 0.1400437636761488,
      "grad_norm": 3.712216377258301,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.0981,
      "step": 64
    },
    {
      "epoch": 0.1422319474835886,
      "grad_norm": 0.948320746421814,
      "learning_rate": 7.065217391304349e-06,
      "loss": 0.0241,
      "step": 65
    },
    {
      "epoch": 0.14442013129102846,
      "grad_norm": 3.3651909828186035,
      "learning_rate": 7.173913043478261e-06,
      "loss": 0.3171,
      "step": 66
    },
    {
      "epoch": 0.14660831509846828,
      "grad_norm": 1.713239312171936,
      "learning_rate": 7.282608695652175e-06,
      "loss": 0.0434,
      "step": 67
    },
    {
      "epoch": 0.1487964989059081,
      "grad_norm": 0.2164396345615387,
      "learning_rate": 7.391304347826087e-06,
      "loss": 0.0063,
      "step": 68
    },
    {
      "epoch": 0.15098468271334792,
      "grad_norm": 0.29880690574645996,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0072,
      "step": 69
    },
    {
      "epoch": 0.15317286652078774,
      "grad_norm": 0.16391891241073608,
      "learning_rate": 7.608695652173914e-06,
      "loss": 0.0059,
      "step": 70
    },
    {
      "epoch": 0.15536105032822758,
      "grad_norm": 3.569581985473633,
      "learning_rate": 7.717391304347827e-06,
      "loss": 0.1553,
      "step": 71
    },
    {
      "epoch": 0.1575492341356674,
      "grad_norm": 2.129352569580078,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.1226,
      "step": 72
    },
    {
      "epoch": 0.15973741794310722,
      "grad_norm": 0.2839913070201874,
      "learning_rate": 7.934782608695653e-06,
      "loss": 0.0091,
      "step": 73
    },
    {
      "epoch": 0.16192560175054704,
      "grad_norm": 0.5524371266365051,
      "learning_rate": 8.043478260869566e-06,
      "loss": 0.0188,
      "step": 74
    },
    {
      "epoch": 0.16411378555798686,
      "grad_norm": 0.3273867070674896,
      "learning_rate": 8.15217391304348e-06,
      "loss": 0.0102,
      "step": 75
    },
    {
      "epoch": 0.16630196936542668,
      "grad_norm": 1.1167811155319214,
      "learning_rate": 8.260869565217392e-06,
      "loss": 0.0229,
      "step": 76
    },
    {
      "epoch": 0.16849015317286653,
      "grad_norm": 0.3959013819694519,
      "learning_rate": 8.369565217391305e-06,
      "loss": 0.0135,
      "step": 77
    },
    {
      "epoch": 0.17067833698030635,
      "grad_norm": 0.3263627886772156,
      "learning_rate": 8.478260869565218e-06,
      "loss": 0.0129,
      "step": 78
    },
    {
      "epoch": 0.17286652078774617,
      "grad_norm": 0.2119074910879135,
      "learning_rate": 8.586956521739131e-06,
      "loss": 0.0079,
      "step": 79
    },
    {
      "epoch": 0.175054704595186,
      "grad_norm": 0.9144782423973083,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0792,
      "step": 80
    },
    {
      "epoch": 0.1772428884026258,
      "grad_norm": 0.07093604654073715,
      "learning_rate": 8.804347826086957e-06,
      "loss": 0.0025,
      "step": 81
    },
    {
      "epoch": 0.17943107221006566,
      "grad_norm": 0.8022505640983582,
      "learning_rate": 8.91304347826087e-06,
      "loss": 0.0112,
      "step": 82
    },
    {
      "epoch": 0.18161925601750548,
      "grad_norm": 0.145287424325943,
      "learning_rate": 9.021739130434784e-06,
      "loss": 0.0045,
      "step": 83
    },
    {
      "epoch": 0.1838074398249453,
      "grad_norm": 1.6540549993515015,
      "learning_rate": 9.130434782608697e-06,
      "loss": 0.2173,
      "step": 84
    },
    {
      "epoch": 0.18599562363238512,
      "grad_norm": 1.604325771331787,
      "learning_rate": 9.23913043478261e-06,
      "loss": 0.1706,
      "step": 85
    },
    {
      "epoch": 0.18818380743982493,
      "grad_norm": 3.446460008621216,
      "learning_rate": 9.347826086956523e-06,
      "loss": 0.1711,
      "step": 86
    },
    {
      "epoch": 0.19037199124726478,
      "grad_norm": 2.3221254348754883,
      "learning_rate": 9.456521739130436e-06,
      "loss": 0.0612,
      "step": 87
    },
    {
      "epoch": 0.1925601750547046,
      "grad_norm": 0.09616374224424362,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0028,
      "step": 88
    },
    {
      "epoch": 0.19474835886214442,
      "grad_norm": 0.8513073325157166,
      "learning_rate": 9.673913043478262e-06,
      "loss": 0.0951,
      "step": 89
    },
    {
      "epoch": 0.19693654266958424,
      "grad_norm": 1.975714921951294,
      "learning_rate": 9.782608695652175e-06,
      "loss": 0.06,
      "step": 90
    },
    {
      "epoch": 0.19912472647702406,
      "grad_norm": 0.0585392601788044,
      "learning_rate": 9.891304347826088e-06,
      "loss": 0.0017,
      "step": 91
    },
    {
      "epoch": 0.2013129102844639,
      "grad_norm": 3.32110333442688,
      "learning_rate": 1e-05,
      "loss": 0.1381,
      "step": 92
    },
    {
      "epoch": 0.20350109409190373,
      "grad_norm": 7.79399299621582,
      "learning_rate": 9.999963482958057e-06,
      "loss": 0.1218,
      "step": 93
    },
    {
      "epoch": 0.20568927789934355,
      "grad_norm": 0.09784691035747528,
      "learning_rate": 9.999853932365623e-06,
      "loss": 0.0036,
      "step": 94
    },
    {
      "epoch": 0.20787746170678337,
      "grad_norm": 0.8106443881988525,
      "learning_rate": 9.999671349822887e-06,
      "loss": 0.0218,
      "step": 95
    },
    {
      "epoch": 0.2100656455142232,
      "grad_norm": 0.26211073994636536,
      "learning_rate": 9.999415737996795e-06,
      "loss": 0.0082,
      "step": 96
    },
    {
      "epoch": 0.212253829321663,
      "grad_norm": 0.07968001067638397,
      "learning_rate": 9.999087100621024e-06,
      "loss": 0.0023,
      "step": 97
    },
    {
      "epoch": 0.21444201312910285,
      "grad_norm": 1.669019341468811,
      "learning_rate": 9.998685442495921e-06,
      "loss": 0.1066,
      "step": 98
    },
    {
      "epoch": 0.21663019693654267,
      "grad_norm": 2.091339588165283,
      "learning_rate": 9.99821076948843e-06,
      "loss": 0.1313,
      "step": 99
    },
    {
      "epoch": 0.2188183807439825,
      "grad_norm": 0.7443447113037109,
      "learning_rate": 9.997663088532015e-06,
      "loss": 0.015,
      "step": 100
    },
    {
      "epoch": 0.2210065645514223,
      "grad_norm": 4.857107639312744,
      "learning_rate": 9.99704240762655e-06,
      "loss": 0.0896,
      "step": 101
    },
    {
      "epoch": 0.22319474835886213,
      "grad_norm": 1.5962547063827515,
      "learning_rate": 9.996348735838207e-06,
      "loss": 0.0905,
      "step": 102
    },
    {
      "epoch": 0.22538293216630198,
      "grad_norm": 1.827211618423462,
      "learning_rate": 9.995582083299323e-06,
      "loss": 0.0252,
      "step": 103
    },
    {
      "epoch": 0.2275711159737418,
      "grad_norm": 0.30125245451927185,
      "learning_rate": 9.994742461208251e-06,
      "loss": 0.0113,
      "step": 104
    },
    {
      "epoch": 0.22975929978118162,
      "grad_norm": 0.7719400525093079,
      "learning_rate": 9.9938298818292e-06,
      "loss": 0.0191,
      "step": 105
    },
    {
      "epoch": 0.23194748358862144,
      "grad_norm": 4.972741603851318,
      "learning_rate": 9.992844358492045e-06,
      "loss": 0.2713,
      "step": 106
    },
    {
      "epoch": 0.23413566739606126,
      "grad_norm": 0.6459964513778687,
      "learning_rate": 9.991785905592149e-06,
      "loss": 0.0176,
      "step": 107
    },
    {
      "epoch": 0.2363238512035011,
      "grad_norm": 0.10298965871334076,
      "learning_rate": 9.990654538590136e-06,
      "loss": 0.0044,
      "step": 108
    },
    {
      "epoch": 0.23851203501094093,
      "grad_norm": 1.7044460773468018,
      "learning_rate": 9.98945027401168e-06,
      "loss": 0.0176,
      "step": 109
    },
    {
      "epoch": 0.24070021881838075,
      "grad_norm": 1.6271607875823975,
      "learning_rate": 9.988173129447251e-06,
      "loss": 0.0215,
      "step": 110
    },
    {
      "epoch": 0.24288840262582057,
      "grad_norm": 0.009151516482234001,
      "learning_rate": 9.986823123551865e-06,
      "loss": 0.0004,
      "step": 111
    },
    {
      "epoch": 0.24507658643326038,
      "grad_norm": 5.363443851470947,
      "learning_rate": 9.985400276044811e-06,
      "loss": 0.047,
      "step": 112
    },
    {
      "epoch": 0.24726477024070023,
      "grad_norm": 4.495186805725098,
      "learning_rate": 9.983904607709365e-06,
      "loss": 0.0816,
      "step": 113
    },
    {
      "epoch": 0.24945295404814005,
      "grad_norm": 0.1768520027399063,
      "learning_rate": 9.982336140392476e-06,
      "loss": 0.0048,
      "step": 114
    },
    {
      "epoch": 0.25164113785557984,
      "grad_norm": 0.09187545627355576,
      "learning_rate": 9.980694897004462e-06,
      "loss": 0.0028,
      "step": 115
    },
    {
      "epoch": 0.2538293216630197,
      "grad_norm": 0.015799526125192642,
      "learning_rate": 9.978980901518663e-06,
      "loss": 0.0006,
      "step": 116
    },
    {
      "epoch": 0.25601750547045954,
      "grad_norm": 1.5121122598648071,
      "learning_rate": 9.977194178971098e-06,
      "loss": 0.196,
      "step": 117
    },
    {
      "epoch": 0.25820568927789933,
      "grad_norm": 1.6397640705108643,
      "learning_rate": 9.975334755460092e-06,
      "loss": 0.0999,
      "step": 118
    },
    {
      "epoch": 0.2603938730853392,
      "grad_norm": 1.7495745420455933,
      "learning_rate": 9.973402658145908e-06,
      "loss": 0.0792,
      "step": 119
    },
    {
      "epoch": 0.26258205689277897,
      "grad_norm": 0.4255240261554718,
      "learning_rate": 9.971397915250336e-06,
      "loss": 0.0072,
      "step": 120
    },
    {
      "epoch": 0.2647702407002188,
      "grad_norm": 1.6011850833892822,
      "learning_rate": 9.969320556056287e-06,
      "loss": 0.1838,
      "step": 121
    },
    {
      "epoch": 0.26695842450765866,
      "grad_norm": 0.14655138552188873,
      "learning_rate": 9.96717061090737e-06,
      "loss": 0.0052,
      "step": 122
    },
    {
      "epoch": 0.26914660831509846,
      "grad_norm": 0.19067755341529846,
      "learning_rate": 9.964948111207435e-06,
      "loss": 0.0085,
      "step": 123
    },
    {
      "epoch": 0.2713347921225383,
      "grad_norm": 1.255624532699585,
      "learning_rate": 9.962653089420132e-06,
      "loss": 0.1059,
      "step": 124
    },
    {
      "epoch": 0.2735229759299781,
      "grad_norm": 0.021253552287817,
      "learning_rate": 9.960285579068419e-06,
      "loss": 0.001,
      "step": 125
    },
    {
      "epoch": 0.27571115973741794,
      "grad_norm": 2.3604700565338135,
      "learning_rate": 9.95784561473409e-06,
      "loss": 0.2022,
      "step": 126
    },
    {
      "epoch": 0.2778993435448578,
      "grad_norm": 2.3471944332122803,
      "learning_rate": 9.955333232057256e-06,
      "loss": 0.0781,
      "step": 127
    },
    {
      "epoch": 0.2800875273522976,
      "grad_norm": 1.601385474205017,
      "learning_rate": 9.95274846773583e-06,
      "loss": 0.1158,
      "step": 128
    },
    {
      "epoch": 0.28227571115973743,
      "grad_norm": 0.45373260974884033,
      "learning_rate": 9.950091359524991e-06,
      "loss": 0.0193,
      "step": 129
    },
    {
      "epoch": 0.2844638949671772,
      "grad_norm": 0.8206059336662292,
      "learning_rate": 9.947361946236632e-06,
      "loss": 0.036,
      "step": 130
    },
    {
      "epoch": 0.28665207877461707,
      "grad_norm": 0.8059540390968323,
      "learning_rate": 9.944560267738792e-06,
      "loss": 0.0842,
      "step": 131
    },
    {
      "epoch": 0.2888402625820569,
      "grad_norm": 0.197442889213562,
      "learning_rate": 9.941686364955077e-06,
      "loss": 0.0089,
      "step": 132
    },
    {
      "epoch": 0.2910284463894967,
      "grad_norm": 0.19427786767482758,
      "learning_rate": 9.938740279864056e-06,
      "loss": 0.0106,
      "step": 133
    },
    {
      "epoch": 0.29321663019693656,
      "grad_norm": 1.2453633546829224,
      "learning_rate": 9.935722055498655e-06,
      "loss": 0.0277,
      "step": 134
    },
    {
      "epoch": 0.29540481400437635,
      "grad_norm": 0.6607263088226318,
      "learning_rate": 9.932631735945527e-06,
      "loss": 0.0817,
      "step": 135
    },
    {
      "epoch": 0.2975929978118162,
      "grad_norm": 1.0865117311477661,
      "learning_rate": 9.929469366344401e-06,
      "loss": 0.1262,
      "step": 136
    },
    {
      "epoch": 0.29978118161925604,
      "grad_norm": 0.3555825352668762,
      "learning_rate": 9.92623499288743e-06,
      "loss": 0.0226,
      "step": 137
    },
    {
      "epoch": 0.30196936542669583,
      "grad_norm": 0.23188722133636475,
      "learning_rate": 9.922928662818515e-06,
      "loss": 0.0128,
      "step": 138
    },
    {
      "epoch": 0.3041575492341357,
      "grad_norm": 1.323904037475586,
      "learning_rate": 9.919550424432615e-06,
      "loss": 0.1633,
      "step": 139
    },
    {
      "epoch": 0.3063457330415755,
      "grad_norm": 1.1618543863296509,
      "learning_rate": 9.916100327075038e-06,
      "loss": 0.1081,
      "step": 140
    },
    {
      "epoch": 0.3085339168490153,
      "grad_norm": 1.970633625984192,
      "learning_rate": 9.912578421140723e-06,
      "loss": 0.1511,
      "step": 141
    },
    {
      "epoch": 0.31072210065645517,
      "grad_norm": 0.7538572549819946,
      "learning_rate": 9.908984758073506e-06,
      "loss": 0.0202,
      "step": 142
    },
    {
      "epoch": 0.31291028446389496,
      "grad_norm": 0.6266758441925049,
      "learning_rate": 9.905319390365364e-06,
      "loss": 0.1434,
      "step": 143
    },
    {
      "epoch": 0.3150984682713348,
      "grad_norm": 0.3137471079826355,
      "learning_rate": 9.901582371555652e-06,
      "loss": 0.0177,
      "step": 144
    },
    {
      "epoch": 0.3172866520787746,
      "grad_norm": 0.14536072313785553,
      "learning_rate": 9.89777375623032e-06,
      "loss": 0.0076,
      "step": 145
    },
    {
      "epoch": 0.31947483588621445,
      "grad_norm": 0.3245254158973694,
      "learning_rate": 9.893893600021112e-06,
      "loss": 0.018,
      "step": 146
    },
    {
      "epoch": 0.32166301969365424,
      "grad_norm": 1.08269202709198,
      "learning_rate": 9.889941959604761e-06,
      "loss": 0.17,
      "step": 147
    },
    {
      "epoch": 0.3238512035010941,
      "grad_norm": 0.09603867679834366,
      "learning_rate": 9.885918892702154e-06,
      "loss": 0.0037,
      "step": 148
    },
    {
      "epoch": 0.32603938730853393,
      "grad_norm": 0.8907763957977295,
      "learning_rate": 9.881824458077491e-06,
      "loss": 0.0617,
      "step": 149
    },
    {
      "epoch": 0.3282275711159737,
      "grad_norm": 0.5579090118408203,
      "learning_rate": 9.877658715537429e-06,
      "loss": 0.1021,
      "step": 150
    },
    {
      "epoch": 0.3304157549234136,
      "grad_norm": 0.23596210777759552,
      "learning_rate": 9.873421725930207e-06,
      "loss": 0.0131,
      "step": 151
    },
    {
      "epoch": 0.33260393873085337,
      "grad_norm": 0.3372742533683777,
      "learning_rate": 9.869113551144754e-06,
      "loss": 0.014,
      "step": 152
    },
    {
      "epoch": 0.3347921225382932,
      "grad_norm": 1.7033387422561646,
      "learning_rate": 9.864734254109793e-06,
      "loss": 0.1733,
      "step": 153
    },
    {
      "epoch": 0.33698030634573306,
      "grad_norm": 0.24345605075359344,
      "learning_rate": 9.860283898792908e-06,
      "loss": 0.0137,
      "step": 154
    },
    {
      "epoch": 0.33916849015317285,
      "grad_norm": 1.408700704574585,
      "learning_rate": 9.85576255019963e-06,
      "loss": 0.1079,
      "step": 155
    },
    {
      "epoch": 0.3413566739606127,
      "grad_norm": 0.6713988780975342,
      "learning_rate": 9.851170274372465e-06,
      "loss": 0.0726,
      "step": 156
    },
    {
      "epoch": 0.3435448577680525,
      "grad_norm": 0.6390308737754822,
      "learning_rate": 9.846507138389948e-06,
      "loss": 0.0296,
      "step": 157
    },
    {
      "epoch": 0.34573304157549234,
      "grad_norm": 0.1809254139661789,
      "learning_rate": 9.841773210365646e-06,
      "loss": 0.0028,
      "step": 158
    },
    {
      "epoch": 0.3479212253829322,
      "grad_norm": 0.10859216749668121,
      "learning_rate": 9.836968559447184e-06,
      "loss": 0.0029,
      "step": 159
    },
    {
      "epoch": 0.350109409190372,
      "grad_norm": 0.353933721780777,
      "learning_rate": 9.832093255815217e-06,
      "loss": 0.0089,
      "step": 160
    },
    {
      "epoch": 0.3522975929978118,
      "grad_norm": 0.48780518770217896,
      "learning_rate": 9.82714737068241e-06,
      "loss": 0.0154,
      "step": 161
    },
    {
      "epoch": 0.3544857768052516,
      "grad_norm": 0.1639184057712555,
      "learning_rate": 9.822130976292402e-06,
      "loss": 0.0075,
      "step": 162
    },
    {
      "epoch": 0.35667396061269147,
      "grad_norm": 0.5431364178657532,
      "learning_rate": 9.817044145918747e-06,
      "loss": 0.0196,
      "step": 163
    },
    {
      "epoch": 0.3588621444201313,
      "grad_norm": 3.208573818206787,
      "learning_rate": 9.811886953863841e-06,
      "loss": 0.1383,
      "step": 164
    },
    {
      "epoch": 0.3610503282275711,
      "grad_norm": 0.16005805134773254,
      "learning_rate": 9.806659475457849e-06,
      "loss": 0.0077,
      "step": 165
    },
    {
      "epoch": 0.36323851203501095,
      "grad_norm": 0.08056265860795975,
      "learning_rate": 9.801361787057586e-06,
      "loss": 0.0027,
      "step": 166
    },
    {
      "epoch": 0.36542669584245074,
      "grad_norm": 0.2320316731929779,
      "learning_rate": 9.795993966045418e-06,
      "loss": 0.0071,
      "step": 167
    },
    {
      "epoch": 0.3676148796498906,
      "grad_norm": 0.07097921520471573,
      "learning_rate": 9.790556090828121e-06,
      "loss": 0.0026,
      "step": 168
    },
    {
      "epoch": 0.36980306345733044,
      "grad_norm": 2.1266441345214844,
      "learning_rate": 9.785048240835745e-06,
      "loss": 0.1841,
      "step": 169
    },
    {
      "epoch": 0.37199124726477023,
      "grad_norm": 1.468055248260498,
      "learning_rate": 9.779470496520442e-06,
      "loss": 0.114,
      "step": 170
    },
    {
      "epoch": 0.3741794310722101,
      "grad_norm": 1.1619718074798584,
      "learning_rate": 9.773822939355305e-06,
      "loss": 0.0958,
      "step": 171
    },
    {
      "epoch": 0.37636761487964987,
      "grad_norm": 0.09561937302350998,
      "learning_rate": 9.768105651833162e-06,
      "loss": 0.0026,
      "step": 172
    },
    {
      "epoch": 0.3785557986870897,
      "grad_norm": 3.5317533016204834,
      "learning_rate": 9.76231871746539e-06,
      "loss": 0.1931,
      "step": 173
    },
    {
      "epoch": 0.38074398249452956,
      "grad_norm": 1.163897156715393,
      "learning_rate": 9.756462220780674e-06,
      "loss": 0.1268,
      "step": 174
    },
    {
      "epoch": 0.38293216630196936,
      "grad_norm": 1.2844792604446411,
      "learning_rate": 9.750536247323791e-06,
      "loss": 0.1151,
      "step": 175
    },
    {
      "epoch": 0.3851203501094092,
      "grad_norm": 1.2339881658554077,
      "learning_rate": 9.744540883654348e-06,
      "loss": 0.1132,
      "step": 176
    },
    {
      "epoch": 0.387308533916849,
      "grad_norm": 1.0875202417373657,
      "learning_rate": 9.738476217345525e-06,
      "loss": 0.1175,
      "step": 177
    },
    {
      "epoch": 0.38949671772428884,
      "grad_norm": 0.860252857208252,
      "learning_rate": 9.732342336982791e-06,
      "loss": 0.0461,
      "step": 178
    },
    {
      "epoch": 0.3916849015317287,
      "grad_norm": 0.43016377091407776,
      "learning_rate": 9.726139332162613e-06,
      "loss": 0.0229,
      "step": 179
    },
    {
      "epoch": 0.3938730853391685,
      "grad_norm": 0.2594497501850128,
      "learning_rate": 9.719867293491146e-06,
      "loss": 0.0141,
      "step": 180
    },
    {
      "epoch": 0.39606126914660833,
      "grad_norm": 2.277158260345459,
      "learning_rate": 9.713526312582909e-06,
      "loss": 0.0598,
      "step": 181
    },
    {
      "epoch": 0.3982494529540481,
      "grad_norm": 0.49194255471229553,
      "learning_rate": 9.707116482059447e-06,
      "loss": 0.0181,
      "step": 182
    },
    {
      "epoch": 0.40043763676148797,
      "grad_norm": 1.2519595623016357,
      "learning_rate": 9.70063789554798e-06,
      "loss": 0.1113,
      "step": 183
    },
    {
      "epoch": 0.4026258205689278,
      "grad_norm": 0.8711631298065186,
      "learning_rate": 9.694090647680038e-06,
      "loss": 0.0529,
      "step": 184
    },
    {
      "epoch": 0.4048140043763676,
      "grad_norm": 0.09224312752485275,
      "learning_rate": 9.68747483409007e-06,
      "loss": 0.0039,
      "step": 185
    },
    {
      "epoch": 0.40700218818380746,
      "grad_norm": 0.07364127784967422,
      "learning_rate": 9.680790551414047e-06,
      "loss": 0.002,
      "step": 186
    },
    {
      "epoch": 0.40919037199124725,
      "grad_norm": 2.5319180488586426,
      "learning_rate": 9.674037897288068e-06,
      "loss": 0.0393,
      "step": 187
    },
    {
      "epoch": 0.4113785557986871,
      "grad_norm": 1.2339311838150024,
      "learning_rate": 9.667216970346916e-06,
      "loss": 0.065,
      "step": 188
    },
    {
      "epoch": 0.4135667396061269,
      "grad_norm": 0.09381360560655594,
      "learning_rate": 9.660327870222614e-06,
      "loss": 0.0041,
      "step": 189
    },
    {
      "epoch": 0.41575492341356673,
      "grad_norm": 0.9039261937141418,
      "learning_rate": 9.653370697542988e-06,
      "loss": 0.0732,
      "step": 190
    },
    {
      "epoch": 0.4179431072210066,
      "grad_norm": 1.5790388584136963,
      "learning_rate": 9.646345553930187e-06,
      "loss": 0.0335,
      "step": 191
    },
    {
      "epoch": 0.4201312910284464,
      "grad_norm": 0.2785559296607971,
      "learning_rate": 9.639252541999196e-06,
      "loss": 0.0044,
      "step": 192
    },
    {
      "epoch": 0.4223194748358862,
      "grad_norm": 0.1337122768163681,
      "learning_rate": 9.632091765356338e-06,
      "loss": 0.0068,
      "step": 193
    },
    {
      "epoch": 0.424507658643326,
      "grad_norm": 1.0661392211914062,
      "learning_rate": 9.624863328597767e-06,
      "loss": 0.1229,
      "step": 194
    },
    {
      "epoch": 0.42669584245076586,
      "grad_norm": 0.33627286553382874,
      "learning_rate": 9.617567337307934e-06,
      "loss": 0.0188,
      "step": 195
    },
    {
      "epoch": 0.4288840262582057,
      "grad_norm": 1.0734790563583374,
      "learning_rate": 9.610203898058049e-06,
      "loss": 0.1366,
      "step": 196
    },
    {
      "epoch": 0.4310722100656455,
      "grad_norm": 0.15494021773338318,
      "learning_rate": 9.602773118404518e-06,
      "loss": 0.007,
      "step": 197
    },
    {
      "epoch": 0.43326039387308535,
      "grad_norm": 0.3554459512233734,
      "learning_rate": 9.595275106887378e-06,
      "loss": 0.0226,
      "step": 198
    },
    {
      "epoch": 0.43544857768052514,
      "grad_norm": 0.10074296593666077,
      "learning_rate": 9.58770997302871e-06,
      "loss": 0.0048,
      "step": 199
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 1.288825511932373,
      "learning_rate": 9.580077827331038e-06,
      "loss": 0.0633,
      "step": 200
    },
    {
      "epoch": 0.43982494529540483,
      "grad_norm": 1.2166872024536133,
      "learning_rate": 9.572378781275714e-06,
      "loss": 0.0963,
      "step": 201
    },
    {
      "epoch": 0.4420131291028446,
      "grad_norm": 1.064192771911621,
      "learning_rate": 9.564612947321297e-06,
      "loss": 0.0646,
      "step": 202
    },
    {
      "epoch": 0.4442013129102845,
      "grad_norm": 0.17834047973155975,
      "learning_rate": 9.556780438901899e-06,
      "loss": 0.005,
      "step": 203
    },
    {
      "epoch": 0.44638949671772427,
      "grad_norm": 0.10526902228593826,
      "learning_rate": 9.548881370425532e-06,
      "loss": 0.0022,
      "step": 204
    },
    {
      "epoch": 0.4485776805251641,
      "grad_norm": 0.26010721921920776,
      "learning_rate": 9.540915857272445e-06,
      "loss": 0.0144,
      "step": 205
    },
    {
      "epoch": 0.45076586433260396,
      "grad_norm": 0.3317566215991974,
      "learning_rate": 9.532884015793432e-06,
      "loss": 0.0166,
      "step": 206
    },
    {
      "epoch": 0.45295404814004375,
      "grad_norm": 0.9699148535728455,
      "learning_rate": 9.524785963308126e-06,
      "loss": 0.0876,
      "step": 207
    },
    {
      "epoch": 0.4551422319474836,
      "grad_norm": 0.6401866674423218,
      "learning_rate": 9.516621818103295e-06,
      "loss": 0.0181,
      "step": 208
    },
    {
      "epoch": 0.4573304157549234,
      "grad_norm": 0.8558279871940613,
      "learning_rate": 9.508391699431114e-06,
      "loss": 0.0243,
      "step": 209
    },
    {
      "epoch": 0.45951859956236324,
      "grad_norm": 0.5781229138374329,
      "learning_rate": 9.50009572750742e-06,
      "loss": 0.0251,
      "step": 210
    },
    {
      "epoch": 0.4617067833698031,
      "grad_norm": 1.2333378791809082,
      "learning_rate": 9.491734023509952e-06,
      "loss": 0.0936,
      "step": 211
    },
    {
      "epoch": 0.4638949671772429,
      "grad_norm": 1.9618113040924072,
      "learning_rate": 9.48330670957659e-06,
      "loss": 0.0424,
      "step": 212
    },
    {
      "epoch": 0.4660831509846827,
      "grad_norm": 0.09318448603153229,
      "learning_rate": 9.474813908803565e-06,
      "loss": 0.0032,
      "step": 213
    },
    {
      "epoch": 0.4682713347921225,
      "grad_norm": 0.5289178490638733,
      "learning_rate": 9.46625574524366e-06,
      "loss": 0.0213,
      "step": 214
    },
    {
      "epoch": 0.47045951859956237,
      "grad_norm": 2.1766743659973145,
      "learning_rate": 9.457632343904404e-06,
      "loss": 0.0424,
      "step": 215
    },
    {
      "epoch": 0.4726477024070022,
      "grad_norm": 1.7345855236053467,
      "learning_rate": 9.448943830746238e-06,
      "loss": 0.1169,
      "step": 216
    },
    {
      "epoch": 0.474835886214442,
      "grad_norm": 1.19883394241333,
      "learning_rate": 9.440190332680683e-06,
      "loss": 0.06,
      "step": 217
    },
    {
      "epoch": 0.47702407002188185,
      "grad_norm": 1.4258489608764648,
      "learning_rate": 9.431371977568483e-06,
      "loss": 0.0243,
      "step": 218
    },
    {
      "epoch": 0.47921225382932164,
      "grad_norm": 0.7490646243095398,
      "learning_rate": 9.422488894217733e-06,
      "loss": 0.0458,
      "step": 219
    },
    {
      "epoch": 0.4814004376367615,
      "grad_norm": 1.145012378692627,
      "learning_rate": 9.413541212382005e-06,
      "loss": 0.0174,
      "step": 220
    },
    {
      "epoch": 0.48358862144420134,
      "grad_norm": 0.05832920968532562,
      "learning_rate": 9.404529062758447e-06,
      "loss": 0.0023,
      "step": 221
    },
    {
      "epoch": 0.48577680525164113,
      "grad_norm": 0.31158000230789185,
      "learning_rate": 9.39545257698588e-06,
      "loss": 0.0082,
      "step": 222
    },
    {
      "epoch": 0.487964989059081,
      "grad_norm": 0.9186124205589294,
      "learning_rate": 9.386311887642867e-06,
      "loss": 0.0763,
      "step": 223
    },
    {
      "epoch": 0.49015317286652077,
      "grad_norm": 0.00419131712988019,
      "learning_rate": 9.377107128245782e-06,
      "loss": 0.0001,
      "step": 224
    },
    {
      "epoch": 0.4923413566739606,
      "grad_norm": 0.010593675076961517,
      "learning_rate": 9.367838433246859e-06,
      "loss": 0.0003,
      "step": 225
    },
    {
      "epoch": 0.49452954048140046,
      "grad_norm": 0.031142959371209145,
      "learning_rate": 9.358505938032227e-06,
      "loss": 0.0012,
      "step": 226
    },
    {
      "epoch": 0.49671772428884026,
      "grad_norm": 1.3976958990097046,
      "learning_rate": 9.349109778919938e-06,
      "loss": 0.2101,
      "step": 227
    },
    {
      "epoch": 0.4989059080962801,
      "grad_norm": 0.03454679250717163,
      "learning_rate": 9.339650093157959e-06,
      "loss": 0.0011,
      "step": 228
    },
    {
      "epoch": 0.5010940919037199,
      "grad_norm": 1.828132152557373,
      "learning_rate": 9.330127018922195e-06,
      "loss": 0.3252,
      "step": 229
    },
    {
      "epoch": 0.5032822757111597,
      "grad_norm": 0.2948853075504303,
      "learning_rate": 9.32054069531444e-06,
      "loss": 0.0078,
      "step": 230
    },
    {
      "epoch": 0.5054704595185996,
      "grad_norm": 0.029109308496117592,
      "learning_rate": 9.31089126236037e-06,
      "loss": 0.0012,
      "step": 231
    },
    {
      "epoch": 0.5076586433260394,
      "grad_norm": 0.9682180285453796,
      "learning_rate": 9.301178861007483e-06,
      "loss": 0.0246,
      "step": 232
    },
    {
      "epoch": 0.5098468271334792,
      "grad_norm": 2.560122489929199,
      "learning_rate": 9.291403633123046e-06,
      "loss": 0.2355,
      "step": 233
    },
    {
      "epoch": 0.5120350109409191,
      "grad_norm": 0.004058727528899908,
      "learning_rate": 9.281565721492023e-06,
      "loss": 0.0002,
      "step": 234
    },
    {
      "epoch": 0.5142231947483589,
      "grad_norm": 0.006520760711282492,
      "learning_rate": 9.271665269814984e-06,
      "loss": 0.0003,
      "step": 235
    },
    {
      "epoch": 0.5164113785557987,
      "grad_norm": 0.9194096326828003,
      "learning_rate": 9.261702422706014e-06,
      "loss": 0.1264,
      "step": 236
    },
    {
      "epoch": 0.5185995623632386,
      "grad_norm": 0.017028359696269035,
      "learning_rate": 9.251677325690596e-06,
      "loss": 0.0005,
      "step": 237
    },
    {
      "epoch": 0.5207877461706784,
      "grad_norm": 0.13760533928871155,
      "learning_rate": 9.241590125203486e-06,
      "loss": 0.0041,
      "step": 238
    },
    {
      "epoch": 0.5229759299781181,
      "grad_norm": 0.7649739384651184,
      "learning_rate": 9.231440968586572e-06,
      "loss": 0.0144,
      "step": 239
    },
    {
      "epoch": 0.5251641137855579,
      "grad_norm": 2.0086145401000977,
      "learning_rate": 9.221230004086723e-06,
      "loss": 0.0769,
      "step": 240
    },
    {
      "epoch": 0.5273522975929978,
      "grad_norm": 2.420017957687378,
      "learning_rate": 9.210957380853631e-06,
      "loss": 0.1572,
      "step": 241
    },
    {
      "epoch": 0.5295404814004376,
      "grad_norm": 0.02879962883889675,
      "learning_rate": 9.200623248937619e-06,
      "loss": 0.0011,
      "step": 242
    },
    {
      "epoch": 0.5317286652078774,
      "grad_norm": 0.06514724344015121,
      "learning_rate": 9.190227759287459e-06,
      "loss": 0.0024,
      "step": 243
    },
    {
      "epoch": 0.5339168490153173,
      "grad_norm": 2.93902850151062,
      "learning_rate": 9.17977106374816e-06,
      "loss": 0.0532,
      "step": 244
    },
    {
      "epoch": 0.5361050328227571,
      "grad_norm": 2.0761449337005615,
      "learning_rate": 9.169253315058764e-06,
      "loss": 0.0577,
      "step": 245
    },
    {
      "epoch": 0.5382932166301969,
      "grad_norm": 0.940010130405426,
      "learning_rate": 9.158674666850096e-06,
      "loss": 0.0475,
      "step": 246
    },
    {
      "epoch": 0.5404814004376368,
      "grad_norm": 4.074369430541992,
      "learning_rate": 9.148035273642532e-06,
      "loss": 0.3776,
      "step": 247
    },
    {
      "epoch": 0.5426695842450766,
      "grad_norm": 1.2472567558288574,
      "learning_rate": 9.13733529084374e-06,
      "loss": 0.0612,
      "step": 248
    },
    {
      "epoch": 0.5448577680525164,
      "grad_norm": 0.8316018581390381,
      "learning_rate": 9.126574874746407e-06,
      "loss": 0.1029,
      "step": 249
    },
    {
      "epoch": 0.5470459518599562,
      "grad_norm": 0.7851415872573853,
      "learning_rate": 9.115754182525962e-06,
      "loss": 0.0274,
      "step": 250
    },
    {
      "epoch": 0.5492341356673961,
      "grad_norm": 0.19272378087043762,
      "learning_rate": 9.104873372238269e-06,
      "loss": 0.0096,
      "step": 251
    },
    {
      "epoch": 0.5514223194748359,
      "grad_norm": 0.9598011374473572,
      "learning_rate": 9.093932602817335e-06,
      "loss": 0.1126,
      "step": 252
    },
    {
      "epoch": 0.5536105032822757,
      "grad_norm": 1.346907377243042,
      "learning_rate": 9.082932034072971e-06,
      "loss": 0.1069,
      "step": 253
    },
    {
      "epoch": 0.5557986870897156,
      "grad_norm": 0.6371232271194458,
      "learning_rate": 9.071871826688472e-06,
      "loss": 0.0426,
      "step": 254
    },
    {
      "epoch": 0.5579868708971554,
      "grad_norm": 0.11388547718524933,
      "learning_rate": 9.060752142218258e-06,
      "loss": 0.0059,
      "step": 255
    },
    {
      "epoch": 0.5601750547045952,
      "grad_norm": 2.0945894718170166,
      "learning_rate": 9.049573143085525e-06,
      "loss": 0.1283,
      "step": 256
    },
    {
      "epoch": 0.562363238512035,
      "grad_norm": 0.2612181603908539,
      "learning_rate": 9.038334992579863e-06,
      "loss": 0.0124,
      "step": 257
    },
    {
      "epoch": 0.5645514223194749,
      "grad_norm": 1.0106643438339233,
      "learning_rate": 9.02703785485488e-06,
      "loss": 0.0546,
      "step": 258
    },
    {
      "epoch": 0.5667396061269147,
      "grad_norm": 0.13043871521949768,
      "learning_rate": 9.015681894925795e-06,
      "loss": 0.0065,
      "step": 259
    },
    {
      "epoch": 0.5689277899343544,
      "grad_norm": 0.07114037126302719,
      "learning_rate": 9.004267278667032e-06,
      "loss": 0.0039,
      "step": 260
    },
    {
      "epoch": 0.5711159737417943,
      "grad_norm": 0.020852230489253998,
      "learning_rate": 8.992794172809805e-06,
      "loss": 0.0011,
      "step": 261
    },
    {
      "epoch": 0.5733041575492341,
      "grad_norm": 0.9453116655349731,
      "learning_rate": 8.981262744939662e-06,
      "loss": 0.0319,
      "step": 262
    },
    {
      "epoch": 0.5754923413566739,
      "grad_norm": 1.027701735496521,
      "learning_rate": 8.969673163494063e-06,
      "loss": 0.0277,
      "step": 263
    },
    {
      "epoch": 0.5776805251641138,
      "grad_norm": 0.3598249852657318,
      "learning_rate": 8.958025597759899e-06,
      "loss": 0.0198,
      "step": 264
    },
    {
      "epoch": 0.5798687089715536,
      "grad_norm": 1.162278175354004,
      "learning_rate": 8.946320217871027e-06,
      "loss": 0.0553,
      "step": 265
    },
    {
      "epoch": 0.5820568927789934,
      "grad_norm": 0.028101589530706406,
      "learning_rate": 8.934557194805787e-06,
      "loss": 0.0014,
      "step": 266
    },
    {
      "epoch": 0.5842450765864332,
      "grad_norm": 1.288244366645813,
      "learning_rate": 8.922736700384502e-06,
      "loss": 0.1108,
      "step": 267
    },
    {
      "epoch": 0.5864332603938731,
      "grad_norm": 0.22579151391983032,
      "learning_rate": 8.910858907266971e-06,
      "loss": 0.0122,
      "step": 268
    },
    {
      "epoch": 0.5886214442013129,
      "grad_norm": 0.11301720142364502,
      "learning_rate": 8.898923988949936e-06,
      "loss": 0.0047,
      "step": 269
    },
    {
      "epoch": 0.5908096280087527,
      "grad_norm": 1.2319167852401733,
      "learning_rate": 8.886932119764566e-06,
      "loss": 0.141,
      "step": 270
    },
    {
      "epoch": 0.5929978118161926,
      "grad_norm": 0.21767501533031464,
      "learning_rate": 8.874883474873896e-06,
      "loss": 0.0099,
      "step": 271
    },
    {
      "epoch": 0.5951859956236324,
      "grad_norm": 0.0744757354259491,
      "learning_rate": 8.862778230270276e-06,
      "loss": 0.0041,
      "step": 272
    },
    {
      "epoch": 0.5973741794310722,
      "grad_norm": 1.5500028133392334,
      "learning_rate": 8.850616562772793e-06,
      "loss": 0.0617,
      "step": 273
    },
    {
      "epoch": 0.5995623632385121,
      "grad_norm": 0.1198822483420372,
      "learning_rate": 8.838398650024698e-06,
      "loss": 0.0065,
      "step": 274
    },
    {
      "epoch": 0.6017505470459519,
      "grad_norm": 1.5486798286437988,
      "learning_rate": 8.826124670490804e-06,
      "loss": 0.1253,
      "step": 275
    },
    {
      "epoch": 0.6039387308533917,
      "grad_norm": 1.0104879140853882,
      "learning_rate": 8.813794803454878e-06,
      "loss": 0.1402,
      "step": 276
    },
    {
      "epoch": 0.6061269146608315,
      "grad_norm": 0.5707199573516846,
      "learning_rate": 8.801409229017033e-06,
      "loss": 0.0154,
      "step": 277
    },
    {
      "epoch": 0.6083150984682714,
      "grad_norm": 1.0895487070083618,
      "learning_rate": 8.788968128091084e-06,
      "loss": 0.0372,
      "step": 278
    },
    {
      "epoch": 0.6105032822757112,
      "grad_norm": 0.1390787661075592,
      "learning_rate": 8.776471682401913e-06,
      "loss": 0.0079,
      "step": 279
    },
    {
      "epoch": 0.612691466083151,
      "grad_norm": 0.2145838588476181,
      "learning_rate": 8.76392007448281e-06,
      "loss": 0.0074,
      "step": 280
    },
    {
      "epoch": 0.6148796498905909,
      "grad_norm": 0.019506720826029778,
      "learning_rate": 8.751313487672815e-06,
      "loss": 0.001,
      "step": 281
    },
    {
      "epoch": 0.6170678336980306,
      "grad_norm": 0.028038959950208664,
      "learning_rate": 8.73865210611403e-06,
      "loss": 0.0014,
      "step": 282
    },
    {
      "epoch": 0.6192560175054704,
      "grad_norm": 1.9147146940231323,
      "learning_rate": 8.725936114748936e-06,
      "loss": 0.1165,
      "step": 283
    },
    {
      "epoch": 0.6214442013129103,
      "grad_norm": 1.0854792594909668,
      "learning_rate": 8.71316569931769e-06,
      "loss": 0.0194,
      "step": 284
    },
    {
      "epoch": 0.6236323851203501,
      "grad_norm": 0.13671043515205383,
      "learning_rate": 8.700341046355412e-06,
      "loss": 0.0069,
      "step": 285
    },
    {
      "epoch": 0.6258205689277899,
      "grad_norm": 0.6969447731971741,
      "learning_rate": 8.687462343189453e-06,
      "loss": 0.015,
      "step": 286
    },
    {
      "epoch": 0.6280087527352297,
      "grad_norm": 0.03514693304896355,
      "learning_rate": 8.674529777936674e-06,
      "loss": 0.0018,
      "step": 287
    },
    {
      "epoch": 0.6301969365426696,
      "grad_norm": 0.03582927957177162,
      "learning_rate": 8.661543539500686e-06,
      "loss": 0.0019,
      "step": 288
    },
    {
      "epoch": 0.6323851203501094,
      "grad_norm": 1.2372585535049438,
      "learning_rate": 8.648503817569091e-06,
      "loss": 0.2112,
      "step": 289
    },
    {
      "epoch": 0.6345733041575492,
      "grad_norm": 1.5037264823913574,
      "learning_rate": 8.635410802610724e-06,
      "loss": 0.0806,
      "step": 290
    },
    {
      "epoch": 0.6367614879649891,
      "grad_norm": 0.9110689759254456,
      "learning_rate": 8.622264685872852e-06,
      "loss": 0.0231,
      "step": 291
    },
    {
      "epoch": 0.6389496717724289,
      "grad_norm": 1.0753402709960938,
      "learning_rate": 8.609065659378395e-06,
      "loss": 0.035,
      "step": 292
    },
    {
      "epoch": 0.6411378555798687,
      "grad_norm": 1.1467188596725464,
      "learning_rate": 8.595813915923113e-06,
      "loss": 0.1548,
      "step": 293
    },
    {
      "epoch": 0.6433260393873085,
      "grad_norm": 0.4238477349281311,
      "learning_rate": 8.582509649072793e-06,
      "loss": 0.0508,
      "step": 294
    },
    {
      "epoch": 0.6455142231947484,
      "grad_norm": 0.9996163845062256,
      "learning_rate": 8.569153053160429e-06,
      "loss": 0.0558,
      "step": 295
    },
    {
      "epoch": 0.6477024070021882,
      "grad_norm": 0.14075565338134766,
      "learning_rate": 8.555744323283364e-06,
      "loss": 0.005,
      "step": 296
    },
    {
      "epoch": 0.649890590809628,
      "grad_norm": 0.13494573533535004,
      "learning_rate": 8.542283655300463e-06,
      "loss": 0.0071,
      "step": 297
    },
    {
      "epoch": 0.6520787746170679,
      "grad_norm": 0.8124021887779236,
      "learning_rate": 8.528771245829234e-06,
      "loss": 0.0491,
      "step": 298
    },
    {
      "epoch": 0.6542669584245077,
      "grad_norm": 1.9401800632476807,
      "learning_rate": 8.515207292242969e-06,
      "loss": 0.1574,
      "step": 299
    },
    {
      "epoch": 0.6564551422319475,
      "grad_norm": 0.14024792611598969,
      "learning_rate": 8.50159199266785e-06,
      "loss": 0.0069,
      "step": 300
    },
    {
      "epoch": 0.6586433260393874,
      "grad_norm": 0.10672183334827423,
      "learning_rate": 8.487925545980066e-06,
      "loss": 0.0057,
      "step": 301
    },
    {
      "epoch": 0.6608315098468271,
      "grad_norm": 0.9897513389587402,
      "learning_rate": 8.474208151802898e-06,
      "loss": 0.047,
      "step": 302
    },
    {
      "epoch": 0.6630196936542669,
      "grad_norm": 0.6200073957443237,
      "learning_rate": 8.46044001050381e-06,
      "loss": 0.0297,
      "step": 303
    },
    {
      "epoch": 0.6652078774617067,
      "grad_norm": 0.024536404758691788,
      "learning_rate": 8.44662132319152e-06,
      "loss": 0.0012,
      "step": 304
    },
    {
      "epoch": 0.6673960612691466,
      "grad_norm": 0.14198735356330872,
      "learning_rate": 8.432752291713058e-06,
      "loss": 0.0062,
      "step": 305
    },
    {
      "epoch": 0.6695842450765864,
      "grad_norm": 0.07026015967130661,
      "learning_rate": 8.41883311865083e-06,
      "loss": 0.0034,
      "step": 306
    },
    {
      "epoch": 0.6717724288840262,
      "grad_norm": 1.0680263042449951,
      "learning_rate": 8.404864007319647e-06,
      "loss": 0.0307,
      "step": 307
    },
    {
      "epoch": 0.6739606126914661,
      "grad_norm": 1.4978212118148804,
      "learning_rate": 8.390845161763756e-06,
      "loss": 0.2641,
      "step": 308
    },
    {
      "epoch": 0.6761487964989059,
      "grad_norm": 1.0577466487884521,
      "learning_rate": 8.376776786753866e-06,
      "loss": 0.1819,
      "step": 309
    },
    {
      "epoch": 0.6783369803063457,
      "grad_norm": 0.3804509937763214,
      "learning_rate": 8.362659087784153e-06,
      "loss": 0.0091,
      "step": 310
    },
    {
      "epoch": 0.6805251641137856,
      "grad_norm": 0.7549909949302673,
      "learning_rate": 8.34849227106926e-06,
      "loss": 0.0708,
      "step": 311
    },
    {
      "epoch": 0.6827133479212254,
      "grad_norm": 0.32280242443084717,
      "learning_rate": 8.334276543541285e-06,
      "loss": 0.0128,
      "step": 312
    },
    {
      "epoch": 0.6849015317286652,
      "grad_norm": 2.1272921562194824,
      "learning_rate": 8.32001211284675e-06,
      "loss": 0.1297,
      "step": 313
    },
    {
      "epoch": 0.687089715536105,
      "grad_norm": 0.5462586283683777,
      "learning_rate": 8.305699187343586e-06,
      "loss": 0.0493,
      "step": 314
    },
    {
      "epoch": 0.6892778993435449,
      "grad_norm": 0.6436428427696228,
      "learning_rate": 8.291337976098069e-06,
      "loss": 0.0698,
      "step": 315
    },
    {
      "epoch": 0.6914660831509847,
      "grad_norm": 0.29550355672836304,
      "learning_rate": 8.276928688881783e-06,
      "loss": 0.0159,
      "step": 316
    },
    {
      "epoch": 0.6936542669584245,
      "grad_norm": 0.43613460659980774,
      "learning_rate": 8.262471536168547e-06,
      "loss": 0.0197,
      "step": 317
    },
    {
      "epoch": 0.6958424507658644,
      "grad_norm": 0.6355897188186646,
      "learning_rate": 8.24796672913134e-06,
      "loss": 0.0248,
      "step": 318
    },
    {
      "epoch": 0.6980306345733042,
      "grad_norm": 0.0752108171582222,
      "learning_rate": 8.233414479639221e-06,
      "loss": 0.0038,
      "step": 319
    },
    {
      "epoch": 0.700218818380744,
      "grad_norm": 0.6476627588272095,
      "learning_rate": 8.218815000254233e-06,
      "loss": 0.0533,
      "step": 320
    },
    {
      "epoch": 0.7024070021881839,
      "grad_norm": 1.1945717334747314,
      "learning_rate": 8.204168504228294e-06,
      "loss": 0.136,
      "step": 321
    },
    {
      "epoch": 0.7045951859956237,
      "grad_norm": 0.9046114087104797,
      "learning_rate": 8.189475205500091e-06,
      "loss": 0.1492,
      "step": 322
    },
    {
      "epoch": 0.7067833698030634,
      "grad_norm": 1.157285451889038,
      "learning_rate": 8.174735318691946e-06,
      "loss": 0.119,
      "step": 323
    },
    {
      "epoch": 0.7089715536105032,
      "grad_norm": 0.16111408174037933,
      "learning_rate": 8.159949059106683e-06,
      "loss": 0.0122,
      "step": 324
    },
    {
      "epoch": 0.7111597374179431,
      "grad_norm": 0.08390490710735321,
      "learning_rate": 8.145116642724487e-06,
      "loss": 0.0036,
      "step": 325
    },
    {
      "epoch": 0.7133479212253829,
      "grad_norm": 0.566569447517395,
      "learning_rate": 8.130238286199747e-06,
      "loss": 0.0225,
      "step": 326
    },
    {
      "epoch": 0.7155361050328227,
      "grad_norm": 0.2947120666503906,
      "learning_rate": 8.115314206857892e-06,
      "loss": 0.0141,
      "step": 327
    },
    {
      "epoch": 0.7177242888402626,
      "grad_norm": 0.08075882494449615,
      "learning_rate": 8.100344622692212e-06,
      "loss": 0.0035,
      "step": 328
    },
    {
      "epoch": 0.7199124726477024,
      "grad_norm": 0.25940456986427307,
      "learning_rate": 8.085329752360683e-06,
      "loss": 0.0172,
      "step": 329
    },
    {
      "epoch": 0.7221006564551422,
      "grad_norm": 0.040982283651828766,
      "learning_rate": 8.07026981518276e-06,
      "loss": 0.002,
      "step": 330
    },
    {
      "epoch": 0.7242888402625821,
      "grad_norm": 1.8780430555343628,
      "learning_rate": 8.055165031136192e-06,
      "loss": 0.0607,
      "step": 331
    },
    {
      "epoch": 0.7264770240700219,
      "grad_norm": 0.19531835615634918,
      "learning_rate": 8.04001562085379e-06,
      "loss": 0.0056,
      "step": 332
    },
    {
      "epoch": 0.7286652078774617,
      "grad_norm": 0.37448355555534363,
      "learning_rate": 8.024821805620211e-06,
      "loss": 0.0224,
      "step": 333
    },
    {
      "epoch": 0.7308533916849015,
      "grad_norm": 0.9661240577697754,
      "learning_rate": 8.009583807368734e-06,
      "loss": 0.0497,
      "step": 334
    },
    {
      "epoch": 0.7330415754923414,
      "grad_norm": 0.29396697878837585,
      "learning_rate": 7.994301848678006e-06,
      "loss": 0.0108,
      "step": 335
    },
    {
      "epoch": 0.7352297592997812,
      "grad_norm": 0.802142322063446,
      "learning_rate": 7.9789761527688e-06,
      "loss": 0.0475,
      "step": 336
    },
    {
      "epoch": 0.737417943107221,
      "grad_norm": 0.012710807844996452,
      "learning_rate": 7.963606943500743e-06,
      "loss": 0.0006,
      "step": 337
    },
    {
      "epoch": 0.7396061269146609,
      "grad_norm": 0.9818058013916016,
      "learning_rate": 7.948194445369065e-06,
      "loss": 0.1001,
      "step": 338
    },
    {
      "epoch": 0.7417943107221007,
      "grad_norm": 0.7887936234474182,
      "learning_rate": 7.932738883501297e-06,
      "loss": 0.1189,
      "step": 339
    },
    {
      "epoch": 0.7439824945295405,
      "grad_norm": 0.32194259762763977,
      "learning_rate": 7.917240483654002e-06,
      "loss": 0.0163,
      "step": 340
    },
    {
      "epoch": 0.7461706783369803,
      "grad_norm": 0.020926276221871376,
      "learning_rate": 7.901699472209467e-06,
      "loss": 0.001,
      "step": 341
    },
    {
      "epoch": 0.7483588621444202,
      "grad_norm": 0.008344520814716816,
      "learning_rate": 7.886116076172398e-06,
      "loss": 0.0005,
      "step": 342
    },
    {
      "epoch": 0.75054704595186,
      "grad_norm": 0.05014216527342796,
      "learning_rate": 7.870490523166606e-06,
      "loss": 0.002,
      "step": 343
    },
    {
      "epoch": 0.7527352297592997,
      "grad_norm": 1.2644366025924683,
      "learning_rate": 7.85482304143168e-06,
      "loss": 0.1516,
      "step": 344
    },
    {
      "epoch": 0.7549234135667396,
      "grad_norm": 0.8187833428382874,
      "learning_rate": 7.839113859819656e-06,
      "loss": 0.0955,
      "step": 345
    },
    {
      "epoch": 0.7571115973741794,
      "grad_norm": 0.15154631435871124,
      "learning_rate": 7.823363207791672e-06,
      "loss": 0.0062,
      "step": 346
    },
    {
      "epoch": 0.7592997811816192,
      "grad_norm": 0.06436019390821457,
      "learning_rate": 7.807571315414616e-06,
      "loss": 0.0036,
      "step": 347
    },
    {
      "epoch": 0.7614879649890591,
      "grad_norm": 0.10148206353187561,
      "learning_rate": 7.791738413357766e-06,
      "loss": 0.0055,
      "step": 348
    },
    {
      "epoch": 0.7636761487964989,
      "grad_norm": 0.12627200782299042,
      "learning_rate": 7.77586473288942e-06,
      "loss": 0.0061,
      "step": 349
    },
    {
      "epoch": 0.7658643326039387,
      "grad_norm": 0.1854252815246582,
      "learning_rate": 7.759950505873523e-06,
      "loss": 0.0097,
      "step": 350
    },
    {
      "epoch": 0.7680525164113785,
      "grad_norm": 0.06402240693569183,
      "learning_rate": 7.743995964766272e-06,
      "loss": 0.0031,
      "step": 351
    },
    {
      "epoch": 0.7702407002188184,
      "grad_norm": 0.09641123563051224,
      "learning_rate": 7.728001342612724e-06,
      "loss": 0.0045,
      "step": 352
    },
    {
      "epoch": 0.7724288840262582,
      "grad_norm": 0.11409725248813629,
      "learning_rate": 7.711966873043396e-06,
      "loss": 0.0044,
      "step": 353
    },
    {
      "epoch": 0.774617067833698,
      "grad_norm": 0.1201825812458992,
      "learning_rate": 7.695892790270849e-06,
      "loss": 0.0063,
      "step": 354
    },
    {
      "epoch": 0.7768052516411379,
      "grad_norm": 0.7409016489982605,
      "learning_rate": 7.67977932908626e-06,
      "loss": 0.0488,
      "step": 355
    },
    {
      "epoch": 0.7789934354485777,
      "grad_norm": 0.03380429744720459,
      "learning_rate": 7.66362672485601e-06,
      "loss": 0.0014,
      "step": 356
    },
    {
      "epoch": 0.7811816192560175,
      "grad_norm": 1.4608606100082397,
      "learning_rate": 7.647435213518225e-06,
      "loss": 0.033,
      "step": 357
    },
    {
      "epoch": 0.7833698030634574,
      "grad_norm": 0.04000420868396759,
      "learning_rate": 7.631205031579344e-06,
      "loss": 0.0021,
      "step": 358
    },
    {
      "epoch": 0.7855579868708972,
      "grad_norm": 0.8002092242240906,
      "learning_rate": 7.614936416110668e-06,
      "loss": 0.0429,
      "step": 359
    },
    {
      "epoch": 0.787746170678337,
      "grad_norm": 0.3164515197277069,
      "learning_rate": 7.598629604744874e-06,
      "loss": 0.0102,
      "step": 360
    },
    {
      "epoch": 0.7899343544857768,
      "grad_norm": 0.7687844038009644,
      "learning_rate": 7.582284835672571e-06,
      "loss": 0.0415,
      "step": 361
    },
    {
      "epoch": 0.7921225382932167,
      "grad_norm": 1.3168476819992065,
      "learning_rate": 7.565902347638806e-06,
      "loss": 0.1378,
      "step": 362
    },
    {
      "epoch": 0.7943107221006565,
      "grad_norm": 1.8663101196289062,
      "learning_rate": 7.54948237993958e-06,
      "loss": 0.1989,
      "step": 363
    },
    {
      "epoch": 0.7964989059080962,
      "grad_norm": 1.4458974599838257,
      "learning_rate": 7.533025172418354e-06,
      "loss": 0.081,
      "step": 364
    },
    {
      "epoch": 0.7986870897155361,
      "grad_norm": 0.5505244135856628,
      "learning_rate": 7.5165309654625405e-06,
      "loss": 0.0797,
      "step": 365
    },
    {
      "epoch": 0.8008752735229759,
      "grad_norm": 0.3456757962703705,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0195,
      "step": 366
    },
    {
      "epoch": 0.8030634573304157,
      "grad_norm": 3.3879971504211426,
      "learning_rate": 7.483432517495517e-06,
      "loss": 0.095,
      "step": 367
    },
    {
      "epoch": 0.8052516411378556,
      "grad_norm": 1.559531569480896,
      "learning_rate": 7.466828759947271e-06,
      "loss": 0.1316,
      "step": 368
    },
    {
      "epoch": 0.8074398249452954,
      "grad_norm": 0.3079027533531189,
      "learning_rate": 7.4501889698833075e-06,
      "loss": 0.0126,
      "step": 369
    },
    {
      "epoch": 0.8096280087527352,
      "grad_norm": 0.6226935386657715,
      "learning_rate": 7.4335133903579906e-06,
      "loss": 0.0147,
      "step": 370
    },
    {
      "epoch": 0.811816192560175,
      "grad_norm": 0.8870019912719727,
      "learning_rate": 7.416802264948455e-06,
      "loss": 0.0845,
      "step": 371
    },
    {
      "epoch": 0.8140043763676149,
      "grad_norm": 0.10124438256025314,
      "learning_rate": 7.4000558377510475e-06,
      "loss": 0.004,
      "step": 372
    },
    {
      "epoch": 0.8161925601750547,
      "grad_norm": 0.8693515658378601,
      "learning_rate": 7.383274353377763e-06,
      "loss": 0.1084,
      "step": 373
    },
    {
      "epoch": 0.8183807439824945,
      "grad_norm": 0.10191979259252548,
      "learning_rate": 7.366458056952668e-06,
      "loss": 0.0053,
      "step": 374
    },
    {
      "epoch": 0.8205689277899344,
      "grad_norm": 0.38809481263160706,
      "learning_rate": 7.349607194108323e-06,
      "loss": 0.0718,
      "step": 375
    },
    {
      "epoch": 0.8227571115973742,
      "grad_norm": 0.88350510597229,
      "learning_rate": 7.332722010982196e-06,
      "loss": 0.0551,
      "step": 376
    },
    {
      "epoch": 0.824945295404814,
      "grad_norm": 0.029542172327637672,
      "learning_rate": 7.315802754213062e-06,
      "loss": 0.0016,
      "step": 377
    },
    {
      "epoch": 0.8271334792122538,
      "grad_norm": 1.2076451778411865,
      "learning_rate": 7.298849670937403e-06,
      "loss": 0.0566,
      "step": 378
    },
    {
      "epoch": 0.8293216630196937,
      "grad_norm": 1.3621599674224854,
      "learning_rate": 7.281863008785804e-06,
      "loss": 0.0719,
      "step": 379
    },
    {
      "epoch": 0.8315098468271335,
      "grad_norm": 1.1126539707183838,
      "learning_rate": 7.264843015879321e-06,
      "loss": 0.0612,
      "step": 380
    },
    {
      "epoch": 0.8336980306345733,
      "grad_norm": 0.18467804789543152,
      "learning_rate": 7.247789940825879e-06,
      "loss": 0.0089,
      "step": 381
    },
    {
      "epoch": 0.8358862144420132,
      "grad_norm": 2.1479151248931885,
      "learning_rate": 7.230704032716615e-06,
      "loss": 0.1087,
      "step": 382
    },
    {
      "epoch": 0.838074398249453,
      "grad_norm": 0.7182452082633972,
      "learning_rate": 7.213585541122261e-06,
      "loss": 0.0228,
      "step": 383
    },
    {
      "epoch": 0.8402625820568927,
      "grad_norm": 0.8182430267333984,
      "learning_rate": 7.196434716089487e-06,
      "loss": 0.0609,
      "step": 384
    },
    {
      "epoch": 0.8424507658643327,
      "grad_norm": 0.526904284954071,
      "learning_rate": 7.179251808137251e-06,
      "loss": 0.0462,
      "step": 385
    },
    {
      "epoch": 0.8446389496717724,
      "grad_norm": 0.015587856061756611,
      "learning_rate": 7.162037068253141e-06,
      "loss": 0.0008,
      "step": 386
    },
    {
      "epoch": 0.8468271334792122,
      "grad_norm": 0.07957712560892105,
      "learning_rate": 7.144790747889709e-06,
      "loss": 0.003,
      "step": 387
    },
    {
      "epoch": 0.849015317286652,
      "grad_norm": 0.8318254351615906,
      "learning_rate": 7.127513098960798e-06,
      "loss": 0.0275,
      "step": 388
    },
    {
      "epoch": 0.8512035010940919,
      "grad_norm": 1.2338038682937622,
      "learning_rate": 7.110204373837857e-06,
      "loss": 0.0271,
      "step": 389
    },
    {
      "epoch": 0.8533916849015317,
      "grad_norm": 0.030947206541895866,
      "learning_rate": 7.092864825346266e-06,
      "loss": 0.0015,
      "step": 390
    },
    {
      "epoch": 0.8555798687089715,
      "grad_norm": 1.2888344526290894,
      "learning_rate": 7.0754947067616295e-06,
      "loss": 0.1546,
      "step": 391
    },
    {
      "epoch": 0.8577680525164114,
      "grad_norm": 0.04152311384677887,
      "learning_rate": 7.058094271806091e-06,
      "loss": 0.0021,
      "step": 392
    },
    {
      "epoch": 0.8599562363238512,
      "grad_norm": 0.3723498284816742,
      "learning_rate": 7.040663774644613e-06,
      "loss": 0.0103,
      "step": 393
    },
    {
      "epoch": 0.862144420131291,
      "grad_norm": 1.201735258102417,
      "learning_rate": 7.023203469881272e-06,
      "loss": 0.0526,
      "step": 394
    },
    {
      "epoch": 0.8643326039387309,
      "grad_norm": 1.5413269996643066,
      "learning_rate": 7.0057136125555456e-06,
      "loss": 0.0487,
      "step": 395
    },
    {
      "epoch": 0.8665207877461707,
      "grad_norm": 0.5987399816513062,
      "learning_rate": 6.988194458138571e-06,
      "loss": 0.0762,
      "step": 396
    },
    {
      "epoch": 0.8687089715536105,
      "grad_norm": 0.07985575497150421,
      "learning_rate": 6.970646262529429e-06,
      "loss": 0.0035,
      "step": 397
    },
    {
      "epoch": 0.8708971553610503,
      "grad_norm": 0.06889932602643967,
      "learning_rate": 6.953069282051397e-06,
      "loss": 0.0032,
      "step": 398
    },
    {
      "epoch": 0.8730853391684902,
      "grad_norm": 0.20964494347572327,
      "learning_rate": 6.935463773448209e-06,
      "loss": 0.0092,
      "step": 399
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 0.35817739367485046,
      "learning_rate": 6.917829993880303e-06,
      "loss": 0.0114,
      "step": 400
    },
    {
      "epoch": 0.8774617067833698,
      "grad_norm": 0.8175051212310791,
      "learning_rate": 6.900168200921065e-06,
      "loss": 0.0482,
      "step": 401
    },
    {
      "epoch": 0.8796498905908097,
      "grad_norm": 0.11672089993953705,
      "learning_rate": 6.882478652553071e-06,
      "loss": 0.005,
      "step": 402
    },
    {
      "epoch": 0.8818380743982495,
      "grad_norm": 1.2245155572891235,
      "learning_rate": 6.86476160716431e-06,
      "loss": 0.0272,
      "step": 403
    },
    {
      "epoch": 0.8840262582056893,
      "grad_norm": 0.3168404996395111,
      "learning_rate": 6.84701732354442e-06,
      "loss": 0.014,
      "step": 404
    },
    {
      "epoch": 0.8862144420131292,
      "grad_norm": 2.0572447776794434,
      "learning_rate": 6.829246060880901e-06,
      "loss": 0.1512,
      "step": 405
    },
    {
      "epoch": 0.888402625820569,
      "grad_norm": 0.3258683383464813,
      "learning_rate": 6.81144807875533e-06,
      "loss": 0.0232,
      "step": 406
    },
    {
      "epoch": 0.8905908096280087,
      "grad_norm": 0.09117390215396881,
      "learning_rate": 6.79362363713957e-06,
      "loss": 0.0048,
      "step": 407
    },
    {
      "epoch": 0.8927789934354485,
      "grad_norm": 1.9741424322128296,
      "learning_rate": 6.775772996391974e-06,
      "loss": 0.1183,
      "step": 408
    },
    {
      "epoch": 0.8949671772428884,
      "grad_norm": 1.2525601387023926,
      "learning_rate": 6.757896417253583e-06,
      "loss": 0.0885,
      "step": 409
    },
    {
      "epoch": 0.8971553610503282,
      "grad_norm": 6.890747547149658,
      "learning_rate": 6.7399941608443096e-06,
      "loss": 0.1326,
      "step": 410
    },
    {
      "epoch": 0.899343544857768,
      "grad_norm": 1.3648271560668945,
      "learning_rate": 6.722066488659136e-06,
      "loss": 0.0787,
      "step": 411
    },
    {
      "epoch": 0.9015317286652079,
      "grad_norm": 1.0042791366577148,
      "learning_rate": 6.7041136625642846e-06,
      "loss": 0.0348,
      "step": 412
    },
    {
      "epoch": 0.9037199124726477,
      "grad_norm": 0.1421915739774704,
      "learning_rate": 6.686135944793395e-06,
      "loss": 0.0042,
      "step": 413
    },
    {
      "epoch": 0.9059080962800875,
      "grad_norm": 1.6911065578460693,
      "learning_rate": 6.668133597943699e-06,
      "loss": 0.1625,
      "step": 414
    },
    {
      "epoch": 0.9080962800875274,
      "grad_norm": 0.15455475449562073,
      "learning_rate": 6.650106884972176e-06,
      "loss": 0.0067,
      "step": 415
    },
    {
      "epoch": 0.9102844638949672,
      "grad_norm": 0.023024767637252808,
      "learning_rate": 6.632056069191723e-06,
      "loss": 0.001,
      "step": 416
    },
    {
      "epoch": 0.912472647702407,
      "grad_norm": 0.10904466360807419,
      "learning_rate": 6.613981414267294e-06,
      "loss": 0.0047,
      "step": 417
    },
    {
      "epoch": 0.9146608315098468,
      "grad_norm": 0.8190321326255798,
      "learning_rate": 6.595883184212067e-06,
      "loss": 0.102,
      "step": 418
    },
    {
      "epoch": 0.9168490153172867,
      "grad_norm": 0.11427313089370728,
      "learning_rate": 6.57776164338357e-06,
      "loss": 0.0058,
      "step": 419
    },
    {
      "epoch": 0.9190371991247265,
      "grad_norm": 0.37133875489234924,
      "learning_rate": 6.559617056479828e-06,
      "loss": 0.0112,
      "step": 420
    },
    {
      "epoch": 0.9212253829321663,
      "grad_norm": 1.2474514245986938,
      "learning_rate": 6.5414496885355006e-06,
      "loss": 0.0717,
      "step": 421
    },
    {
      "epoch": 0.9234135667396062,
      "grad_norm": 0.6900101900100708,
      "learning_rate": 6.523259804918001e-06,
      "loss": 0.0217,
      "step": 422
    },
    {
      "epoch": 0.925601750547046,
      "grad_norm": 1.682441234588623,
      "learning_rate": 6.505047671323625e-06,
      "loss": 0.051,
      "step": 423
    },
    {
      "epoch": 0.9277899343544858,
      "grad_norm": 0.6159668564796448,
      "learning_rate": 6.486813553773673e-06,
      "loss": 0.035,
      "step": 424
    },
    {
      "epoch": 0.9299781181619255,
      "grad_norm": 0.7444408535957336,
      "learning_rate": 6.4685577186105595e-06,
      "loss": 0.0459,
      "step": 425
    },
    {
      "epoch": 0.9321663019693655,
      "grad_norm": 0.1586015373468399,
      "learning_rate": 6.450280432493925e-06,
      "loss": 0.0076,
      "step": 426
    },
    {
      "epoch": 0.9343544857768052,
      "grad_norm": 0.004871482495218515,
      "learning_rate": 6.431981962396734e-06,
      "loss": 0.0003,
      "step": 427
    },
    {
      "epoch": 0.936542669584245,
      "grad_norm": 0.1906866878271103,
      "learning_rate": 6.413662575601391e-06,
      "loss": 0.0063,
      "step": 428
    },
    {
      "epoch": 0.9387308533916849,
      "grad_norm": 1.163019061088562,
      "learning_rate": 6.395322539695821e-06,
      "loss": 0.077,
      "step": 429
    },
    {
      "epoch": 0.9409190371991247,
      "grad_norm": 1.1039557456970215,
      "learning_rate": 6.3769621225695675e-06,
      "loss": 0.1017,
      "step": 430
    },
    {
      "epoch": 0.9431072210065645,
      "grad_norm": 0.32126927375793457,
      "learning_rate": 6.358581592409881e-06,
      "loss": 0.0115,
      "step": 431
    },
    {
      "epoch": 0.9452954048140044,
      "grad_norm": 1.6674760580062866,
      "learning_rate": 6.340181217697797e-06,
      "loss": 0.1128,
      "step": 432
    },
    {
      "epoch": 0.9474835886214442,
      "grad_norm": 0.021152038127183914,
      "learning_rate": 6.3217612672042175e-06,
      "loss": 0.0008,
      "step": 433
    },
    {
      "epoch": 0.949671772428884,
      "grad_norm": 0.16989880800247192,
      "learning_rate": 6.303322009985984e-06,
      "loss": 0.0048,
      "step": 434
    },
    {
      "epoch": 0.9518599562363238,
      "grad_norm": 1.8037865161895752,
      "learning_rate": 6.2848637153819495e-06,
      "loss": 0.1038,
      "step": 435
    },
    {
      "epoch": 0.9540481400437637,
      "grad_norm": 1.5411584377288818,
      "learning_rate": 6.2663866530090374e-06,
      "loss": 0.0689,
      "step": 436
    },
    {
      "epoch": 0.9562363238512035,
      "grad_norm": 0.933207631111145,
      "learning_rate": 6.247891092758319e-06,
      "loss": 0.0475,
      "step": 437
    },
    {
      "epoch": 0.9584245076586433,
      "grad_norm": 1.4413621425628662,
      "learning_rate": 6.229377304791049e-06,
      "loss": 0.1751,
      "step": 438
    },
    {
      "epoch": 0.9606126914660832,
      "grad_norm": 0.5506259799003601,
      "learning_rate": 6.2108455595347375e-06,
      "loss": 0.0578,
      "step": 439
    },
    {
      "epoch": 0.962800875273523,
      "grad_norm": 1.3057429790496826,
      "learning_rate": 6.1922961276791925e-06,
      "loss": 0.1422,
      "step": 440
    },
    {
      "epoch": 0.9649890590809628,
      "grad_norm": 0.21492163836956024,
      "learning_rate": 6.173729280172565e-06,
      "loss": 0.0106,
      "step": 441
    },
    {
      "epoch": 0.9671772428884027,
      "grad_norm": 0.1733931601047516,
      "learning_rate": 6.1551452882173975e-06,
      "loss": 0.008,
      "step": 442
    },
    {
      "epoch": 0.9693654266958425,
      "grad_norm": 0.3639136552810669,
      "learning_rate": 6.136544423266651e-06,
      "loss": 0.006,
      "step": 443
    },
    {
      "epoch": 0.9715536105032823,
      "grad_norm": 0.5210350751876831,
      "learning_rate": 6.117926957019758e-06,
      "loss": 0.0327,
      "step": 444
    },
    {
      "epoch": 0.973741794310722,
      "grad_norm": 0.22870194911956787,
      "learning_rate": 6.09929316141863e-06,
      "loss": 0.0097,
      "step": 445
    },
    {
      "epoch": 0.975929978118162,
      "grad_norm": 0.08032616227865219,
      "learning_rate": 6.08064330864371e-06,
      "loss": 0.003,
      "step": 446
    },
    {
      "epoch": 0.9781181619256017,
      "grad_norm": 0.5016306638717651,
      "learning_rate": 6.0619776711099785e-06,
      "loss": 0.0825,
      "step": 447
    },
    {
      "epoch": 0.9803063457330415,
      "grad_norm": 1.0331315994262695,
      "learning_rate": 6.043296521462982e-06,
      "loss": 0.0777,
      "step": 448
    },
    {
      "epoch": 0.9824945295404814,
      "grad_norm": 0.4221677780151367,
      "learning_rate": 6.024600132574855e-06,
      "loss": 0.0158,
      "step": 449
    },
    {
      "epoch": 0.9846827133479212,
      "grad_norm": 0.08498886972665787,
      "learning_rate": 6.0058887775403196e-06,
      "loss": 0.0036,
      "step": 450
    },
    {
      "epoch": 0.986870897155361,
      "grad_norm": 1.7985659837722778,
      "learning_rate": 5.987162729672712e-06,
      "loss": 0.0885,
      "step": 451
    },
    {
      "epoch": 0.9890590809628009,
      "grad_norm": 1.0317997932434082,
      "learning_rate": 5.968422262499983e-06,
      "loss": 0.038,
      "step": 452
    },
    {
      "epoch": 0.9912472647702407,
      "grad_norm": 0.007754984311759472,
      "learning_rate": 5.949667649760702e-06,
      "loss": 0.0003,
      "step": 453
    },
    {
      "epoch": 0.9934354485776805,
      "grad_norm": 0.06187564507126808,
      "learning_rate": 5.930899165400063e-06,
      "loss": 0.0025,
      "step": 454
    },
    {
      "epoch": 0.9956236323851203,
      "grad_norm": 0.1540619134902954,
      "learning_rate": 5.912117083565874e-06,
      "loss": 0.008,
      "step": 455
    },
    {
      "epoch": 0.9978118161925602,
      "grad_norm": 0.21946822106838226,
      "learning_rate": 5.893321678604568e-06,
      "loss": 0.0099,
      "step": 456
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.48518040776252747,
      "learning_rate": 5.874513225057179e-06,
      "loss": 0.0292,
      "step": 457
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.14705882352941177,
      "eval_loss": 0.027475552633404732,
      "eval_runtime": 1068.4028,
      "eval_samples_per_second": 0.191,
      "eval_steps_per_second": 0.191,
      "step": 457
    }
  ],
  "logging_steps": 1,
  "max_steps": 914,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.817470351103304e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
