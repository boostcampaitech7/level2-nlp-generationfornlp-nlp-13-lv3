{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 457,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002188183807439825,
      "grad_norm": 21.693819046020508,
      "learning_rate": 9.999881857639567e-06,
      "loss": 4.23,
      "step": 1
    },
    {
      "epoch": 0.00437636761487965,
      "grad_norm": 30.745235443115234,
      "learning_rate": 9.999527436141312e-06,
      "loss": 3.1972,
      "step": 2
    },
    {
      "epoch": 0.006564551422319475,
      "grad_norm": 18.426443099975586,
      "learning_rate": 9.998936752254111e-06,
      "loss": 1.8796,
      "step": 3
    },
    {
      "epoch": 0.0087527352297593,
      "grad_norm": 17.94615936279297,
      "learning_rate": 9.998109833891883e-06,
      "loss": 1.4874,
      "step": 4
    },
    {
      "epoch": 0.010940919037199124,
      "grad_norm": 11.072229385375977,
      "learning_rate": 9.997046720132262e-06,
      "loss": 0.893,
      "step": 5
    },
    {
      "epoch": 0.01312910284463895,
      "grad_norm": 12.247950553894043,
      "learning_rate": 9.995747461214752e-06,
      "loss": 0.6749,
      "step": 6
    },
    {
      "epoch": 0.015317286652078774,
      "grad_norm": 1.9416444301605225,
      "learning_rate": 9.994212118538364e-06,
      "loss": 0.0752,
      "step": 7
    },
    {
      "epoch": 0.0175054704595186,
      "grad_norm": 1.6910789012908936,
      "learning_rate": 9.992440764658697e-06,
      "loss": 0.0382,
      "step": 8
    },
    {
      "epoch": 0.019693654266958426,
      "grad_norm": 0.13603654503822327,
      "learning_rate": 9.990433483284527e-06,
      "loss": 0.0031,
      "step": 9
    },
    {
      "epoch": 0.02188183807439825,
      "grad_norm": 2.1646060943603516,
      "learning_rate": 9.988190369273834e-06,
      "loss": 0.3102,
      "step": 10
    },
    {
      "epoch": 0.024070021881838075,
      "grad_norm": 4.723790645599365,
      "learning_rate": 9.985711528629332e-06,
      "loss": 0.2189,
      "step": 11
    },
    {
      "epoch": 0.0262582056892779,
      "grad_norm": 0.07904914021492004,
      "learning_rate": 9.982997078493457e-06,
      "loss": 0.0021,
      "step": 12
    },
    {
      "epoch": 0.028446389496717725,
      "grad_norm": 3.2896554470062256,
      "learning_rate": 9.980047147142824e-06,
      "loss": 0.0317,
      "step": 13
    },
    {
      "epoch": 0.030634573304157548,
      "grad_norm": 4.350715160369873,
      "learning_rate": 9.976861873982177e-06,
      "loss": 0.1344,
      "step": 14
    },
    {
      "epoch": 0.03282275711159737,
      "grad_norm": 0.02053164131939411,
      "learning_rate": 9.973441409537795e-06,
      "loss": 0.0005,
      "step": 15
    },
    {
      "epoch": 0.0350109409190372,
      "grad_norm": 0.039261069148778915,
      "learning_rate": 9.969785915450368e-06,
      "loss": 0.0011,
      "step": 16
    },
    {
      "epoch": 0.037199124726477024,
      "grad_norm": 4.273735523223877,
      "learning_rate": 9.965895564467381e-06,
      "loss": 0.5232,
      "step": 17
    },
    {
      "epoch": 0.03938730853391685,
      "grad_norm": 5.6763410568237305,
      "learning_rate": 9.961770540434931e-06,
      "loss": 0.0824,
      "step": 18
    },
    {
      "epoch": 0.04157549234135667,
      "grad_norm": 0.05296498164534569,
      "learning_rate": 9.95741103828905e-06,
      "loss": 0.0011,
      "step": 19
    },
    {
      "epoch": 0.0437636761487965,
      "grad_norm": 2.278010606765747,
      "learning_rate": 9.952817264046486e-06,
      "loss": 0.1159,
      "step": 20
    },
    {
      "epoch": 0.045951859956236324,
      "grad_norm": 0.24612818658351898,
      "learning_rate": 9.947989434794973e-06,
      "loss": 0.0033,
      "step": 21
    },
    {
      "epoch": 0.04814004376367615,
      "grad_norm": 0.05432749167084694,
      "learning_rate": 9.942927778682968e-06,
      "loss": 0.0016,
      "step": 22
    },
    {
      "epoch": 0.05032822757111598,
      "grad_norm": 3.1551389694213867,
      "learning_rate": 9.937632534908872e-06,
      "loss": 0.334,
      "step": 23
    },
    {
      "epoch": 0.0525164113785558,
      "grad_norm": 3.9203572273254395,
      "learning_rate": 9.932103953709724e-06,
      "loss": 0.2722,
      "step": 24
    },
    {
      "epoch": 0.05470459518599562,
      "grad_norm": 0.07866737991571426,
      "learning_rate": 9.926342296349378e-06,
      "loss": 0.0029,
      "step": 25
    },
    {
      "epoch": 0.05689277899343545,
      "grad_norm": 0.06832297891378403,
      "learning_rate": 9.920347835106152e-06,
      "loss": 0.0023,
      "step": 26
    },
    {
      "epoch": 0.05908096280087528,
      "grad_norm": 0.08773283660411835,
      "learning_rate": 9.914120853259968e-06,
      "loss": 0.0023,
      "step": 27
    },
    {
      "epoch": 0.061269146608315096,
      "grad_norm": 0.17509578168392181,
      "learning_rate": 9.90766164507896e-06,
      "loss": 0.0048,
      "step": 28
    },
    {
      "epoch": 0.06345733041575492,
      "grad_norm": 1.6481633186340332,
      "learning_rate": 9.900970515805564e-06,
      "loss": 0.1354,
      "step": 29
    },
    {
      "epoch": 0.06564551422319474,
      "grad_norm": 0.3454577326774597,
      "learning_rate": 9.89404778164211e-06,
      "loss": 0.0088,
      "step": 30
    },
    {
      "epoch": 0.06783369803063458,
      "grad_norm": 1.8212140798568726,
      "learning_rate": 9.886893769735852e-06,
      "loss": 0.1802,
      "step": 31
    },
    {
      "epoch": 0.0700218818380744,
      "grad_norm": 1.6224843263626099,
      "learning_rate": 9.879508818163536e-06,
      "loss": 0.1498,
      "step": 32
    },
    {
      "epoch": 0.07221006564551423,
      "grad_norm": 0.7306630611419678,
      "learning_rate": 9.871893275915408e-06,
      "loss": 0.022,
      "step": 33
    },
    {
      "epoch": 0.07439824945295405,
      "grad_norm": 0.8881978988647461,
      "learning_rate": 9.864047502878717e-06,
      "loss": 0.0508,
      "step": 34
    },
    {
      "epoch": 0.07658643326039387,
      "grad_norm": 1.3903475999832153,
      "learning_rate": 9.855971869820726e-06,
      "loss": 0.1873,
      "step": 35
    },
    {
      "epoch": 0.0787746170678337,
      "grad_norm": 2.6582493782043457,
      "learning_rate": 9.847666758371175e-06,
      "loss": 0.2202,
      "step": 36
    },
    {
      "epoch": 0.08096280087527352,
      "grad_norm": 0.5509325861930847,
      "learning_rate": 9.83913256100425e-06,
      "loss": 0.0673,
      "step": 37
    },
    {
      "epoch": 0.08315098468271334,
      "grad_norm": 0.5887856483459473,
      "learning_rate": 9.830369681020043e-06,
      "loss": 0.0239,
      "step": 38
    },
    {
      "epoch": 0.08533916849015317,
      "grad_norm": 1.3366611003875732,
      "learning_rate": 9.821378532525479e-06,
      "loss": 0.0482,
      "step": 39
    },
    {
      "epoch": 0.087527352297593,
      "grad_norm": 1.3743606805801392,
      "learning_rate": 9.812159540414766e-06,
      "loss": 0.0905,
      "step": 40
    },
    {
      "epoch": 0.08971553610503283,
      "grad_norm": 1.2476050853729248,
      "learning_rate": 9.802713140349294e-06,
      "loss": 0.0333,
      "step": 41
    },
    {
      "epoch": 0.09190371991247265,
      "grad_norm": 0.33715730905532837,
      "learning_rate": 9.79303977873707e-06,
      "loss": 0.0114,
      "step": 42
    },
    {
      "epoch": 0.09409190371991247,
      "grad_norm": 0.8090652227401733,
      "learning_rate": 9.783139912711597e-06,
      "loss": 0.052,
      "step": 43
    },
    {
      "epoch": 0.0962800875273523,
      "grad_norm": 1.944566011428833,
      "learning_rate": 9.773014010110298e-06,
      "loss": 0.1136,
      "step": 44
    },
    {
      "epoch": 0.09846827133479212,
      "grad_norm": 0.03333115205168724,
      "learning_rate": 9.76266254945238e-06,
      "loss": 0.0008,
      "step": 45
    },
    {
      "epoch": 0.10065645514223195,
      "grad_norm": 1.1109334230422974,
      "learning_rate": 9.752086019916246e-06,
      "loss": 0.0773,
      "step": 46
    },
    {
      "epoch": 0.10284463894967177,
      "grad_norm": 3.8398754596710205,
      "learning_rate": 9.74128492131636e-06,
      "loss": 0.0444,
      "step": 47
    },
    {
      "epoch": 0.1050328227571116,
      "grad_norm": 0.3181980550289154,
      "learning_rate": 9.730259764079636e-06,
      "loss": 0.0092,
      "step": 48
    },
    {
      "epoch": 0.10722100656455143,
      "grad_norm": 0.05790109932422638,
      "learning_rate": 9.719011069221316e-06,
      "loss": 0.0016,
      "step": 49
    },
    {
      "epoch": 0.10940919037199125,
      "grad_norm": 1.1177542209625244,
      "learning_rate": 9.70753936832034e-06,
      "loss": 0.0992,
      "step": 50
    },
    {
      "epoch": 0.11159737417943107,
      "grad_norm": 0.009031534194946289,
      "learning_rate": 9.695845203494242e-06,
      "loss": 0.0004,
      "step": 51
    },
    {
      "epoch": 0.1137855579868709,
      "grad_norm": 0.10835855454206467,
      "learning_rate": 9.683929127373514e-06,
      "loss": 0.0015,
      "step": 52
    },
    {
      "epoch": 0.11597374179431072,
      "grad_norm": 3.3282341957092285,
      "learning_rate": 9.671791703075502e-06,
      "loss": 0.0301,
      "step": 53
    },
    {
      "epoch": 0.11816192560175055,
      "grad_norm": 2.2217905521392822,
      "learning_rate": 9.659433504177786e-06,
      "loss": 0.1828,
      "step": 54
    },
    {
      "epoch": 0.12035010940919037,
      "grad_norm": 1.276170253753662,
      "learning_rate": 9.646855114691081e-06,
      "loss": 0.0682,
      "step": 55
    },
    {
      "epoch": 0.12253829321663019,
      "grad_norm": 2.950737237930298,
      "learning_rate": 9.63405712903164e-06,
      "loss": 0.153,
      "step": 56
    },
    {
      "epoch": 0.12472647702407003,
      "grad_norm": 1.3589904308319092,
      "learning_rate": 9.621040151993153e-06,
      "loss": 0.0308,
      "step": 57
    },
    {
      "epoch": 0.12691466083150985,
      "grad_norm": 4.297350883483887,
      "learning_rate": 9.607804798718182e-06,
      "loss": 0.3571,
      "step": 58
    },
    {
      "epoch": 0.12910284463894967,
      "grad_norm": 2.643850803375244,
      "learning_rate": 9.59435169466907e-06,
      "loss": 0.1935,
      "step": 59
    },
    {
      "epoch": 0.13129102844638948,
      "grad_norm": 2.1607935428619385,
      "learning_rate": 9.580681475598413e-06,
      "loss": 0.1921,
      "step": 60
    },
    {
      "epoch": 0.13347921225382933,
      "grad_norm": 2.6639506816864014,
      "learning_rate": 9.566794787518986e-06,
      "loss": 0.1118,
      "step": 61
    },
    {
      "epoch": 0.13566739606126915,
      "grad_norm": 0.009255927987396717,
      "learning_rate": 9.552692286673231e-06,
      "loss": 0.0004,
      "step": 62
    },
    {
      "epoch": 0.13785557986870897,
      "grad_norm": 1.3893415927886963,
      "learning_rate": 9.538374639502247e-06,
      "loss": 0.2249,
      "step": 63
    },
    {
      "epoch": 0.1400437636761488,
      "grad_norm": 5.322909355163574,
      "learning_rate": 9.523842522614285e-06,
      "loss": 0.0703,
      "step": 64
    },
    {
      "epoch": 0.1422319474835886,
      "grad_norm": 0.8377759456634521,
      "learning_rate": 9.509096622752781e-06,
      "loss": 0.0408,
      "step": 65
    },
    {
      "epoch": 0.14442013129102846,
      "grad_norm": 2.0446269512176514,
      "learning_rate": 9.4941376367639e-06,
      "loss": 0.2901,
      "step": 66
    },
    {
      "epoch": 0.14660831509846828,
      "grad_norm": 1.4815703630447388,
      "learning_rate": 9.478966271563614e-06,
      "loss": 0.0454,
      "step": 67
    },
    {
      "epoch": 0.1487964989059081,
      "grad_norm": 0.16734860837459564,
      "learning_rate": 9.463583244104274e-06,
      "loss": 0.0085,
      "step": 68
    },
    {
      "epoch": 0.15098468271334792,
      "grad_norm": 0.16894939541816711,
      "learning_rate": 9.447989281340753e-06,
      "loss": 0.0081,
      "step": 69
    },
    {
      "epoch": 0.15317286652078774,
      "grad_norm": 0.10100539028644562,
      "learning_rate": 9.43218512019608e-06,
      "loss": 0.0049,
      "step": 70
    },
    {
      "epoch": 0.15536105032822758,
      "grad_norm": 1.1265023946762085,
      "learning_rate": 9.416171507526615e-06,
      "loss": 0.0602,
      "step": 71
    },
    {
      "epoch": 0.1575492341356674,
      "grad_norm": 1.30184006690979,
      "learning_rate": 9.399949200086757e-06,
      "loss": 0.1081,
      "step": 72
    },
    {
      "epoch": 0.15973741794310722,
      "grad_norm": 0.15092524886131287,
      "learning_rate": 9.383518964493183e-06,
      "loss": 0.0074,
      "step": 73
    },
    {
      "epoch": 0.16192560175054704,
      "grad_norm": 0.4574563503265381,
      "learning_rate": 9.36688157718862e-06,
      "loss": 0.0244,
      "step": 74
    },
    {
      "epoch": 0.16411378555798686,
      "grad_norm": 0.13550738990306854,
      "learning_rate": 9.350037824405151e-06,
      "loss": 0.0073,
      "step": 75
    },
    {
      "epoch": 0.16630196936542668,
      "grad_norm": 0.49631011486053467,
      "learning_rate": 9.332988502127063e-06,
      "loss": 0.0327,
      "step": 76
    },
    {
      "epoch": 0.16849015317286653,
      "grad_norm": 0.2540188729763031,
      "learning_rate": 9.315734416053223e-06,
      "loss": 0.0121,
      "step": 77
    },
    {
      "epoch": 0.17067833698030635,
      "grad_norm": 0.24731966853141785,
      "learning_rate": 9.298276381559015e-06,
      "loss": 0.0144,
      "step": 78
    },
    {
      "epoch": 0.17286652078774617,
      "grad_norm": 0.1939709335565567,
      "learning_rate": 9.280615223657801e-06,
      "loss": 0.0096,
      "step": 79
    },
    {
      "epoch": 0.175054704595186,
      "grad_norm": 0.7376169562339783,
      "learning_rate": 9.262751776961936e-06,
      "loss": 0.0591,
      "step": 80
    },
    {
      "epoch": 0.1772428884026258,
      "grad_norm": 0.07107039541006088,
      "learning_rate": 9.24468688564332e-06,
      "loss": 0.0036,
      "step": 81
    },
    {
      "epoch": 0.17943107221006566,
      "grad_norm": 0.7379336357116699,
      "learning_rate": 9.226421403393513e-06,
      "loss": 0.0172,
      "step": 82
    },
    {
      "epoch": 0.18161925601750548,
      "grad_norm": 0.20716774463653564,
      "learning_rate": 9.207956193383392e-06,
      "loss": 0.0106,
      "step": 83
    },
    {
      "epoch": 0.1838074398249453,
      "grad_norm": 1.2815359830856323,
      "learning_rate": 9.189292128222355e-06,
      "loss": 0.1552,
      "step": 84
    },
    {
      "epoch": 0.18599562363238512,
      "grad_norm": 1.7607992887496948,
      "learning_rate": 9.170430089917089e-06,
      "loss": 0.1344,
      "step": 85
    },
    {
      "epoch": 0.18818380743982493,
      "grad_norm": 2.6728498935699463,
      "learning_rate": 9.151370969829883e-06,
      "loss": 0.1228,
      "step": 86
    },
    {
      "epoch": 0.19037199124726478,
      "grad_norm": 1.5076944828033447,
      "learning_rate": 9.132115668636512e-06,
      "loss": 0.0534,
      "step": 87
    },
    {
      "epoch": 0.1925601750547046,
      "grad_norm": 0.13277330994606018,
      "learning_rate": 9.112665096283668e-06,
      "loss": 0.0066,
      "step": 88
    },
    {
      "epoch": 0.19474835886214442,
      "grad_norm": 0.580326497554779,
      "learning_rate": 9.093020171945966e-06,
      "loss": 0.0861,
      "step": 89
    },
    {
      "epoch": 0.19693654266958424,
      "grad_norm": 1.1636477708816528,
      "learning_rate": 9.073181823982495e-06,
      "loss": 0.0532,
      "step": 90
    },
    {
      "epoch": 0.19912472647702406,
      "grad_norm": 0.049506254494190216,
      "learning_rate": 9.05315098989296e-06,
      "loss": 0.002,
      "step": 91
    },
    {
      "epoch": 0.2013129102844639,
      "grad_norm": 1.8892238140106201,
      "learning_rate": 9.032928616273369e-06,
      "loss": 0.137,
      "step": 92
    },
    {
      "epoch": 0.20350109409190373,
      "grad_norm": 2.246816396713257,
      "learning_rate": 9.012515658771301e-06,
      "loss": 0.0943,
      "step": 93
    },
    {
      "epoch": 0.20568927789934355,
      "grad_norm": 0.07783576846122742,
      "learning_rate": 8.991913082040752e-06,
      "loss": 0.0039,
      "step": 94
    },
    {
      "epoch": 0.20787746170678337,
      "grad_norm": 0.4490543007850647,
      "learning_rate": 8.971121859696539e-06,
      "loss": 0.0152,
      "step": 95
    },
    {
      "epoch": 0.2100656455142232,
      "grad_norm": 0.1256019026041031,
      "learning_rate": 8.950142974268295e-06,
      "loss": 0.0068,
      "step": 96
    },
    {
      "epoch": 0.212253829321663,
      "grad_norm": 0.06342838704586029,
      "learning_rate": 8.928977417154037e-06,
      "loss": 0.0029,
      "step": 97
    },
    {
      "epoch": 0.21444201312910285,
      "grad_norm": 1.4201726913452148,
      "learning_rate": 8.907626188573319e-06,
      "loss": 0.092,
      "step": 98
    },
    {
      "epoch": 0.21663019693654267,
      "grad_norm": 1.3794480562210083,
      "learning_rate": 8.886090297519956e-06,
      "loss": 0.119,
      "step": 99
    },
    {
      "epoch": 0.2188183807439825,
      "grad_norm": 0.43214258551597595,
      "learning_rate": 8.864370761714348e-06,
      "loss": 0.0088,
      "step": 100
    },
    {
      "epoch": 0.2210065645514223,
      "grad_norm": 4.859084129333496,
      "learning_rate": 8.842468607555389e-06,
      "loss": 0.1171,
      "step": 101
    },
    {
      "epoch": 0.22319474835886213,
      "grad_norm": 1.0864267349243164,
      "learning_rate": 8.820384870071951e-06,
      "loss": 0.073,
      "step": 102
    },
    {
      "epoch": 0.22538293216630198,
      "grad_norm": 2.916283130645752,
      "learning_rate": 8.79812059287399e-06,
      "loss": 0.0477,
      "step": 103
    },
    {
      "epoch": 0.2275711159737418,
      "grad_norm": 0.46885788440704346,
      "learning_rate": 8.775676828103205e-06,
      "loss": 0.0235,
      "step": 104
    },
    {
      "epoch": 0.22975929978118162,
      "grad_norm": 0.6064348220825195,
      "learning_rate": 8.753054636383336e-06,
      "loss": 0.0246,
      "step": 105
    },
    {
      "epoch": 0.23194748358862144,
      "grad_norm": 3.526150941848755,
      "learning_rate": 8.730255086770037e-06,
      "loss": 0.1845,
      "step": 106
    },
    {
      "epoch": 0.23413566739606126,
      "grad_norm": 0.34258097410202026,
      "learning_rate": 8.707279256700348e-06,
      "loss": 0.0139,
      "step": 107
    },
    {
      "epoch": 0.2363238512035011,
      "grad_norm": 0.11680421233177185,
      "learning_rate": 8.684128231941789e-06,
      "loss": 0.0065,
      "step": 108
    },
    {
      "epoch": 0.23851203501094093,
      "grad_norm": 0.9051072001457214,
      "learning_rate": 8.660803106541044e-06,
      "loss": 0.0191,
      "step": 109
    },
    {
      "epoch": 0.24070021881838075,
      "grad_norm": 1.4388622045516968,
      "learning_rate": 8.637304982772263e-06,
      "loss": 0.0274,
      "step": 110
    },
    {
      "epoch": 0.24288840262582057,
      "grad_norm": 0.01735556498169899,
      "learning_rate": 8.613634971084967e-06,
      "loss": 0.0009,
      "step": 111
    },
    {
      "epoch": 0.24507658643326038,
      "grad_norm": 2.8659145832061768,
      "learning_rate": 8.589794190051582e-06,
      "loss": 0.0914,
      "step": 112
    },
    {
      "epoch": 0.24726477024070023,
      "grad_norm": 2.775895357131958,
      "learning_rate": 8.56578376631456e-06,
      "loss": 0.0783,
      "step": 113
    },
    {
      "epoch": 0.24945295404814005,
      "grad_norm": 0.21499711275100708,
      "learning_rate": 8.541604834533159e-06,
      "loss": 0.0058,
      "step": 114
    },
    {
      "epoch": 0.25164113785557984,
      "grad_norm": 0.10828080028295517,
      "learning_rate": 8.51725853732981e-06,
      "loss": 0.0041,
      "step": 115
    },
    {
      "epoch": 0.2538293216630197,
      "grad_norm": 0.04919016361236572,
      "learning_rate": 8.492746025236113e-06,
      "loss": 0.0017,
      "step": 116
    },
    {
      "epoch": 0.25601750547045954,
      "grad_norm": 1.3147042989730835,
      "learning_rate": 8.468068456638491e-06,
      "loss": 0.1808,
      "step": 117
    },
    {
      "epoch": 0.25820568927789933,
      "grad_norm": 1.406943440437317,
      "learning_rate": 8.443226997723426e-06,
      "loss": 0.071,
      "step": 118
    },
    {
      "epoch": 0.2603938730853392,
      "grad_norm": 1.477866291999817,
      "learning_rate": 8.418222822422348e-06,
      "loss": 0.086,
      "step": 119
    },
    {
      "epoch": 0.26258205689277897,
      "grad_norm": 0.6603275537490845,
      "learning_rate": 8.393057112356181e-06,
      "loss": 0.0158,
      "step": 120
    },
    {
      "epoch": 0.2647702407002188,
      "grad_norm": 1.1603745222091675,
      "learning_rate": 8.367731056779476e-06,
      "loss": 0.2085,
      "step": 121
    },
    {
      "epoch": 0.26695842450765866,
      "grad_norm": 0.05894363299012184,
      "learning_rate": 8.342245852524229e-06,
      "loss": 0.0032,
      "step": 122
    },
    {
      "epoch": 0.26914660831509846,
      "grad_norm": 0.27439531683921814,
      "learning_rate": 8.316602703943315e-06,
      "loss": 0.0125,
      "step": 123
    },
    {
      "epoch": 0.2713347921225383,
      "grad_norm": 1.8112233877182007,
      "learning_rate": 8.290802822853576e-06,
      "loss": 0.1092,
      "step": 124
    },
    {
      "epoch": 0.2735229759299781,
      "grad_norm": 0.027622006833553314,
      "learning_rate": 8.26484742847855e-06,
      "loss": 0.0013,
      "step": 125
    },
    {
      "epoch": 0.27571115973741794,
      "grad_norm": 1.8014037609100342,
      "learning_rate": 8.238737747390859e-06,
      "loss": 0.1718,
      "step": 126
    },
    {
      "epoch": 0.2778993435448578,
      "grad_norm": 3.1541523933410645,
      "learning_rate": 8.212475013454249e-06,
      "loss": 0.0717,
      "step": 127
    },
    {
      "epoch": 0.2800875273522976,
      "grad_norm": 1.0960850715637207,
      "learning_rate": 8.186060467765268e-06,
      "loss": 0.0954,
      "step": 128
    },
    {
      "epoch": 0.28227571115973743,
      "grad_norm": 0.21787621080875397,
      "learning_rate": 8.159495358594627e-06,
      "loss": 0.0091,
      "step": 129
    },
    {
      "epoch": 0.2844638949671772,
      "grad_norm": 0.5464204549789429,
      "learning_rate": 8.13278094132821e-06,
      "loss": 0.0285,
      "step": 130
    },
    {
      "epoch": 0.28665207877461707,
      "grad_norm": 0.9032495617866516,
      "learning_rate": 8.10591847840774e-06,
      "loss": 0.0828,
      "step": 131
    },
    {
      "epoch": 0.2888402625820569,
      "grad_norm": 0.08506917953491211,
      "learning_rate": 8.078909239271127e-06,
      "loss": 0.0049,
      "step": 132
    },
    {
      "epoch": 0.2910284463894967,
      "grad_norm": 0.11536233127117157,
      "learning_rate": 8.051754500292479e-06,
      "loss": 0.0072,
      "step": 133
    },
    {
      "epoch": 0.29321663019693656,
      "grad_norm": 0.9819198846817017,
      "learning_rate": 8.024455544721778e-06,
      "loss": 0.0334,
      "step": 134
    },
    {
      "epoch": 0.29540481400437635,
      "grad_norm": 0.8913558721542358,
      "learning_rate": 7.997013662624246e-06,
      "loss": 0.0933,
      "step": 135
    },
    {
      "epoch": 0.2975929978118162,
      "grad_norm": 1.2133674621582031,
      "learning_rate": 7.969430150819372e-06,
      "loss": 0.1524,
      "step": 136
    },
    {
      "epoch": 0.29978118161925604,
      "grad_norm": 0.16390360891819,
      "learning_rate": 7.941706312819632e-06,
      "loss": 0.0119,
      "step": 137
    },
    {
      "epoch": 0.30196936542669583,
      "grad_norm": 0.15632551908493042,
      "learning_rate": 7.913843458768892e-06,
      "loss": 0.0112,
      "step": 138
    },
    {
      "epoch": 0.3041575492341357,
      "grad_norm": 1.0863312482833862,
      "learning_rate": 7.88584290538049e-06,
      "loss": 0.1735,
      "step": 139
    },
    {
      "epoch": 0.3063457330415755,
      "grad_norm": 0.6228667497634888,
      "learning_rate": 7.857705975875015e-06,
      "loss": 0.0913,
      "step": 140
    },
    {
      "epoch": 0.3085339168490153,
      "grad_norm": 1.3794505596160889,
      "learning_rate": 7.829433999917773e-06,
      "loss": 0.1354,
      "step": 141
    },
    {
      "epoch": 0.31072210065645517,
      "grad_norm": 0.8446667790412903,
      "learning_rate": 7.801028313555954e-06,
      "loss": 0.0219,
      "step": 142
    },
    {
      "epoch": 0.31291028446389496,
      "grad_norm": 0.6322844624519348,
      "learning_rate": 7.772490259155493e-06,
      "loss": 0.135,
      "step": 143
    },
    {
      "epoch": 0.3150984682713348,
      "grad_norm": 0.25178244709968567,
      "learning_rate": 7.743821185337634e-06,
      "loss": 0.0167,
      "step": 144
    },
    {
      "epoch": 0.3172866520787746,
      "grad_norm": 0.14827439188957214,
      "learning_rate": 7.715022446915195e-06,
      "loss": 0.0091,
      "step": 145
    },
    {
      "epoch": 0.31947483588621445,
      "grad_norm": 0.25524652004241943,
      "learning_rate": 7.686095404828552e-06,
      "loss": 0.0171,
      "step": 146
    },
    {
      "epoch": 0.32166301969365424,
      "grad_norm": 0.9178484082221985,
      "learning_rate": 7.65704142608132e-06,
      "loss": 0.169,
      "step": 147
    },
    {
      "epoch": 0.3238512035010941,
      "grad_norm": 0.11120043694972992,
      "learning_rate": 7.627861883675748e-06,
      "loss": 0.0058,
      "step": 148
    },
    {
      "epoch": 0.32603938730853393,
      "grad_norm": 0.6585461497306824,
      "learning_rate": 7.598558156547842e-06,
      "loss": 0.0429,
      "step": 149
    },
    {
      "epoch": 0.3282275711159737,
      "grad_norm": 0.5084070563316345,
      "learning_rate": 7.569131629502201e-06,
      "loss": 0.0987,
      "step": 150
    },
    {
      "epoch": 0.3304157549234136,
      "grad_norm": 0.17489348351955414,
      "learning_rate": 7.53958369314657e-06,
      "loss": 0.0125,
      "step": 151
    },
    {
      "epoch": 0.33260393873085337,
      "grad_norm": 0.27731984853744507,
      "learning_rate": 7.509915743826128e-06,
      "loss": 0.0146,
      "step": 152
    },
    {
      "epoch": 0.3347921225382932,
      "grad_norm": 1.0554250478744507,
      "learning_rate": 7.480129183557499e-06,
      "loss": 0.1545,
      "step": 153
    },
    {
      "epoch": 0.33698030634573306,
      "grad_norm": 0.15322357416152954,
      "learning_rate": 7.450225419962498e-06,
      "loss": 0.0097,
      "step": 154
    },
    {
      "epoch": 0.33916849015317285,
      "grad_norm": 0.8667902946472168,
      "learning_rate": 7.4202058662016155e-06,
      "loss": 0.0896,
      "step": 155
    },
    {
      "epoch": 0.3413566739606127,
      "grad_norm": 0.5364158749580383,
      "learning_rate": 7.390071940907222e-06,
      "loss": 0.0689,
      "step": 156
    },
    {
      "epoch": 0.3435448577680525,
      "grad_norm": 0.4730071723461151,
      "learning_rate": 7.3598250681165485e-06,
      "loss": 0.0263,
      "step": 157
    },
    {
      "epoch": 0.34573304157549234,
      "grad_norm": 0.22382156550884247,
      "learning_rate": 7.329466677204371e-06,
      "loss": 0.0066,
      "step": 158
    },
    {
      "epoch": 0.3479212253829322,
      "grad_norm": 0.08549030125141144,
      "learning_rate": 7.298998202815474e-06,
      "loss": 0.0045,
      "step": 159
    },
    {
      "epoch": 0.350109409190372,
      "grad_norm": 0.36939147114753723,
      "learning_rate": 7.268421084796852e-06,
      "loss": 0.019,
      "step": 160
    },
    {
      "epoch": 0.3522975929978118,
      "grad_norm": 0.5489363670349121,
      "learning_rate": 7.237736768129663e-06,
      "loss": 0.0229,
      "step": 161
    },
    {
      "epoch": 0.3544857768052516,
      "grad_norm": 0.11684847623109818,
      "learning_rate": 7.206946702860948e-06,
      "loss": 0.007,
      "step": 162
    },
    {
      "epoch": 0.35667396061269147,
      "grad_norm": 0.6022321581840515,
      "learning_rate": 7.176052344035101e-06,
      "loss": 0.0329,
      "step": 163
    },
    {
      "epoch": 0.3588621444201313,
      "grad_norm": 1.6616214513778687,
      "learning_rate": 7.145055151625113e-06,
      "loss": 0.0921,
      "step": 164
    },
    {
      "epoch": 0.3610503282275711,
      "grad_norm": 0.2474159598350525,
      "learning_rate": 7.1139565904635755e-06,
      "loss": 0.0139,
      "step": 165
    },
    {
      "epoch": 0.36323851203501095,
      "grad_norm": 0.09189622849225998,
      "learning_rate": 7.082758130173456e-06,
      "loss": 0.0052,
      "step": 166
    },
    {
      "epoch": 0.36542669584245074,
      "grad_norm": 0.1593523919582367,
      "learning_rate": 7.051461245098654e-06,
      "loss": 0.0096,
      "step": 167
    },
    {
      "epoch": 0.3676148796498906,
      "grad_norm": 0.1269555240869522,
      "learning_rate": 7.020067414234315e-06,
      "loss": 0.0059,
      "step": 168
    },
    {
      "epoch": 0.36980306345733044,
      "grad_norm": 1.439542531967163,
      "learning_rate": 6.988578121156956e-06,
      "loss": 0.1593,
      "step": 169
    },
    {
      "epoch": 0.37199124726477023,
      "grad_norm": 0.8714684844017029,
      "learning_rate": 6.956994853954342e-06,
      "loss": 0.1259,
      "step": 170
    },
    {
      "epoch": 0.3741794310722101,
      "grad_norm": 0.7349157333374023,
      "learning_rate": 6.925319105155165e-06,
      "loss": 0.0933,
      "step": 171
    },
    {
      "epoch": 0.37636761487964987,
      "grad_norm": 0.1393168866634369,
      "learning_rate": 6.8935523716585195e-06,
      "loss": 0.0053,
      "step": 172
    },
    {
      "epoch": 0.3785557986870897,
      "grad_norm": 1.8437480926513672,
      "learning_rate": 6.8616961546631575e-06,
      "loss": 0.1718,
      "step": 173
    },
    {
      "epoch": 0.38074398249452956,
      "grad_norm": 0.8539078235626221,
      "learning_rate": 6.829751959596544e-06,
      "loss": 0.0963,
      "step": 174
    },
    {
      "epoch": 0.38293216630196936,
      "grad_norm": 0.9641526937484741,
      "learning_rate": 6.797721296043727e-06,
      "loss": 0.1024,
      "step": 175
    },
    {
      "epoch": 0.3851203501094092,
      "grad_norm": 0.9292231798171997,
      "learning_rate": 6.765605677675982e-06,
      "loss": 0.0975,
      "step": 176
    },
    {
      "epoch": 0.387308533916849,
      "grad_norm": 0.6548910140991211,
      "learning_rate": 6.733406622179295e-06,
      "loss": 0.1073,
      "step": 177
    },
    {
      "epoch": 0.38949671772428884,
      "grad_norm": 0.5929000973701477,
      "learning_rate": 6.701125651182631e-06,
      "loss": 0.0491,
      "step": 178
    },
    {
      "epoch": 0.3916849015317287,
      "grad_norm": 0.4183684289455414,
      "learning_rate": 6.668764290186039e-06,
      "loss": 0.0226,
      "step": 179
    },
    {
      "epoch": 0.3938730853391685,
      "grad_norm": 0.26102274656295776,
      "learning_rate": 6.6363240684885465e-06,
      "loss": 0.0187,
      "step": 180
    },
    {
      "epoch": 0.39606126914660833,
      "grad_norm": 1.7436633110046387,
      "learning_rate": 6.603806519115899e-06,
      "loss": 0.0415,
      "step": 181
    },
    {
      "epoch": 0.3982494529540481,
      "grad_norm": 0.44935575127601624,
      "learning_rate": 6.571213178748112e-06,
      "loss": 0.0214,
      "step": 182
    },
    {
      "epoch": 0.40043763676148797,
      "grad_norm": 1.0849740505218506,
      "learning_rate": 6.538545587646854e-06,
      "loss": 0.1048,
      "step": 183
    },
    {
      "epoch": 0.4026258205689278,
      "grad_norm": 0.7200307846069336,
      "learning_rate": 6.50580528958265e-06,
      "loss": 0.0504,
      "step": 184
    },
    {
      "epoch": 0.4048140043763676,
      "grad_norm": 0.10440302640199661,
      "learning_rate": 6.47299383176194e-06,
      "loss": 0.0056,
      "step": 185
    },
    {
      "epoch": 0.40700218818380746,
      "grad_norm": 0.060927558690309525,
      "learning_rate": 6.440112764753956e-06,
      "loss": 0.0023,
      "step": 186
    },
    {
      "epoch": 0.40919037199124725,
      "grad_norm": 1.8766518831253052,
      "learning_rate": 6.4071636424174435e-06,
      "loss": 0.0365,
      "step": 187
    },
    {
      "epoch": 0.4113785557986871,
      "grad_norm": 1.1711500883102417,
      "learning_rate": 6.374148021827237e-06,
      "loss": 0.0642,
      "step": 188
    },
    {
      "epoch": 0.4135667396061269,
      "grad_norm": 0.09909448027610779,
      "learning_rate": 6.341067463200678e-06,
      "loss": 0.0051,
      "step": 189
    },
    {
      "epoch": 0.41575492341356673,
      "grad_norm": 0.6192730665206909,
      "learning_rate": 6.307923529823876e-06,
      "loss": 0.0658,
      "step": 190
    },
    {
      "epoch": 0.4179431072210066,
      "grad_norm": 1.2255553007125854,
      "learning_rate": 6.2747177879778424e-06,
      "loss": 0.036,
      "step": 191
    },
    {
      "epoch": 0.4201312910284464,
      "grad_norm": 2.369842529296875,
      "learning_rate": 6.241451806864465e-06,
      "loss": 0.0132,
      "step": 192
    },
    {
      "epoch": 0.4223194748358862,
      "grad_norm": 0.11621212214231491,
      "learning_rate": 6.208127158532358e-06,
      "loss": 0.0073,
      "step": 193
    },
    {
      "epoch": 0.424507658643326,
      "grad_norm": 0.9171841144561768,
      "learning_rate": 6.174745417802563e-06,
      "loss": 0.1289,
      "step": 194
    },
    {
      "epoch": 0.42669584245076586,
      "grad_norm": 0.2952517867088318,
      "learning_rate": 6.141308162194141e-06,
      "loss": 0.0189,
      "step": 195
    },
    {
      "epoch": 0.4288840262582057,
      "grad_norm": 0.846849799156189,
      "learning_rate": 6.1078169718496164e-06,
      "loss": 0.1301,
      "step": 196
    },
    {
      "epoch": 0.4310722100656455,
      "grad_norm": 0.10027792304754257,
      "learning_rate": 6.074273429460296e-06,
      "loss": 0.005,
      "step": 197
    },
    {
      "epoch": 0.43326039387308535,
      "grad_norm": 0.2806321382522583,
      "learning_rate": 6.040679120191491e-06,
      "loss": 0.0191,
      "step": 198
    },
    {
      "epoch": 0.43544857768052514,
      "grad_norm": 0.050859756767749786,
      "learning_rate": 6.007035631607605e-06,
      "loss": 0.0027,
      "step": 199
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 0.8901111483573914,
      "learning_rate": 5.9733445535970915e-06,
      "loss": 0.0717,
      "step": 200
    },
    {
      "epoch": 0.43982494529540483,
      "grad_norm": 1.1302452087402344,
      "learning_rate": 5.939607478297347e-06,
      "loss": 0.0786,
      "step": 201
    },
    {
      "epoch": 0.4420131291028446,
      "grad_norm": 0.9025186896324158,
      "learning_rate": 5.905826000019458e-06,
      "loss": 0.0626,
      "step": 202
    },
    {
      "epoch": 0.4442013129102845,
      "grad_norm": 0.04018203541636467,
      "learning_rate": 5.8720017151728526e-06,
      "loss": 0.0018,
      "step": 203
    },
    {
      "epoch": 0.44638949671772427,
      "grad_norm": 0.03783510997891426,
      "learning_rate": 5.838136222189874e-06,
      "loss": 0.0015,
      "step": 204
    },
    {
      "epoch": 0.4485776805251641,
      "grad_norm": 0.39908379316329956,
      "learning_rate": 5.804231121450235e-06,
      "loss": 0.0184,
      "step": 205
    },
    {
      "epoch": 0.45076586433260396,
      "grad_norm": 0.42886778712272644,
      "learning_rate": 5.770288015205385e-06,
      "loss": 0.0196,
      "step": 206
    },
    {
      "epoch": 0.45295404814004375,
      "grad_norm": 0.5633195638656616,
      "learning_rate": 5.736308507502805e-06,
      "loss": 0.0944,
      "step": 207
    },
    {
      "epoch": 0.4551422319474836,
      "grad_norm": 0.3394029438495636,
      "learning_rate": 5.702294204110191e-06,
      "loss": 0.0124,
      "step": 208
    },
    {
      "epoch": 0.4573304157549234,
      "grad_norm": 0.955794632434845,
      "learning_rate": 5.668246712439579e-06,
      "loss": 0.0306,
      "step": 209
    },
    {
      "epoch": 0.45951859956236324,
      "grad_norm": 0.5480477809906006,
      "learning_rate": 5.634167641471383e-06,
      "loss": 0.0302,
      "step": 210
    },
    {
      "epoch": 0.4617067833698031,
      "grad_norm": 0.8581005334854126,
      "learning_rate": 5.600058601678357e-06,
      "loss": 0.0954,
      "step": 211
    },
    {
      "epoch": 0.4638949671772429,
      "grad_norm": 1.490744948387146,
      "learning_rate": 5.5659212049494915e-06,
      "loss": 0.0433,
      "step": 212
    },
    {
      "epoch": 0.4660831509846827,
      "grad_norm": 0.05115273967385292,
      "learning_rate": 5.531757064513837e-06,
      "loss": 0.0027,
      "step": 213
    },
    {
      "epoch": 0.4682713347921225,
      "grad_norm": 0.338157594203949,
      "learning_rate": 5.4975677948642704e-06,
      "loss": 0.018,
      "step": 214
    },
    {
      "epoch": 0.47045951859956237,
      "grad_norm": 0.9683653116226196,
      "learning_rate": 5.4633550116812e-06,
      "loss": 0.0377,
      "step": 215
    },
    {
      "epoch": 0.4726477024070022,
      "grad_norm": 1.2448917627334595,
      "learning_rate": 5.429120331756208e-06,
      "loss": 0.1068,
      "step": 216
    },
    {
      "epoch": 0.474835886214442,
      "grad_norm": 1.1274679899215698,
      "learning_rate": 5.394865372915656e-06,
      "loss": 0.0661,
      "step": 217
    },
    {
      "epoch": 0.47702407002188185,
      "grad_norm": 1.3839744329452515,
      "learning_rate": 5.360591753944221e-06,
      "loss": 0.0388,
      "step": 218
    },
    {
      "epoch": 0.47921225382932164,
      "grad_norm": 0.8305552005767822,
      "learning_rate": 5.3263010945083994e-06,
      "loss": 0.0679,
      "step": 219
    },
    {
      "epoch": 0.4814004376367615,
      "grad_norm": 0.6508780121803284,
      "learning_rate": 5.291995015079969e-06,
      "loss": 0.0153,
      "step": 220
    },
    {
      "epoch": 0.48358862144420134,
      "grad_norm": 0.12869389355182648,
      "learning_rate": 5.257675136859415e-06,
      "loss": 0.0069,
      "step": 221
    },
    {
      "epoch": 0.48577680525164113,
      "grad_norm": 0.3307591378688812,
      "learning_rate": 5.223343081699302e-06,
      "loss": 0.0129,
      "step": 222
    },
    {
      "epoch": 0.487964989059081,
      "grad_norm": 0.7359892725944519,
      "learning_rate": 5.189000472027645e-06,
      "loss": 0.0817,
      "step": 223
    },
    {
      "epoch": 0.49015317286652077,
      "grad_norm": 0.010269359685480595,
      "learning_rate": 5.1546489307712345e-06,
      "loss": 0.0004,
      "step": 224
    },
    {
      "epoch": 0.4923413566739606,
      "grad_norm": 0.029753487557172775,
      "learning_rate": 5.1202900812789346e-06,
      "loss": 0.001,
      "step": 225
    },
    {
      "epoch": 0.49452954048140046,
      "grad_norm": 0.046108052134513855,
      "learning_rate": 5.085925547244978e-06,
      "loss": 0.002,
      "step": 226
    },
    {
      "epoch": 0.49671772428884026,
      "grad_norm": 1.029268741607666,
      "learning_rate": 5.051556952632235e-06,
      "loss": 0.1909,
      "step": 227
    },
    {
      "epoch": 0.4989059080962801,
      "grad_norm": 0.0349777415394783,
      "learning_rate": 5.0171859215954575e-06,
      "loss": 0.0015,
      "step": 228
    },
    {
      "epoch": 0.5010940919037199,
      "grad_norm": 1.6073672771453857,
      "learning_rate": 4.982814078404543e-06,
      "loss": 0.2817,
      "step": 229
    },
    {
      "epoch": 0.5032822757111597,
      "grad_norm": 0.08773263543844223,
      "learning_rate": 4.948443047367767e-06,
      "loss": 0.0042,
      "step": 230
    },
    {
      "epoch": 0.5054704595185996,
      "grad_norm": 0.050334371626377106,
      "learning_rate": 4.9140744527550225e-06,
      "loss": 0.0026,
      "step": 231
    },
    {
      "epoch": 0.5076586433260394,
      "grad_norm": 1.0086191892623901,
      "learning_rate": 4.879709918721067e-06,
      "loss": 0.0361,
      "step": 232
    },
    {
      "epoch": 0.5098468271334792,
      "grad_norm": 1.9498145580291748,
      "learning_rate": 4.845351069228767e-06,
      "loss": 0.1654,
      "step": 233
    },
    {
      "epoch": 0.5120350109409191,
      "grad_norm": 0.005721115507185459,
      "learning_rate": 4.8109995279723556e-06,
      "loss": 0.0003,
      "step": 234
    },
    {
      "epoch": 0.5142231947483589,
      "grad_norm": 0.015962788835167885,
      "learning_rate": 4.776656918300699e-06,
      "loss": 0.0006,
      "step": 235
    },
    {
      "epoch": 0.5164113785557987,
      "grad_norm": 0.8821823596954346,
      "learning_rate": 4.742324863140587e-06,
      "loss": 0.1105,
      "step": 236
    },
    {
      "epoch": 0.5185995623632386,
      "grad_norm": 0.018718110397458076,
      "learning_rate": 4.70800498492003e-06,
      "loss": 0.0008,
      "step": 237
    },
    {
      "epoch": 0.5207877461706784,
      "grad_norm": 0.2069554626941681,
      "learning_rate": 4.673698905491602e-06,
      "loss": 0.0074,
      "step": 238
    },
    {
      "epoch": 0.5229759299781181,
      "grad_norm": 0.7712518572807312,
      "learning_rate": 4.639408246055781e-06,
      "loss": 0.0126,
      "step": 239
    },
    {
      "epoch": 0.5251641137855579,
      "grad_norm": 1.355142593383789,
      "learning_rate": 4.605134627084345e-06,
      "loss": 0.0476,
      "step": 240
    },
    {
      "epoch": 0.5273522975929978,
      "grad_norm": 1.3627309799194336,
      "learning_rate": 4.570879668243792e-06,
      "loss": 0.131,
      "step": 241
    },
    {
      "epoch": 0.5295404814004376,
      "grad_norm": 0.026976406574249268,
      "learning_rate": 4.536644988318802e-06,
      "loss": 0.0013,
      "step": 242
    },
    {
      "epoch": 0.5317286652078774,
      "grad_norm": 0.054517991840839386,
      "learning_rate": 4.502432205135731e-06,
      "loss": 0.0026,
      "step": 243
    },
    {
      "epoch": 0.5339168490153173,
      "grad_norm": 0.931753933429718,
      "learning_rate": 4.468242935486164e-06,
      "loss": 0.0512,
      "step": 244
    },
    {
      "epoch": 0.5361050328227571,
      "grad_norm": 1.5184392929077148,
      "learning_rate": 4.434078795050509e-06,
      "loss": 0.0518,
      "step": 245
    },
    {
      "epoch": 0.5382932166301969,
      "grad_norm": 0.38117513060569763,
      "learning_rate": 4.3999413983216434e-06,
      "loss": 0.0212,
      "step": 246
    },
    {
      "epoch": 0.5404814004376368,
      "grad_norm": 3.524531602859497,
      "learning_rate": 4.365832358528618e-06,
      "loss": 0.299,
      "step": 247
    },
    {
      "epoch": 0.5426695842450766,
      "grad_norm": 1.0988812446594238,
      "learning_rate": 4.331753287560423e-06,
      "loss": 0.0586,
      "step": 248
    },
    {
      "epoch": 0.5448577680525164,
      "grad_norm": 0.7053582072257996,
      "learning_rate": 4.29770579588981e-06,
      "loss": 0.0911,
      "step": 249
    },
    {
      "epoch": 0.5470459518599562,
      "grad_norm": 0.706597626209259,
      "learning_rate": 4.263691492497197e-06,
      "loss": 0.023,
      "step": 250
    },
    {
      "epoch": 0.5492341356673961,
      "grad_norm": 0.2049330770969391,
      "learning_rate": 4.229711984794614e-06,
      "loss": 0.0107,
      "step": 251
    },
    {
      "epoch": 0.5514223194748359,
      "grad_norm": 0.7492695450782776,
      "learning_rate": 4.195768878549766e-06,
      "loss": 0.1174,
      "step": 252
    },
    {
      "epoch": 0.5536105032822757,
      "grad_norm": 1.8531229496002197,
      "learning_rate": 4.161863777810128e-06,
      "loss": 0.1152,
      "step": 253
    },
    {
      "epoch": 0.5557986870897156,
      "grad_norm": 0.6519593000411987,
      "learning_rate": 4.127998284827148e-06,
      "loss": 0.0428,
      "step": 254
    },
    {
      "epoch": 0.5579868708971554,
      "grad_norm": 0.06980860233306885,
      "learning_rate": 4.094173999980544e-06,
      "loss": 0.0037,
      "step": 255
    },
    {
      "epoch": 0.5601750547045952,
      "grad_norm": 1.9488458633422852,
      "learning_rate": 4.060392521702655e-06,
      "loss": 0.1049,
      "step": 256
    },
    {
      "epoch": 0.562363238512035,
      "grad_norm": 0.11421229690313339,
      "learning_rate": 4.026655446402912e-06,
      "loss": 0.0059,
      "step": 257
    },
    {
      "epoch": 0.5645514223194749,
      "grad_norm": 1.328544020652771,
      "learning_rate": 3.9929643683923965e-06,
      "loss": 0.0621,
      "step": 258
    },
    {
      "epoch": 0.5667396061269147,
      "grad_norm": 0.071404829621315,
      "learning_rate": 3.9593208798085094e-06,
      "loss": 0.0036,
      "step": 259
    },
    {
      "epoch": 0.5689277899343544,
      "grad_norm": 0.0724036768078804,
      "learning_rate": 3.9257265705397065e-06,
      "loss": 0.0041,
      "step": 260
    },
    {
      "epoch": 0.5711159737417943,
      "grad_norm": 0.018740981817245483,
      "learning_rate": 3.892183028150384e-06,
      "loss": 0.0009,
      "step": 261
    },
    {
      "epoch": 0.5733041575492341,
      "grad_norm": 1.238190770149231,
      "learning_rate": 3.8586918378058595e-06,
      "loss": 0.0387,
      "step": 262
    },
    {
      "epoch": 0.5754923413566739,
      "grad_norm": 0.6099205017089844,
      "learning_rate": 3.8252545821974385e-06,
      "loss": 0.0171,
      "step": 263
    },
    {
      "epoch": 0.5776805251641138,
      "grad_norm": 0.3969406485557556,
      "learning_rate": 3.791872841467643e-06,
      "loss": 0.0204,
      "step": 264
    },
    {
      "epoch": 0.5798687089715536,
      "grad_norm": 1.8998205661773682,
      "learning_rate": 3.758548193135536e-06,
      "loss": 0.0781,
      "step": 265
    },
    {
      "epoch": 0.5820568927789934,
      "grad_norm": 0.024642566218972206,
      "learning_rate": 3.7252822120221592e-06,
      "loss": 0.0012,
      "step": 266
    },
    {
      "epoch": 0.5842450765864332,
      "grad_norm": 1.115889072418213,
      "learning_rate": 3.6920764701761263e-06,
      "loss": 0.1017,
      "step": 267
    },
    {
      "epoch": 0.5864332603938731,
      "grad_norm": 0.2591744065284729,
      "learning_rate": 3.6589325367993243e-06,
      "loss": 0.0153,
      "step": 268
    },
    {
      "epoch": 0.5886214442013129,
      "grad_norm": 0.11297856271266937,
      "learning_rate": 3.625851978172765e-06,
      "loss": 0.0063,
      "step": 269
    },
    {
      "epoch": 0.5908096280087527,
      "grad_norm": 1.001126766204834,
      "learning_rate": 3.59283635758256e-06,
      "loss": 0.1159,
      "step": 270
    },
    {
      "epoch": 0.5929978118161926,
      "grad_norm": 0.20863710343837738,
      "learning_rate": 3.5598872352460457e-06,
      "loss": 0.0113,
      "step": 271
    },
    {
      "epoch": 0.5951859956236324,
      "grad_norm": 0.08837909996509552,
      "learning_rate": 3.527006168238061e-06,
      "loss": 0.0055,
      "step": 272
    },
    {
      "epoch": 0.5973741794310722,
      "grad_norm": 0.5907989144325256,
      "learning_rate": 3.4941947104173514e-06,
      "loss": 0.041,
      "step": 273
    },
    {
      "epoch": 0.5995623632385121,
      "grad_norm": 0.13835440576076508,
      "learning_rate": 3.4614544123531476e-06,
      "loss": 0.008,
      "step": 274
    },
    {
      "epoch": 0.6017505470459519,
      "grad_norm": 1.3448940515518188,
      "learning_rate": 3.428786821251888e-06,
      "loss": 0.1017,
      "step": 275
    },
    {
      "epoch": 0.6039387308533917,
      "grad_norm": 0.7067652940750122,
      "learning_rate": 3.3961934808841023e-06,
      "loss": 0.1204,
      "step": 276
    },
    {
      "epoch": 0.6061269146608315,
      "grad_norm": 0.32697802782058716,
      "learning_rate": 3.363675931511455e-06,
      "loss": 0.0084,
      "step": 277
    },
    {
      "epoch": 0.6083150984682714,
      "grad_norm": 0.8121664524078369,
      "learning_rate": 3.331235709813962e-06,
      "loss": 0.0188,
      "step": 278
    },
    {
      "epoch": 0.6105032822757112,
      "grad_norm": 0.19050802290439606,
      "learning_rate": 3.29887434881737e-06,
      "loss": 0.0117,
      "step": 279
    },
    {
      "epoch": 0.612691466083151,
      "grad_norm": 0.10412326455116272,
      "learning_rate": 3.2665933778207082e-06,
      "loss": 0.0049,
      "step": 280
    },
    {
      "epoch": 0.6148796498905909,
      "grad_norm": 0.02882825769484043,
      "learning_rate": 3.234394322324019e-06,
      "loss": 0.0015,
      "step": 281
    },
    {
      "epoch": 0.6170678336980306,
      "grad_norm": 0.03416011855006218,
      "learning_rate": 3.2022787039562745e-06,
      "loss": 0.0015,
      "step": 282
    },
    {
      "epoch": 0.6192560175054704,
      "grad_norm": 1.2673507928848267,
      "learning_rate": 3.170248040403457e-06,
      "loss": 0.0845,
      "step": 283
    },
    {
      "epoch": 0.6214442013129103,
      "grad_norm": 0.30653080344200134,
      "learning_rate": 3.138303845336844e-06,
      "loss": 0.0064,
      "step": 284
    },
    {
      "epoch": 0.6236323851203501,
      "grad_norm": 0.2129947394132614,
      "learning_rate": 3.1064476283414818e-06,
      "loss": 0.0122,
      "step": 285
    },
    {
      "epoch": 0.6258205689277899,
      "grad_norm": 0.7980894446372986,
      "learning_rate": 3.074680894844837e-06,
      "loss": 0.0194,
      "step": 286
    },
    {
      "epoch": 0.6280087527352297,
      "grad_norm": 0.04302386939525604,
      "learning_rate": 3.04300514604566e-06,
      "loss": 0.0024,
      "step": 287
    },
    {
      "epoch": 0.6301969365426696,
      "grad_norm": 0.042577434331178665,
      "learning_rate": 3.011421878843044e-06,
      "loss": 0.0023,
      "step": 288
    },
    {
      "epoch": 0.6323851203501094,
      "grad_norm": 1.3895162343978882,
      "learning_rate": 2.9799325857656856e-06,
      "loss": 0.2129,
      "step": 289
    },
    {
      "epoch": 0.6345733041575492,
      "grad_norm": 1.156243085861206,
      "learning_rate": 2.948538754901349e-06,
      "loss": 0.0677,
      "step": 290
    },
    {
      "epoch": 0.6367614879649891,
      "grad_norm": 1.1977258920669556,
      "learning_rate": 2.917241869826545e-06,
      "loss": 0.0293,
      "step": 291
    },
    {
      "epoch": 0.6389496717724289,
      "grad_norm": 1.2063170671463013,
      "learning_rate": 2.8860434095364266e-06,
      "loss": 0.0399,
      "step": 292
    },
    {
      "epoch": 0.6411378555798687,
      "grad_norm": 1.1270692348480225,
      "learning_rate": 2.8549448483748888e-06,
      "loss": 0.166,
      "step": 293
    },
    {
      "epoch": 0.6433260393873085,
      "grad_norm": 0.5172305107116699,
      "learning_rate": 2.8239476559649013e-06,
      "loss": 0.0613,
      "step": 294
    },
    {
      "epoch": 0.6455142231947484,
      "grad_norm": 0.9346317052841187,
      "learning_rate": 2.7930532971390543e-06,
      "loss": 0.0412,
      "step": 295
    },
    {
      "epoch": 0.6477024070021882,
      "grad_norm": 0.0995471403002739,
      "learning_rate": 2.762263231870339e-06,
      "loss": 0.0036,
      "step": 296
    },
    {
      "epoch": 0.649890590809628,
      "grad_norm": 0.1383901834487915,
      "learning_rate": 2.7315789152031504e-06,
      "loss": 0.0081,
      "step": 297
    },
    {
      "epoch": 0.6520787746170679,
      "grad_norm": 0.8380966782569885,
      "learning_rate": 2.7010017971845267e-06,
      "loss": 0.0526,
      "step": 298
    },
    {
      "epoch": 0.6542669584245077,
      "grad_norm": 1.3845183849334717,
      "learning_rate": 2.6705333227956304e-06,
      "loss": 0.1414,
      "step": 299
    },
    {
      "epoch": 0.6564551422319475,
      "grad_norm": 0.14591088891029358,
      "learning_rate": 2.6401749318834528e-06,
      "loss": 0.0073,
      "step": 300
    },
    {
      "epoch": 0.6586433260393874,
      "grad_norm": 0.07555296272039413,
      "learning_rate": 2.609928059092779e-06,
      "loss": 0.0046,
      "step": 301
    },
    {
      "epoch": 0.6608315098468271,
      "grad_norm": 1.0099620819091797,
      "learning_rate": 2.579794133798388e-06,
      "loss": 0.0586,
      "step": 302
    },
    {
      "epoch": 0.6630196936542669,
      "grad_norm": 0.452395498752594,
      "learning_rate": 2.549774580037504e-06,
      "loss": 0.022,
      "step": 303
    },
    {
      "epoch": 0.6652078774617067,
      "grad_norm": 0.02514701709151268,
      "learning_rate": 2.5198708164425046e-06,
      "loss": 0.0012,
      "step": 304
    },
    {
      "epoch": 0.6673960612691466,
      "grad_norm": 0.13923096656799316,
      "learning_rate": 2.4900842561738736e-06,
      "loss": 0.0055,
      "step": 305
    },
    {
      "epoch": 0.6695842450765864,
      "grad_norm": 0.06949138641357422,
      "learning_rate": 2.4604163068534313e-06,
      "loss": 0.0036,
      "step": 306
    },
    {
      "epoch": 0.6717724288840262,
      "grad_norm": 0.9737526774406433,
      "learning_rate": 2.4308683704978e-06,
      "loss": 0.0448,
      "step": 307
    },
    {
      "epoch": 0.6739606126914661,
      "grad_norm": 1.4408031702041626,
      "learning_rate": 2.401441843452159e-06,
      "loss": 0.2419,
      "step": 308
    },
    {
      "epoch": 0.6761487964989059,
      "grad_norm": 1.0048445463180542,
      "learning_rate": 2.372138116324254e-06,
      "loss": 0.1577,
      "step": 309
    },
    {
      "epoch": 0.6783369803063457,
      "grad_norm": 0.16815468668937683,
      "learning_rate": 2.342958573918682e-06,
      "loss": 0.0058,
      "step": 310
    },
    {
      "epoch": 0.6805251641137856,
      "grad_norm": 0.6716362237930298,
      "learning_rate": 2.3139045951714473e-06,
      "loss": 0.0691,
      "step": 311
    },
    {
      "epoch": 0.6827133479212254,
      "grad_norm": 0.4712567627429962,
      "learning_rate": 2.2849775530848057e-06,
      "loss": 0.0165,
      "step": 312
    },
    {
      "epoch": 0.6849015317286652,
      "grad_norm": 3.1558778285980225,
      "learning_rate": 2.256178814662368e-06,
      "loss": 0.1129,
      "step": 313
    },
    {
      "epoch": 0.687089715536105,
      "grad_norm": 0.5113745331764221,
      "learning_rate": 2.227509740844508e-06,
      "loss": 0.0373,
      "step": 314
    },
    {
      "epoch": 0.6892778993435449,
      "grad_norm": 0.7477394342422485,
      "learning_rate": 2.198971686444047e-06,
      "loss": 0.0712,
      "step": 315
    },
    {
      "epoch": 0.6914660831509847,
      "grad_norm": 0.2921401858329773,
      "learning_rate": 2.1705660000822286e-06,
      "loss": 0.0146,
      "step": 316
    },
    {
      "epoch": 0.6936542669584245,
      "grad_norm": 0.4279050827026367,
      "learning_rate": 2.1422940241249875e-06,
      "loss": 0.0172,
      "step": 317
    },
    {
      "epoch": 0.6958424507658644,
      "grad_norm": 0.9140868782997131,
      "learning_rate": 2.1141570946195106e-06,
      "loss": 0.0375,
      "step": 318
    },
    {
      "epoch": 0.6980306345733042,
      "grad_norm": 0.06922470033168793,
      "learning_rate": 2.086156541231109e-06,
      "loss": 0.0038,
      "step": 319
    },
    {
      "epoch": 0.700218818380744,
      "grad_norm": 0.693082332611084,
      "learning_rate": 2.0582936871803692e-06,
      "loss": 0.0541,
      "step": 320
    },
    {
      "epoch": 0.7024070021881839,
      "grad_norm": 1.0022284984588623,
      "learning_rate": 2.0305698491806297e-06,
      "loss": 0.1206,
      "step": 321
    },
    {
      "epoch": 0.7045951859956237,
      "grad_norm": 0.9094358086585999,
      "learning_rate": 2.0029863373757553e-06,
      "loss": 0.1515,
      "step": 322
    },
    {
      "epoch": 0.7067833698030634,
      "grad_norm": 1.270714282989502,
      "learning_rate": 1.9755444552782228e-06,
      "loss": 0.1125,
      "step": 323
    },
    {
      "epoch": 0.7089715536105032,
      "grad_norm": 0.13254065811634064,
      "learning_rate": 1.948245499707523e-06,
      "loss": 0.0095,
      "step": 324
    },
    {
      "epoch": 0.7111597374179431,
      "grad_norm": 0.08191127330064774,
      "learning_rate": 1.9210907607288728e-06,
      "loss": 0.0032,
      "step": 325
    },
    {
      "epoch": 0.7133479212253829,
      "grad_norm": 0.4450894594192505,
      "learning_rate": 1.8940815215922609e-06,
      "loss": 0.0195,
      "step": 326
    },
    {
      "epoch": 0.7155361050328227,
      "grad_norm": 0.31175872683525085,
      "learning_rate": 1.867219058671791e-06,
      "loss": 0.0147,
      "step": 327
    },
    {
      "epoch": 0.7177242888402626,
      "grad_norm": 0.10807587206363678,
      "learning_rate": 1.8405046414053728e-06,
      "loss": 0.0047,
      "step": 328
    },
    {
      "epoch": 0.7199124726477024,
      "grad_norm": 0.2989639937877655,
      "learning_rate": 1.8139395322347335e-06,
      "loss": 0.0195,
      "step": 329
    },
    {
      "epoch": 0.7221006564551422,
      "grad_norm": 0.03554043173789978,
      "learning_rate": 1.787524986545753e-06,
      "loss": 0.002,
      "step": 330
    },
    {
      "epoch": 0.7242888402625821,
      "grad_norm": 1.7021892070770264,
      "learning_rate": 1.7612622526091406e-06,
      "loss": 0.0794,
      "step": 331
    },
    {
      "epoch": 0.7264770240700219,
      "grad_norm": 0.14061015844345093,
      "learning_rate": 1.7351525715214512e-06,
      "loss": 0.0049,
      "step": 332
    },
    {
      "epoch": 0.7286652078774617,
      "grad_norm": 0.3537355065345764,
      "learning_rate": 1.709197177146425e-06,
      "loss": 0.0202,
      "step": 333
    },
    {
      "epoch": 0.7308533916849015,
      "grad_norm": 1.0706983804702759,
      "learning_rate": 1.6833972960566868e-06,
      "loss": 0.0601,
      "step": 334
    },
    {
      "epoch": 0.7330415754923414,
      "grad_norm": 0.7408068776130676,
      "learning_rate": 1.6577541474757712e-06,
      "loss": 0.0269,
      "step": 335
    },
    {
      "epoch": 0.7352297592997812,
      "grad_norm": 0.704780638217926,
      "learning_rate": 1.6322689432205252e-06,
      "loss": 0.0478,
      "step": 336
    },
    {
      "epoch": 0.737417943107221,
      "grad_norm": 0.02287714183330536,
      "learning_rate": 1.6069428876438203e-06,
      "loss": 0.0011,
      "step": 337
    },
    {
      "epoch": 0.7396061269146609,
      "grad_norm": 0.9569922685623169,
      "learning_rate": 1.5817771775776508e-06,
      "loss": 0.1014,
      "step": 338
    },
    {
      "epoch": 0.7417943107221007,
      "grad_norm": 0.7031758427619934,
      "learning_rate": 1.5567730022765753e-06,
      "loss": 0.0955,
      "step": 339
    },
    {
      "epoch": 0.7439824945295405,
      "grad_norm": 0.1989745944738388,
      "learning_rate": 1.5319315433615101e-06,
      "loss": 0.0126,
      "step": 340
    },
    {
      "epoch": 0.7461706783369803,
      "grad_norm": 0.03552668169140816,
      "learning_rate": 1.5072539747638887e-06,
      "loss": 0.0017,
      "step": 341
    },
    {
      "epoch": 0.7483588621444202,
      "grad_norm": 0.014245983213186264,
      "learning_rate": 1.482741462670193e-06,
      "loss": 0.0008,
      "step": 342
    },
    {
      "epoch": 0.75054704595186,
      "grad_norm": 0.1464129537343979,
      "learning_rate": 1.4583951654668416e-06,
      "loss": 0.007,
      "step": 343
    },
    {
      "epoch": 0.7527352297592997,
      "grad_norm": 1.222846269607544,
      "learning_rate": 1.434216233685441e-06,
      "loss": 0.1435,
      "step": 344
    },
    {
      "epoch": 0.7549234135667396,
      "grad_norm": 0.841230571269989,
      "learning_rate": 1.4102058099484188e-06,
      "loss": 0.1003,
      "step": 345
    },
    {
      "epoch": 0.7571115973741794,
      "grad_norm": 0.19701069593429565,
      "learning_rate": 1.3863650289150338e-06,
      "loss": 0.0111,
      "step": 346
    },
    {
      "epoch": 0.7592997811816192,
      "grad_norm": 0.12432289123535156,
      "learning_rate": 1.3626950172277398e-06,
      "loss": 0.0068,
      "step": 347
    },
    {
      "epoch": 0.7614879649890591,
      "grad_norm": 0.12971007823944092,
      "learning_rate": 1.3391968934589573e-06,
      "loss": 0.0067,
      "step": 348
    },
    {
      "epoch": 0.7636761487964989,
      "grad_norm": 0.16889971494674683,
      "learning_rate": 1.3158717680582128e-06,
      "loss": 0.0103,
      "step": 349
    },
    {
      "epoch": 0.7658643326039387,
      "grad_norm": 0.18550348281860352,
      "learning_rate": 1.292720743299654e-06,
      "loss": 0.0101,
      "step": 350
    },
    {
      "epoch": 0.7680525164113785,
      "grad_norm": 0.08809703588485718,
      "learning_rate": 1.2697449132299649e-06,
      "loss": 0.0045,
      "step": 351
    },
    {
      "epoch": 0.7702407002188184,
      "grad_norm": 0.1383749097585678,
      "learning_rate": 1.2469453636166645e-06,
      "loss": 0.0076,
      "step": 352
    },
    {
      "epoch": 0.7724288840262582,
      "grad_norm": 0.08031852543354034,
      "learning_rate": 1.224323171896797e-06,
      "loss": 0.0037,
      "step": 353
    },
    {
      "epoch": 0.774617067833698,
      "grad_norm": 0.13594304025173187,
      "learning_rate": 1.201879407126012e-06,
      "loss": 0.008,
      "step": 354
    },
    {
      "epoch": 0.7768052516411379,
      "grad_norm": 0.7467914819717407,
      "learning_rate": 1.1796151299280483e-06,
      "loss": 0.0455,
      "step": 355
    },
    {
      "epoch": 0.7789934354485777,
      "grad_norm": 0.08074288815259933,
      "learning_rate": 1.1575313924446123e-06,
      "loss": 0.003,
      "step": 356
    },
    {
      "epoch": 0.7811816192560175,
      "grad_norm": 1.1160669326782227,
      "learning_rate": 1.1356292382856531e-06,
      "loss": 0.0253,
      "step": 357
    },
    {
      "epoch": 0.7833698030634574,
      "grad_norm": 0.04272481054067612,
      "learning_rate": 1.113909702480046e-06,
      "loss": 0.0022,
      "step": 358
    },
    {
      "epoch": 0.7855579868708972,
      "grad_norm": 0.9849004149436951,
      "learning_rate": 1.0923738114266824e-06,
      "loss": 0.0462,
      "step": 359
    },
    {
      "epoch": 0.787746170678337,
      "grad_norm": 0.24054153263568878,
      "learning_rate": 1.0710225828459642e-06,
      "loss": 0.0131,
      "step": 360
    },
    {
      "epoch": 0.7899343544857768,
      "grad_norm": 0.7638225555419922,
      "learning_rate": 1.0498570257317075e-06,
      "loss": 0.0414,
      "step": 361
    },
    {
      "epoch": 0.7921225382932167,
      "grad_norm": 1.3115203380584717,
      "learning_rate": 1.028878140303462e-06,
      "loss": 0.1368,
      "step": 362
    },
    {
      "epoch": 0.7943107221006565,
      "grad_norm": 1.5852915048599243,
      "learning_rate": 1.008086917959249e-06,
      "loss": 0.1495,
      "step": 363
    },
    {
      "epoch": 0.7964989059080962,
      "grad_norm": 1.151593804359436,
      "learning_rate": 9.874843412286994e-07,
      "loss": 0.049,
      "step": 364
    },
    {
      "epoch": 0.7986870897155361,
      "grad_norm": 0.5000481009483337,
      "learning_rate": 9.670713837266322e-07,
      "loss": 0.0703,
      "step": 365
    },
    {
      "epoch": 0.8008752735229759,
      "grad_norm": 0.3628782033920288,
      "learning_rate": 9.46849010107041e-07,
      "loss": 0.023,
      "step": 366
    },
    {
      "epoch": 0.8030634573304157,
      "grad_norm": 2.099855661392212,
      "learning_rate": 9.26818176017506e-07,
      "loss": 0.1285,
      "step": 367
    },
    {
      "epoch": 0.8052516411378556,
      "grad_norm": 1.4717903137207031,
      "learning_rate": 9.069798280540348e-07,
      "loss": 0.1344,
      "step": 368
    },
    {
      "epoch": 0.8074398249452954,
      "grad_norm": 0.3499912917613983,
      "learning_rate": 8.87334903716332e-07,
      "loss": 0.0186,
      "step": 369
    },
    {
      "epoch": 0.8096280087527352,
      "grad_norm": 1.0058705806732178,
      "learning_rate": 8.678843313634894e-07,
      "loss": 0.0258,
      "step": 370
    },
    {
      "epoch": 0.811816192560175,
      "grad_norm": 0.6947938203811646,
      "learning_rate": 8.486290301701183e-07,
      "loss": 0.0975,
      "step": 371
    },
    {
      "epoch": 0.8140043763676149,
      "grad_norm": 0.08618401736021042,
      "learning_rate": 8.295699100829124e-07,
      "loss": 0.0032,
      "step": 372
    },
    {
      "epoch": 0.8161925601750547,
      "grad_norm": 0.8913024663925171,
      "learning_rate": 8.107078717776457e-07,
      "loss": 0.1064,
      "step": 373
    },
    {
      "epoch": 0.8183807439824945,
      "grad_norm": 0.12204021960496902,
      "learning_rate": 7.920438066166097e-07,
      "loss": 0.007,
      "step": 374
    },
    {
      "epoch": 0.8205689277899344,
      "grad_norm": 0.519547164440155,
      "learning_rate": 7.735785966064885e-07,
      "loss": 0.0801,
      "step": 375
    },
    {
      "epoch": 0.8227571115973742,
      "grad_norm": 0.8925865292549133,
      "learning_rate": 7.553131143566822e-07,
      "loss": 0.0629,
      "step": 376
    },
    {
      "epoch": 0.824945295404814,
      "grad_norm": 0.022270280867815018,
      "learning_rate": 7.372482230380657e-07,
      "loss": 0.0011,
      "step": 377
    },
    {
      "epoch": 0.8271334792122538,
      "grad_norm": 1.2032333612442017,
      "learning_rate": 7.193847763421991e-07,
      "loss": 0.0379,
      "step": 378
    },
    {
      "epoch": 0.8293216630196937,
      "grad_norm": 1.0047138929367065,
      "learning_rate": 7.017236184409859e-07,
      "loss": 0.0523,
      "step": 379
    },
    {
      "epoch": 0.8315098468271335,
      "grad_norm": 0.5162358283996582,
      "learning_rate": 6.842655839467787e-07,
      "loss": 0.0417,
      "step": 380
    },
    {
      "epoch": 0.8336980306345733,
      "grad_norm": 0.19038501381874084,
      "learning_rate": 6.670114978729392e-07,
      "loss": 0.0104,
      "step": 381
    },
    {
      "epoch": 0.8358862144420132,
      "grad_norm": 1.9529792070388794,
      "learning_rate": 6.499621755948487e-07,
      "loss": 0.1266,
      "step": 382
    },
    {
      "epoch": 0.838074398249453,
      "grad_norm": 1.6609997749328613,
      "learning_rate": 6.331184228113801e-07,
      "loss": 0.0388,
      "step": 383
    },
    {
      "epoch": 0.8402625820568927,
      "grad_norm": 0.8662549257278442,
      "learning_rate": 6.164810355068179e-07,
      "loss": 0.0686,
      "step": 384
    },
    {
      "epoch": 0.8424507658643327,
      "grad_norm": 0.5557909607887268,
      "learning_rate": 6.000507999132444e-07,
      "loss": 0.0509,
      "step": 385
    },
    {
      "epoch": 0.8446389496717724,
      "grad_norm": 0.016307786107063293,
      "learning_rate": 5.838284924733866e-07,
      "loss": 0.0008,
      "step": 386
    },
    {
      "epoch": 0.8468271334792122,
      "grad_norm": 0.05876423791050911,
      "learning_rate": 5.678148798039213e-07,
      "loss": 0.0027,
      "step": 387
    },
    {
      "epoch": 0.849015317286652,
      "grad_norm": 1.1307599544525146,
      "learning_rate": 5.520107186592477e-07,
      "loss": 0.0418,
      "step": 388
    },
    {
      "epoch": 0.8512035010940919,
      "grad_norm": 0.8495901226997375,
      "learning_rate": 5.364167558957267e-07,
      "loss": 0.0224,
      "step": 389
    },
    {
      "epoch": 0.8533916849015317,
      "grad_norm": 0.059243425726890564,
      "learning_rate": 5.210337284363876e-07,
      "loss": 0.0028,
      "step": 390
    },
    {
      "epoch": 0.8555798687089715,
      "grad_norm": 1.426680326461792,
      "learning_rate": 5.058623632361004e-07,
      "loss": 0.181,
      "step": 391
    },
    {
      "epoch": 0.8577680525164114,
      "grad_norm": 0.056257933378219604,
      "learning_rate": 4.909033772472204e-07,
      "loss": 0.0031,
      "step": 392
    },
    {
      "epoch": 0.8599562363238512,
      "grad_norm": 0.2283673733472824,
      "learning_rate": 4.7615747738571636e-07,
      "loss": 0.0067,
      "step": 393
    },
    {
      "epoch": 0.862144420131291,
      "grad_norm": 0.9073981642723083,
      "learning_rate": 4.6162536049775387e-07,
      "loss": 0.0382,
      "step": 394
    },
    {
      "epoch": 0.8643326039387309,
      "grad_norm": 1.5168408155441284,
      "learning_rate": 4.473077133267684e-07,
      "loss": 0.0676,
      "step": 395
    },
    {
      "epoch": 0.8665207877461707,
      "grad_norm": 0.9888849854469299,
      "learning_rate": 4.3320521248101487e-07,
      "loss": 0.0994,
      "step": 396
    },
    {
      "epoch": 0.8687089715536105,
      "grad_norm": 0.15305738151073456,
      "learning_rate": 4.193185244015879e-07,
      "loss": 0.0061,
      "step": 397
    },
    {
      "epoch": 0.8708971553610503,
      "grad_norm": 0.07003610581159592,
      "learning_rate": 4.0564830533093014e-07,
      "loss": 0.0033,
      "step": 398
    },
    {
      "epoch": 0.8730853391684902,
      "grad_norm": 0.10461792349815369,
      "learning_rate": 3.9219520128182087e-07,
      "loss": 0.0051,
      "step": 399
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 0.5037143230438232,
      "learning_rate": 3.789598480068479e-07,
      "loss": 0.0081,
      "step": 400
    },
    {
      "epoch": 0.8774617067833698,
      "grad_norm": 1.1439661979675293,
      "learning_rate": 3.659428709683621e-07,
      "loss": 0.0963,
      "step": 401
    },
    {
      "epoch": 0.8796498905908097,
      "grad_norm": 0.11487782001495361,
      "learning_rate": 3.531448853089192e-07,
      "loss": 0.0056,
      "step": 402
    },
    {
      "epoch": 0.8818380743982495,
      "grad_norm": 1.107894778251648,
      "learning_rate": 3.40566495822216e-07,
      "loss": 0.0435,
      "step": 403
    },
    {
      "epoch": 0.8840262582056893,
      "grad_norm": 0.320011168718338,
      "learning_rate": 3.2820829692449984e-07,
      "loss": 0.0161,
      "step": 404
    },
    {
      "epoch": 0.8862144420131292,
      "grad_norm": 1.9681226015090942,
      "learning_rate": 3.160708726264855e-07,
      "loss": 0.1875,
      "step": 405
    },
    {
      "epoch": 0.888402625820569,
      "grad_norm": 0.5993462800979614,
      "learning_rate": 3.0415479650575783e-07,
      "loss": 0.0437,
      "step": 406
    },
    {
      "epoch": 0.8905908096280087,
      "grad_norm": 0.10300309211015701,
      "learning_rate": 2.9246063167965963e-07,
      "loss": 0.0058,
      "step": 407
    },
    {
      "epoch": 0.8927789934354485,
      "grad_norm": 1.1593304872512817,
      "learning_rate": 2.809889307786856e-07,
      "loss": 0.0794,
      "step": 408
    },
    {
      "epoch": 0.8949671772428884,
      "grad_norm": 1.1079577207565308,
      "learning_rate": 2.697402359203638e-07,
      "loss": 0.1124,
      "step": 409
    },
    {
      "epoch": 0.8971553610503282,
      "grad_norm": 1.9490385055541992,
      "learning_rate": 2.587150786836407e-07,
      "loss": 0.0788,
      "step": 410
    },
    {
      "epoch": 0.899343544857768,
      "grad_norm": 1.0399385690689087,
      "learning_rate": 2.4791398008375545e-07,
      "loss": 0.1243,
      "step": 411
    },
    {
      "epoch": 0.9015317286652079,
      "grad_norm": 3.2320756912231445,
      "learning_rate": 2.3733745054762059e-07,
      "loss": 0.1042,
      "step": 412
    },
    {
      "epoch": 0.9037199124726477,
      "grad_norm": 0.15835551917552948,
      "learning_rate": 2.2698598988970422e-07,
      "loss": 0.0059,
      "step": 413
    },
    {
      "epoch": 0.9059080962800875,
      "grad_norm": 1.1656138896942139,
      "learning_rate": 2.1686008728840301e-07,
      "loss": 0.1582,
      "step": 414
    },
    {
      "epoch": 0.9080962800875274,
      "grad_norm": 0.4506356120109558,
      "learning_rate": 2.0696022126293126e-07,
      "loss": 0.0122,
      "step": 415
    },
    {
      "epoch": 0.9102844638949672,
      "grad_norm": 0.027121560648083687,
      "learning_rate": 1.9728685965070604e-07,
      "loss": 0.0014,
      "step": 416
    },
    {
      "epoch": 0.912472647702407,
      "grad_norm": 0.1574181616306305,
      "learning_rate": 1.8784045958523623e-07,
      "loss": 0.0059,
      "step": 417
    },
    {
      "epoch": 0.9146608315098468,
      "grad_norm": 0.5923903584480286,
      "learning_rate": 1.786214674745218e-07,
      "loss": 0.0978,
      "step": 418
    },
    {
      "epoch": 0.9168490153172867,
      "grad_norm": 0.08655330538749695,
      "learning_rate": 1.6963031897995863e-07,
      "loss": 0.0047,
      "step": 419
    },
    {
      "epoch": 0.9190371991247265,
      "grad_norm": 0.46953630447387695,
      "learning_rate": 1.6086743899575042e-07,
      "loss": 0.0135,
      "step": 420
    },
    {
      "epoch": 0.9212253829321663,
      "grad_norm": 1.7530204057693481,
      "learning_rate": 1.523332416288259e-07,
      "loss": 0.117,
      "step": 421
    },
    {
      "epoch": 0.9234135667396062,
      "grad_norm": 0.6124274134635925,
      "learning_rate": 1.4402813017927396e-07,
      "loss": 0.0279,
      "step": 422
    },
    {
      "epoch": 0.925601750547046,
      "grad_norm": 0.8682643175125122,
      "learning_rate": 1.3595249712128334e-07,
      "loss": 0.058,
      "step": 423
    },
    {
      "epoch": 0.9277899343544858,
      "grad_norm": 0.6341071128845215,
      "learning_rate": 1.28106724084594e-07,
      "loss": 0.05,
      "step": 424
    },
    {
      "epoch": 0.9299781181619255,
      "grad_norm": 1.4174789190292358,
      "learning_rate": 1.2049118183646403e-07,
      "loss": 0.0674,
      "step": 425
    },
    {
      "epoch": 0.9321663019693655,
      "grad_norm": 0.15165479481220245,
      "learning_rate": 1.1310623026414891e-07,
      "loss": 0.0072,
      "step": 426
    },
    {
      "epoch": 0.9343544857768052,
      "grad_norm": 0.005760813597589731,
      "learning_rate": 1.059522183578926e-07,
      "loss": 0.0004,
      "step": 427
    },
    {
      "epoch": 0.936542669584245,
      "grad_norm": 0.08940393477678299,
      "learning_rate": 9.902948419443669e-08,
      "loss": 0.0042,
      "step": 428
    },
    {
      "epoch": 0.9387308533916849,
      "grad_norm": 0.847574770450592,
      "learning_rate": 9.233835492104326e-08,
      "loss": 0.0574,
      "step": 429
    },
    {
      "epoch": 0.9409190371991247,
      "grad_norm": 0.9758285284042358,
      "learning_rate": 8.587914674003384e-08,
      "loss": 0.1419,
      "step": 430
    },
    {
      "epoch": 0.9431072210065645,
      "grad_norm": 0.23801711201667786,
      "learning_rate": 7.965216489384919e-08,
      "loss": 0.0109,
      "step": 431
    },
    {
      "epoch": 0.9452954048140044,
      "grad_norm": 1.3882057666778564,
      "learning_rate": 7.365770365062308e-08,
      "loss": 0.1153,
      "step": 432
    },
    {
      "epoch": 0.9474835886214442,
      "grad_norm": 0.07280251383781433,
      "learning_rate": 6.789604629027614e-08,
      "loss": 0.0023,
      "step": 433
    },
    {
      "epoch": 0.949671772428884,
      "grad_norm": 0.7810183167457581,
      "learning_rate": 6.236746509112824e-08,
      "loss": 0.0173,
      "step": 434
    },
    {
      "epoch": 0.9518599562363238,
      "grad_norm": 1.2599942684173584,
      "learning_rate": 5.707222131703216e-08,
      "loss": 0.0871,
      "step": 435
    },
    {
      "epoch": 0.9540481400437637,
      "grad_norm": 1.3363019227981567,
      "learning_rate": 5.201056520502734e-08,
      "loss": 0.095,
      "step": 436
    },
    {
      "epoch": 0.9562363238512035,
      "grad_norm": 0.645294189453125,
      "learning_rate": 4.718273595351486e-08,
      "loss": 0.0762,
      "step": 437
    },
    {
      "epoch": 0.9584245076586433,
      "grad_norm": 1.3120590448379517,
      "learning_rate": 4.25889617109515e-08,
      "loss": 0.189,
      "step": 438
    },
    {
      "epoch": 0.9606126914660832,
      "grad_norm": 1.1475335359573364,
      "learning_rate": 3.8229459565070074e-08,
      "loss": 0.0938,
      "step": 439
    },
    {
      "epoch": 0.962800875273523,
      "grad_norm": 1.0089627504348755,
      "learning_rate": 3.410443553262033e-08,
      "loss": 0.1169,
      "step": 440
    },
    {
      "epoch": 0.9649890590809628,
      "grad_norm": 0.32787927985191345,
      "learning_rate": 3.0214084549632925e-08,
      "loss": 0.0151,
      "step": 441
    },
    {
      "epoch": 0.9671772428884027,
      "grad_norm": 0.09323866665363312,
      "learning_rate": 2.6558590462207322e-08,
      "loss": 0.0049,
      "step": 442
    },
    {
      "epoch": 0.9693654266958425,
      "grad_norm": 0.1898127794265747,
      "learning_rate": 2.3138126017822614e-08,
      "loss": 0.0057,
      "step": 443
    },
    {
      "epoch": 0.9715536105032823,
      "grad_norm": 0.574744462966919,
      "learning_rate": 1.99528528571763e-08,
      "loss": 0.0439,
      "step": 444
    },
    {
      "epoch": 0.973741794310722,
      "grad_norm": 0.10907912254333496,
      "learning_rate": 1.7002921506544812e-08,
      "loss": 0.006,
      "step": 445
    },
    {
      "epoch": 0.975929978118162,
      "grad_norm": 0.15643493831157684,
      "learning_rate": 1.4288471370669244e-08,
      "loss": 0.0064,
      "step": 446
    },
    {
      "epoch": 0.9781181619256017,
      "grad_norm": 0.749664843082428,
      "learning_rate": 1.1809630726167808e-08,
      "loss": 0.1016,
      "step": 447
    },
    {
      "epoch": 0.9803063457330415,
      "grad_norm": 0.7018001079559326,
      "learning_rate": 9.566516715474594e-09,
      "loss": 0.0825,
      "step": 448
    },
    {
      "epoch": 0.9824945295404814,
      "grad_norm": 0.22933605313301086,
      "learning_rate": 7.559235341302872e-09,
      "loss": 0.0104,
      "step": 449
    },
    {
      "epoch": 0.9846827133479212,
      "grad_norm": 0.11052269488573074,
      "learning_rate": 5.787881461636891e-09,
      "loss": 0.0053,
      "step": 450
    },
    {
      "epoch": 0.986870897155361,
      "grad_norm": 1.5405389070510864,
      "learning_rate": 4.252538785248228e-09,
      "loss": 0.0951,
      "step": 451
    },
    {
      "epoch": 0.9890590809628009,
      "grad_norm": 1.2305186986923218,
      "learning_rate": 2.9532798677395226e-09,
      "loss": 0.061,
      "step": 452
    },
    {
      "epoch": 0.9912472647702407,
      "grad_norm": 0.015914125367999077,
      "learning_rate": 1.8901661081172084e-09,
      "loss": 0.0008,
      "step": 453
    },
    {
      "epoch": 0.9934354485776805,
      "grad_norm": 0.09280901402235031,
      "learning_rate": 1.0632477458888401e-09,
      "loss": 0.0053,
      "step": 454
    },
    {
      "epoch": 0.9956236323851203,
      "grad_norm": 0.08597525209188461,
      "learning_rate": 4.725638586894344e-10,
      "loss": 0.0052,
      "step": 455
    },
    {
      "epoch": 0.9978118161925602,
      "grad_norm": 0.23178566992282867,
      "learning_rate": 1.1814236043405924e-10,
      "loss": 0.0129,
      "step": 456
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.23055201768875122,
      "learning_rate": 0.0,
      "loss": 0.0131,
      "step": 457
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.17647058823529413,
      "eval_loss": 0.03364944830536842,
      "eval_runtime": 1068.5087,
      "eval_samples_per_second": 0.191,
      "eval_steps_per_second": 0.191,
      "step": 457
    }
  ],
  "logging_steps": 1,
  "max_steps": 457,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.817470351103304e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
