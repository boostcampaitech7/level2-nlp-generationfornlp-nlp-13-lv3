{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1827,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005473453749315818,
      "grad_norm": 1.3655444383621216,
      "learning_rate": 9.999992607989888e-06,
      "loss": 0.8917,
      "step": 1
    },
    {
      "epoch": 0.0010946907498631637,
      "grad_norm": 1.2899166345596313,
      "learning_rate": 9.999970431981408e-06,
      "loss": 0.5421,
      "step": 2
    },
    {
      "epoch": 0.0016420361247947454,
      "grad_norm": 1.1164754629135132,
      "learning_rate": 9.999933472040129e-06,
      "loss": 0.8062,
      "step": 3
    },
    {
      "epoch": 0.0021893814997263274,
      "grad_norm": 1.2152819633483887,
      "learning_rate": 9.999881728275334e-06,
      "loss": 0.6148,
      "step": 4
    },
    {
      "epoch": 0.002736726874657909,
      "grad_norm": 1.3578966856002808,
      "learning_rate": 9.99981520084002e-06,
      "loss": 0.5651,
      "step": 5
    },
    {
      "epoch": 0.003284072249589491,
      "grad_norm": 1.248755931854248,
      "learning_rate": 9.999733889930897e-06,
      "loss": 0.5451,
      "step": 6
    },
    {
      "epoch": 0.0038314176245210726,
      "grad_norm": 1.5810112953186035,
      "learning_rate": 9.999637795788383e-06,
      "loss": 0.5618,
      "step": 7
    },
    {
      "epoch": 0.004378762999452655,
      "grad_norm": 1.2505470514297485,
      "learning_rate": 9.999526918696613e-06,
      "loss": 0.5799,
      "step": 8
    },
    {
      "epoch": 0.0049261083743842365,
      "grad_norm": 1.4498575925827026,
      "learning_rate": 9.999401258983426e-06,
      "loss": 0.5304,
      "step": 9
    },
    {
      "epoch": 0.005473453749315818,
      "grad_norm": 1.7860374450683594,
      "learning_rate": 9.999260817020373e-06,
      "loss": 0.6904,
      "step": 10
    },
    {
      "epoch": 0.0060207991242474,
      "grad_norm": 1.2950209379196167,
      "learning_rate": 9.999105593222714e-06,
      "loss": 0.4599,
      "step": 11
    },
    {
      "epoch": 0.006568144499178982,
      "grad_norm": 1.2054051160812378,
      "learning_rate": 9.998935588049414e-06,
      "loss": 0.3366,
      "step": 12
    },
    {
      "epoch": 0.0071154898741105635,
      "grad_norm": 1.776957631111145,
      "learning_rate": 9.998750802003148e-06,
      "loss": 0.6046,
      "step": 13
    },
    {
      "epoch": 0.007662835249042145,
      "grad_norm": 1.2920169830322266,
      "learning_rate": 9.99855123563029e-06,
      "loss": 0.3139,
      "step": 14
    },
    {
      "epoch": 0.008210180623973728,
      "grad_norm": 1.5033079385757446,
      "learning_rate": 9.99833688952092e-06,
      "loss": 0.4005,
      "step": 15
    },
    {
      "epoch": 0.00875752599890531,
      "grad_norm": 1.36214280128479,
      "learning_rate": 9.998107764308815e-06,
      "loss": 0.2695,
      "step": 16
    },
    {
      "epoch": 0.009304871373836891,
      "grad_norm": 0.8397142887115479,
      "learning_rate": 9.997863860671457e-06,
      "loss": 0.1657,
      "step": 17
    },
    {
      "epoch": 0.009852216748768473,
      "grad_norm": 1.9673718214035034,
      "learning_rate": 9.997605179330018e-06,
      "loss": 0.446,
      "step": 18
    },
    {
      "epoch": 0.010399562123700055,
      "grad_norm": 0.7945515513420105,
      "learning_rate": 9.99733172104937e-06,
      "loss": 0.1794,
      "step": 19
    },
    {
      "epoch": 0.010946907498631636,
      "grad_norm": 0.7620091438293457,
      "learning_rate": 9.997043486638076e-06,
      "loss": 0.1457,
      "step": 20
    },
    {
      "epoch": 0.011494252873563218,
      "grad_norm": 0.8933471441268921,
      "learning_rate": 9.996740476948386e-06,
      "loss": 0.1694,
      "step": 21
    },
    {
      "epoch": 0.0120415982484948,
      "grad_norm": 1.7631518840789795,
      "learning_rate": 9.996422692876242e-06,
      "loss": 0.3776,
      "step": 22
    },
    {
      "epoch": 0.012588943623426382,
      "grad_norm": 0.9656022191047668,
      "learning_rate": 9.996090135361269e-06,
      "loss": 0.1717,
      "step": 23
    },
    {
      "epoch": 0.013136288998357963,
      "grad_norm": 1.0638951063156128,
      "learning_rate": 9.995742805386775e-06,
      "loss": 0.3095,
      "step": 24
    },
    {
      "epoch": 0.013683634373289545,
      "grad_norm": 0.35801637172698975,
      "learning_rate": 9.995380703979744e-06,
      "loss": 0.0656,
      "step": 25
    },
    {
      "epoch": 0.014230979748221127,
      "grad_norm": 0.44991573691368103,
      "learning_rate": 9.995003832210843e-06,
      "loss": 0.0633,
      "step": 26
    },
    {
      "epoch": 0.014778325123152709,
      "grad_norm": 0.5955299735069275,
      "learning_rate": 9.994612191194407e-06,
      "loss": 0.1037,
      "step": 27
    },
    {
      "epoch": 0.01532567049808429,
      "grad_norm": 0.39537593722343445,
      "learning_rate": 9.994205782088438e-06,
      "loss": 0.0582,
      "step": 28
    },
    {
      "epoch": 0.015873015873015872,
      "grad_norm": 0.25289902091026306,
      "learning_rate": 9.993784606094612e-06,
      "loss": 0.0356,
      "step": 29
    },
    {
      "epoch": 0.016420361247947456,
      "grad_norm": 0.507150411605835,
      "learning_rate": 9.993348664458263e-06,
      "loss": 0.0614,
      "step": 30
    },
    {
      "epoch": 0.016967706622879036,
      "grad_norm": 0.30564624071121216,
      "learning_rate": 9.992897958468386e-06,
      "loss": 0.0488,
      "step": 31
    },
    {
      "epoch": 0.01751505199781062,
      "grad_norm": 1.1908172369003296,
      "learning_rate": 9.992432489457626e-06,
      "loss": 0.1376,
      "step": 32
    },
    {
      "epoch": 0.0180623973727422,
      "grad_norm": 0.28160253167152405,
      "learning_rate": 9.991952258802288e-06,
      "loss": 0.0302,
      "step": 33
    },
    {
      "epoch": 0.018609742747673783,
      "grad_norm": 0.23844848573207855,
      "learning_rate": 9.99145726792232e-06,
      "loss": 0.026,
      "step": 34
    },
    {
      "epoch": 0.019157088122605363,
      "grad_norm": 0.2693338692188263,
      "learning_rate": 9.990947518281312e-06,
      "loss": 0.0283,
      "step": 35
    },
    {
      "epoch": 0.019704433497536946,
      "grad_norm": 0.1960669606924057,
      "learning_rate": 9.990423011386489e-06,
      "loss": 0.0212,
      "step": 36
    },
    {
      "epoch": 0.020251778872468526,
      "grad_norm": 0.5815450549125671,
      "learning_rate": 9.989883748788724e-06,
      "loss": 0.0569,
      "step": 37
    },
    {
      "epoch": 0.02079912424740011,
      "grad_norm": 0.1244417130947113,
      "learning_rate": 9.989329732082504e-06,
      "loss": 0.013,
      "step": 38
    },
    {
      "epoch": 0.021346469622331693,
      "grad_norm": 0.35323432087898254,
      "learning_rate": 9.98876096290595e-06,
      "loss": 0.0262,
      "step": 39
    },
    {
      "epoch": 0.021893814997263273,
      "grad_norm": 1.1206235885620117,
      "learning_rate": 9.988177442940803e-06,
      "loss": 0.2586,
      "step": 40
    },
    {
      "epoch": 0.022441160372194856,
      "grad_norm": 0.2701440751552582,
      "learning_rate": 9.987579173912413e-06,
      "loss": 0.0228,
      "step": 41
    },
    {
      "epoch": 0.022988505747126436,
      "grad_norm": 2.2235307693481445,
      "learning_rate": 9.986966157589751e-06,
      "loss": 0.1254,
      "step": 42
    },
    {
      "epoch": 0.02353585112205802,
      "grad_norm": 0.13449810445308685,
      "learning_rate": 9.986338395785377e-06,
      "loss": 0.0106,
      "step": 43
    },
    {
      "epoch": 0.0240831964969896,
      "grad_norm": 1.1059627532958984,
      "learning_rate": 9.985695890355467e-06,
      "loss": 0.1104,
      "step": 44
    },
    {
      "epoch": 0.024630541871921183,
      "grad_norm": 0.7324213981628418,
      "learning_rate": 9.98503864319978e-06,
      "loss": 0.0591,
      "step": 45
    },
    {
      "epoch": 0.025177887246852763,
      "grad_norm": 0.077621228992939,
      "learning_rate": 9.98436665626167e-06,
      "loss": 0.007,
      "step": 46
    },
    {
      "epoch": 0.025725232621784347,
      "grad_norm": 0.04926523193717003,
      "learning_rate": 9.983679931528068e-06,
      "loss": 0.0048,
      "step": 47
    },
    {
      "epoch": 0.026272577996715927,
      "grad_norm": 0.08407854288816452,
      "learning_rate": 9.982978471029485e-06,
      "loss": 0.0065,
      "step": 48
    },
    {
      "epoch": 0.02681992337164751,
      "grad_norm": 0.049823418259620667,
      "learning_rate": 9.982262276840002e-06,
      "loss": 0.004,
      "step": 49
    },
    {
      "epoch": 0.02736726874657909,
      "grad_norm": 0.055847786366939545,
      "learning_rate": 9.981531351077266e-06,
      "loss": 0.0053,
      "step": 50
    },
    {
      "epoch": 0.027914614121510674,
      "grad_norm": 0.047207485884428024,
      "learning_rate": 9.980785695902481e-06,
      "loss": 0.0034,
      "step": 51
    },
    {
      "epoch": 0.028461959496442254,
      "grad_norm": 3.061703681945801,
      "learning_rate": 9.980025313520403e-06,
      "loss": 0.3171,
      "step": 52
    },
    {
      "epoch": 0.029009304871373837,
      "grad_norm": 1.731115460395813,
      "learning_rate": 9.979250206179333e-06,
      "loss": 0.0898,
      "step": 53
    },
    {
      "epoch": 0.029556650246305417,
      "grad_norm": 0.04649697616696358,
      "learning_rate": 9.978460376171113e-06,
      "loss": 0.0034,
      "step": 54
    },
    {
      "epoch": 0.030103995621237,
      "grad_norm": 0.10942641645669937,
      "learning_rate": 9.977655825831114e-06,
      "loss": 0.0063,
      "step": 55
    },
    {
      "epoch": 0.03065134099616858,
      "grad_norm": 0.23842106759548187,
      "learning_rate": 9.976836557538234e-06,
      "loss": 0.0134,
      "step": 56
    },
    {
      "epoch": 0.031198686371100164,
      "grad_norm": 0.020831553265452385,
      "learning_rate": 9.97600257371489e-06,
      "loss": 0.0017,
      "step": 57
    },
    {
      "epoch": 0.031746031746031744,
      "grad_norm": 0.03266531229019165,
      "learning_rate": 9.975153876827008e-06,
      "loss": 0.0022,
      "step": 58
    },
    {
      "epoch": 0.03229337712096333,
      "grad_norm": 0.04754291847348213,
      "learning_rate": 9.974290469384019e-06,
      "loss": 0.0031,
      "step": 59
    },
    {
      "epoch": 0.03284072249589491,
      "grad_norm": 0.0744960829615593,
      "learning_rate": 9.973412353938847e-06,
      "loss": 0.0046,
      "step": 60
    },
    {
      "epoch": 0.033388067870826495,
      "grad_norm": 0.04004577919840813,
      "learning_rate": 9.97251953308791e-06,
      "loss": 0.0026,
      "step": 61
    },
    {
      "epoch": 0.03393541324575807,
      "grad_norm": 0.01883239857852459,
      "learning_rate": 9.971612009471105e-06,
      "loss": 0.0013,
      "step": 62
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 0.018762197345495224,
      "learning_rate": 9.970689785771798e-06,
      "loss": 0.0013,
      "step": 63
    },
    {
      "epoch": 0.03503010399562124,
      "grad_norm": 0.03573403134942055,
      "learning_rate": 9.969752864716828e-06,
      "loss": 0.0029,
      "step": 64
    },
    {
      "epoch": 0.03557744937055282,
      "grad_norm": 0.0522276870906353,
      "learning_rate": 9.968801249076484e-06,
      "loss": 0.0038,
      "step": 65
    },
    {
      "epoch": 0.0361247947454844,
      "grad_norm": 2.526148557662964,
      "learning_rate": 9.967834941664508e-06,
      "loss": 0.5409,
      "step": 66
    },
    {
      "epoch": 0.03667214012041598,
      "grad_norm": 0.028796246275305748,
      "learning_rate": 9.96685394533808e-06,
      "loss": 0.002,
      "step": 67
    },
    {
      "epoch": 0.037219485495347565,
      "grad_norm": 4.1738667488098145,
      "learning_rate": 9.965858262997817e-06,
      "loss": 0.32,
      "step": 68
    },
    {
      "epoch": 0.03776683087027915,
      "grad_norm": 0.30512574315071106,
      "learning_rate": 9.964847897587753e-06,
      "loss": 0.0122,
      "step": 69
    },
    {
      "epoch": 0.038314176245210725,
      "grad_norm": 0.04131510481238365,
      "learning_rate": 9.963822852095344e-06,
      "loss": 0.0022,
      "step": 70
    },
    {
      "epoch": 0.03886152162014231,
      "grad_norm": 0.017993789166212082,
      "learning_rate": 9.962783129551447e-06,
      "loss": 0.001,
      "step": 71
    },
    {
      "epoch": 0.03940886699507389,
      "grad_norm": 3.031198263168335,
      "learning_rate": 9.961728733030318e-06,
      "loss": 0.2249,
      "step": 72
    },
    {
      "epoch": 0.039956212370005476,
      "grad_norm": 0.015394095331430435,
      "learning_rate": 9.9606596656496e-06,
      "loss": 0.0013,
      "step": 73
    },
    {
      "epoch": 0.04050355774493705,
      "grad_norm": 0.025913352146744728,
      "learning_rate": 9.959575930570318e-06,
      "loss": 0.0012,
      "step": 74
    },
    {
      "epoch": 0.041050903119868636,
      "grad_norm": 0.029639683663845062,
      "learning_rate": 9.958477530996862e-06,
      "loss": 0.0026,
      "step": 75
    },
    {
      "epoch": 0.04159824849480022,
      "grad_norm": 0.039415184408426285,
      "learning_rate": 9.957364470176986e-06,
      "loss": 0.0024,
      "step": 76
    },
    {
      "epoch": 0.0421455938697318,
      "grad_norm": 0.054223496466875076,
      "learning_rate": 9.95623675140179e-06,
      "loss": 0.0034,
      "step": 77
    },
    {
      "epoch": 0.042692939244663386,
      "grad_norm": 2.5645596981048584,
      "learning_rate": 9.955094378005723e-06,
      "loss": 0.1499,
      "step": 78
    },
    {
      "epoch": 0.04324028461959496,
      "grad_norm": 0.02336292527616024,
      "learning_rate": 9.953937353366551e-06,
      "loss": 0.0016,
      "step": 79
    },
    {
      "epoch": 0.043787629994526546,
      "grad_norm": 0.8025956749916077,
      "learning_rate": 9.952765680905378e-06,
      "loss": 0.0389,
      "step": 80
    },
    {
      "epoch": 0.04433497536945813,
      "grad_norm": 0.22243143618106842,
      "learning_rate": 9.951579364086603e-06,
      "loss": 0.0096,
      "step": 81
    },
    {
      "epoch": 0.04488232074438971,
      "grad_norm": 0.01292973943054676,
      "learning_rate": 9.950378406417935e-06,
      "loss": 0.001,
      "step": 82
    },
    {
      "epoch": 0.04542966611932129,
      "grad_norm": 0.07396076619625092,
      "learning_rate": 9.949162811450373e-06,
      "loss": 0.0048,
      "step": 83
    },
    {
      "epoch": 0.04597701149425287,
      "grad_norm": 0.021583886817097664,
      "learning_rate": 9.947932582778188e-06,
      "loss": 0.0015,
      "step": 84
    },
    {
      "epoch": 0.046524356869184456,
      "grad_norm": 0.029099684208631516,
      "learning_rate": 9.946687724038929e-06,
      "loss": 0.0018,
      "step": 85
    },
    {
      "epoch": 0.04707170224411604,
      "grad_norm": 0.013434143736958504,
      "learning_rate": 9.945428238913396e-06,
      "loss": 0.001,
      "step": 86
    },
    {
      "epoch": 0.047619047619047616,
      "grad_norm": 0.012765005230903625,
      "learning_rate": 9.944154131125643e-06,
      "loss": 0.0009,
      "step": 87
    },
    {
      "epoch": 0.0481663929939792,
      "grad_norm": 0.030429109930992126,
      "learning_rate": 9.942865404442955e-06,
      "loss": 0.0021,
      "step": 88
    },
    {
      "epoch": 0.04871373836891078,
      "grad_norm": 4.361706733703613,
      "learning_rate": 9.941562062675848e-06,
      "loss": 0.291,
      "step": 89
    },
    {
      "epoch": 0.04926108374384237,
      "grad_norm": 4.7438812255859375,
      "learning_rate": 9.940244109678043e-06,
      "loss": 0.4362,
      "step": 90
    },
    {
      "epoch": 0.04980842911877394,
      "grad_norm": 0.011661645956337452,
      "learning_rate": 9.938911549346473e-06,
      "loss": 0.0009,
      "step": 91
    },
    {
      "epoch": 0.05035577449370553,
      "grad_norm": 0.07497643679380417,
      "learning_rate": 9.937564385621254e-06,
      "loss": 0.0058,
      "step": 92
    },
    {
      "epoch": 0.05090311986863711,
      "grad_norm": 0.037235602736473083,
      "learning_rate": 9.936202622485687e-06,
      "loss": 0.0019,
      "step": 93
    },
    {
      "epoch": 0.051450465243568694,
      "grad_norm": 2.5072927474975586,
      "learning_rate": 9.93482626396624e-06,
      "loss": 0.4071,
      "step": 94
    },
    {
      "epoch": 0.05199781061850027,
      "grad_norm": 2.388990640640259,
      "learning_rate": 9.933435314132534e-06,
      "loss": 0.1287,
      "step": 95
    },
    {
      "epoch": 0.052545155993431854,
      "grad_norm": 2.973095178604126,
      "learning_rate": 9.932029777097333e-06,
      "loss": 0.1193,
      "step": 96
    },
    {
      "epoch": 0.05309250136836344,
      "grad_norm": 0.03974832221865654,
      "learning_rate": 9.93060965701654e-06,
      "loss": 0.0022,
      "step": 97
    },
    {
      "epoch": 0.05363984674329502,
      "grad_norm": 0.2817555069923401,
      "learning_rate": 9.929174958089167e-06,
      "loss": 0.0142,
      "step": 98
    },
    {
      "epoch": 0.054187192118226604,
      "grad_norm": 1.1841061115264893,
      "learning_rate": 9.927725684557339e-06,
      "loss": 0.0476,
      "step": 99
    },
    {
      "epoch": 0.05473453749315818,
      "grad_norm": 0.015623957850039005,
      "learning_rate": 9.926261840706275e-06,
      "loss": 0.001,
      "step": 100
    },
    {
      "epoch": 0.055281882868089764,
      "grad_norm": 0.0449078269302845,
      "learning_rate": 9.924783430864273e-06,
      "loss": 0.0026,
      "step": 101
    },
    {
      "epoch": 0.05582922824302135,
      "grad_norm": 0.020737232640385628,
      "learning_rate": 9.923290459402701e-06,
      "loss": 0.0011,
      "step": 102
    },
    {
      "epoch": 0.05637657361795293,
      "grad_norm": 0.006141902878880501,
      "learning_rate": 9.921782930735985e-06,
      "loss": 0.0004,
      "step": 103
    },
    {
      "epoch": 0.05692391899288451,
      "grad_norm": 0.02859128825366497,
      "learning_rate": 9.92026084932159e-06,
      "loss": 0.0015,
      "step": 104
    },
    {
      "epoch": 0.05747126436781609,
      "grad_norm": 1.3648432493209839,
      "learning_rate": 9.918724219660013e-06,
      "loss": 0.0365,
      "step": 105
    },
    {
      "epoch": 0.058018609742747675,
      "grad_norm": 0.004119763616472483,
      "learning_rate": 9.917173046294769e-06,
      "loss": 0.0003,
      "step": 106
    },
    {
      "epoch": 0.05856595511767926,
      "grad_norm": 0.08560014516115189,
      "learning_rate": 9.91560733381237e-06,
      "loss": 0.0035,
      "step": 107
    },
    {
      "epoch": 0.059113300492610835,
      "grad_norm": 0.005785383749753237,
      "learning_rate": 9.914027086842323e-06,
      "loss": 0.0004,
      "step": 108
    },
    {
      "epoch": 0.05966064586754242,
      "grad_norm": 0.04567496106028557,
      "learning_rate": 9.912432310057108e-06,
      "loss": 0.0031,
      "step": 109
    },
    {
      "epoch": 0.060207991242474,
      "grad_norm": 0.10184209048748016,
      "learning_rate": 9.910823008172168e-06,
      "loss": 0.0051,
      "step": 110
    },
    {
      "epoch": 0.060755336617405585,
      "grad_norm": 0.031166184693574905,
      "learning_rate": 9.909199185945893e-06,
      "loss": 0.0014,
      "step": 111
    },
    {
      "epoch": 0.06130268199233716,
      "grad_norm": 0.01992623694241047,
      "learning_rate": 9.907560848179607e-06,
      "loss": 0.0012,
      "step": 112
    },
    {
      "epoch": 0.061850027367268745,
      "grad_norm": 0.004671156406402588,
      "learning_rate": 9.905907999717551e-06,
      "loss": 0.0003,
      "step": 113
    },
    {
      "epoch": 0.06239737274220033,
      "grad_norm": 0.5064135789871216,
      "learning_rate": 9.90424064544688e-06,
      "loss": 0.0248,
      "step": 114
    },
    {
      "epoch": 0.06294471811713191,
      "grad_norm": 2.9117133617401123,
      "learning_rate": 9.902558790297631e-06,
      "loss": 0.511,
      "step": 115
    },
    {
      "epoch": 0.06349206349206349,
      "grad_norm": 1.4276529550552368,
      "learning_rate": 9.900862439242719e-06,
      "loss": 0.1255,
      "step": 116
    },
    {
      "epoch": 0.06403940886699508,
      "grad_norm": 1.5085148811340332,
      "learning_rate": 9.899151597297923e-06,
      "loss": 0.0509,
      "step": 117
    },
    {
      "epoch": 0.06458675424192666,
      "grad_norm": 0.01620265655219555,
      "learning_rate": 9.897426269521868e-06,
      "loss": 0.0008,
      "step": 118
    },
    {
      "epoch": 0.06513409961685823,
      "grad_norm": 4.5460205078125,
      "learning_rate": 9.895686461016007e-06,
      "loss": 0.2241,
      "step": 119
    },
    {
      "epoch": 0.06568144499178982,
      "grad_norm": 0.0054456209763884544,
      "learning_rate": 9.893932176924616e-06,
      "loss": 0.0004,
      "step": 120
    },
    {
      "epoch": 0.0662287903667214,
      "grad_norm": 0.019272517412900925,
      "learning_rate": 9.892163422434767e-06,
      "loss": 0.0011,
      "step": 121
    },
    {
      "epoch": 0.06677613574165299,
      "grad_norm": 5.605646133422852,
      "learning_rate": 9.890380202776323e-06,
      "loss": 0.3302,
      "step": 122
    },
    {
      "epoch": 0.06732348111658457,
      "grad_norm": 0.006593388505280018,
      "learning_rate": 9.888582523221912e-06,
      "loss": 0.0004,
      "step": 123
    },
    {
      "epoch": 0.06787082649151614,
      "grad_norm": 1.452279806137085,
      "learning_rate": 9.886770389086923e-06,
      "loss": 0.3062,
      "step": 124
    },
    {
      "epoch": 0.06841817186644773,
      "grad_norm": 0.024616796523332596,
      "learning_rate": 9.884943805729481e-06,
      "loss": 0.0011,
      "step": 125
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.02932334505021572,
      "learning_rate": 9.883102778550434e-06,
      "loss": 0.0017,
      "step": 126
    },
    {
      "epoch": 0.06951286261631089,
      "grad_norm": 2.4326837062835693,
      "learning_rate": 9.88124731299334e-06,
      "loss": 0.5019,
      "step": 127
    },
    {
      "epoch": 0.07006020799124248,
      "grad_norm": 0.015503285452723503,
      "learning_rate": 9.879377414544444e-06,
      "loss": 0.001,
      "step": 128
    },
    {
      "epoch": 0.07060755336617405,
      "grad_norm": 0.01804860308766365,
      "learning_rate": 9.877493088732672e-06,
      "loss": 0.0013,
      "step": 129
    },
    {
      "epoch": 0.07115489874110564,
      "grad_norm": 0.009511834010481834,
      "learning_rate": 9.875594341129607e-06,
      "loss": 0.0005,
      "step": 130
    },
    {
      "epoch": 0.07170224411603722,
      "grad_norm": 2.3239996433258057,
      "learning_rate": 9.873681177349473e-06,
      "loss": 0.2421,
      "step": 131
    },
    {
      "epoch": 0.0722495894909688,
      "grad_norm": 0.15909063816070557,
      "learning_rate": 9.871753603049117e-06,
      "loss": 0.0117,
      "step": 132
    },
    {
      "epoch": 0.07279693486590039,
      "grad_norm": 0.014082671143114567,
      "learning_rate": 9.869811623928001e-06,
      "loss": 0.0008,
      "step": 133
    },
    {
      "epoch": 0.07334428024083196,
      "grad_norm": 1.2785812616348267,
      "learning_rate": 9.86785524572818e-06,
      "loss": 0.2494,
      "step": 134
    },
    {
      "epoch": 0.07389162561576355,
      "grad_norm": 0.05871053785085678,
      "learning_rate": 9.865884474234275e-06,
      "loss": 0.0043,
      "step": 135
    },
    {
      "epoch": 0.07443897099069513,
      "grad_norm": 0.01066194660961628,
      "learning_rate": 9.863899315273475e-06,
      "loss": 0.0007,
      "step": 136
    },
    {
      "epoch": 0.0749863163656267,
      "grad_norm": 0.81246018409729,
      "learning_rate": 9.861899774715504e-06,
      "loss": 0.0633,
      "step": 137
    },
    {
      "epoch": 0.0755336617405583,
      "grad_norm": 2.458688735961914,
      "learning_rate": 9.859885858472614e-06,
      "loss": 0.4321,
      "step": 138
    },
    {
      "epoch": 0.07608100711548987,
      "grad_norm": 0.012773022055625916,
      "learning_rate": 9.857857572499559e-06,
      "loss": 0.0007,
      "step": 139
    },
    {
      "epoch": 0.07662835249042145,
      "grad_norm": 0.9848124980926514,
      "learning_rate": 9.855814922793583e-06,
      "loss": 0.0582,
      "step": 140
    },
    {
      "epoch": 0.07717569786535304,
      "grad_norm": 1.7945340871810913,
      "learning_rate": 9.853757915394403e-06,
      "loss": 0.2129,
      "step": 141
    },
    {
      "epoch": 0.07772304324028462,
      "grad_norm": 0.022208815440535545,
      "learning_rate": 9.851686556384182e-06,
      "loss": 0.0013,
      "step": 142
    },
    {
      "epoch": 0.07827038861521621,
      "grad_norm": 0.014823067001998425,
      "learning_rate": 9.849600851887528e-06,
      "loss": 0.001,
      "step": 143
    },
    {
      "epoch": 0.07881773399014778,
      "grad_norm": 4.168272495269775,
      "learning_rate": 9.847500808071458e-06,
      "loss": 0.4398,
      "step": 144
    },
    {
      "epoch": 0.07936507936507936,
      "grad_norm": 0.08765898644924164,
      "learning_rate": 9.84538643114539e-06,
      "loss": 0.0056,
      "step": 145
    },
    {
      "epoch": 0.07991242474001095,
      "grad_norm": 0.00912446528673172,
      "learning_rate": 9.843257727361124e-06,
      "loss": 0.0006,
      "step": 146
    },
    {
      "epoch": 0.08045977011494253,
      "grad_norm": 0.6443724632263184,
      "learning_rate": 9.841114703012817e-06,
      "loss": 0.0222,
      "step": 147
    },
    {
      "epoch": 0.0810071154898741,
      "grad_norm": 1.218262791633606,
      "learning_rate": 9.838957364436973e-06,
      "loss": 0.2583,
      "step": 148
    },
    {
      "epoch": 0.0815544608648057,
      "grad_norm": 0.10387217253446579,
      "learning_rate": 9.836785718012422e-06,
      "loss": 0.0051,
      "step": 149
    },
    {
      "epoch": 0.08210180623973727,
      "grad_norm": 0.0468461737036705,
      "learning_rate": 9.834599770160296e-06,
      "loss": 0.0027,
      "step": 150
    },
    {
      "epoch": 0.08264915161466886,
      "grad_norm": 0.22243686020374298,
      "learning_rate": 9.832399527344012e-06,
      "loss": 0.0108,
      "step": 151
    },
    {
      "epoch": 0.08319649698960044,
      "grad_norm": 0.11452081054449081,
      "learning_rate": 9.830184996069259e-06,
      "loss": 0.0058,
      "step": 152
    },
    {
      "epoch": 0.08374384236453201,
      "grad_norm": 1.4733725786209106,
      "learning_rate": 9.82795618288397e-06,
      "loss": 0.0991,
      "step": 153
    },
    {
      "epoch": 0.0842911877394636,
      "grad_norm": 1.8733961582183838,
      "learning_rate": 9.82571309437831e-06,
      "loss": 0.07,
      "step": 154
    },
    {
      "epoch": 0.08483853311439518,
      "grad_norm": 0.021173100918531418,
      "learning_rate": 9.823455737184655e-06,
      "loss": 0.0012,
      "step": 155
    },
    {
      "epoch": 0.08538587848932677,
      "grad_norm": 0.04782456159591675,
      "learning_rate": 9.821184117977564e-06,
      "loss": 0.0022,
      "step": 156
    },
    {
      "epoch": 0.08593322386425835,
      "grad_norm": 0.0069906506687402725,
      "learning_rate": 9.81889824347377e-06,
      "loss": 0.0004,
      "step": 157
    },
    {
      "epoch": 0.08648056923918993,
      "grad_norm": 0.32343170046806335,
      "learning_rate": 9.816598120432159e-06,
      "loss": 0.0201,
      "step": 158
    },
    {
      "epoch": 0.08702791461412152,
      "grad_norm": 0.06642960757017136,
      "learning_rate": 9.81428375565374e-06,
      "loss": 0.0033,
      "step": 159
    },
    {
      "epoch": 0.08757525998905309,
      "grad_norm": 4.123462200164795,
      "learning_rate": 9.811955155981641e-06,
      "loss": 0.7053,
      "step": 160
    },
    {
      "epoch": 0.08812260536398467,
      "grad_norm": 0.31419819593429565,
      "learning_rate": 9.809612328301071e-06,
      "loss": 0.0158,
      "step": 161
    },
    {
      "epoch": 0.08866995073891626,
      "grad_norm": 0.009367585182189941,
      "learning_rate": 9.807255279539313e-06,
      "loss": 0.0006,
      "step": 162
    },
    {
      "epoch": 0.08921729611384784,
      "grad_norm": 3.5425283908843994,
      "learning_rate": 9.8048840166657e-06,
      "loss": 0.2014,
      "step": 163
    },
    {
      "epoch": 0.08976464148877943,
      "grad_norm": 0.031086882576346397,
      "learning_rate": 9.80249854669159e-06,
      "loss": 0.0011,
      "step": 164
    },
    {
      "epoch": 0.090311986863711,
      "grad_norm": 0.06080402061343193,
      "learning_rate": 9.80009887667035e-06,
      "loss": 0.0035,
      "step": 165
    },
    {
      "epoch": 0.09085933223864258,
      "grad_norm": 0.027103329077363014,
      "learning_rate": 9.797685013697336e-06,
      "loss": 0.0014,
      "step": 166
    },
    {
      "epoch": 0.09140667761357417,
      "grad_norm": 0.020595962181687355,
      "learning_rate": 9.795256964909868e-06,
      "loss": 0.0009,
      "step": 167
    },
    {
      "epoch": 0.09195402298850575,
      "grad_norm": 0.03514695540070534,
      "learning_rate": 9.792814737487207e-06,
      "loss": 0.0015,
      "step": 168
    },
    {
      "epoch": 0.09250136836343732,
      "grad_norm": 2.151623487472534,
      "learning_rate": 9.790358338650546e-06,
      "loss": 0.1242,
      "step": 169
    },
    {
      "epoch": 0.09304871373836891,
      "grad_norm": 0.012730772607028484,
      "learning_rate": 9.787887775662969e-06,
      "loss": 0.0007,
      "step": 170
    },
    {
      "epoch": 0.09359605911330049,
      "grad_norm": 0.02603985369205475,
      "learning_rate": 9.78540305582945e-06,
      "loss": 0.0013,
      "step": 171
    },
    {
      "epoch": 0.09414340448823208,
      "grad_norm": 0.1406971961259842,
      "learning_rate": 9.78290418649682e-06,
      "loss": 0.0082,
      "step": 172
    },
    {
      "epoch": 0.09469074986316366,
      "grad_norm": 0.014594093896448612,
      "learning_rate": 9.780391175053744e-06,
      "loss": 0.0008,
      "step": 173
    },
    {
      "epoch": 0.09523809523809523,
      "grad_norm": 2.351489782333374,
      "learning_rate": 9.777864028930705e-06,
      "loss": 0.4187,
      "step": 174
    },
    {
      "epoch": 0.09578544061302682,
      "grad_norm": 1.1376105546951294,
      "learning_rate": 9.775322755599979e-06,
      "loss": 0.0667,
      "step": 175
    },
    {
      "epoch": 0.0963327859879584,
      "grad_norm": 0.3136812746524811,
      "learning_rate": 9.77276736257561e-06,
      "loss": 0.0161,
      "step": 176
    },
    {
      "epoch": 0.09688013136288999,
      "grad_norm": 0.029925355687737465,
      "learning_rate": 9.7701978574134e-06,
      "loss": 0.0013,
      "step": 177
    },
    {
      "epoch": 0.09742747673782157,
      "grad_norm": 0.01181731652468443,
      "learning_rate": 9.76761424771087e-06,
      "loss": 0.0007,
      "step": 178
    },
    {
      "epoch": 0.09797482211275314,
      "grad_norm": 0.01413095835596323,
      "learning_rate": 9.765016541107247e-06,
      "loss": 0.0008,
      "step": 179
    },
    {
      "epoch": 0.09852216748768473,
      "grad_norm": 0.0596909373998642,
      "learning_rate": 9.762404745283439e-06,
      "loss": 0.0029,
      "step": 180
    },
    {
      "epoch": 0.09906951286261631,
      "grad_norm": 0.004191346000880003,
      "learning_rate": 9.759778867962017e-06,
      "loss": 0.0002,
      "step": 181
    },
    {
      "epoch": 0.09961685823754789,
      "grad_norm": 0.09016533941030502,
      "learning_rate": 9.757138916907184e-06,
      "loss": 0.0052,
      "step": 182
    },
    {
      "epoch": 0.10016420361247948,
      "grad_norm": 0.7831616997718811,
      "learning_rate": 9.754484899924762e-06,
      "loss": 0.1808,
      "step": 183
    },
    {
      "epoch": 0.10071154898741105,
      "grad_norm": 0.11813922971487045,
      "learning_rate": 9.751816824862152e-06,
      "loss": 0.0058,
      "step": 184
    },
    {
      "epoch": 0.10125889436234264,
      "grad_norm": 2.5723724365234375,
      "learning_rate": 9.749134699608336e-06,
      "loss": 0.1791,
      "step": 185
    },
    {
      "epoch": 0.10180623973727422,
      "grad_norm": 0.010698007419705391,
      "learning_rate": 9.746438532093827e-06,
      "loss": 0.0006,
      "step": 186
    },
    {
      "epoch": 0.1023535851122058,
      "grad_norm": 0.021495478227734566,
      "learning_rate": 9.74372833029067e-06,
      "loss": 0.0008,
      "step": 187
    },
    {
      "epoch": 0.10290093048713739,
      "grad_norm": 0.10986939817667007,
      "learning_rate": 9.741004102212395e-06,
      "loss": 0.005,
      "step": 188
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 0.09254218637943268,
      "learning_rate": 9.738265855914014e-06,
      "loss": 0.0054,
      "step": 189
    },
    {
      "epoch": 0.10399562123700054,
      "grad_norm": 0.995465099811554,
      "learning_rate": 9.735513599491982e-06,
      "loss": 0.0142,
      "step": 190
    },
    {
      "epoch": 0.10454296661193213,
      "grad_norm": 0.0022371739614754915,
      "learning_rate": 9.732747341084185e-06,
      "loss": 0.0001,
      "step": 191
    },
    {
      "epoch": 0.10509031198686371,
      "grad_norm": 0.028587354347109795,
      "learning_rate": 9.729967088869907e-06,
      "loss": 0.0016,
      "step": 192
    },
    {
      "epoch": 0.1056376573617953,
      "grad_norm": 0.006883230991661549,
      "learning_rate": 9.727172851069807e-06,
      "loss": 0.0005,
      "step": 193
    },
    {
      "epoch": 0.10618500273672687,
      "grad_norm": 0.1677386611700058,
      "learning_rate": 9.7243646359459e-06,
      "loss": 0.0051,
      "step": 194
    },
    {
      "epoch": 0.10673234811165845,
      "grad_norm": 0.018670285120606422,
      "learning_rate": 9.721542451801526e-06,
      "loss": 0.0009,
      "step": 195
    },
    {
      "epoch": 0.10727969348659004,
      "grad_norm": 0.12450981885194778,
      "learning_rate": 9.718706306981332e-06,
      "loss": 0.0058,
      "step": 196
    },
    {
      "epoch": 0.10782703886152162,
      "grad_norm": 0.004229319281876087,
      "learning_rate": 9.715856209871243e-06,
      "loss": 0.0003,
      "step": 197
    },
    {
      "epoch": 0.10837438423645321,
      "grad_norm": 0.01869300566613674,
      "learning_rate": 9.712992168898436e-06,
      "loss": 0.0008,
      "step": 198
    },
    {
      "epoch": 0.10892172961138478,
      "grad_norm": 2.7555603981018066,
      "learning_rate": 9.71011419253132e-06,
      "loss": 0.3438,
      "step": 199
    },
    {
      "epoch": 0.10946907498631636,
      "grad_norm": 0.019834227859973907,
      "learning_rate": 9.707222289279508e-06,
      "loss": 0.0014,
      "step": 200
    },
    {
      "epoch": 0.11001642036124795,
      "grad_norm": 0.06497181951999664,
      "learning_rate": 9.704316467693789e-06,
      "loss": 0.0029,
      "step": 201
    },
    {
      "epoch": 0.11056376573617953,
      "grad_norm": 0.008430249989032745,
      "learning_rate": 9.701396736366108e-06,
      "loss": 0.0005,
      "step": 202
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.030042970553040504,
      "learning_rate": 9.698463103929542e-06,
      "loss": 0.0022,
      "step": 203
    },
    {
      "epoch": 0.1116584564860427,
      "grad_norm": 0.0432233065366745,
      "learning_rate": 9.695515579058265e-06,
      "loss": 0.0022,
      "step": 204
    },
    {
      "epoch": 0.11220580186097427,
      "grad_norm": 0.012117008678615093,
      "learning_rate": 9.692554170467529e-06,
      "loss": 0.0007,
      "step": 205
    },
    {
      "epoch": 0.11275314723590586,
      "grad_norm": 2.7579357624053955,
      "learning_rate": 9.689578886913641e-06,
      "loss": 0.1048,
      "step": 206
    },
    {
      "epoch": 0.11330049261083744,
      "grad_norm": 0.015060403384268284,
      "learning_rate": 9.686589737193929e-06,
      "loss": 0.0007,
      "step": 207
    },
    {
      "epoch": 0.11384783798576902,
      "grad_norm": 0.05284305289387703,
      "learning_rate": 9.683586730146727e-06,
      "loss": 0.0019,
      "step": 208
    },
    {
      "epoch": 0.1143951833607006,
      "grad_norm": 1.859195590019226,
      "learning_rate": 9.680569874651336e-06,
      "loss": 0.124,
      "step": 209
    },
    {
      "epoch": 0.11494252873563218,
      "grad_norm": 0.01710464246571064,
      "learning_rate": 9.677539179628005e-06,
      "loss": 0.0011,
      "step": 210
    },
    {
      "epoch": 0.11548987411056376,
      "grad_norm": 0.0024151778779923916,
      "learning_rate": 9.674494654037909e-06,
      "loss": 0.0002,
      "step": 211
    },
    {
      "epoch": 0.11603721948549535,
      "grad_norm": 0.6669631004333496,
      "learning_rate": 9.67143630688311e-06,
      "loss": 0.0355,
      "step": 212
    },
    {
      "epoch": 0.11658456486042693,
      "grad_norm": 0.007927939295768738,
      "learning_rate": 9.668364147206542e-06,
      "loss": 0.0004,
      "step": 213
    },
    {
      "epoch": 0.11713191023535852,
      "grad_norm": 2.277109146118164,
      "learning_rate": 9.665278184091981e-06,
      "loss": 0.2615,
      "step": 214
    },
    {
      "epoch": 0.11767925561029009,
      "grad_norm": 0.006817269138991833,
      "learning_rate": 9.662178426664014e-06,
      "loss": 0.0004,
      "step": 215
    },
    {
      "epoch": 0.11822660098522167,
      "grad_norm": 0.0903991162776947,
      "learning_rate": 9.659064884088017e-06,
      "loss": 0.0037,
      "step": 216
    },
    {
      "epoch": 0.11877394636015326,
      "grad_norm": 0.0019560400396585464,
      "learning_rate": 9.655937565570124e-06,
      "loss": 0.0001,
      "step": 217
    },
    {
      "epoch": 0.11932129173508484,
      "grad_norm": 0.0038291055243462324,
      "learning_rate": 9.652796480357203e-06,
      "loss": 0.0003,
      "step": 218
    },
    {
      "epoch": 0.11986863711001643,
      "grad_norm": 0.014715095050632954,
      "learning_rate": 9.649641637736829e-06,
      "loss": 0.0007,
      "step": 219
    },
    {
      "epoch": 0.120415982484948,
      "grad_norm": 2.2227537631988525,
      "learning_rate": 9.646473047037252e-06,
      "loss": 0.4447,
      "step": 220
    },
    {
      "epoch": 0.12096332785987958,
      "grad_norm": 3.017958879470825,
      "learning_rate": 9.643290717627376e-06,
      "loss": 0.8667,
      "step": 221
    },
    {
      "epoch": 0.12151067323481117,
      "grad_norm": 0.04366392642259598,
      "learning_rate": 9.640094658916723e-06,
      "loss": 0.0024,
      "step": 222
    },
    {
      "epoch": 0.12205801860974275,
      "grad_norm": 0.0045592524111270905,
      "learning_rate": 9.636884880355412e-06,
      "loss": 0.0003,
      "step": 223
    },
    {
      "epoch": 0.12260536398467432,
      "grad_norm": 0.005687805823981762,
      "learning_rate": 9.63366139143413e-06,
      "loss": 0.0004,
      "step": 224
    },
    {
      "epoch": 0.12315270935960591,
      "grad_norm": 1.6736704111099243,
      "learning_rate": 9.630424201684105e-06,
      "loss": 0.0783,
      "step": 225
    },
    {
      "epoch": 0.12370005473453749,
      "grad_norm": 0.017245952039957047,
      "learning_rate": 9.62717332067707e-06,
      "loss": 0.0006,
      "step": 226
    },
    {
      "epoch": 0.12424740010946908,
      "grad_norm": 0.006390247493982315,
      "learning_rate": 9.623908758025243e-06,
      "loss": 0.0003,
      "step": 227
    },
    {
      "epoch": 0.12479474548440066,
      "grad_norm": 0.2859886586666107,
      "learning_rate": 9.620630523381295e-06,
      "loss": 0.0115,
      "step": 228
    },
    {
      "epoch": 0.12534209085933223,
      "grad_norm": 0.0027628119569271803,
      "learning_rate": 9.617338626438326e-06,
      "loss": 0.0002,
      "step": 229
    },
    {
      "epoch": 0.12588943623426382,
      "grad_norm": 3.420689105987549,
      "learning_rate": 9.61403307692983e-06,
      "loss": 0.2646,
      "step": 230
    },
    {
      "epoch": 0.12643678160919541,
      "grad_norm": 1.6848602294921875,
      "learning_rate": 9.610713884629667e-06,
      "loss": 0.0499,
      "step": 231
    },
    {
      "epoch": 0.12698412698412698,
      "grad_norm": 0.011032557114958763,
      "learning_rate": 9.60738105935204e-06,
      "loss": 0.0005,
      "step": 232
    },
    {
      "epoch": 0.12753147235905857,
      "grad_norm": 0.06910665333271027,
      "learning_rate": 9.604034610951458e-06,
      "loss": 0.0021,
      "step": 233
    },
    {
      "epoch": 0.12807881773399016,
      "grad_norm": 0.005227838177233934,
      "learning_rate": 9.600674549322716e-06,
      "loss": 0.0003,
      "step": 234
    },
    {
      "epoch": 0.12862616310892172,
      "grad_norm": 3.5226261615753174,
      "learning_rate": 9.597300884400858e-06,
      "loss": 0.3826,
      "step": 235
    },
    {
      "epoch": 0.1291735084838533,
      "grad_norm": 0.06952756643295288,
      "learning_rate": 9.593913626161148e-06,
      "loss": 0.0036,
      "step": 236
    },
    {
      "epoch": 0.1297208538587849,
      "grad_norm": 0.016257425770163536,
      "learning_rate": 9.590512784619045e-06,
      "loss": 0.0006,
      "step": 237
    },
    {
      "epoch": 0.13026819923371646,
      "grad_norm": 2.5584001541137695,
      "learning_rate": 9.587098369830171e-06,
      "loss": 0.4214,
      "step": 238
    },
    {
      "epoch": 0.13081554460864805,
      "grad_norm": 0.03221333026885986,
      "learning_rate": 9.583670391890285e-06,
      "loss": 0.0025,
      "step": 239
    },
    {
      "epoch": 0.13136288998357964,
      "grad_norm": 0.42730969190597534,
      "learning_rate": 9.580228860935242e-06,
      "loss": 0.0121,
      "step": 240
    },
    {
      "epoch": 0.1319102353585112,
      "grad_norm": 1.2866452932357788,
      "learning_rate": 9.576773787140974e-06,
      "loss": 0.0462,
      "step": 241
    },
    {
      "epoch": 0.1324575807334428,
      "grad_norm": 1.5715864896774292,
      "learning_rate": 9.57330518072346e-06,
      "loss": 0.2623,
      "step": 242
    },
    {
      "epoch": 0.1330049261083744,
      "grad_norm": 0.02781909517943859,
      "learning_rate": 9.569823051938689e-06,
      "loss": 0.0017,
      "step": 243
    },
    {
      "epoch": 0.13355227148330598,
      "grad_norm": 0.011087936349213123,
      "learning_rate": 9.566327411082634e-06,
      "loss": 0.0005,
      "step": 244
    },
    {
      "epoch": 0.13409961685823754,
      "grad_norm": 0.004937173333019018,
      "learning_rate": 9.562818268491216e-06,
      "loss": 0.0003,
      "step": 245
    },
    {
      "epoch": 0.13464696223316913,
      "grad_norm": 0.0030751090962439775,
      "learning_rate": 9.559295634540287e-06,
      "loss": 0.0002,
      "step": 246
    },
    {
      "epoch": 0.13519430760810072,
      "grad_norm": 0.03551468998193741,
      "learning_rate": 9.555759519645584e-06,
      "loss": 0.0015,
      "step": 247
    },
    {
      "epoch": 0.13574165298303228,
      "grad_norm": 0.01322123222053051,
      "learning_rate": 9.552209934262703e-06,
      "loss": 0.0006,
      "step": 248
    },
    {
      "epoch": 0.13628899835796388,
      "grad_norm": 0.014488070271909237,
      "learning_rate": 9.548646888887076e-06,
      "loss": 0.0008,
      "step": 249
    },
    {
      "epoch": 0.13683634373289547,
      "grad_norm": 0.054674409329891205,
      "learning_rate": 9.54507039405393e-06,
      "loss": 0.0021,
      "step": 250
    },
    {
      "epoch": 0.13738368910782703,
      "grad_norm": 3.164015769958496,
      "learning_rate": 9.541480460338255e-06,
      "loss": 0.8382,
      "step": 251
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.81158447265625,
      "learning_rate": 9.537877098354787e-06,
      "loss": 0.0962,
      "step": 252
    },
    {
      "epoch": 0.1384783798576902,
      "grad_norm": 0.011217145249247551,
      "learning_rate": 9.534260318757956e-06,
      "loss": 0.0005,
      "step": 253
    },
    {
      "epoch": 0.13902572523262177,
      "grad_norm": 0.11490277200937271,
      "learning_rate": 9.530630132241876e-06,
      "loss": 0.0052,
      "step": 254
    },
    {
      "epoch": 0.13957307060755336,
      "grad_norm": 0.9270853400230408,
      "learning_rate": 9.526986549540292e-06,
      "loss": 0.1946,
      "step": 255
    },
    {
      "epoch": 0.14012041598248495,
      "grad_norm": 0.5014409422874451,
      "learning_rate": 9.523329581426568e-06,
      "loss": 0.0318,
      "step": 256
    },
    {
      "epoch": 0.14066776135741654,
      "grad_norm": 0.007876098155975342,
      "learning_rate": 9.519659238713642e-06,
      "loss": 0.0004,
      "step": 257
    },
    {
      "epoch": 0.1412151067323481,
      "grad_norm": 0.5999244451522827,
      "learning_rate": 9.515975532253994e-06,
      "loss": 0.1788,
      "step": 258
    },
    {
      "epoch": 0.1417624521072797,
      "grad_norm": 0.039550717920064926,
      "learning_rate": 9.512278472939627e-06,
      "loss": 0.0012,
      "step": 259
    },
    {
      "epoch": 0.1423097974822113,
      "grad_norm": 0.6229004859924316,
      "learning_rate": 9.508568071702016e-06,
      "loss": 0.1584,
      "step": 260
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.004531140439212322,
      "learning_rate": 9.504844339512096e-06,
      "loss": 0.0002,
      "step": 261
    },
    {
      "epoch": 0.14340448823207444,
      "grad_norm": 0.15723533928394318,
      "learning_rate": 9.50110728738021e-06,
      "loss": 0.0075,
      "step": 262
    },
    {
      "epoch": 0.14395183360700603,
      "grad_norm": 0.048570871353149414,
      "learning_rate": 9.49735692635609e-06,
      "loss": 0.0024,
      "step": 263
    },
    {
      "epoch": 0.1444991789819376,
      "grad_norm": 3.946690082550049,
      "learning_rate": 9.493593267528818e-06,
      "loss": 0.7816,
      "step": 264
    },
    {
      "epoch": 0.14504652435686918,
      "grad_norm": 0.0384691059589386,
      "learning_rate": 9.489816322026796e-06,
      "loss": 0.0018,
      "step": 265
    },
    {
      "epoch": 0.14559386973180077,
      "grad_norm": 0.025972256436944008,
      "learning_rate": 9.486026101017711e-06,
      "loss": 0.001,
      "step": 266
    },
    {
      "epoch": 0.14614121510673234,
      "grad_norm": 0.060490723699331284,
      "learning_rate": 9.482222615708506e-06,
      "loss": 0.0036,
      "step": 267
    },
    {
      "epoch": 0.14668856048166393,
      "grad_norm": 2.3960936069488525,
      "learning_rate": 9.478405877345339e-06,
      "loss": 0.2742,
      "step": 268
    },
    {
      "epoch": 0.14723590585659552,
      "grad_norm": 1.100036859512329,
      "learning_rate": 9.474575897213558e-06,
      "loss": 0.0585,
      "step": 269
    },
    {
      "epoch": 0.1477832512315271,
      "grad_norm": 0.7070713639259338,
      "learning_rate": 9.470732686637665e-06,
      "loss": 0.0546,
      "step": 270
    },
    {
      "epoch": 0.14833059660645867,
      "grad_norm": 0.018481096252799034,
      "learning_rate": 9.466876256981279e-06,
      "loss": 0.0006,
      "step": 271
    },
    {
      "epoch": 0.14887794198139026,
      "grad_norm": 0.08746657520532608,
      "learning_rate": 9.463006619647109e-06,
      "loss": 0.0039,
      "step": 272
    },
    {
      "epoch": 0.14942528735632185,
      "grad_norm": 0.4034903645515442,
      "learning_rate": 9.459123786076911e-06,
      "loss": 0.03,
      "step": 273
    },
    {
      "epoch": 0.1499726327312534,
      "grad_norm": 0.047934990376234055,
      "learning_rate": 9.455227767751467e-06,
      "loss": 0.0018,
      "step": 274
    },
    {
      "epoch": 0.150519978106185,
      "grad_norm": 0.024474691599607468,
      "learning_rate": 9.451318576190538e-06,
      "loss": 0.001,
      "step": 275
    },
    {
      "epoch": 0.1510673234811166,
      "grad_norm": 0.09166815876960754,
      "learning_rate": 9.447396222952837e-06,
      "loss": 0.0033,
      "step": 276
    },
    {
      "epoch": 0.15161466885604816,
      "grad_norm": 0.03293546661734581,
      "learning_rate": 9.443460719635993e-06,
      "loss": 0.0013,
      "step": 277
    },
    {
      "epoch": 0.15216201423097975,
      "grad_norm": 0.1560712307691574,
      "learning_rate": 9.43951207787652e-06,
      "loss": 0.0077,
      "step": 278
    },
    {
      "epoch": 0.15270935960591134,
      "grad_norm": 0.1661752313375473,
      "learning_rate": 9.435550309349776e-06,
      "loss": 0.009,
      "step": 279
    },
    {
      "epoch": 0.1532567049808429,
      "grad_norm": 0.02781626395881176,
      "learning_rate": 9.431575425769938e-06,
      "loss": 0.0009,
      "step": 280
    },
    {
      "epoch": 0.1538040503557745,
      "grad_norm": 1.1563446521759033,
      "learning_rate": 9.427587438889954e-06,
      "loss": 0.0756,
      "step": 281
    },
    {
      "epoch": 0.15435139573070608,
      "grad_norm": 0.662655770778656,
      "learning_rate": 9.423586360501521e-06,
      "loss": 0.046,
      "step": 282
    },
    {
      "epoch": 0.15489874110563764,
      "grad_norm": 0.0047677913680672646,
      "learning_rate": 9.419572202435044e-06,
      "loss": 0.0002,
      "step": 283
    },
    {
      "epoch": 0.15544608648056923,
      "grad_norm": 0.01116353739053011,
      "learning_rate": 9.415544976559601e-06,
      "loss": 0.0005,
      "step": 284
    },
    {
      "epoch": 0.15599343185550082,
      "grad_norm": 2.6496481895446777,
      "learning_rate": 9.411504694782909e-06,
      "loss": 0.2375,
      "step": 285
    },
    {
      "epoch": 0.15654077723043242,
      "grad_norm": 0.0020393601153045893,
      "learning_rate": 9.407451369051293e-06,
      "loss": 0.0001,
      "step": 286
    },
    {
      "epoch": 0.15708812260536398,
      "grad_norm": 0.0037431686650961637,
      "learning_rate": 9.40338501134964e-06,
      "loss": 0.0002,
      "step": 287
    },
    {
      "epoch": 0.15763546798029557,
      "grad_norm": 4.152092456817627,
      "learning_rate": 9.399305633701372e-06,
      "loss": 0.4402,
      "step": 288
    },
    {
      "epoch": 0.15818281335522716,
      "grad_norm": 0.017035065218806267,
      "learning_rate": 9.395213248168414e-06,
      "loss": 0.0008,
      "step": 289
    },
    {
      "epoch": 0.15873015873015872,
      "grad_norm": 0.009140928275883198,
      "learning_rate": 9.391107866851143e-06,
      "loss": 0.0003,
      "step": 290
    },
    {
      "epoch": 0.1592775041050903,
      "grad_norm": 0.02858644351363182,
      "learning_rate": 9.38698950188837e-06,
      "loss": 0.0013,
      "step": 291
    },
    {
      "epoch": 0.1598248494800219,
      "grad_norm": 0.005926493555307388,
      "learning_rate": 9.382858165457291e-06,
      "loss": 0.0003,
      "step": 292
    },
    {
      "epoch": 0.16037219485495346,
      "grad_norm": 1.6762354373931885,
      "learning_rate": 9.378713869773462e-06,
      "loss": 0.2948,
      "step": 293
    },
    {
      "epoch": 0.16091954022988506,
      "grad_norm": 1.615936517715454,
      "learning_rate": 9.374556627090749e-06,
      "loss": 0.0393,
      "step": 294
    },
    {
      "epoch": 0.16146688560481665,
      "grad_norm": 0.0076006194576621056,
      "learning_rate": 9.370386449701306e-06,
      "loss": 0.0004,
      "step": 295
    },
    {
      "epoch": 0.1620142309797482,
      "grad_norm": 0.18345554172992706,
      "learning_rate": 9.366203349935531e-06,
      "loss": 0.0093,
      "step": 296
    },
    {
      "epoch": 0.1625615763546798,
      "grad_norm": 0.004320617765188217,
      "learning_rate": 9.36200734016203e-06,
      "loss": 0.0002,
      "step": 297
    },
    {
      "epoch": 0.1631089217296114,
      "grad_norm": 0.002908125054091215,
      "learning_rate": 9.35779843278758e-06,
      "loss": 0.0001,
      "step": 298
    },
    {
      "epoch": 0.16365626710454298,
      "grad_norm": 0.11647922545671463,
      "learning_rate": 9.353576640257096e-06,
      "loss": 0.0061,
      "step": 299
    },
    {
      "epoch": 0.16420361247947454,
      "grad_norm": 0.01617673970758915,
      "learning_rate": 9.349341975053593e-06,
      "loss": 0.0007,
      "step": 300
    },
    {
      "epoch": 0.16475095785440613,
      "grad_norm": 0.7812187075614929,
      "learning_rate": 9.345094449698143e-06,
      "loss": 0.0558,
      "step": 301
    },
    {
      "epoch": 0.16529830322933772,
      "grad_norm": 0.012498322874307632,
      "learning_rate": 9.34083407674985e-06,
      "loss": 0.0006,
      "step": 302
    },
    {
      "epoch": 0.16584564860426929,
      "grad_norm": 0.5021430850028992,
      "learning_rate": 9.336560868805799e-06,
      "loss": 0.1699,
      "step": 303
    },
    {
      "epoch": 0.16639299397920088,
      "grad_norm": 0.0076477318070828915,
      "learning_rate": 9.33227483850103e-06,
      "loss": 0.0003,
      "step": 304
    },
    {
      "epoch": 0.16694033935413247,
      "grad_norm": 0.03205980360507965,
      "learning_rate": 9.327975998508496e-06,
      "loss": 0.0008,
      "step": 305
    },
    {
      "epoch": 0.16748768472906403,
      "grad_norm": 0.04194890707731247,
      "learning_rate": 9.32366436153902e-06,
      "loss": 0.0025,
      "step": 306
    },
    {
      "epoch": 0.16803503010399562,
      "grad_norm": 0.014767547138035297,
      "learning_rate": 9.319339940341272e-06,
      "loss": 0.0007,
      "step": 307
    },
    {
      "epoch": 0.1685823754789272,
      "grad_norm": 0.22116778790950775,
      "learning_rate": 9.315002747701716e-06,
      "loss": 0.0099,
      "step": 308
    },
    {
      "epoch": 0.16912972085385877,
      "grad_norm": 0.025060897693037987,
      "learning_rate": 9.310652796444581e-06,
      "loss": 0.0016,
      "step": 309
    },
    {
      "epoch": 0.16967706622879036,
      "grad_norm": 0.0068942466750741005,
      "learning_rate": 9.306290099431822e-06,
      "loss": 0.0003,
      "step": 310
    },
    {
      "epoch": 0.17022441160372195,
      "grad_norm": 0.007744511589407921,
      "learning_rate": 9.301914669563077e-06,
      "loss": 0.0005,
      "step": 311
    },
    {
      "epoch": 0.17077175697865354,
      "grad_norm": 0.4967727065086365,
      "learning_rate": 9.297526519775637e-06,
      "loss": 0.0252,
      "step": 312
    },
    {
      "epoch": 0.1713191023535851,
      "grad_norm": 0.03269048035144806,
      "learning_rate": 9.293125663044399e-06,
      "loss": 0.0013,
      "step": 313
    },
    {
      "epoch": 0.1718664477285167,
      "grad_norm": 0.27753227949142456,
      "learning_rate": 9.288712112381834e-06,
      "loss": 0.014,
      "step": 314
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.006993559189140797,
      "learning_rate": 9.284285880837947e-06,
      "loss": 0.0004,
      "step": 315
    },
    {
      "epoch": 0.17296113847837985,
      "grad_norm": 0.549428403377533,
      "learning_rate": 9.279846981500237e-06,
      "loss": 0.0213,
      "step": 316
    },
    {
      "epoch": 0.17350848385331144,
      "grad_norm": 0.00912394281476736,
      "learning_rate": 9.275395427493662e-06,
      "loss": 0.0004,
      "step": 317
    },
    {
      "epoch": 0.17405582922824303,
      "grad_norm": 0.004364835564047098,
      "learning_rate": 9.27093123198059e-06,
      "loss": 0.0003,
      "step": 318
    },
    {
      "epoch": 0.1746031746031746,
      "grad_norm": 1.0090898275375366,
      "learning_rate": 9.266454408160779e-06,
      "loss": 0.1641,
      "step": 319
    },
    {
      "epoch": 0.17515051997810618,
      "grad_norm": 0.012392750009894371,
      "learning_rate": 9.261964969271315e-06,
      "loss": 0.0006,
      "step": 320
    },
    {
      "epoch": 0.17569786535303777,
      "grad_norm": 0.03388480469584465,
      "learning_rate": 9.257462928586589e-06,
      "loss": 0.0018,
      "step": 321
    },
    {
      "epoch": 0.17624521072796934,
      "grad_norm": 0.0020455988124012947,
      "learning_rate": 9.252948299418255e-06,
      "loss": 0.0001,
      "step": 322
    },
    {
      "epoch": 0.17679255610290093,
      "grad_norm": 0.005185797344893217,
      "learning_rate": 9.248421095115185e-06,
      "loss": 0.0003,
      "step": 323
    },
    {
      "epoch": 0.17733990147783252,
      "grad_norm": 0.0037107334937900305,
      "learning_rate": 9.243881329063436e-06,
      "loss": 0.0002,
      "step": 324
    },
    {
      "epoch": 0.17788724685276408,
      "grad_norm": 0.39402660727500916,
      "learning_rate": 9.239329014686207e-06,
      "loss": 0.0261,
      "step": 325
    },
    {
      "epoch": 0.17843459222769567,
      "grad_norm": 0.0029675220139324665,
      "learning_rate": 9.2347641654438e-06,
      "loss": 0.0002,
      "step": 326
    },
    {
      "epoch": 0.17898193760262726,
      "grad_norm": 0.05478639900684357,
      "learning_rate": 9.230186794833578e-06,
      "loss": 0.0025,
      "step": 327
    },
    {
      "epoch": 0.17952928297755885,
      "grad_norm": 0.036193422973155975,
      "learning_rate": 9.225596916389929e-06,
      "loss": 0.0024,
      "step": 328
    },
    {
      "epoch": 0.18007662835249041,
      "grad_norm": 0.02998141385614872,
      "learning_rate": 9.220994543684225e-06,
      "loss": 0.0012,
      "step": 329
    },
    {
      "epoch": 0.180623973727422,
      "grad_norm": 0.2926265299320221,
      "learning_rate": 9.216379690324782e-06,
      "loss": 0.0148,
      "step": 330
    },
    {
      "epoch": 0.1811713191023536,
      "grad_norm": 0.0027401878032833338,
      "learning_rate": 9.211752369956814e-06,
      "loss": 0.0001,
      "step": 331
    },
    {
      "epoch": 0.18171866447728516,
      "grad_norm": 0.05815352126955986,
      "learning_rate": 9.207112596262404e-06,
      "loss": 0.0028,
      "step": 332
    },
    {
      "epoch": 0.18226600985221675,
      "grad_norm": 3.9201138019561768,
      "learning_rate": 9.202460382960449e-06,
      "loss": 0.9249,
      "step": 333
    },
    {
      "epoch": 0.18281335522714834,
      "grad_norm": 1.582148790359497,
      "learning_rate": 9.197795743806634e-06,
      "loss": 0.0623,
      "step": 334
    },
    {
      "epoch": 0.1833607006020799,
      "grad_norm": 0.3804430067539215,
      "learning_rate": 9.193118692593385e-06,
      "loss": 0.016,
      "step": 335
    },
    {
      "epoch": 0.1839080459770115,
      "grad_norm": 0.2567972242832184,
      "learning_rate": 9.188429243149824e-06,
      "loss": 0.0151,
      "step": 336
    },
    {
      "epoch": 0.18445539135194308,
      "grad_norm": 0.0027828768361359835,
      "learning_rate": 9.183727409341737e-06,
      "loss": 0.0002,
      "step": 337
    },
    {
      "epoch": 0.18500273672687464,
      "grad_norm": 0.01566651649773121,
      "learning_rate": 9.179013205071518e-06,
      "loss": 0.0006,
      "step": 338
    },
    {
      "epoch": 0.18555008210180624,
      "grad_norm": 2.274597406387329,
      "learning_rate": 9.174286644278154e-06,
      "loss": 0.1273,
      "step": 339
    },
    {
      "epoch": 0.18609742747673783,
      "grad_norm": 0.0010587741853669286,
      "learning_rate": 9.169547740937152e-06,
      "loss": 0.0001,
      "step": 340
    },
    {
      "epoch": 0.18664477285166942,
      "grad_norm": 0.004240550100803375,
      "learning_rate": 9.164796509060526e-06,
      "loss": 0.0002,
      "step": 341
    },
    {
      "epoch": 0.18719211822660098,
      "grad_norm": 0.10997644811868668,
      "learning_rate": 9.160032962696734e-06,
      "loss": 0.0041,
      "step": 342
    },
    {
      "epoch": 0.18773946360153257,
      "grad_norm": 2.554443120956421,
      "learning_rate": 9.155257115930651e-06,
      "loss": 0.2045,
      "step": 343
    },
    {
      "epoch": 0.18828680897646416,
      "grad_norm": 0.060324691236019135,
      "learning_rate": 9.15046898288352e-06,
      "loss": 0.0023,
      "step": 344
    },
    {
      "epoch": 0.18883415435139572,
      "grad_norm": 0.2988241910934448,
      "learning_rate": 9.145668577712911e-06,
      "loss": 0.0113,
      "step": 345
    },
    {
      "epoch": 0.1893814997263273,
      "grad_norm": 0.013895167969167233,
      "learning_rate": 9.140855914612683e-06,
      "loss": 0.0007,
      "step": 346
    },
    {
      "epoch": 0.1899288451012589,
      "grad_norm": 0.0013494835002347827,
      "learning_rate": 9.136031007812937e-06,
      "loss": 0.0001,
      "step": 347
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 0.001819790923036635,
      "learning_rate": 9.131193871579975e-06,
      "loss": 0.0001,
      "step": 348
    },
    {
      "epoch": 0.19102353585112206,
      "grad_norm": 0.002317516366019845,
      "learning_rate": 9.126344520216264e-06,
      "loss": 0.0001,
      "step": 349
    },
    {
      "epoch": 0.19157088122605365,
      "grad_norm": 0.0012026987969875336,
      "learning_rate": 9.121482968060384e-06,
      "loss": 0.0001,
      "step": 350
    },
    {
      "epoch": 0.1921182266009852,
      "grad_norm": 0.002415985334664583,
      "learning_rate": 9.116609229486992e-06,
      "loss": 0.0001,
      "step": 351
    },
    {
      "epoch": 0.1926655719759168,
      "grad_norm": 0.20342646539211273,
      "learning_rate": 9.11172331890678e-06,
      "loss": 0.0136,
      "step": 352
    },
    {
      "epoch": 0.1932129173508484,
      "grad_norm": 3.324154853820801,
      "learning_rate": 9.106825250766424e-06,
      "loss": 0.1621,
      "step": 353
    },
    {
      "epoch": 0.19376026272577998,
      "grad_norm": 0.01826445572078228,
      "learning_rate": 9.101915039548557e-06,
      "loss": 0.0008,
      "step": 354
    },
    {
      "epoch": 0.19430760810071154,
      "grad_norm": 1.4845014810562134,
      "learning_rate": 9.096992699771707e-06,
      "loss": 0.1276,
      "step": 355
    },
    {
      "epoch": 0.19485495347564313,
      "grad_norm": 0.007865088991820812,
      "learning_rate": 9.092058245990271e-06,
      "loss": 0.0005,
      "step": 356
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 0.0025685420259833336,
      "learning_rate": 9.08711169279446e-06,
      "loss": 0.0001,
      "step": 357
    },
    {
      "epoch": 0.1959496442255063,
      "grad_norm": 0.012677297927439213,
      "learning_rate": 9.082153054810263e-06,
      "loss": 0.0006,
      "step": 358
    },
    {
      "epoch": 0.19649698960043788,
      "grad_norm": 2.798283100128174,
      "learning_rate": 9.077182346699402e-06,
      "loss": 0.1939,
      "step": 359
    },
    {
      "epoch": 0.19704433497536947,
      "grad_norm": 0.005475998390465975,
      "learning_rate": 9.072199583159285e-06,
      "loss": 0.0002,
      "step": 360
    },
    {
      "epoch": 0.19759168035030103,
      "grad_norm": 0.0036891840863972902,
      "learning_rate": 9.067204778922968e-06,
      "loss": 0.0002,
      "step": 361
    },
    {
      "epoch": 0.19813902572523262,
      "grad_norm": 0.001365787466056645,
      "learning_rate": 9.062197948759112e-06,
      "loss": 0.0001,
      "step": 362
    },
    {
      "epoch": 0.1986863711001642,
      "grad_norm": 0.004518306348472834,
      "learning_rate": 9.057179107471926e-06,
      "loss": 0.0003,
      "step": 363
    },
    {
      "epoch": 0.19923371647509577,
      "grad_norm": 0.013051324523985386,
      "learning_rate": 9.052148269901145e-06,
      "loss": 0.0004,
      "step": 364
    },
    {
      "epoch": 0.19978106185002736,
      "grad_norm": 3.1763477325439453,
      "learning_rate": 9.047105450921968e-06,
      "loss": 0.2782,
      "step": 365
    },
    {
      "epoch": 0.20032840722495895,
      "grad_norm": 1.3873274326324463,
      "learning_rate": 9.042050665445024e-06,
      "loss": 0.2482,
      "step": 366
    },
    {
      "epoch": 0.20087575259989054,
      "grad_norm": 0.02219286933541298,
      "learning_rate": 9.03698392841632e-06,
      "loss": 0.0013,
      "step": 367
    },
    {
      "epoch": 0.2014230979748221,
      "grad_norm": 0.016388343647122383,
      "learning_rate": 9.031905254817209e-06,
      "loss": 0.0006,
      "step": 368
    },
    {
      "epoch": 0.2019704433497537,
      "grad_norm": 0.019673733040690422,
      "learning_rate": 9.026814659664331e-06,
      "loss": 0.0008,
      "step": 369
    },
    {
      "epoch": 0.2025177887246853,
      "grad_norm": 0.0731121152639389,
      "learning_rate": 9.021712158009578e-06,
      "loss": 0.0038,
      "step": 370
    },
    {
      "epoch": 0.20306513409961685,
      "grad_norm": 2.1403443813323975,
      "learning_rate": 9.01659776494005e-06,
      "loss": 0.0419,
      "step": 371
    },
    {
      "epoch": 0.20361247947454844,
      "grad_norm": 4.477548122406006,
      "learning_rate": 9.011471495578e-06,
      "loss": 0.6446,
      "step": 372
    },
    {
      "epoch": 0.20415982484948003,
      "grad_norm": 0.009029140695929527,
      "learning_rate": 9.006333365080808e-06,
      "loss": 0.0005,
      "step": 373
    },
    {
      "epoch": 0.2047071702244116,
      "grad_norm": 0.12299131602048874,
      "learning_rate": 9.001183388640915e-06,
      "loss": 0.0052,
      "step": 374
    },
    {
      "epoch": 0.20525451559934318,
      "grad_norm": 0.01799800619482994,
      "learning_rate": 8.996021581485795e-06,
      "loss": 0.0007,
      "step": 375
    },
    {
      "epoch": 0.20580186097427478,
      "grad_norm": 0.001605588709935546,
      "learning_rate": 8.990847958877897e-06,
      "loss": 0.0001,
      "step": 376
    },
    {
      "epoch": 0.20634920634920634,
      "grad_norm": 0.01120750606060028,
      "learning_rate": 8.985662536114614e-06,
      "loss": 0.0007,
      "step": 377
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.0011993194930255413,
      "learning_rate": 8.98046532852822e-06,
      "loss": 0.0001,
      "step": 378
    },
    {
      "epoch": 0.20744389709906952,
      "grad_norm": 0.01046249270439148,
      "learning_rate": 8.975256351485842e-06,
      "loss": 0.0004,
      "step": 379
    },
    {
      "epoch": 0.20799124247400108,
      "grad_norm": 1.6339671611785889,
      "learning_rate": 8.970035620389404e-06,
      "loss": 0.1263,
      "step": 380
    },
    {
      "epoch": 0.20853858784893267,
      "grad_norm": 0.01426183246076107,
      "learning_rate": 8.964803150675583e-06,
      "loss": 0.0007,
      "step": 381
    },
    {
      "epoch": 0.20908593322386426,
      "grad_norm": 0.0019121590303257108,
      "learning_rate": 8.95955895781577e-06,
      "loss": 0.0001,
      "step": 382
    },
    {
      "epoch": 0.20963327859879585,
      "grad_norm": 0.11075831949710846,
      "learning_rate": 8.954303057316014e-06,
      "loss": 0.0059,
      "step": 383
    },
    {
      "epoch": 0.21018062397372742,
      "grad_norm": 0.16603931784629822,
      "learning_rate": 8.949035464716984e-06,
      "loss": 0.0063,
      "step": 384
    },
    {
      "epoch": 0.210727969348659,
      "grad_norm": 0.13519646227359772,
      "learning_rate": 8.943756195593916e-06,
      "loss": 0.0048,
      "step": 385
    },
    {
      "epoch": 0.2112753147235906,
      "grad_norm": 0.01505594328045845,
      "learning_rate": 8.938465265556576e-06,
      "loss": 0.0005,
      "step": 386
    },
    {
      "epoch": 0.21182266009852216,
      "grad_norm": 0.002303576795384288,
      "learning_rate": 8.93316269024921e-06,
      "loss": 0.0001,
      "step": 387
    },
    {
      "epoch": 0.21237000547345375,
      "grad_norm": 0.01708918809890747,
      "learning_rate": 8.92784848535049e-06,
      "loss": 0.0008,
      "step": 388
    },
    {
      "epoch": 0.21291735084838534,
      "grad_norm": 3.9915552139282227,
      "learning_rate": 8.92252266657348e-06,
      "loss": 0.4924,
      "step": 389
    },
    {
      "epoch": 0.2134646962233169,
      "grad_norm": 0.7279453277587891,
      "learning_rate": 8.917185249665583e-06,
      "loss": 0.0188,
      "step": 390
    },
    {
      "epoch": 0.2140120415982485,
      "grad_norm": 0.002763046184554696,
      "learning_rate": 8.911836250408494e-06,
      "loss": 0.0001,
      "step": 391
    },
    {
      "epoch": 0.21455938697318008,
      "grad_norm": 0.005032614804804325,
      "learning_rate": 8.90647568461816e-06,
      "loss": 0.0002,
      "step": 392
    },
    {
      "epoch": 0.21510673234811165,
      "grad_norm": 0.004743133671581745,
      "learning_rate": 8.901103568144715e-06,
      "loss": 0.0002,
      "step": 393
    },
    {
      "epoch": 0.21565407772304324,
      "grad_norm": 0.8033201694488525,
      "learning_rate": 8.895719916872463e-06,
      "loss": 0.0181,
      "step": 394
    },
    {
      "epoch": 0.21620142309797483,
      "grad_norm": 2.2534615993499756,
      "learning_rate": 8.8903247467198e-06,
      "loss": 0.2673,
      "step": 395
    },
    {
      "epoch": 0.21674876847290642,
      "grad_norm": 0.021912703290581703,
      "learning_rate": 8.88491807363919e-06,
      "loss": 0.0009,
      "step": 396
    },
    {
      "epoch": 0.21729611384783798,
      "grad_norm": 0.015198400244116783,
      "learning_rate": 8.879499913617107e-06,
      "loss": 0.0006,
      "step": 397
    },
    {
      "epoch": 0.21784345922276957,
      "grad_norm": 1.4581880569458008,
      "learning_rate": 8.874070282673985e-06,
      "loss": 0.0442,
      "step": 398
    },
    {
      "epoch": 0.21839080459770116,
      "grad_norm": 0.009783484041690826,
      "learning_rate": 8.868629196864182e-06,
      "loss": 0.0004,
      "step": 399
    },
    {
      "epoch": 0.21893814997263272,
      "grad_norm": 0.01400721725076437,
      "learning_rate": 8.863176672275921e-06,
      "loss": 0.0007,
      "step": 400
    },
    {
      "epoch": 0.2194854953475643,
      "grad_norm": 0.002226783661171794,
      "learning_rate": 8.857712725031247e-06,
      "loss": 0.0001,
      "step": 401
    },
    {
      "epoch": 0.2200328407224959,
      "grad_norm": 1.2499287128448486,
      "learning_rate": 8.852237371285984e-06,
      "loss": 0.1157,
      "step": 402
    },
    {
      "epoch": 0.22058018609742747,
      "grad_norm": 0.1320461928844452,
      "learning_rate": 8.84675062722968e-06,
      "loss": 0.0049,
      "step": 403
    },
    {
      "epoch": 0.22112753147235906,
      "grad_norm": 0.011133654974400997,
      "learning_rate": 8.841252509085561e-06,
      "loss": 0.0005,
      "step": 404
    },
    {
      "epoch": 0.22167487684729065,
      "grad_norm": 0.030495785176753998,
      "learning_rate": 8.835743033110482e-06,
      "loss": 0.0009,
      "step": 405
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 1.5797675848007202,
      "learning_rate": 8.83022221559489e-06,
      "loss": 0.1083,
      "step": 406
    },
    {
      "epoch": 0.2227695675971538,
      "grad_norm": 0.00430386932566762,
      "learning_rate": 8.824690072862758e-06,
      "loss": 0.0002,
      "step": 407
    },
    {
      "epoch": 0.2233169129720854,
      "grad_norm": 1.3098835945129395,
      "learning_rate": 8.819146621271546e-06,
      "loss": 0.0848,
      "step": 408
    },
    {
      "epoch": 0.22386425834701698,
      "grad_norm": 0.0014868773287162185,
      "learning_rate": 8.813591877212157e-06,
      "loss": 0.0001,
      "step": 409
    },
    {
      "epoch": 0.22441160372194854,
      "grad_norm": 6.543228626251221,
      "learning_rate": 8.80802585710888e-06,
      "loss": 0.3624,
      "step": 410
    },
    {
      "epoch": 0.22495894909688013,
      "grad_norm": 0.19780850410461426,
      "learning_rate": 8.802448577419343e-06,
      "loss": 0.0069,
      "step": 411
    },
    {
      "epoch": 0.22550629447181172,
      "grad_norm": 0.006174061447381973,
      "learning_rate": 8.796860054634471e-06,
      "loss": 0.0003,
      "step": 412
    },
    {
      "epoch": 0.2260536398467433,
      "grad_norm": 0.0014546852326020598,
      "learning_rate": 8.791260305278434e-06,
      "loss": 0.0001,
      "step": 413
    },
    {
      "epoch": 0.22660098522167488,
      "grad_norm": 0.029020192101597786,
      "learning_rate": 8.78564934590859e-06,
      "loss": 0.0012,
      "step": 414
    },
    {
      "epoch": 0.22714833059660647,
      "grad_norm": 0.0021669077686965466,
      "learning_rate": 8.780027193115444e-06,
      "loss": 0.0001,
      "step": 415
    },
    {
      "epoch": 0.22769567597153803,
      "grad_norm": 0.7334997653961182,
      "learning_rate": 8.774393863522606e-06,
      "loss": 0.0259,
      "step": 416
    },
    {
      "epoch": 0.22824302134646962,
      "grad_norm": 1.8123842477798462,
      "learning_rate": 8.768749373786722e-06,
      "loss": 0.1017,
      "step": 417
    },
    {
      "epoch": 0.2287903667214012,
      "grad_norm": 0.014731330797076225,
      "learning_rate": 8.763093740597447e-06,
      "loss": 0.0004,
      "step": 418
    },
    {
      "epoch": 0.22933771209633277,
      "grad_norm": 0.003496374236419797,
      "learning_rate": 8.757426980677377e-06,
      "loss": 0.0002,
      "step": 419
    },
    {
      "epoch": 0.22988505747126436,
      "grad_norm": 0.0009668404818512499,
      "learning_rate": 8.751749110782013e-06,
      "loss": 0.0,
      "step": 420
    },
    {
      "epoch": 0.23043240284619596,
      "grad_norm": 0.002660682424902916,
      "learning_rate": 8.746060147699701e-06,
      "loss": 0.0001,
      "step": 421
    },
    {
      "epoch": 0.23097974822112752,
      "grad_norm": 0.0013944864040240645,
      "learning_rate": 8.740360108251592e-06,
      "loss": 0.0001,
      "step": 422
    },
    {
      "epoch": 0.2315270935960591,
      "grad_norm": 6.9048662185668945,
      "learning_rate": 8.734649009291586e-06,
      "loss": 1.0083,
      "step": 423
    },
    {
      "epoch": 0.2320744389709907,
      "grad_norm": 0.000864550587721169,
      "learning_rate": 8.72892686770628e-06,
      "loss": 0.0,
      "step": 424
    },
    {
      "epoch": 0.2326217843459223,
      "grad_norm": 0.07142631709575653,
      "learning_rate": 8.72319370041493e-06,
      "loss": 0.003,
      "step": 425
    },
    {
      "epoch": 0.23316912972085385,
      "grad_norm": 0.08108633011579514,
      "learning_rate": 8.717449524369386e-06,
      "loss": 0.0028,
      "step": 426
    },
    {
      "epoch": 0.23371647509578544,
      "grad_norm": 0.5510886907577515,
      "learning_rate": 8.71169435655405e-06,
      "loss": 0.021,
      "step": 427
    },
    {
      "epoch": 0.23426382047071703,
      "grad_norm": 0.001556964823976159,
      "learning_rate": 8.705928213985827e-06,
      "loss": 0.0001,
      "step": 428
    },
    {
      "epoch": 0.2348111658456486,
      "grad_norm": 0.024227650836110115,
      "learning_rate": 8.700151113714071e-06,
      "loss": 0.0011,
      "step": 429
    },
    {
      "epoch": 0.23535851122058019,
      "grad_norm": 0.002216652035713196,
      "learning_rate": 8.694363072820535e-06,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 0.23590585659551178,
      "grad_norm": 0.5916431546211243,
      "learning_rate": 8.688564108419321e-06,
      "loss": 0.0182,
      "step": 431
    },
    {
      "epoch": 0.23645320197044334,
      "grad_norm": 0.05704738199710846,
      "learning_rate": 8.68275423765683e-06,
      "loss": 0.0027,
      "step": 432
    },
    {
      "epoch": 0.23700054734537493,
      "grad_norm": 0.04652688652276993,
      "learning_rate": 8.676933477711714e-06,
      "loss": 0.0019,
      "step": 433
    },
    {
      "epoch": 0.23754789272030652,
      "grad_norm": 0.001590778469108045,
      "learning_rate": 8.671101845794816e-06,
      "loss": 0.0001,
      "step": 434
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 0.4748682677745819,
      "learning_rate": 8.665259359149132e-06,
      "loss": 0.0118,
      "step": 435
    },
    {
      "epoch": 0.23864258347016967,
      "grad_norm": 0.00951937586069107,
      "learning_rate": 8.65940603504975e-06,
      "loss": 0.0006,
      "step": 436
    },
    {
      "epoch": 0.23918992884510126,
      "grad_norm": 0.004846447613090277,
      "learning_rate": 8.653541890803798e-06,
      "loss": 0.0002,
      "step": 437
    },
    {
      "epoch": 0.23973727422003285,
      "grad_norm": 0.031883712857961655,
      "learning_rate": 8.647666943750405e-06,
      "loss": 0.0013,
      "step": 438
    },
    {
      "epoch": 0.24028461959496442,
      "grad_norm": 0.001513091498054564,
      "learning_rate": 8.641781211260641e-06,
      "loss": 0.0001,
      "step": 439
    },
    {
      "epoch": 0.240831964969896,
      "grad_norm": 0.8598031401634216,
      "learning_rate": 8.635884710737458e-06,
      "loss": 0.0083,
      "step": 440
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 0.001031615654937923,
      "learning_rate": 8.629977459615655e-06,
      "loss": 0.0001,
      "step": 441
    },
    {
      "epoch": 0.24192665571975916,
      "grad_norm": 0.0004249604244250804,
      "learning_rate": 8.624059475361818e-06,
      "loss": 0.0,
      "step": 442
    },
    {
      "epoch": 0.24247400109469075,
      "grad_norm": 0.0007998205837793648,
      "learning_rate": 8.618130775474262e-06,
      "loss": 0.0,
      "step": 443
    },
    {
      "epoch": 0.24302134646962234,
      "grad_norm": 0.0017613136442378163,
      "learning_rate": 8.612191377482995e-06,
      "loss": 0.0001,
      "step": 444
    },
    {
      "epoch": 0.2435686918445539,
      "grad_norm": 0.0007269097259268165,
      "learning_rate": 8.606241298949651e-06,
      "loss": 0.0,
      "step": 445
    },
    {
      "epoch": 0.2441160372194855,
      "grad_norm": 0.04038122296333313,
      "learning_rate": 8.600280557467448e-06,
      "loss": 0.0012,
      "step": 446
    },
    {
      "epoch": 0.24466338259441708,
      "grad_norm": 0.005297824740409851,
      "learning_rate": 8.594309170661128e-06,
      "loss": 0.0003,
      "step": 447
    },
    {
      "epoch": 0.24521072796934865,
      "grad_norm": 0.3802763819694519,
      "learning_rate": 8.588327156186915e-06,
      "loss": 0.0087,
      "step": 448
    },
    {
      "epoch": 0.24575807334428024,
      "grad_norm": 0.0017056223005056381,
      "learning_rate": 8.58233453173245e-06,
      "loss": 0.0001,
      "step": 449
    },
    {
      "epoch": 0.24630541871921183,
      "grad_norm": 5.159848690032959,
      "learning_rate": 8.576331315016753e-06,
      "loss": 0.4604,
      "step": 450
    },
    {
      "epoch": 0.24685276409414342,
      "grad_norm": 0.0013483628863468766,
      "learning_rate": 8.570317523790155e-06,
      "loss": 0.0001,
      "step": 451
    },
    {
      "epoch": 0.24740010946907498,
      "grad_norm": 0.0006778071401640773,
      "learning_rate": 8.564293175834261e-06,
      "loss": 0.0,
      "step": 452
    },
    {
      "epoch": 0.24794745484400657,
      "grad_norm": 0.0006542521878145635,
      "learning_rate": 8.558258288961887e-06,
      "loss": 0.0,
      "step": 453
    },
    {
      "epoch": 0.24849480021893816,
      "grad_norm": 3.6082868576049805,
      "learning_rate": 8.552212881017012e-06,
      "loss": 0.2632,
      "step": 454
    },
    {
      "epoch": 0.24904214559386972,
      "grad_norm": 0.020652681589126587,
      "learning_rate": 8.546156969874723e-06,
      "loss": 0.0009,
      "step": 455
    },
    {
      "epoch": 0.24958949096880131,
      "grad_norm": 0.001072196988388896,
      "learning_rate": 8.540090573441159e-06,
      "loss": 0.0001,
      "step": 456
    },
    {
      "epoch": 0.2501368363437329,
      "grad_norm": 0.0008579727727919817,
      "learning_rate": 8.534013709653469e-06,
      "loss": 0.0001,
      "step": 457
    },
    {
      "epoch": 0.25068418171866447,
      "grad_norm": 0.38297420740127563,
      "learning_rate": 8.527926396479746e-06,
      "loss": 0.0142,
      "step": 458
    },
    {
      "epoch": 0.2512315270935961,
      "grad_norm": 0.004905950278043747,
      "learning_rate": 8.521828651918983e-06,
      "loss": 0.0003,
      "step": 459
    },
    {
      "epoch": 0.25177887246852765,
      "grad_norm": 0.005214395001530647,
      "learning_rate": 8.515720494001016e-06,
      "loss": 0.0002,
      "step": 460
    },
    {
      "epoch": 0.2523262178434592,
      "grad_norm": 0.025402160361409187,
      "learning_rate": 8.509601940786472e-06,
      "loss": 0.001,
      "step": 461
    },
    {
      "epoch": 0.25287356321839083,
      "grad_norm": 0.0021994970738887787,
      "learning_rate": 8.503473010366713e-06,
      "loss": 0.0001,
      "step": 462
    },
    {
      "epoch": 0.2534209085933224,
      "grad_norm": 0.000938941549975425,
      "learning_rate": 8.497333720863786e-06,
      "loss": 0.0001,
      "step": 463
    },
    {
      "epoch": 0.25396825396825395,
      "grad_norm": 0.007120966911315918,
      "learning_rate": 8.491184090430365e-06,
      "loss": 0.0004,
      "step": 464
    },
    {
      "epoch": 0.2545155993431856,
      "grad_norm": 2.6635191440582275,
      "learning_rate": 8.485024137249705e-06,
      "loss": 0.1192,
      "step": 465
    },
    {
      "epoch": 0.25506294471811713,
      "grad_norm": 0.3342060446739197,
      "learning_rate": 8.478853879535578e-06,
      "loss": 0.0101,
      "step": 466
    },
    {
      "epoch": 0.2556102900930487,
      "grad_norm": 0.07913763076066971,
      "learning_rate": 8.472673335532226e-06,
      "loss": 0.0042,
      "step": 467
    },
    {
      "epoch": 0.2561576354679803,
      "grad_norm": 4.626941204071045,
      "learning_rate": 8.46648252351431e-06,
      "loss": 0.8965,
      "step": 468
    },
    {
      "epoch": 0.2567049808429119,
      "grad_norm": 0.0014947270974516869,
      "learning_rate": 8.460281461786848e-06,
      "loss": 0.0001,
      "step": 469
    },
    {
      "epoch": 0.25725232621784344,
      "grad_norm": 3.5636613368988037,
      "learning_rate": 8.454070168685162e-06,
      "loss": 0.2006,
      "step": 470
    },
    {
      "epoch": 0.25779967159277506,
      "grad_norm": 0.0059119523502886295,
      "learning_rate": 8.447848662574828e-06,
      "loss": 0.0003,
      "step": 471
    },
    {
      "epoch": 0.2583470169677066,
      "grad_norm": 0.15589165687561035,
      "learning_rate": 8.441616961851624e-06,
      "loss": 0.0088,
      "step": 472
    },
    {
      "epoch": 0.2588943623426382,
      "grad_norm": 1.452197790145874,
      "learning_rate": 8.435375084941464e-06,
      "loss": 0.0365,
      "step": 473
    },
    {
      "epoch": 0.2594417077175698,
      "grad_norm": 0.7616869211196899,
      "learning_rate": 8.429123050300357e-06,
      "loss": 0.023,
      "step": 474
    },
    {
      "epoch": 0.25998905309250137,
      "grad_norm": 0.02911139652132988,
      "learning_rate": 8.422860876414344e-06,
      "loss": 0.0014,
      "step": 475
    },
    {
      "epoch": 0.26053639846743293,
      "grad_norm": 0.002363229636102915,
      "learning_rate": 8.416588581799447e-06,
      "loss": 0.0001,
      "step": 476
    },
    {
      "epoch": 0.26108374384236455,
      "grad_norm": 0.07544245570898056,
      "learning_rate": 8.41030618500161e-06,
      "loss": 0.0042,
      "step": 477
    },
    {
      "epoch": 0.2616310892172961,
      "grad_norm": 0.0007695093518123031,
      "learning_rate": 8.404013704596653e-06,
      "loss": 0.0001,
      "step": 478
    },
    {
      "epoch": 0.26217843459222767,
      "grad_norm": 0.017121996730566025,
      "learning_rate": 8.3977111591902e-06,
      "loss": 0.0006,
      "step": 479
    },
    {
      "epoch": 0.2627257799671593,
      "grad_norm": 0.11365637928247452,
      "learning_rate": 8.391398567417653e-06,
      "loss": 0.0053,
      "step": 480
    },
    {
      "epoch": 0.26327312534209085,
      "grad_norm": 4.831299304962158,
      "learning_rate": 8.385075947944101e-06,
      "loss": 0.1409,
      "step": 481
    },
    {
      "epoch": 0.2638204707170224,
      "grad_norm": 0.01369810663163662,
      "learning_rate": 8.378743319464293e-06,
      "loss": 0.0008,
      "step": 482
    },
    {
      "epoch": 0.26436781609195403,
      "grad_norm": 3.3139376640319824,
      "learning_rate": 8.372400700702569e-06,
      "loss": 1.2469,
      "step": 483
    },
    {
      "epoch": 0.2649151614668856,
      "grad_norm": 0.06146810203790665,
      "learning_rate": 8.366048110412817e-06,
      "loss": 0.0028,
      "step": 484
    },
    {
      "epoch": 0.2654625068418172,
      "grad_norm": 0.014722381718456745,
      "learning_rate": 8.359685567378392e-06,
      "loss": 0.0004,
      "step": 485
    },
    {
      "epoch": 0.2660098522167488,
      "grad_norm": 0.06078818067908287,
      "learning_rate": 8.353313090412093e-06,
      "loss": 0.0013,
      "step": 486
    },
    {
      "epoch": 0.26655719759168034,
      "grad_norm": 0.00245315907523036,
      "learning_rate": 8.346930698356083e-06,
      "loss": 0.0001,
      "step": 487
    },
    {
      "epoch": 0.26710454296661196,
      "grad_norm": 0.06558837741613388,
      "learning_rate": 8.340538410081846e-06,
      "loss": 0.0024,
      "step": 488
    },
    {
      "epoch": 0.2676518883415435,
      "grad_norm": 0.0057716392911970615,
      "learning_rate": 8.334136244490128e-06,
      "loss": 0.0004,
      "step": 489
    },
    {
      "epoch": 0.2681992337164751,
      "grad_norm": 0.5216295719146729,
      "learning_rate": 8.327724220510873e-06,
      "loss": 0.024,
      "step": 490
    },
    {
      "epoch": 0.2687465790914067,
      "grad_norm": 0.009259022772312164,
      "learning_rate": 8.321302357103183e-06,
      "loss": 0.0006,
      "step": 491
    },
    {
      "epoch": 0.26929392446633826,
      "grad_norm": 0.011879867874085903,
      "learning_rate": 8.314870673255248e-06,
      "loss": 0.0007,
      "step": 492
    },
    {
      "epoch": 0.2698412698412698,
      "grad_norm": 0.014412668533623219,
      "learning_rate": 8.308429187984298e-06,
      "loss": 0.0008,
      "step": 493
    },
    {
      "epoch": 0.27038861521620144,
      "grad_norm": 0.0010953384917229414,
      "learning_rate": 8.301977920336542e-06,
      "loss": 0.0001,
      "step": 494
    },
    {
      "epoch": 0.270935960591133,
      "grad_norm": 3.0654993057250977,
      "learning_rate": 8.295516889387115e-06,
      "loss": 0.0836,
      "step": 495
    },
    {
      "epoch": 0.27148330596606457,
      "grad_norm": 2.8851399421691895,
      "learning_rate": 8.289046114240019e-06,
      "loss": 0.5774,
      "step": 496
    },
    {
      "epoch": 0.2720306513409962,
      "grad_norm": 0.0014909834135323763,
      "learning_rate": 8.282565614028068e-06,
      "loss": 0.0001,
      "step": 497
    },
    {
      "epoch": 0.27257799671592775,
      "grad_norm": 0.0021966518834233284,
      "learning_rate": 8.276075407912831e-06,
      "loss": 0.0001,
      "step": 498
    },
    {
      "epoch": 0.2731253420908593,
      "grad_norm": 0.02141057327389717,
      "learning_rate": 8.269575515084577e-06,
      "loss": 0.0011,
      "step": 499
    },
    {
      "epoch": 0.27367268746579093,
      "grad_norm": 0.0020442374516278505,
      "learning_rate": 8.263065954762212e-06,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 0.2742200328407225,
      "grad_norm": 0.01249377615749836,
      "learning_rate": 8.256546746193237e-06,
      "loss": 0.0006,
      "step": 501
    },
    {
      "epoch": 0.27476737821565406,
      "grad_norm": 0.013269650749862194,
      "learning_rate": 8.250017908653666e-06,
      "loss": 0.0007,
      "step": 502
    },
    {
      "epoch": 0.2753147235905857,
      "grad_norm": 1.4034570455551147,
      "learning_rate": 8.243479461447999e-06,
      "loss": 0.0914,
      "step": 503
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 2.610060453414917,
      "learning_rate": 8.23693142390914e-06,
      "loss": 0.6805,
      "step": 504
    },
    {
      "epoch": 0.2764094143404488,
      "grad_norm": 1.8987330198287964,
      "learning_rate": 8.230373815398352e-06,
      "loss": 0.0641,
      "step": 505
    },
    {
      "epoch": 0.2769567597153804,
      "grad_norm": 0.0025170736480504274,
      "learning_rate": 8.2238066553052e-06,
      "loss": 0.0002,
      "step": 506
    },
    {
      "epoch": 0.277504105090312,
      "grad_norm": 0.016338244080543518,
      "learning_rate": 8.21722996304749e-06,
      "loss": 0.0009,
      "step": 507
    },
    {
      "epoch": 0.27805145046524354,
      "grad_norm": 0.009682532399892807,
      "learning_rate": 8.210643758071211e-06,
      "loss": 0.0006,
      "step": 508
    },
    {
      "epoch": 0.27859879584017516,
      "grad_norm": 1.6947555541992188,
      "learning_rate": 8.20404805985048e-06,
      "loss": 0.0776,
      "step": 509
    },
    {
      "epoch": 0.2791461412151067,
      "grad_norm": 0.0011098610702902079,
      "learning_rate": 8.197442887887488e-06,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 0.2796934865900383,
      "grad_norm": 0.1431194692850113,
      "learning_rate": 8.19082826171243e-06,
      "loss": 0.0036,
      "step": 511
    },
    {
      "epoch": 0.2802408319649699,
      "grad_norm": 4.919512748718262,
      "learning_rate": 8.184204200883458e-06,
      "loss": 0.7382,
      "step": 512
    },
    {
      "epoch": 0.28078817733990147,
      "grad_norm": 0.003851655637845397,
      "learning_rate": 8.177570724986627e-06,
      "loss": 0.0003,
      "step": 513
    },
    {
      "epoch": 0.2813355227148331,
      "grad_norm": 0.11160436272621155,
      "learning_rate": 8.170927853635824e-06,
      "loss": 0.0065,
      "step": 514
    },
    {
      "epoch": 0.28188286808976465,
      "grad_norm": 0.06886071711778641,
      "learning_rate": 8.164275606472716e-06,
      "loss": 0.0048,
      "step": 515
    },
    {
      "epoch": 0.2824302134646962,
      "grad_norm": 1.0991485118865967,
      "learning_rate": 8.157614003166695e-06,
      "loss": 0.0442,
      "step": 516
    },
    {
      "epoch": 0.28297755883962783,
      "grad_norm": 0.00606236606836319,
      "learning_rate": 8.150943063414815e-06,
      "loss": 0.0004,
      "step": 517
    },
    {
      "epoch": 0.2835249042145594,
      "grad_norm": 0.7126990556716919,
      "learning_rate": 8.144262806941743e-06,
      "loss": 0.0686,
      "step": 518
    },
    {
      "epoch": 0.28407224958949095,
      "grad_norm": 0.0036921524442732334,
      "learning_rate": 8.137573253499683e-06,
      "loss": 0.0002,
      "step": 519
    },
    {
      "epoch": 0.2846195949644226,
      "grad_norm": 0.004952317103743553,
      "learning_rate": 8.130874422868335e-06,
      "loss": 0.0003,
      "step": 520
    },
    {
      "epoch": 0.28516694033935414,
      "grad_norm": 0.011891587637364864,
      "learning_rate": 8.124166334854831e-06,
      "loss": 0.0004,
      "step": 521
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.006746396888047457,
      "learning_rate": 8.117449009293668e-06,
      "loss": 0.0002,
      "step": 522
    },
    {
      "epoch": 0.2862616310892173,
      "grad_norm": 3.892575979232788,
      "learning_rate": 8.110722466046666e-06,
      "loss": 0.6556,
      "step": 523
    },
    {
      "epoch": 0.2868089764641489,
      "grad_norm": 0.004911983385682106,
      "learning_rate": 8.103986725002893e-06,
      "loss": 0.0002,
      "step": 524
    },
    {
      "epoch": 0.28735632183908044,
      "grad_norm": 0.03258136659860611,
      "learning_rate": 8.097241806078616e-06,
      "loss": 0.0016,
      "step": 525
    },
    {
      "epoch": 0.28790366721401206,
      "grad_norm": 0.01775350794196129,
      "learning_rate": 8.090487729217238e-06,
      "loss": 0.001,
      "step": 526
    },
    {
      "epoch": 0.2884510125889436,
      "grad_norm": 0.02190772071480751,
      "learning_rate": 8.083724514389242e-06,
      "loss": 0.0009,
      "step": 527
    },
    {
      "epoch": 0.2889983579638752,
      "grad_norm": 0.01968459226191044,
      "learning_rate": 8.076952181592125e-06,
      "loss": 0.001,
      "step": 528
    },
    {
      "epoch": 0.2895457033388068,
      "grad_norm": 0.014719190075993538,
      "learning_rate": 8.070170750850354e-06,
      "loss": 0.0005,
      "step": 529
    },
    {
      "epoch": 0.29009304871373837,
      "grad_norm": 0.1697867512702942,
      "learning_rate": 8.063380242215289e-06,
      "loss": 0.0103,
      "step": 530
    },
    {
      "epoch": 0.29064039408866993,
      "grad_norm": 0.009283920750021935,
      "learning_rate": 8.05658067576513e-06,
      "loss": 0.0005,
      "step": 531
    },
    {
      "epoch": 0.29118773946360155,
      "grad_norm": 0.009003879502415657,
      "learning_rate": 8.049772071604864e-06,
      "loss": 0.0004,
      "step": 532
    },
    {
      "epoch": 0.2917350848385331,
      "grad_norm": 0.3108828067779541,
      "learning_rate": 8.042954449866203e-06,
      "loss": 0.0195,
      "step": 533
    },
    {
      "epoch": 0.2922824302134647,
      "grad_norm": 0.002856335835531354,
      "learning_rate": 8.036127830707515e-06,
      "loss": 0.0002,
      "step": 534
    },
    {
      "epoch": 0.2928297755883963,
      "grad_norm": 0.012315835803747177,
      "learning_rate": 8.029292234313777e-06,
      "loss": 0.0006,
      "step": 535
    },
    {
      "epoch": 0.29337712096332785,
      "grad_norm": 0.5404115915298462,
      "learning_rate": 8.022447680896505e-06,
      "loss": 0.0381,
      "step": 536
    },
    {
      "epoch": 0.2939244663382594,
      "grad_norm": 0.003850596724078059,
      "learning_rate": 8.015594190693705e-06,
      "loss": 0.0002,
      "step": 537
    },
    {
      "epoch": 0.29447181171319103,
      "grad_norm": 0.017621885985136032,
      "learning_rate": 8.008731783969803e-06,
      "loss": 0.0009,
      "step": 538
    },
    {
      "epoch": 0.2950191570881226,
      "grad_norm": 0.0026343895588070154,
      "learning_rate": 8.001860481015594e-06,
      "loss": 0.0002,
      "step": 539
    },
    {
      "epoch": 0.2955665024630542,
      "grad_norm": 1.7503541707992554,
      "learning_rate": 7.99498030214817e-06,
      "loss": 0.3291,
      "step": 540
    },
    {
      "epoch": 0.2961138478379858,
      "grad_norm": 0.13900676369667053,
      "learning_rate": 7.988091267710873e-06,
      "loss": 0.0077,
      "step": 541
    },
    {
      "epoch": 0.29666119321291734,
      "grad_norm": 0.4062604308128357,
      "learning_rate": 7.981193398073232e-06,
      "loss": 0.025,
      "step": 542
    },
    {
      "epoch": 0.29720853858784896,
      "grad_norm": 5.719942569732666,
      "learning_rate": 7.97428671363089e-06,
      "loss": 0.3741,
      "step": 543
    },
    {
      "epoch": 0.2977558839627805,
      "grad_norm": 0.01417833473533392,
      "learning_rate": 7.967371234805563e-06,
      "loss": 0.0008,
      "step": 544
    },
    {
      "epoch": 0.2983032293377121,
      "grad_norm": 0.004907727707177401,
      "learning_rate": 7.960446982044964e-06,
      "loss": 0.0003,
      "step": 545
    },
    {
      "epoch": 0.2988505747126437,
      "grad_norm": 0.05758337676525116,
      "learning_rate": 7.953513975822755e-06,
      "loss": 0.0034,
      "step": 546
    },
    {
      "epoch": 0.29939792008757526,
      "grad_norm": 0.10244325548410416,
      "learning_rate": 7.946572236638477e-06,
      "loss": 0.008,
      "step": 547
    },
    {
      "epoch": 0.2999452654625068,
      "grad_norm": 0.005103905685245991,
      "learning_rate": 7.939621785017488e-06,
      "loss": 0.0003,
      "step": 548
    },
    {
      "epoch": 0.30049261083743845,
      "grad_norm": 0.016332430765032768,
      "learning_rate": 7.932662641510915e-06,
      "loss": 0.0007,
      "step": 549
    },
    {
      "epoch": 0.30103995621237,
      "grad_norm": 0.09064442664384842,
      "learning_rate": 7.925694826695582e-06,
      "loss": 0.0037,
      "step": 550
    },
    {
      "epoch": 0.30158730158730157,
      "grad_norm": 0.12898586690425873,
      "learning_rate": 7.918718361173951e-06,
      "loss": 0.0119,
      "step": 551
    },
    {
      "epoch": 0.3021346469622332,
      "grad_norm": 0.553221583366394,
      "learning_rate": 7.911733265574061e-06,
      "loss": 0.0346,
      "step": 552
    },
    {
      "epoch": 0.30268199233716475,
      "grad_norm": 0.0136052081361413,
      "learning_rate": 7.904739560549475e-06,
      "loss": 0.0006,
      "step": 553
    },
    {
      "epoch": 0.3032293377120963,
      "grad_norm": 0.3376741409301758,
      "learning_rate": 7.897737266779207e-06,
      "loss": 0.0051,
      "step": 554
    },
    {
      "epoch": 0.30377668308702793,
      "grad_norm": 0.009592575952410698,
      "learning_rate": 7.890726404967665e-06,
      "loss": 0.0003,
      "step": 555
    },
    {
      "epoch": 0.3043240284619595,
      "grad_norm": 3.290745496749878,
      "learning_rate": 7.883706995844598e-06,
      "loss": 1.1552,
      "step": 556
    },
    {
      "epoch": 0.30487137383689106,
      "grad_norm": 0.02947666496038437,
      "learning_rate": 7.87667906016502e-06,
      "loss": 0.0019,
      "step": 557
    },
    {
      "epoch": 0.3054187192118227,
      "grad_norm": 1.9127118587493896,
      "learning_rate": 7.869642618709162e-06,
      "loss": 0.3917,
      "step": 558
    },
    {
      "epoch": 0.30596606458675424,
      "grad_norm": 0.28851523995399475,
      "learning_rate": 7.8625976922824e-06,
      "loss": 0.0223,
      "step": 559
    },
    {
      "epoch": 0.3065134099616858,
      "grad_norm": 0.1708579659461975,
      "learning_rate": 7.855544301715203e-06,
      "loss": 0.0139,
      "step": 560
    },
    {
      "epoch": 0.3070607553366174,
      "grad_norm": 0.06637328118085861,
      "learning_rate": 7.848482467863062e-06,
      "loss": 0.004,
      "step": 561
    },
    {
      "epoch": 0.307608100711549,
      "grad_norm": 0.016610033810138702,
      "learning_rate": 7.841412211606439e-06,
      "loss": 0.0005,
      "step": 562
    },
    {
      "epoch": 0.30815544608648054,
      "grad_norm": 2.7192347049713135,
      "learning_rate": 7.834333553850694e-06,
      "loss": 0.3873,
      "step": 563
    },
    {
      "epoch": 0.30870279146141216,
      "grad_norm": 0.10645106434822083,
      "learning_rate": 7.827246515526035e-06,
      "loss": 0.007,
      "step": 564
    },
    {
      "epoch": 0.3092501368363437,
      "grad_norm": 0.004362063482403755,
      "learning_rate": 7.82015111758744e-06,
      "loss": 0.0002,
      "step": 565
    },
    {
      "epoch": 0.3097974822112753,
      "grad_norm": 0.01006432343274355,
      "learning_rate": 7.813047381014613e-06,
      "loss": 0.0005,
      "step": 566
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 1.0483968257904053,
      "learning_rate": 7.805935326811913e-06,
      "loss": 0.0422,
      "step": 567
    },
    {
      "epoch": 0.31089217296113847,
      "grad_norm": 0.003497976576909423,
      "learning_rate": 7.798814976008286e-06,
      "loss": 0.0002,
      "step": 568
    },
    {
      "epoch": 0.3114395183360701,
      "grad_norm": 1.6734627485275269,
      "learning_rate": 7.791686349657219e-06,
      "loss": 0.1163,
      "step": 569
    },
    {
      "epoch": 0.31198686371100165,
      "grad_norm": 0.06700564175844193,
      "learning_rate": 7.78454946883666e-06,
      "loss": 0.0047,
      "step": 570
    },
    {
      "epoch": 0.3125342090859332,
      "grad_norm": 0.054846201092004776,
      "learning_rate": 7.777404354648967e-06,
      "loss": 0.0035,
      "step": 571
    },
    {
      "epoch": 0.31308155446086483,
      "grad_norm": 2.20139741897583,
      "learning_rate": 7.770251028220844e-06,
      "loss": 0.5211,
      "step": 572
    },
    {
      "epoch": 0.3136288998357964,
      "grad_norm": 0.022523751482367516,
      "learning_rate": 7.763089510703276e-06,
      "loss": 0.0016,
      "step": 573
    },
    {
      "epoch": 0.31417624521072796,
      "grad_norm": 0.0366409569978714,
      "learning_rate": 7.755919823271466e-06,
      "loss": 0.0019,
      "step": 574
    },
    {
      "epoch": 0.3147235905856596,
      "grad_norm": 1.0965900421142578,
      "learning_rate": 7.748741987124773e-06,
      "loss": 0.0356,
      "step": 575
    },
    {
      "epoch": 0.31527093596059114,
      "grad_norm": 0.19283118844032288,
      "learning_rate": 7.741556023486655e-06,
      "loss": 0.0069,
      "step": 576
    },
    {
      "epoch": 0.3158182813355227,
      "grad_norm": 0.013840774074196815,
      "learning_rate": 7.734361953604596e-06,
      "loss": 0.0007,
      "step": 577
    },
    {
      "epoch": 0.3163656267104543,
      "grad_norm": 0.005516275763511658,
      "learning_rate": 7.727159798750054e-06,
      "loss": 0.0003,
      "step": 578
    },
    {
      "epoch": 0.3169129720853859,
      "grad_norm": 0.0406813807785511,
      "learning_rate": 7.719949580218387e-06,
      "loss": 0.0023,
      "step": 579
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 0.0375928170979023,
      "learning_rate": 7.712731319328798e-06,
      "loss": 0.002,
      "step": 580
    },
    {
      "epoch": 0.31800766283524906,
      "grad_norm": 0.002322946907952428,
      "learning_rate": 7.70550503742427e-06,
      "loss": 0.0001,
      "step": 581
    },
    {
      "epoch": 0.3185550082101806,
      "grad_norm": 0.009377961978316307,
      "learning_rate": 7.698270755871506e-06,
      "loss": 0.0005,
      "step": 582
    },
    {
      "epoch": 0.3191023535851122,
      "grad_norm": 0.28144925832748413,
      "learning_rate": 7.691028496060856e-06,
      "loss": 0.0155,
      "step": 583
    },
    {
      "epoch": 0.3196496989600438,
      "grad_norm": 0.30781883001327515,
      "learning_rate": 7.683778279406261e-06,
      "loss": 0.018,
      "step": 584
    },
    {
      "epoch": 0.32019704433497537,
      "grad_norm": 0.03713702782988548,
      "learning_rate": 7.676520127345198e-06,
      "loss": 0.0021,
      "step": 585
    },
    {
      "epoch": 0.32074438970990693,
      "grad_norm": 2.1465322971343994,
      "learning_rate": 7.669254061338591e-06,
      "loss": 0.5439,
      "step": 586
    },
    {
      "epoch": 0.32129173508483855,
      "grad_norm": 2.981400966644287,
      "learning_rate": 7.66198010287078e-06,
      "loss": 0.5754,
      "step": 587
    },
    {
      "epoch": 0.3218390804597701,
      "grad_norm": 0.352286159992218,
      "learning_rate": 7.654698273449435e-06,
      "loss": 0.0159,
      "step": 588
    },
    {
      "epoch": 0.3223864258347017,
      "grad_norm": 0.007093922700732946,
      "learning_rate": 7.647408594605495e-06,
      "loss": 0.0003,
      "step": 589
    },
    {
      "epoch": 0.3229337712096333,
      "grad_norm": 0.00480629550293088,
      "learning_rate": 7.640111087893114e-06,
      "loss": 0.0003,
      "step": 590
    },
    {
      "epoch": 0.32348111658456485,
      "grad_norm": 0.007620492018759251,
      "learning_rate": 7.632805774889589e-06,
      "loss": 0.0005,
      "step": 591
    },
    {
      "epoch": 0.3240284619594964,
      "grad_norm": 0.0071716089732944965,
      "learning_rate": 7.625492677195298e-06,
      "loss": 0.0005,
      "step": 592
    },
    {
      "epoch": 0.32457580733442803,
      "grad_norm": 0.09126060456037521,
      "learning_rate": 7.6181718164336415e-06,
      "loss": 0.0051,
      "step": 593
    },
    {
      "epoch": 0.3251231527093596,
      "grad_norm": 0.06266578286886215,
      "learning_rate": 7.610843214250964e-06,
      "loss": 0.0054,
      "step": 594
    },
    {
      "epoch": 0.32567049808429116,
      "grad_norm": 2.620022773742676,
      "learning_rate": 7.603506892316513e-06,
      "loss": 0.3858,
      "step": 595
    },
    {
      "epoch": 0.3262178434592228,
      "grad_norm": 0.05527752265334129,
      "learning_rate": 7.5961628723223505e-06,
      "loss": 0.0025,
      "step": 596
    },
    {
      "epoch": 0.32676518883415434,
      "grad_norm": 0.004206737037748098,
      "learning_rate": 7.588811175983305e-06,
      "loss": 0.0003,
      "step": 597
    },
    {
      "epoch": 0.32731253420908596,
      "grad_norm": 1.0503450632095337,
      "learning_rate": 7.581451825036903e-06,
      "loss": 0.029,
      "step": 598
    },
    {
      "epoch": 0.3278598795840175,
      "grad_norm": 0.017230508849024773,
      "learning_rate": 7.574084841243302e-06,
      "loss": 0.0012,
      "step": 599
    },
    {
      "epoch": 0.3284072249589491,
      "grad_norm": 1.0851572751998901,
      "learning_rate": 7.5667102463852314e-06,
      "loss": 0.3047,
      "step": 600
    },
    {
      "epoch": 0.3289545703338807,
      "grad_norm": 0.12032447755336761,
      "learning_rate": 7.55932806226792e-06,
      "loss": 0.0066,
      "step": 601
    },
    {
      "epoch": 0.32950191570881227,
      "grad_norm": 0.06687518954277039,
      "learning_rate": 7.551938310719043e-06,
      "loss": 0.0038,
      "step": 602
    },
    {
      "epoch": 0.33004926108374383,
      "grad_norm": 0.013836498372256756,
      "learning_rate": 7.5445410135886455e-06,
      "loss": 0.0008,
      "step": 603
    },
    {
      "epoch": 0.33059660645867545,
      "grad_norm": 0.008111769333481789,
      "learning_rate": 7.537136192749086e-06,
      "loss": 0.0005,
      "step": 604
    },
    {
      "epoch": 0.331143951833607,
      "grad_norm": 0.018092483282089233,
      "learning_rate": 7.529723870094969e-06,
      "loss": 0.0009,
      "step": 605
    },
    {
      "epoch": 0.33169129720853857,
      "grad_norm": 2.438403367996216,
      "learning_rate": 7.522304067543082e-06,
      "loss": 0.369,
      "step": 606
    },
    {
      "epoch": 0.3322386425834702,
      "grad_norm": 0.020286623388528824,
      "learning_rate": 7.514876807032323e-06,
      "loss": 0.0015,
      "step": 607
    },
    {
      "epoch": 0.33278598795840175,
      "grad_norm": 0.00606251647695899,
      "learning_rate": 7.507442110523649e-06,
      "loss": 0.0004,
      "step": 608
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.0028585991822183132,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0002,
      "step": 609
    },
    {
      "epoch": 0.33388067870826493,
      "grad_norm": 2.60063099861145,
      "learning_rate": 7.492550497466239e-06,
      "loss": 0.5953,
      "step": 610
    },
    {
      "epoch": 0.3344280240831965,
      "grad_norm": 1.0973745584487915,
      "learning_rate": 7.485093624949085e-06,
      "loss": 0.2524,
      "step": 611
    },
    {
      "epoch": 0.33497536945812806,
      "grad_norm": 0.11632592976093292,
      "learning_rate": 7.477629404497048e-06,
      "loss": 0.0029,
      "step": 612
    },
    {
      "epoch": 0.3355227148330597,
      "grad_norm": 0.1462218016386032,
      "learning_rate": 7.470157858180365e-06,
      "loss": 0.0087,
      "step": 613
    },
    {
      "epoch": 0.33607006020799124,
      "grad_norm": 0.03426429256796837,
      "learning_rate": 7.462679008090935e-06,
      "loss": 0.0025,
      "step": 614
    },
    {
      "epoch": 0.3366174055829228,
      "grad_norm": 0.11435136198997498,
      "learning_rate": 7.455192876342253e-06,
      "loss": 0.0081,
      "step": 615
    },
    {
      "epoch": 0.3371647509578544,
      "grad_norm": 0.010991192422807217,
      "learning_rate": 7.447699485069342e-06,
      "loss": 0.0005,
      "step": 616
    },
    {
      "epoch": 0.337712096332786,
      "grad_norm": 0.01172308437526226,
      "learning_rate": 7.440198856428693e-06,
      "loss": 0.0009,
      "step": 617
    },
    {
      "epoch": 0.33825944170771755,
      "grad_norm": 0.013174332678318024,
      "learning_rate": 7.432691012598196e-06,
      "loss": 0.0009,
      "step": 618
    },
    {
      "epoch": 0.33880678708264916,
      "grad_norm": 1.8827731609344482,
      "learning_rate": 7.42517597577707e-06,
      "loss": 0.5865,
      "step": 619
    },
    {
      "epoch": 0.3393541324575807,
      "grad_norm": 0.4179116487503052,
      "learning_rate": 7.41765376818581e-06,
      "loss": 0.0256,
      "step": 620
    },
    {
      "epoch": 0.3399014778325123,
      "grad_norm": 0.022340985015034676,
      "learning_rate": 7.4101244120661105e-06,
      "loss": 0.0012,
      "step": 621
    },
    {
      "epoch": 0.3404488232074439,
      "grad_norm": 0.8227971196174622,
      "learning_rate": 7.4025879296807975e-06,
      "loss": 0.2403,
      "step": 622
    },
    {
      "epoch": 0.34099616858237547,
      "grad_norm": 0.005457259248942137,
      "learning_rate": 7.395044343313777e-06,
      "loss": 0.0003,
      "step": 623
    },
    {
      "epoch": 0.3415435139573071,
      "grad_norm": 0.10630811005830765,
      "learning_rate": 7.387493675269955e-06,
      "loss": 0.0094,
      "step": 624
    },
    {
      "epoch": 0.34209085933223865,
      "grad_norm": 0.26457127928733826,
      "learning_rate": 7.379935947875177e-06,
      "loss": 0.0248,
      "step": 625
    },
    {
      "epoch": 0.3426382047071702,
      "grad_norm": 0.017088670283555984,
      "learning_rate": 7.372371183476159e-06,
      "loss": 0.0012,
      "step": 626
    },
    {
      "epoch": 0.34318555008210183,
      "grad_norm": 0.00555271003395319,
      "learning_rate": 7.36479940444043e-06,
      "loss": 0.0003,
      "step": 627
    },
    {
      "epoch": 0.3437328954570334,
      "grad_norm": 0.7324652671813965,
      "learning_rate": 7.3572206331562575e-06,
      "loss": 0.066,
      "step": 628
    },
    {
      "epoch": 0.34428024083196496,
      "grad_norm": 0.022519147023558617,
      "learning_rate": 7.349634892032582e-06,
      "loss": 0.001,
      "step": 629
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.01817464269697666,
      "learning_rate": 7.342042203498952e-06,
      "loss": 0.0008,
      "step": 630
    },
    {
      "epoch": 0.34537493158182814,
      "grad_norm": 1.1613433361053467,
      "learning_rate": 7.334442590005462e-06,
      "loss": 0.116,
      "step": 631
    },
    {
      "epoch": 0.3459222769567597,
      "grad_norm": 0.010080925188958645,
      "learning_rate": 7.3268360740226785e-06,
      "loss": 0.0005,
      "step": 632
    },
    {
      "epoch": 0.3464696223316913,
      "grad_norm": 0.08003698289394379,
      "learning_rate": 7.319222678041578e-06,
      "loss": 0.0055,
      "step": 633
    },
    {
      "epoch": 0.3470169677066229,
      "grad_norm": 0.005561640951782465,
      "learning_rate": 7.311602424573483e-06,
      "loss": 0.0003,
      "step": 634
    },
    {
      "epoch": 0.34756431308155444,
      "grad_norm": 0.04773717001080513,
      "learning_rate": 7.3039753361499885e-06,
      "loss": 0.0031,
      "step": 635
    },
    {
      "epoch": 0.34811165845648606,
      "grad_norm": 0.06357687711715698,
      "learning_rate": 7.2963414353229e-06,
      "loss": 0.0041,
      "step": 636
    },
    {
      "epoch": 0.3486590038314176,
      "grad_norm": 0.04053463786840439,
      "learning_rate": 7.288700744664167e-06,
      "loss": 0.0026,
      "step": 637
    },
    {
      "epoch": 0.3492063492063492,
      "grad_norm": 0.4455021917819977,
      "learning_rate": 7.281053286765816e-06,
      "loss": 0.0272,
      "step": 638
    },
    {
      "epoch": 0.3497536945812808,
      "grad_norm": 0.04329623281955719,
      "learning_rate": 7.273399084239878e-06,
      "loss": 0.0024,
      "step": 639
    },
    {
      "epoch": 0.35030103995621237,
      "grad_norm": 0.1581658571958542,
      "learning_rate": 7.265738159718332e-06,
      "loss": 0.0119,
      "step": 640
    },
    {
      "epoch": 0.35084838533114393,
      "grad_norm": 0.020159656181931496,
      "learning_rate": 7.258070535853031e-06,
      "loss": 0.0012,
      "step": 641
    },
    {
      "epoch": 0.35139573070607555,
      "grad_norm": 0.015948781743645668,
      "learning_rate": 7.250396235315634e-06,
      "loss": 0.0009,
      "step": 642
    },
    {
      "epoch": 0.3519430760810071,
      "grad_norm": 1.8170660734176636,
      "learning_rate": 7.242715280797547e-06,
      "loss": 0.1837,
      "step": 643
    },
    {
      "epoch": 0.3524904214559387,
      "grad_norm": 0.024073567241430283,
      "learning_rate": 7.235027695009846e-06,
      "loss": 0.0012,
      "step": 644
    },
    {
      "epoch": 0.3530377668308703,
      "grad_norm": 0.10497935861349106,
      "learning_rate": 7.2273335006832144e-06,
      "loss": 0.0071,
      "step": 645
    },
    {
      "epoch": 0.35358511220580185,
      "grad_norm": 0.005542223807424307,
      "learning_rate": 7.219632720567879e-06,
      "loss": 0.0003,
      "step": 646
    },
    {
      "epoch": 0.3541324575807334,
      "grad_norm": 0.036429379135370255,
      "learning_rate": 7.211925377433537e-06,
      "loss": 0.0022,
      "step": 647
    },
    {
      "epoch": 0.35467980295566504,
      "grad_norm": 0.0030355199705809355,
      "learning_rate": 7.204211494069292e-06,
      "loss": 0.0001,
      "step": 648
    },
    {
      "epoch": 0.3552271483305966,
      "grad_norm": 0.23288480937480927,
      "learning_rate": 7.196491093283585e-06,
      "loss": 0.0163,
      "step": 649
    },
    {
      "epoch": 0.35577449370552816,
      "grad_norm": 0.0168252382427454,
      "learning_rate": 7.188764197904129e-06,
      "loss": 0.0007,
      "step": 650
    },
    {
      "epoch": 0.3563218390804598,
      "grad_norm": 1.0806885957717896,
      "learning_rate": 7.181030830777838e-06,
      "loss": 0.1059,
      "step": 651
    },
    {
      "epoch": 0.35686918445539134,
      "grad_norm": 0.007992301136255264,
      "learning_rate": 7.173291014770765e-06,
      "loss": 0.0003,
      "step": 652
    },
    {
      "epoch": 0.35741652983032296,
      "grad_norm": 0.31654584407806396,
      "learning_rate": 7.165544772768027e-06,
      "loss": 0.0125,
      "step": 653
    },
    {
      "epoch": 0.3579638752052545,
      "grad_norm": 0.01570254936814308,
      "learning_rate": 7.157792127673747e-06,
      "loss": 0.0007,
      "step": 654
    },
    {
      "epoch": 0.3585112205801861,
      "grad_norm": 0.12349551171064377,
      "learning_rate": 7.150033102410975e-06,
      "loss": 0.0081,
      "step": 655
    },
    {
      "epoch": 0.3590585659551177,
      "grad_norm": 2.745945453643799,
      "learning_rate": 7.142267719921629e-06,
      "loss": 0.4678,
      "step": 656
    },
    {
      "epoch": 0.35960591133004927,
      "grad_norm": 0.20581771433353424,
      "learning_rate": 7.134496003166423e-06,
      "loss": 0.0143,
      "step": 657
    },
    {
      "epoch": 0.36015325670498083,
      "grad_norm": 0.035796597599983215,
      "learning_rate": 7.1267179751248005e-06,
      "loss": 0.0023,
      "step": 658
    },
    {
      "epoch": 0.36070060207991245,
      "grad_norm": 0.026349762454628944,
      "learning_rate": 7.118933658794868e-06,
      "loss": 0.0016,
      "step": 659
    },
    {
      "epoch": 0.361247947454844,
      "grad_norm": 0.1853169947862625,
      "learning_rate": 7.111143077193321e-06,
      "loss": 0.0142,
      "step": 660
    },
    {
      "epoch": 0.36179529282977557,
      "grad_norm": 0.010469730943441391,
      "learning_rate": 7.103346253355383e-06,
      "loss": 0.0006,
      "step": 661
    },
    {
      "epoch": 0.3623426382047072,
      "grad_norm": 0.017436837777495384,
      "learning_rate": 7.0955432103347355e-06,
      "loss": 0.0008,
      "step": 662
    },
    {
      "epoch": 0.36288998357963875,
      "grad_norm": 0.003593792673200369,
      "learning_rate": 7.087733971203448e-06,
      "loss": 0.0002,
      "step": 663
    },
    {
      "epoch": 0.3634373289545703,
      "grad_norm": 0.1219901517033577,
      "learning_rate": 7.0799185590519086e-06,
      "loss": 0.0097,
      "step": 664
    },
    {
      "epoch": 0.36398467432950193,
      "grad_norm": 0.07112132757902145,
      "learning_rate": 7.0720969969887595e-06,
      "loss": 0.005,
      "step": 665
    },
    {
      "epoch": 0.3645320197044335,
      "grad_norm": 0.012998882681131363,
      "learning_rate": 7.06426930814083e-06,
      "loss": 0.0009,
      "step": 666
    },
    {
      "epoch": 0.36507936507936506,
      "grad_norm": 0.004774371162056923,
      "learning_rate": 7.056435515653059e-06,
      "loss": 0.0002,
      "step": 667
    },
    {
      "epoch": 0.3656267104542967,
      "grad_norm": 0.06849734485149384,
      "learning_rate": 7.048595642688436e-06,
      "loss": 0.0044,
      "step": 668
    },
    {
      "epoch": 0.36617405582922824,
      "grad_norm": 0.002525399439036846,
      "learning_rate": 7.040749712427932e-06,
      "loss": 0.0001,
      "step": 669
    },
    {
      "epoch": 0.3667214012041598,
      "grad_norm": 0.00474682729691267,
      "learning_rate": 7.032897748070423e-06,
      "loss": 0.0003,
      "step": 670
    },
    {
      "epoch": 0.3672687465790914,
      "grad_norm": 0.19950242340564728,
      "learning_rate": 7.0250397728326295e-06,
      "loss": 0.0147,
      "step": 671
    },
    {
      "epoch": 0.367816091954023,
      "grad_norm": 0.00391264446079731,
      "learning_rate": 7.017175809949044e-06,
      "loss": 0.0002,
      "step": 672
    },
    {
      "epoch": 0.36836343732895455,
      "grad_norm": 0.8328525424003601,
      "learning_rate": 7.009305882671864e-06,
      "loss": 0.0348,
      "step": 673
    },
    {
      "epoch": 0.36891078270388616,
      "grad_norm": 0.010690494440495968,
      "learning_rate": 7.001430014270921e-06,
      "loss": 0.0005,
      "step": 674
    },
    {
      "epoch": 0.3694581280788177,
      "grad_norm": 0.0021359992679208517,
      "learning_rate": 6.993548228033618e-06,
      "loss": 0.0001,
      "step": 675
    },
    {
      "epoch": 0.3700054734537493,
      "grad_norm": 2.0369694232940674,
      "learning_rate": 6.9856605472648494e-06,
      "loss": 0.3117,
      "step": 676
    },
    {
      "epoch": 0.3705528188286809,
      "grad_norm": 1.2182072401046753,
      "learning_rate": 6.977766995286943e-06,
      "loss": 0.0943,
      "step": 677
    },
    {
      "epoch": 0.37110016420361247,
      "grad_norm": 1.3776416778564453,
      "learning_rate": 6.969867595439586e-06,
      "loss": 0.3976,
      "step": 678
    },
    {
      "epoch": 0.3716475095785441,
      "grad_norm": 0.2830551862716675,
      "learning_rate": 6.961962371079752e-06,
      "loss": 0.0175,
      "step": 679
    },
    {
      "epoch": 0.37219485495347565,
      "grad_norm": 0.01174697745591402,
      "learning_rate": 6.954051345581645e-06,
      "loss": 0.0007,
      "step": 680
    },
    {
      "epoch": 0.3727422003284072,
      "grad_norm": 0.002880762331187725,
      "learning_rate": 6.946134542336615e-06,
      "loss": 0.0002,
      "step": 681
    },
    {
      "epoch": 0.37328954570333883,
      "grad_norm": 2.0193097591400146,
      "learning_rate": 6.938211984753097e-06,
      "loss": 0.4208,
      "step": 682
    },
    {
      "epoch": 0.3738368910782704,
      "grad_norm": 0.002231145976111293,
      "learning_rate": 6.930283696256543e-06,
      "loss": 0.0001,
      "step": 683
    },
    {
      "epoch": 0.37438423645320196,
      "grad_norm": 0.1625058501958847,
      "learning_rate": 6.922349700289348e-06,
      "loss": 0.0123,
      "step": 684
    },
    {
      "epoch": 0.3749315818281336,
      "grad_norm": 0.01109352521598339,
      "learning_rate": 6.914410020310782e-06,
      "loss": 0.0004,
      "step": 685
    },
    {
      "epoch": 0.37547892720306514,
      "grad_norm": 0.008098452351987362,
      "learning_rate": 6.906464679796927e-06,
      "loss": 0.0005,
      "step": 686
    },
    {
      "epoch": 0.3760262725779967,
      "grad_norm": 0.008087802678346634,
      "learning_rate": 6.898513702240592e-06,
      "loss": 0.0003,
      "step": 687
    },
    {
      "epoch": 0.3765736179529283,
      "grad_norm": 0.0760936588048935,
      "learning_rate": 6.890557111151266e-06,
      "loss": 0.0043,
      "step": 688
    },
    {
      "epoch": 0.3771209633278599,
      "grad_norm": 0.02241450361907482,
      "learning_rate": 6.882594930055024e-06,
      "loss": 0.001,
      "step": 689
    },
    {
      "epoch": 0.37766830870279144,
      "grad_norm": 4.740147113800049,
      "learning_rate": 6.8746271824944774e-06,
      "loss": 0.659,
      "step": 690
    },
    {
      "epoch": 0.37821565407772306,
      "grad_norm": 0.00517101539298892,
      "learning_rate": 6.8666538920286965e-06,
      "loss": 0.0002,
      "step": 691
    },
    {
      "epoch": 0.3787629994526546,
      "grad_norm": 0.47874972224235535,
      "learning_rate": 6.858675082233135e-06,
      "loss": 0.0223,
      "step": 692
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 1.1477383375167847,
      "learning_rate": 6.850690776699574e-06,
      "loss": 0.1252,
      "step": 693
    },
    {
      "epoch": 0.3798576902025178,
      "grad_norm": 0.22710518538951874,
      "learning_rate": 6.842700999036036e-06,
      "loss": 0.0212,
      "step": 694
    },
    {
      "epoch": 0.38040503557744937,
      "grad_norm": 0.36024829745292664,
      "learning_rate": 6.834705772866732e-06,
      "loss": 0.0371,
      "step": 695
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 0.0041975053027272224,
      "learning_rate": 6.8267051218319766e-06,
      "loss": 0.0002,
      "step": 696
    },
    {
      "epoch": 0.38149972632731255,
      "grad_norm": 0.006099354475736618,
      "learning_rate": 6.8186990695881275e-06,
      "loss": 0.0003,
      "step": 697
    },
    {
      "epoch": 0.3820470717022441,
      "grad_norm": 0.003718011546880007,
      "learning_rate": 6.810687639807514e-06,
      "loss": 0.0002,
      "step": 698
    },
    {
      "epoch": 0.3825944170771757,
      "grad_norm": 1.894804835319519,
      "learning_rate": 6.802670856178362e-06,
      "loss": 0.241,
      "step": 699
    },
    {
      "epoch": 0.3831417624521073,
      "grad_norm": 1.3862837553024292,
      "learning_rate": 6.79464874240473e-06,
      "loss": 0.147,
      "step": 700
    },
    {
      "epoch": 0.38368910782703886,
      "grad_norm": 0.4544786214828491,
      "learning_rate": 6.7866213222064385e-06,
      "loss": 0.194,
      "step": 701
    },
    {
      "epoch": 0.3842364532019704,
      "grad_norm": 0.005294317379593849,
      "learning_rate": 6.7785886193189936e-06,
      "loss": 0.0003,
      "step": 702
    },
    {
      "epoch": 0.38478379857690204,
      "grad_norm": 0.005809370893985033,
      "learning_rate": 6.770550657493525e-06,
      "loss": 0.0002,
      "step": 703
    },
    {
      "epoch": 0.3853311439518336,
      "grad_norm": 5.397134780883789,
      "learning_rate": 6.76250746049671e-06,
      "loss": 0.5976,
      "step": 704
    },
    {
      "epoch": 0.38587848932676516,
      "grad_norm": 0.0036762424279004335,
      "learning_rate": 6.754459052110707e-06,
      "loss": 0.0002,
      "step": 705
    },
    {
      "epoch": 0.3864258347016968,
      "grad_norm": 1.7116286754608154,
      "learning_rate": 6.7464054561330805e-06,
      "loss": 0.4844,
      "step": 706
    },
    {
      "epoch": 0.38697318007662834,
      "grad_norm": 0.023576248437166214,
      "learning_rate": 6.7383466963767386e-06,
      "loss": 0.0011,
      "step": 707
    },
    {
      "epoch": 0.38752052545155996,
      "grad_norm": 0.005346619989722967,
      "learning_rate": 6.730282796669853e-06,
      "loss": 0.0003,
      "step": 708
    },
    {
      "epoch": 0.3880678708264915,
      "grad_norm": 1.3141039609909058,
      "learning_rate": 6.722213780855795e-06,
      "loss": 0.1154,
      "step": 709
    },
    {
      "epoch": 0.3886152162014231,
      "grad_norm": 0.5670556426048279,
      "learning_rate": 6.714139672793063e-06,
      "loss": 0.0437,
      "step": 710
    },
    {
      "epoch": 0.3891625615763547,
      "grad_norm": 0.9592277407646179,
      "learning_rate": 6.7060604963552125e-06,
      "loss": 0.1316,
      "step": 711
    },
    {
      "epoch": 0.38970990695128627,
      "grad_norm": 0.1321696788072586,
      "learning_rate": 6.697976275430786e-06,
      "loss": 0.0092,
      "step": 712
    },
    {
      "epoch": 0.39025725232621783,
      "grad_norm": 0.40682703256607056,
      "learning_rate": 6.6898870339232405e-06,
      "loss": 0.0325,
      "step": 713
    },
    {
      "epoch": 0.39080459770114945,
      "grad_norm": 0.20595793426036835,
      "learning_rate": 6.681792795750876e-06,
      "loss": 0.012,
      "step": 714
    },
    {
      "epoch": 0.391351943076081,
      "grad_norm": 0.02716330997645855,
      "learning_rate": 6.673693584846771e-06,
      "loss": 0.0011,
      "step": 715
    },
    {
      "epoch": 0.3918992884510126,
      "grad_norm": 0.17218895256519318,
      "learning_rate": 6.665589425158705e-06,
      "loss": 0.0105,
      "step": 716
    },
    {
      "epoch": 0.3924466338259442,
      "grad_norm": 0.044622935354709625,
      "learning_rate": 6.657480340649088e-06,
      "loss": 0.0027,
      "step": 717
    },
    {
      "epoch": 0.39299397920087575,
      "grad_norm": 0.14009137451648712,
      "learning_rate": 6.649366355294895e-06,
      "loss": 0.0108,
      "step": 718
    },
    {
      "epoch": 0.3935413245758073,
      "grad_norm": 0.3257148563861847,
      "learning_rate": 6.641247493087591e-06,
      "loss": 0.0238,
      "step": 719
    },
    {
      "epoch": 0.39408866995073893,
      "grad_norm": 0.011366697028279305,
      "learning_rate": 6.633123778033061e-06,
      "loss": 0.0005,
      "step": 720
    },
    {
      "epoch": 0.3946360153256705,
      "grad_norm": 0.017103077843785286,
      "learning_rate": 6.624995234151539e-06,
      "loss": 0.0009,
      "step": 721
    },
    {
      "epoch": 0.39518336070060206,
      "grad_norm": 1.3907700777053833,
      "learning_rate": 6.616861885477535e-06,
      "loss": 0.1009,
      "step": 722
    },
    {
      "epoch": 0.3957307060755337,
      "grad_norm": 0.022432222962379456,
      "learning_rate": 6.608723756059768e-06,
      "loss": 0.0009,
      "step": 723
    },
    {
      "epoch": 0.39627805145046524,
      "grad_norm": 0.035762593150138855,
      "learning_rate": 6.600580869961091e-06,
      "loss": 0.0024,
      "step": 724
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 0.002616943558678031,
      "learning_rate": 6.592433251258423e-06,
      "loss": 0.0001,
      "step": 725
    },
    {
      "epoch": 0.3973727422003284,
      "grad_norm": 0.2397133857011795,
      "learning_rate": 6.5842809240426765e-06,
      "loss": 0.0108,
      "step": 726
    },
    {
      "epoch": 0.39792008757526,
      "grad_norm": 0.021851183846592903,
      "learning_rate": 6.576123912418686e-06,
      "loss": 0.0014,
      "step": 727
    },
    {
      "epoch": 0.39846743295019155,
      "grad_norm": 0.2460842877626419,
      "learning_rate": 6.567962240505136e-06,
      "loss": 0.0154,
      "step": 728
    },
    {
      "epoch": 0.39901477832512317,
      "grad_norm": 1.7685003280639648,
      "learning_rate": 6.559795932434489e-06,
      "loss": 0.3523,
      "step": 729
    },
    {
      "epoch": 0.3995621237000547,
      "grad_norm": 0.004333908669650555,
      "learning_rate": 6.551625012352921e-06,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.4001094690749863,
      "grad_norm": 1.0495126247406006,
      "learning_rate": 6.543449504420241e-06,
      "loss": 0.1618,
      "step": 731
    },
    {
      "epoch": 0.4006568144499179,
      "grad_norm": 0.07470511645078659,
      "learning_rate": 6.535269432809821e-06,
      "loss": 0.0039,
      "step": 732
    },
    {
      "epoch": 0.40120415982484947,
      "grad_norm": 1.7604902982711792,
      "learning_rate": 6.5270848217085325e-06,
      "loss": 0.2848,
      "step": 733
    },
    {
      "epoch": 0.4017515051997811,
      "grad_norm": 0.022594556212425232,
      "learning_rate": 6.518895695316666e-06,
      "loss": 0.0011,
      "step": 734
    },
    {
      "epoch": 0.40229885057471265,
      "grad_norm": 0.38731640577316284,
      "learning_rate": 6.510702077847864e-06,
      "loss": 0.0234,
      "step": 735
    },
    {
      "epoch": 0.4028461959496442,
      "grad_norm": 0.043282847851514816,
      "learning_rate": 6.502503993529048e-06,
      "loss": 0.0027,
      "step": 736
    },
    {
      "epoch": 0.40339354132457583,
      "grad_norm": 0.9928524494171143,
      "learning_rate": 6.494301466600345e-06,
      "loss": 0.0468,
      "step": 737
    },
    {
      "epoch": 0.4039408866995074,
      "grad_norm": 0.006927076727151871,
      "learning_rate": 6.486094521315022e-06,
      "loss": 0.0003,
      "step": 738
    },
    {
      "epoch": 0.40448823207443896,
      "grad_norm": 0.0009298663353547454,
      "learning_rate": 6.477883181939406e-06,
      "loss": 0.0001,
      "step": 739
    },
    {
      "epoch": 0.4050355774493706,
      "grad_norm": 0.012560609728097916,
      "learning_rate": 6.469667472752821e-06,
      "loss": 0.0006,
      "step": 740
    },
    {
      "epoch": 0.40558292282430214,
      "grad_norm": 0.005616576410830021,
      "learning_rate": 6.461447418047506e-06,
      "loss": 0.0002,
      "step": 741
    },
    {
      "epoch": 0.4061302681992337,
      "grad_norm": 0.06171350181102753,
      "learning_rate": 6.453223042128556e-06,
      "loss": 0.0036,
      "step": 742
    },
    {
      "epoch": 0.4066776135741653,
      "grad_norm": 0.011364221572875977,
      "learning_rate": 6.444994369313835e-06,
      "loss": 0.0005,
      "step": 743
    },
    {
      "epoch": 0.4072249589490969,
      "grad_norm": 0.0026471870951354504,
      "learning_rate": 6.4367614239339185e-06,
      "loss": 0.0001,
      "step": 744
    },
    {
      "epoch": 0.40777230432402845,
      "grad_norm": 0.01618381403386593,
      "learning_rate": 6.428524230332012e-06,
      "loss": 0.0008,
      "step": 745
    },
    {
      "epoch": 0.40831964969896006,
      "grad_norm": 2.547823905944824,
      "learning_rate": 6.420282812863881e-06,
      "loss": 0.1683,
      "step": 746
    },
    {
      "epoch": 0.4088669950738916,
      "grad_norm": 0.39628303050994873,
      "learning_rate": 6.412037195897786e-06,
      "loss": 0.0207,
      "step": 747
    },
    {
      "epoch": 0.4094143404488232,
      "grad_norm": 0.009464872069656849,
      "learning_rate": 6.403787403814399e-06,
      "loss": 0.0005,
      "step": 748
    },
    {
      "epoch": 0.4099616858237548,
      "grad_norm": 2.6054821014404297,
      "learning_rate": 6.395533461006736e-06,
      "loss": 0.4376,
      "step": 749
    },
    {
      "epoch": 0.41050903119868637,
      "grad_norm": 0.003519018879160285,
      "learning_rate": 6.387275391880091e-06,
      "loss": 0.0001,
      "step": 750
    },
    {
      "epoch": 0.41105637657361793,
      "grad_norm": 0.0016952584264799953,
      "learning_rate": 6.379013220851956e-06,
      "loss": 0.0001,
      "step": 751
    },
    {
      "epoch": 0.41160372194854955,
      "grad_norm": 0.005479486659169197,
      "learning_rate": 6.370746972351952e-06,
      "loss": 0.0003,
      "step": 752
    },
    {
      "epoch": 0.4121510673234811,
      "grad_norm": 0.08002389222383499,
      "learning_rate": 6.362476670821755e-06,
      "loss": 0.0047,
      "step": 753
    },
    {
      "epoch": 0.4126984126984127,
      "grad_norm": 0.011858136393129826,
      "learning_rate": 6.354202340715027e-06,
      "loss": 0.0005,
      "step": 754
    },
    {
      "epoch": 0.4132457580733443,
      "grad_norm": 0.005212915595620871,
      "learning_rate": 6.345924006497339e-06,
      "loss": 0.0002,
      "step": 755
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.05420675873756409,
      "learning_rate": 6.337641692646106e-06,
      "loss": 0.0035,
      "step": 756
    },
    {
      "epoch": 0.4143404488232074,
      "grad_norm": 2.1553845405578613,
      "learning_rate": 6.329355423650504e-06,
      "loss": 0.4001,
      "step": 757
    },
    {
      "epoch": 0.41488779419813904,
      "grad_norm": 0.024078695103526115,
      "learning_rate": 6.321065224011408e-06,
      "loss": 0.0014,
      "step": 758
    },
    {
      "epoch": 0.4154351395730706,
      "grad_norm": 0.0023700296878814697,
      "learning_rate": 6.312771118241314e-06,
      "loss": 0.0001,
      "step": 759
    },
    {
      "epoch": 0.41598248494800216,
      "grad_norm": 0.040566932410001755,
      "learning_rate": 6.3044731308642685e-06,
      "loss": 0.0017,
      "step": 760
    },
    {
      "epoch": 0.4165298303229338,
      "grad_norm": 0.05763727426528931,
      "learning_rate": 6.296171286415791e-06,
      "loss": 0.0035,
      "step": 761
    },
    {
      "epoch": 0.41707717569786534,
      "grad_norm": 0.0022259464021772146,
      "learning_rate": 6.287865609442812e-06,
      "loss": 0.0001,
      "step": 762
    },
    {
      "epoch": 0.41762452107279696,
      "grad_norm": 0.98305743932724,
      "learning_rate": 6.2795561245035895e-06,
      "loss": 0.0645,
      "step": 763
    },
    {
      "epoch": 0.4181718664477285,
      "grad_norm": 0.48837098479270935,
      "learning_rate": 6.271242856167642e-06,
      "loss": 0.0276,
      "step": 764
    },
    {
      "epoch": 0.4187192118226601,
      "grad_norm": 0.06717122346162796,
      "learning_rate": 6.262925829015675e-06,
      "loss": 0.0035,
      "step": 765
    },
    {
      "epoch": 0.4192665571975917,
      "grad_norm": 0.06258969753980637,
      "learning_rate": 6.254605067639509e-06,
      "loss": 0.0038,
      "step": 766
    },
    {
      "epoch": 0.41981390257252327,
      "grad_norm": 0.004777120426297188,
      "learning_rate": 6.246280596642004e-06,
      "loss": 0.0002,
      "step": 767
    },
    {
      "epoch": 0.42036124794745483,
      "grad_norm": 0.03006153739988804,
      "learning_rate": 6.23795244063699e-06,
      "loss": 0.0015,
      "step": 768
    },
    {
      "epoch": 0.42090859332238645,
      "grad_norm": 0.0028580978978425264,
      "learning_rate": 6.229620624249189e-06,
      "loss": 0.0001,
      "step": 769
    },
    {
      "epoch": 0.421455938697318,
      "grad_norm": 0.29681891202926636,
      "learning_rate": 6.221285172114156e-06,
      "loss": 0.0198,
      "step": 770
    },
    {
      "epoch": 0.4220032840722496,
      "grad_norm": 0.07169494777917862,
      "learning_rate": 6.212946108878185e-06,
      "loss": 0.0052,
      "step": 771
    },
    {
      "epoch": 0.4225506294471812,
      "grad_norm": 0.002539635170251131,
      "learning_rate": 6.204603459198252e-06,
      "loss": 0.0001,
      "step": 772
    },
    {
      "epoch": 0.42309797482211275,
      "grad_norm": 1.799579381942749,
      "learning_rate": 6.196257247741939e-06,
      "loss": 0.3128,
      "step": 773
    },
    {
      "epoch": 0.4236453201970443,
      "grad_norm": 0.017401453107595444,
      "learning_rate": 6.187907499187357e-06,
      "loss": 0.001,
      "step": 774
    },
    {
      "epoch": 0.42419266557197594,
      "grad_norm": 0.055426426231861115,
      "learning_rate": 6.179554238223076e-06,
      "loss": 0.0023,
      "step": 775
    },
    {
      "epoch": 0.4247400109469075,
      "grad_norm": 0.028435885906219482,
      "learning_rate": 6.171197489548051e-06,
      "loss": 0.0015,
      "step": 776
    },
    {
      "epoch": 0.42528735632183906,
      "grad_norm": 0.005395287182182074,
      "learning_rate": 6.162837277871553e-06,
      "loss": 0.0002,
      "step": 777
    },
    {
      "epoch": 0.4258347016967707,
      "grad_norm": 0.05064927414059639,
      "learning_rate": 6.1544736279130865e-06,
      "loss": 0.0034,
      "step": 778
    },
    {
      "epoch": 0.42638204707170224,
      "grad_norm": 0.045946523547172546,
      "learning_rate": 6.146106564402329e-06,
      "loss": 0.0033,
      "step": 779
    },
    {
      "epoch": 0.4269293924466338,
      "grad_norm": 0.23413774371147156,
      "learning_rate": 6.1377361120790445e-06,
      "loss": 0.0156,
      "step": 780
    },
    {
      "epoch": 0.4274767378215654,
      "grad_norm": 0.0022116010077297688,
      "learning_rate": 6.129362295693022e-06,
      "loss": 0.0001,
      "step": 781
    },
    {
      "epoch": 0.428024083196497,
      "grad_norm": 0.014064570888876915,
      "learning_rate": 6.120985140003996e-06,
      "loss": 0.0007,
      "step": 782
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 2.829383373260498,
      "learning_rate": 6.112604669781572e-06,
      "loss": 0.5324,
      "step": 783
    },
    {
      "epoch": 0.42911877394636017,
      "grad_norm": 0.007210441865026951,
      "learning_rate": 6.104220909805162e-06,
      "loss": 0.0003,
      "step": 784
    },
    {
      "epoch": 0.42966611932129173,
      "grad_norm": 0.002382508013397455,
      "learning_rate": 6.095833884863897e-06,
      "loss": 0.0002,
      "step": 785
    },
    {
      "epoch": 0.4302134646962233,
      "grad_norm": 0.021061023697257042,
      "learning_rate": 6.08744361975657e-06,
      "loss": 0.0013,
      "step": 786
    },
    {
      "epoch": 0.4307608100711549,
      "grad_norm": 0.05284823104739189,
      "learning_rate": 6.07905013929155e-06,
      "loss": 0.0024,
      "step": 787
    },
    {
      "epoch": 0.43130815544608647,
      "grad_norm": 0.37565889954566956,
      "learning_rate": 6.0706534682867125e-06,
      "loss": 0.0315,
      "step": 788
    },
    {
      "epoch": 0.4318555008210181,
      "grad_norm": 0.13435113430023193,
      "learning_rate": 6.062253631569368e-06,
      "loss": 0.0086,
      "step": 789
    },
    {
      "epoch": 0.43240284619594965,
      "grad_norm": 0.6931627988815308,
      "learning_rate": 6.053850653976191e-06,
      "loss": 0.0423,
      "step": 790
    },
    {
      "epoch": 0.4329501915708812,
      "grad_norm": 0.6118049025535583,
      "learning_rate": 6.045444560353136e-06,
      "loss": 0.0555,
      "step": 791
    },
    {
      "epoch": 0.43349753694581283,
      "grad_norm": 0.524542510509491,
      "learning_rate": 6.037035375555376e-06,
      "loss": 0.0472,
      "step": 792
    },
    {
      "epoch": 0.4340448823207444,
      "grad_norm": 0.006565346848219633,
      "learning_rate": 6.028623124447224e-06,
      "loss": 0.0003,
      "step": 793
    },
    {
      "epoch": 0.43459222769567596,
      "grad_norm": 0.02722448669373989,
      "learning_rate": 6.020207831902056e-06,
      "loss": 0.002,
      "step": 794
    },
    {
      "epoch": 0.4351395730706076,
      "grad_norm": 0.00823283288627863,
      "learning_rate": 6.011789522802242e-06,
      "loss": 0.0003,
      "step": 795
    },
    {
      "epoch": 0.43568691844553914,
      "grad_norm": 0.05936018377542496,
      "learning_rate": 6.003368222039078e-06,
      "loss": 0.0039,
      "step": 796
    },
    {
      "epoch": 0.4362342638204707,
      "grad_norm": 1.473726749420166,
      "learning_rate": 5.994943954512694e-06,
      "loss": 0.2025,
      "step": 797
    },
    {
      "epoch": 0.4367816091954023,
      "grad_norm": 1.0486841201782227,
      "learning_rate": 5.986516745132e-06,
      "loss": 0.2123,
      "step": 798
    },
    {
      "epoch": 0.4373289545703339,
      "grad_norm": 0.01115555688738823,
      "learning_rate": 5.978086618814606e-06,
      "loss": 0.0005,
      "step": 799
    },
    {
      "epoch": 0.43787629994526545,
      "grad_norm": 0.019556615501642227,
      "learning_rate": 5.96965360048674e-06,
      "loss": 0.0012,
      "step": 800
    },
    {
      "epoch": 0.43842364532019706,
      "grad_norm": 0.6547853350639343,
      "learning_rate": 5.961217715083185e-06,
      "loss": 0.0472,
      "step": 801
    },
    {
      "epoch": 0.4389709906951286,
      "grad_norm": 0.040504761040210724,
      "learning_rate": 5.952778987547203e-06,
      "loss": 0.0025,
      "step": 802
    },
    {
      "epoch": 0.4395183360700602,
      "grad_norm": 0.033022813498973846,
      "learning_rate": 5.944337442830457e-06,
      "loss": 0.0017,
      "step": 803
    },
    {
      "epoch": 0.4400656814449918,
      "grad_norm": 1.034399390220642,
      "learning_rate": 5.935893105892938e-06,
      "loss": 0.0991,
      "step": 804
    },
    {
      "epoch": 0.44061302681992337,
      "grad_norm": 0.002179005416110158,
      "learning_rate": 5.927446001702899e-06,
      "loss": 0.0001,
      "step": 805
    },
    {
      "epoch": 0.44116037219485493,
      "grad_norm": 0.003501959377899766,
      "learning_rate": 5.918996155236771e-06,
      "loss": 0.0001,
      "step": 806
    },
    {
      "epoch": 0.44170771756978655,
      "grad_norm": 0.9970118403434753,
      "learning_rate": 5.9105435914790935e-06,
      "loss": 0.0788,
      "step": 807
    },
    {
      "epoch": 0.4422550629447181,
      "grad_norm": 0.02765066549181938,
      "learning_rate": 5.902088335422442e-06,
      "loss": 0.0014,
      "step": 808
    },
    {
      "epoch": 0.4428024083196497,
      "grad_norm": 0.0017816947074607015,
      "learning_rate": 5.893630412067351e-06,
      "loss": 0.0001,
      "step": 809
    },
    {
      "epoch": 0.4433497536945813,
      "grad_norm": 0.01075491402298212,
      "learning_rate": 5.885169846422242e-06,
      "loss": 0.0006,
      "step": 810
    },
    {
      "epoch": 0.44389709906951286,
      "grad_norm": 0.005405724979937077,
      "learning_rate": 5.876706663503352e-06,
      "loss": 0.0002,
      "step": 811
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.09176081418991089,
      "learning_rate": 5.8682408883346535e-06,
      "loss": 0.0032,
      "step": 812
    },
    {
      "epoch": 0.44499178981937604,
      "grad_norm": 0.002494881395250559,
      "learning_rate": 5.859772545947782e-06,
      "loss": 0.0001,
      "step": 813
    },
    {
      "epoch": 0.4455391351943076,
      "grad_norm": 0.0015737097710371017,
      "learning_rate": 5.85130166138197e-06,
      "loss": 0.0001,
      "step": 814
    },
    {
      "epoch": 0.44608648056923916,
      "grad_norm": 0.0029730189125984907,
      "learning_rate": 5.8428282596839625e-06,
      "loss": 0.0001,
      "step": 815
    },
    {
      "epoch": 0.4466338259441708,
      "grad_norm": 0.17593710124492645,
      "learning_rate": 5.834352365907946e-06,
      "loss": 0.0066,
      "step": 816
    },
    {
      "epoch": 0.44718117131910234,
      "grad_norm": 0.000760188209824264,
      "learning_rate": 5.82587400511548e-06,
      "loss": 0.0,
      "step": 817
    },
    {
      "epoch": 0.44772851669403396,
      "grad_norm": 0.004076672717928886,
      "learning_rate": 5.817393202375416e-06,
      "loss": 0.0002,
      "step": 818
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 1.302188754081726,
      "learning_rate": 5.808909982763825e-06,
      "loss": 0.1418,
      "step": 819
    },
    {
      "epoch": 0.4488232074438971,
      "grad_norm": 0.019618166610598564,
      "learning_rate": 5.800424371363924e-06,
      "loss": 0.0012,
      "step": 820
    },
    {
      "epoch": 0.4493705528188287,
      "grad_norm": 0.0025738615076988935,
      "learning_rate": 5.791936393266004e-06,
      "loss": 0.0001,
      "step": 821
    },
    {
      "epoch": 0.44991789819376027,
      "grad_norm": 0.08965732902288437,
      "learning_rate": 5.783446073567353e-06,
      "loss": 0.004,
      "step": 822
    },
    {
      "epoch": 0.45046524356869183,
      "grad_norm": 0.009330305270850658,
      "learning_rate": 5.774953437372181e-06,
      "loss": 0.0005,
      "step": 823
    },
    {
      "epoch": 0.45101258894362345,
      "grad_norm": 0.08290552347898483,
      "learning_rate": 5.766458509791553e-06,
      "loss": 0.0053,
      "step": 824
    },
    {
      "epoch": 0.451559934318555,
      "grad_norm": 0.03778264671564102,
      "learning_rate": 5.757961315943303e-06,
      "loss": 0.0014,
      "step": 825
    },
    {
      "epoch": 0.4521072796934866,
      "grad_norm": 0.1019243448972702,
      "learning_rate": 5.749461880951966e-06,
      "loss": 0.004,
      "step": 826
    },
    {
      "epoch": 0.4526546250684182,
      "grad_norm": 0.12591150403022766,
      "learning_rate": 5.7409602299487085e-06,
      "loss": 0.0076,
      "step": 827
    },
    {
      "epoch": 0.45320197044334976,
      "grad_norm": 1.7693229913711548,
      "learning_rate": 5.732456388071247e-06,
      "loss": 0.4578,
      "step": 828
    },
    {
      "epoch": 0.4537493158182813,
      "grad_norm": 0.0013048258842900395,
      "learning_rate": 5.723950380463774e-06,
      "loss": 0.0001,
      "step": 829
    },
    {
      "epoch": 0.45429666119321294,
      "grad_norm": 0.00774482823908329,
      "learning_rate": 5.715442232276887e-06,
      "loss": 0.0004,
      "step": 830
    },
    {
      "epoch": 0.4548440065681445,
      "grad_norm": 0.0013780449517071247,
      "learning_rate": 5.706931968667514e-06,
      "loss": 0.0001,
      "step": 831
    },
    {
      "epoch": 0.45539135194307606,
      "grad_norm": 0.26762568950653076,
      "learning_rate": 5.6984196147988365e-06,
      "loss": 0.0179,
      "step": 832
    },
    {
      "epoch": 0.4559386973180077,
      "grad_norm": 0.007660985458642244,
      "learning_rate": 5.689905195840216e-06,
      "loss": 0.0004,
      "step": 833
    },
    {
      "epoch": 0.45648604269293924,
      "grad_norm": 0.02823932282626629,
      "learning_rate": 5.681388736967124e-06,
      "loss": 0.0008,
      "step": 834
    },
    {
      "epoch": 0.4570333880678708,
      "grad_norm": 0.000797456072177738,
      "learning_rate": 5.672870263361057e-06,
      "loss": 0.0,
      "step": 835
    },
    {
      "epoch": 0.4575807334428024,
      "grad_norm": 5.113959312438965,
      "learning_rate": 5.6643498002094725e-06,
      "loss": 0.2043,
      "step": 836
    },
    {
      "epoch": 0.458128078817734,
      "grad_norm": 0.222451850771904,
      "learning_rate": 5.655827372705712e-06,
      "loss": 0.0131,
      "step": 837
    },
    {
      "epoch": 0.45867542419266555,
      "grad_norm": 0.20374563336372375,
      "learning_rate": 5.647303006048924e-06,
      "loss": 0.01,
      "step": 838
    },
    {
      "epoch": 0.45922276956759717,
      "grad_norm": 0.006748910062015057,
      "learning_rate": 5.638776725443989e-06,
      "loss": 0.0002,
      "step": 839
    },
    {
      "epoch": 0.45977011494252873,
      "grad_norm": 0.22755107283592224,
      "learning_rate": 5.630248556101448e-06,
      "loss": 0.015,
      "step": 840
    },
    {
      "epoch": 0.4603174603174603,
      "grad_norm": 0.8569607734680176,
      "learning_rate": 5.621718523237427e-06,
      "loss": 0.0646,
      "step": 841
    },
    {
      "epoch": 0.4608648056923919,
      "grad_norm": 0.49240297079086304,
      "learning_rate": 5.613186652073561e-06,
      "loss": 0.0133,
      "step": 842
    },
    {
      "epoch": 0.4614121510673235,
      "grad_norm": 0.0012375196674838662,
      "learning_rate": 5.604652967836922e-06,
      "loss": 0.0001,
      "step": 843
    },
    {
      "epoch": 0.46195949644225504,
      "grad_norm": 1.3362196683883667,
      "learning_rate": 5.596117495759943e-06,
      "loss": 0.1722,
      "step": 844
    },
    {
      "epoch": 0.46250684181718665,
      "grad_norm": 0.9487481117248535,
      "learning_rate": 5.58758026108034e-06,
      "loss": 0.1095,
      "step": 845
    },
    {
      "epoch": 0.4630541871921182,
      "grad_norm": 0.0009652157896198332,
      "learning_rate": 5.579041289041045e-06,
      "loss": 0.0,
      "step": 846
    },
    {
      "epoch": 0.46360153256704983,
      "grad_norm": 0.001282971352338791,
      "learning_rate": 5.570500604890124e-06,
      "loss": 0.0001,
      "step": 847
    },
    {
      "epoch": 0.4641488779419814,
      "grad_norm": 0.3122837543487549,
      "learning_rate": 5.561958233880707e-06,
      "loss": 0.0155,
      "step": 848
    },
    {
      "epoch": 0.46469622331691296,
      "grad_norm": 0.03989687189459801,
      "learning_rate": 5.55341420127091e-06,
      "loss": 0.0021,
      "step": 849
    },
    {
      "epoch": 0.4652435686918446,
      "grad_norm": 0.10388272255659103,
      "learning_rate": 5.544868532323766e-06,
      "loss": 0.0037,
      "step": 850
    },
    {
      "epoch": 0.46579091406677614,
      "grad_norm": 0.003795329015702009,
      "learning_rate": 5.536321252307141e-06,
      "loss": 0.0001,
      "step": 851
    },
    {
      "epoch": 0.4663382594417077,
      "grad_norm": 0.0006622592336498201,
      "learning_rate": 5.527772386493667e-06,
      "loss": 0.0,
      "step": 852
    },
    {
      "epoch": 0.4668856048166393,
      "grad_norm": 0.00041852693539112806,
      "learning_rate": 5.519221960160666e-06,
      "loss": 0.0,
      "step": 853
    },
    {
      "epoch": 0.4674329501915709,
      "grad_norm": 1.2449188232421875,
      "learning_rate": 5.510669998590074e-06,
      "loss": 0.0986,
      "step": 854
    },
    {
      "epoch": 0.46798029556650245,
      "grad_norm": 0.12065764516592026,
      "learning_rate": 5.502116527068363e-06,
      "loss": 0.0028,
      "step": 855
    },
    {
      "epoch": 0.46852764094143406,
      "grad_norm": 0.004115154966711998,
      "learning_rate": 5.493561570886473e-06,
      "loss": 0.0002,
      "step": 856
    },
    {
      "epoch": 0.4690749863163656,
      "grad_norm": 0.24036113917827606,
      "learning_rate": 5.485005155339736e-06,
      "loss": 0.0119,
      "step": 857
    },
    {
      "epoch": 0.4696223316912972,
      "grad_norm": 0.38649430871009827,
      "learning_rate": 5.4764473057277925e-06,
      "loss": 0.02,
      "step": 858
    },
    {
      "epoch": 0.4701696770662288,
      "grad_norm": 0.004165897611528635,
      "learning_rate": 5.467888047354528e-06,
      "loss": 0.0002,
      "step": 859
    },
    {
      "epoch": 0.47071702244116037,
      "grad_norm": 0.023097684606909752,
      "learning_rate": 5.4593274055279935e-06,
      "loss": 0.0009,
      "step": 860
    },
    {
      "epoch": 0.47126436781609193,
      "grad_norm": 0.0023480262607336044,
      "learning_rate": 5.450765405560328e-06,
      "loss": 0.0001,
      "step": 861
    },
    {
      "epoch": 0.47181171319102355,
      "grad_norm": 0.0006399550475180149,
      "learning_rate": 5.442202072767686e-06,
      "loss": 0.0,
      "step": 862
    },
    {
      "epoch": 0.4723590585659551,
      "grad_norm": 2.7541401386260986,
      "learning_rate": 5.433637432470169e-06,
      "loss": 0.1758,
      "step": 863
    },
    {
      "epoch": 0.4729064039408867,
      "grad_norm": 0.7569266557693481,
      "learning_rate": 5.425071509991737e-06,
      "loss": 0.0378,
      "step": 864
    },
    {
      "epoch": 0.4734537493158183,
      "grad_norm": 0.017241017892956734,
      "learning_rate": 5.4165043306601436e-06,
      "loss": 0.0008,
      "step": 865
    },
    {
      "epoch": 0.47400109469074986,
      "grad_norm": 0.001771081006154418,
      "learning_rate": 5.407935919806862e-06,
      "loss": 0.0001,
      "step": 866
    },
    {
      "epoch": 0.4745484400656814,
      "grad_norm": 0.00035428363480605185,
      "learning_rate": 5.399366302767003e-06,
      "loss": 0.0,
      "step": 867
    },
    {
      "epoch": 0.47509578544061304,
      "grad_norm": 1.9787276983261108,
      "learning_rate": 5.390795504879243e-06,
      "loss": 0.2098,
      "step": 868
    },
    {
      "epoch": 0.4756431308155446,
      "grad_norm": 0.0021114398259669542,
      "learning_rate": 5.382223551485754e-06,
      "loss": 0.0001,
      "step": 869
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 0.00046936373109929264,
      "learning_rate": 5.373650467932122e-06,
      "loss": 0.0,
      "step": 870
    },
    {
      "epoch": 0.4767378215654078,
      "grad_norm": 1.6014357805252075,
      "learning_rate": 5.3650762795672755e-06,
      "loss": 0.0439,
      "step": 871
    },
    {
      "epoch": 0.47728516694033934,
      "grad_norm": 0.030676763504743576,
      "learning_rate": 5.356501011743408e-06,
      "loss": 0.001,
      "step": 872
    },
    {
      "epoch": 0.47783251231527096,
      "grad_norm": 0.0011511696502566338,
      "learning_rate": 5.347924689815906e-06,
      "loss": 0.0,
      "step": 873
    },
    {
      "epoch": 0.4783798576902025,
      "grad_norm": 1.2372933626174927,
      "learning_rate": 5.3393473391432745e-06,
      "loss": 0.2319,
      "step": 874
    },
    {
      "epoch": 0.4789272030651341,
      "grad_norm": 0.49274304509162903,
      "learning_rate": 5.330768985087059e-06,
      "loss": 0.0208,
      "step": 875
    },
    {
      "epoch": 0.4794745484400657,
      "grad_norm": 0.022832922637462616,
      "learning_rate": 5.32218965301177e-06,
      "loss": 0.0009,
      "step": 876
    },
    {
      "epoch": 0.48002189381499727,
      "grad_norm": 0.028788138180971146,
      "learning_rate": 5.313609368284813e-06,
      "loss": 0.0009,
      "step": 877
    },
    {
      "epoch": 0.48056923918992883,
      "grad_norm": 0.0015290683368220925,
      "learning_rate": 5.305028156276405e-06,
      "loss": 0.0001,
      "step": 878
    },
    {
      "epoch": 0.48111658456486045,
      "grad_norm": 0.0008398305508308113,
      "learning_rate": 5.296446042359512e-06,
      "loss": 0.0,
      "step": 879
    },
    {
      "epoch": 0.481663929939792,
      "grad_norm": 2.397152900695801,
      "learning_rate": 5.2878630519097605e-06,
      "loss": 0.1984,
      "step": 880
    },
    {
      "epoch": 0.4822112753147236,
      "grad_norm": 0.002422459190711379,
      "learning_rate": 5.279279210305373e-06,
      "loss": 0.0001,
      "step": 881
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.16335998475551605,
      "learning_rate": 5.270694542927089e-06,
      "loss": 0.0063,
      "step": 882
    },
    {
      "epoch": 0.48330596606458676,
      "grad_norm": 0.0011322450591251254,
      "learning_rate": 5.262109075158084e-06,
      "loss": 0.0,
      "step": 883
    },
    {
      "epoch": 0.4838533114395183,
      "grad_norm": 0.029906444251537323,
      "learning_rate": 5.2535228323839046e-06,
      "loss": 0.0017,
      "step": 884
    },
    {
      "epoch": 0.48440065681444994,
      "grad_norm": 0.00040645329863764346,
      "learning_rate": 5.2449358399923885e-06,
      "loss": 0.0,
      "step": 885
    },
    {
      "epoch": 0.4849480021893815,
      "grad_norm": 0.0004335923003964126,
      "learning_rate": 5.236348123373593e-06,
      "loss": 0.0,
      "step": 886
    },
    {
      "epoch": 0.48549534756431306,
      "grad_norm": 1.4093660116195679,
      "learning_rate": 5.227759707919707e-06,
      "loss": 0.0392,
      "step": 887
    },
    {
      "epoch": 0.4860426929392447,
      "grad_norm": 0.008594567887485027,
      "learning_rate": 5.219170619024996e-06,
      "loss": 0.0004,
      "step": 888
    },
    {
      "epoch": 0.48659003831417624,
      "grad_norm": 0.001886027050204575,
      "learning_rate": 5.2105808820857126e-06,
      "loss": 0.0001,
      "step": 889
    },
    {
      "epoch": 0.4871373836891078,
      "grad_norm": 1.7329763174057007,
      "learning_rate": 5.201990522500027e-06,
      "loss": 0.2633,
      "step": 890
    },
    {
      "epoch": 0.4876847290640394,
      "grad_norm": 0.08091209828853607,
      "learning_rate": 5.193399565667945e-06,
      "loss": 0.0022,
      "step": 891
    },
    {
      "epoch": 0.488232074438971,
      "grad_norm": 0.001181705272756517,
      "learning_rate": 5.184808036991246e-06,
      "loss": 0.0,
      "step": 892
    },
    {
      "epoch": 0.48877941981390255,
      "grad_norm": 0.001276014605537057,
      "learning_rate": 5.1762159618733954e-06,
      "loss": 0.0,
      "step": 893
    },
    {
      "epoch": 0.48932676518883417,
      "grad_norm": 0.0019202844705432653,
      "learning_rate": 5.167623365719474e-06,
      "loss": 0.0001,
      "step": 894
    },
    {
      "epoch": 0.48987411056376573,
      "grad_norm": 0.0005227384972386062,
      "learning_rate": 5.1590302739361096e-06,
      "loss": 0.0,
      "step": 895
    },
    {
      "epoch": 0.4904214559386973,
      "grad_norm": 0.00021066561748739332,
      "learning_rate": 5.150436711931387e-06,
      "loss": 0.0,
      "step": 896
    },
    {
      "epoch": 0.4909688013136289,
      "grad_norm": 2.1856143575860187e-05,
      "learning_rate": 5.1418427051147855e-06,
      "loss": 0.0,
      "step": 897
    },
    {
      "epoch": 0.4915161466885605,
      "grad_norm": 0.0005178875289857388,
      "learning_rate": 5.1332482788971005e-06,
      "loss": 0.0,
      "step": 898
    },
    {
      "epoch": 0.49206349206349204,
      "grad_norm": 0.004271036945283413,
      "learning_rate": 5.1246534586903655e-06,
      "loss": 0.0002,
      "step": 899
    },
    {
      "epoch": 0.49261083743842365,
      "grad_norm": 0.0007727842894382775,
      "learning_rate": 5.116058269907779e-06,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.4931581828133552,
      "grad_norm": 0.0004252692742738873,
      "learning_rate": 5.107462737963631e-06,
      "loss": 0.0,
      "step": 901
    },
    {
      "epoch": 0.49370552818828684,
      "grad_norm": 0.0001849114487413317,
      "learning_rate": 5.098866888273224e-06,
      "loss": 0.0,
      "step": 902
    },
    {
      "epoch": 0.4942528735632184,
      "grad_norm": 0.0010997502831742167,
      "learning_rate": 5.090270746252803e-06,
      "loss": 0.0,
      "step": 903
    },
    {
      "epoch": 0.49480021893814996,
      "grad_norm": 0.013869285583496094,
      "learning_rate": 5.081674337319473e-06,
      "loss": 0.0005,
      "step": 904
    },
    {
      "epoch": 0.4953475643130816,
      "grad_norm": 4.305586338043213,
      "learning_rate": 5.073077686891132e-06,
      "loss": 0.8245,
      "step": 905
    },
    {
      "epoch": 0.49589490968801314,
      "grad_norm": 2.254753828048706,
      "learning_rate": 5.0644808203863926e-06,
      "loss": 0.3568,
      "step": 906
    },
    {
      "epoch": 0.4964422550629447,
      "grad_norm": 0.0018512940732762218,
      "learning_rate": 5.055883763224502e-06,
      "loss": 0.0001,
      "step": 907
    },
    {
      "epoch": 0.4969896004378763,
      "grad_norm": 0.00021449064661283046,
      "learning_rate": 5.047286540825273e-06,
      "loss": 0.0,
      "step": 908
    },
    {
      "epoch": 0.4975369458128079,
      "grad_norm": 0.0024165092036128044,
      "learning_rate": 5.038689178609011e-06,
      "loss": 0.0001,
      "step": 909
    },
    {
      "epoch": 0.49808429118773945,
      "grad_norm": 0.0024142004549503326,
      "learning_rate": 5.030091701996428e-06,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.49863163656267107,
      "grad_norm": 0.013886503875255585,
      "learning_rate": 5.021494136408578e-06,
      "loss": 0.0006,
      "step": 911
    },
    {
      "epoch": 0.49917898193760263,
      "grad_norm": 0.00026073234039358795,
      "learning_rate": 5.012896507266779e-06,
      "loss": 0.0,
      "step": 912
    },
    {
      "epoch": 0.4997263273125342,
      "grad_norm": 4.660869598388672,
      "learning_rate": 5.0042988399925365e-06,
      "loss": 1.197,
      "step": 913
    },
    {
      "epoch": 0.5002736726874658,
      "grad_norm": 0.08007229119539261,
      "learning_rate": 4.995701160007466e-06,
      "loss": 0.0038,
      "step": 914
    },
    {
      "epoch": 0.5008210180623974,
      "grad_norm": 0.0006899655563756824,
      "learning_rate": 4.987103492733221e-06,
      "loss": 0.0,
      "step": 915
    },
    {
      "epoch": 0.5013683634373289,
      "grad_norm": 0.000642841390799731,
      "learning_rate": 4.9785058635914234e-06,
      "loss": 0.0,
      "step": 916
    },
    {
      "epoch": 0.5019157088122606,
      "grad_norm": 0.10209622234106064,
      "learning_rate": 4.9699082980035735e-06,
      "loss": 0.0026,
      "step": 917
    },
    {
      "epoch": 0.5024630541871922,
      "grad_norm": 0.0023626009933650494,
      "learning_rate": 4.96131082139099e-06,
      "loss": 0.0001,
      "step": 918
    },
    {
      "epoch": 0.5030103995621237,
      "grad_norm": 0.009768937714397907,
      "learning_rate": 4.952713459174728e-06,
      "loss": 0.0005,
      "step": 919
    },
    {
      "epoch": 0.5035577449370553,
      "grad_norm": 0.00041657217661850154,
      "learning_rate": 4.944116236775499e-06,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 0.5041050903119869,
      "grad_norm": 0.0010911704739555717,
      "learning_rate": 4.935519179613607e-06,
      "loss": 0.0,
      "step": 921
    },
    {
      "epoch": 0.5046524356869184,
      "grad_norm": 0.005551759619265795,
      "learning_rate": 4.9269223131088685e-06,
      "loss": 0.0002,
      "step": 922
    },
    {
      "epoch": 0.50519978106185,
      "grad_norm": 0.006575553212314844,
      "learning_rate": 4.9183256626805276e-06,
      "loss": 0.0003,
      "step": 923
    },
    {
      "epoch": 0.5057471264367817,
      "grad_norm": 0.013901177793741226,
      "learning_rate": 4.909729253747197e-06,
      "loss": 0.0005,
      "step": 924
    },
    {
      "epoch": 0.5062944718117132,
      "grad_norm": 1.5175549983978271,
      "learning_rate": 4.901133111726777e-06,
      "loss": 0.073,
      "step": 925
    },
    {
      "epoch": 0.5068418171866448,
      "grad_norm": 3.358978509902954,
      "learning_rate": 4.892537262036371e-06,
      "loss": 0.2471,
      "step": 926
    },
    {
      "epoch": 0.5073891625615764,
      "grad_norm": 4.988062858581543,
      "learning_rate": 4.883941730092222e-06,
      "loss": 0.4919,
      "step": 927
    },
    {
      "epoch": 0.5079365079365079,
      "grad_norm": 0.1463773399591446,
      "learning_rate": 4.875346541309637e-06,
      "loss": 0.0069,
      "step": 928
    },
    {
      "epoch": 0.5084838533114395,
      "grad_norm": 4.092678070068359,
      "learning_rate": 4.866751721102901e-06,
      "loss": 0.6202,
      "step": 929
    },
    {
      "epoch": 0.5090311986863711,
      "grad_norm": 0.003399160923436284,
      "learning_rate": 4.858157294885215e-06,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 0.5095785440613027,
      "grad_norm": 0.062302470207214355,
      "learning_rate": 4.8495632880686155e-06,
      "loss": 0.0021,
      "step": 931
    },
    {
      "epoch": 0.5101258894362343,
      "grad_norm": 0.00044705820619128644,
      "learning_rate": 4.840969726063892e-06,
      "loss": 0.0,
      "step": 932
    },
    {
      "epoch": 0.5106732348111659,
      "grad_norm": 0.0003987425589002669,
      "learning_rate": 4.832376634280526e-06,
      "loss": 0.0,
      "step": 933
    },
    {
      "epoch": 0.5112205801860974,
      "grad_norm": 0.0005271355621516705,
      "learning_rate": 4.823784038126608e-06,
      "loss": 0.0,
      "step": 934
    },
    {
      "epoch": 0.511767925561029,
      "grad_norm": 0.014913531951606274,
      "learning_rate": 4.8151919630087565e-06,
      "loss": 0.0006,
      "step": 935
    },
    {
      "epoch": 0.5123152709359606,
      "grad_norm": 0.000541572633665055,
      "learning_rate": 4.806600434332056e-06,
      "loss": 0.0,
      "step": 936
    },
    {
      "epoch": 0.5128626163108921,
      "grad_norm": 0.0056103733368217945,
      "learning_rate": 4.7980094774999765e-06,
      "loss": 0.0003,
      "step": 937
    },
    {
      "epoch": 0.5134099616858238,
      "grad_norm": 0.0006830109050497413,
      "learning_rate": 4.789419117914288e-06,
      "loss": 0.0,
      "step": 938
    },
    {
      "epoch": 0.5139573070607554,
      "grad_norm": 0.0006879201391711831,
      "learning_rate": 4.780829380975004e-06,
      "loss": 0.0,
      "step": 939
    },
    {
      "epoch": 0.5145046524356869,
      "grad_norm": 0.0007039613556116819,
      "learning_rate": 4.772240292080295e-06,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 0.5150519978106185,
      "grad_norm": 0.05298076570034027,
      "learning_rate": 4.76365187662641e-06,
      "loss": 0.0031,
      "step": 941
    },
    {
      "epoch": 0.5155993431855501,
      "grad_norm": 0.0012256661430001259,
      "learning_rate": 4.755064160007612e-06,
      "loss": 0.0001,
      "step": 942
    },
    {
      "epoch": 0.5161466885604816,
      "grad_norm": 0.0012102493783459067,
      "learning_rate": 4.746477167616098e-06,
      "loss": 0.0001,
      "step": 943
    },
    {
      "epoch": 0.5166940339354132,
      "grad_norm": 2.676253318786621,
      "learning_rate": 4.737890924841918e-06,
      "loss": 0.474,
      "step": 944
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.004694405011832714,
      "learning_rate": 4.729305457072913e-06,
      "loss": 0.0002,
      "step": 945
    },
    {
      "epoch": 0.5177887246852764,
      "grad_norm": 0.009479188360273838,
      "learning_rate": 4.7207207896946275e-06,
      "loss": 0.0004,
      "step": 946
    },
    {
      "epoch": 0.518336070060208,
      "grad_norm": 0.0035201581194996834,
      "learning_rate": 4.712136948090241e-06,
      "loss": 0.0002,
      "step": 947
    },
    {
      "epoch": 0.5188834154351396,
      "grad_norm": 0.004573117475956678,
      "learning_rate": 4.70355395764049e-06,
      "loss": 0.0002,
      "step": 948
    },
    {
      "epoch": 0.5194307608100711,
      "grad_norm": 0.0006347939488478005,
      "learning_rate": 4.694971843723596e-06,
      "loss": 0.0,
      "step": 949
    },
    {
      "epoch": 0.5199781061850027,
      "grad_norm": 0.21034711599349976,
      "learning_rate": 4.68639063171519e-06,
      "loss": 0.0082,
      "step": 950
    },
    {
      "epoch": 0.5205254515599343,
      "grad_norm": 0.2801590859889984,
      "learning_rate": 4.677810346988231e-06,
      "loss": 0.0135,
      "step": 951
    },
    {
      "epoch": 0.5210727969348659,
      "grad_norm": 0.0023894787300378084,
      "learning_rate": 4.6692310149129425e-06,
      "loss": 0.0001,
      "step": 952
    },
    {
      "epoch": 0.5216201423097975,
      "grad_norm": 0.0012811381602659822,
      "learning_rate": 4.660652660856726e-06,
      "loss": 0.0001,
      "step": 953
    },
    {
      "epoch": 0.5221674876847291,
      "grad_norm": 0.01098531112074852,
      "learning_rate": 4.6520753101840945e-06,
      "loss": 0.0004,
      "step": 954
    },
    {
      "epoch": 0.5227148330596606,
      "grad_norm": 0.0032795167062431574,
      "learning_rate": 4.643498988256595e-06,
      "loss": 0.0002,
      "step": 955
    },
    {
      "epoch": 0.5232621784345922,
      "grad_norm": 0.08193386346101761,
      "learning_rate": 4.634923720432727e-06,
      "loss": 0.0046,
      "step": 956
    },
    {
      "epoch": 0.5238095238095238,
      "grad_norm": 0.004404212813824415,
      "learning_rate": 4.626349532067879e-06,
      "loss": 0.0002,
      "step": 957
    },
    {
      "epoch": 0.5243568691844553,
      "grad_norm": 1.7145532369613647,
      "learning_rate": 4.617776448514248e-06,
      "loss": 0.1303,
      "step": 958
    },
    {
      "epoch": 0.524904214559387,
      "grad_norm": 0.009254885837435722,
      "learning_rate": 4.609204495120759e-06,
      "loss": 0.0004,
      "step": 959
    },
    {
      "epoch": 0.5254515599343186,
      "grad_norm": 0.0035961109679192305,
      "learning_rate": 4.600633697232999e-06,
      "loss": 0.0002,
      "step": 960
    },
    {
      "epoch": 0.5259989053092501,
      "grad_norm": 0.001837221090681851,
      "learning_rate": 4.59206408019314e-06,
      "loss": 0.0001,
      "step": 961
    },
    {
      "epoch": 0.5265462506841817,
      "grad_norm": 0.2756393253803253,
      "learning_rate": 4.583495669339857e-06,
      "loss": 0.0166,
      "step": 962
    },
    {
      "epoch": 0.5270935960591133,
      "grad_norm": 2.067518472671509,
      "learning_rate": 4.574928490008264e-06,
      "loss": 0.3385,
      "step": 963
    },
    {
      "epoch": 0.5276409414340448,
      "grad_norm": 0.002155408961698413,
      "learning_rate": 4.566362567529834e-06,
      "loss": 0.0001,
      "step": 964
    },
    {
      "epoch": 0.5281882868089764,
      "grad_norm": 0.0029582607094198465,
      "learning_rate": 4.557797927232315e-06,
      "loss": 0.0001,
      "step": 965
    },
    {
      "epoch": 0.5287356321839081,
      "grad_norm": 0.01895778439939022,
      "learning_rate": 4.549234594439674e-06,
      "loss": 0.0009,
      "step": 966
    },
    {
      "epoch": 0.5292829775588396,
      "grad_norm": 0.07389695942401886,
      "learning_rate": 4.54067259447201e-06,
      "loss": 0.0035,
      "step": 967
    },
    {
      "epoch": 0.5298303229337712,
      "grad_norm": 0.013815285637974739,
      "learning_rate": 4.532111952645474e-06,
      "loss": 0.0006,
      "step": 968
    },
    {
      "epoch": 0.5303776683087028,
      "grad_norm": 0.0035076832864433527,
      "learning_rate": 4.523552694272208e-06,
      "loss": 0.0002,
      "step": 969
    },
    {
      "epoch": 0.5309250136836344,
      "grad_norm": 0.33735764026641846,
      "learning_rate": 4.514994844660265e-06,
      "loss": 0.0092,
      "step": 970
    },
    {
      "epoch": 0.5314723590585659,
      "grad_norm": 0.1473022848367691,
      "learning_rate": 4.506438429113528e-06,
      "loss": 0.0052,
      "step": 971
    },
    {
      "epoch": 0.5320197044334976,
      "grad_norm": 0.0023626992478966713,
      "learning_rate": 4.497883472931639e-06,
      "loss": 0.0001,
      "step": 972
    },
    {
      "epoch": 0.5325670498084292,
      "grad_norm": 2.766012191772461,
      "learning_rate": 4.489330001409929e-06,
      "loss": 0.3144,
      "step": 973
    },
    {
      "epoch": 0.5331143951833607,
      "grad_norm": 0.31422752141952515,
      "learning_rate": 4.480778039839336e-06,
      "loss": 0.0141,
      "step": 974
    },
    {
      "epoch": 0.5336617405582923,
      "grad_norm": 0.008195869624614716,
      "learning_rate": 4.472227613506334e-06,
      "loss": 0.0003,
      "step": 975
    },
    {
      "epoch": 0.5342090859332239,
      "grad_norm": 0.00780548295006156,
      "learning_rate": 4.4636787476928605e-06,
      "loss": 0.0004,
      "step": 976
    },
    {
      "epoch": 0.5347564313081554,
      "grad_norm": 0.0005352984298951924,
      "learning_rate": 4.455131467676235e-06,
      "loss": 0.0,
      "step": 977
    },
    {
      "epoch": 0.535303776683087,
      "grad_norm": 0.911663293838501,
      "learning_rate": 4.446585798729091e-06,
      "loss": 0.041,
      "step": 978
    },
    {
      "epoch": 0.5358511220580187,
      "grad_norm": 0.012656357139348984,
      "learning_rate": 4.438041766119293e-06,
      "loss": 0.0007,
      "step": 979
    },
    {
      "epoch": 0.5363984674329502,
      "grad_norm": 1.191988229751587,
      "learning_rate": 4.429499395109877e-06,
      "loss": 0.1296,
      "step": 980
    },
    {
      "epoch": 0.5369458128078818,
      "grad_norm": 1.0622273683547974,
      "learning_rate": 4.4209587109589565e-06,
      "loss": 0.1639,
      "step": 981
    },
    {
      "epoch": 0.5374931581828134,
      "grad_norm": 0.0018951299134641886,
      "learning_rate": 4.412419738919661e-06,
      "loss": 0.0001,
      "step": 982
    },
    {
      "epoch": 0.5380405035577449,
      "grad_norm": 0.0006265489500947297,
      "learning_rate": 4.40388250424006e-06,
      "loss": 0.0,
      "step": 983
    },
    {
      "epoch": 0.5385878489326765,
      "grad_norm": 0.003240352962166071,
      "learning_rate": 4.395347032163079e-06,
      "loss": 0.0001,
      "step": 984
    },
    {
      "epoch": 0.5391351943076081,
      "grad_norm": 3.5216872692108154,
      "learning_rate": 4.38681334792644e-06,
      "loss": 0.4857,
      "step": 985
    },
    {
      "epoch": 0.5396825396825397,
      "grad_norm": 3.7577157020568848,
      "learning_rate": 4.3782814767625755e-06,
      "loss": 0.145,
      "step": 986
    },
    {
      "epoch": 0.5402298850574713,
      "grad_norm": 0.015162983909249306,
      "learning_rate": 4.369751443898554e-06,
      "loss": 0.0004,
      "step": 987
    },
    {
      "epoch": 0.5407772304324029,
      "grad_norm": 2.793144702911377,
      "learning_rate": 4.361223274556012e-06,
      "loss": 0.5689,
      "step": 988
    },
    {
      "epoch": 0.5413245758073344,
      "grad_norm": 0.008402367122471333,
      "learning_rate": 4.3526969939510785e-06,
      "loss": 0.0005,
      "step": 989
    },
    {
      "epoch": 0.541871921182266,
      "grad_norm": 0.0006886696210131049,
      "learning_rate": 4.3441726272942895e-06,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 0.5424192665571976,
      "grad_norm": 0.005813713651150465,
      "learning_rate": 4.335650199790528e-06,
      "loss": 0.0003,
      "step": 991
    },
    {
      "epoch": 0.5429666119321291,
      "grad_norm": 0.910251259803772,
      "learning_rate": 4.327129736638946e-06,
      "loss": 0.1932,
      "step": 992
    },
    {
      "epoch": 0.5435139573070608,
      "grad_norm": 1.3571258783340454,
      "learning_rate": 4.318611263032878e-06,
      "loss": 0.3708,
      "step": 993
    },
    {
      "epoch": 0.5440613026819924,
      "grad_norm": 2.939852237701416,
      "learning_rate": 4.310094804159784e-06,
      "loss": 0.1309,
      "step": 994
    },
    {
      "epoch": 0.5446086480569239,
      "grad_norm": 0.008258461952209473,
      "learning_rate": 4.301580385201166e-06,
      "loss": 0.0003,
      "step": 995
    },
    {
      "epoch": 0.5451559934318555,
      "grad_norm": 0.890642523765564,
      "learning_rate": 4.293068031332488e-06,
      "loss": 0.0275,
      "step": 996
    },
    {
      "epoch": 0.5457033388067871,
      "grad_norm": 0.01869889907538891,
      "learning_rate": 4.284557767723114e-06,
      "loss": 0.0009,
      "step": 997
    },
    {
      "epoch": 0.5462506841817186,
      "grad_norm": 0.005374888889491558,
      "learning_rate": 4.2760496195362285e-06,
      "loss": 0.0003,
      "step": 998
    },
    {
      "epoch": 0.5467980295566502,
      "grad_norm": 1.3763353824615479,
      "learning_rate": 4.267543611928755e-06,
      "loss": 0.1025,
      "step": 999
    },
    {
      "epoch": 0.5473453749315819,
      "grad_norm": 0.026802819222211838,
      "learning_rate": 4.259039770051292e-06,
      "loss": 0.0012,
      "step": 1000
    },
    {
      "epoch": 0.5478927203065134,
      "grad_norm": 0.24822171032428741,
      "learning_rate": 4.250538119048036e-06,
      "loss": 0.0131,
      "step": 1001
    },
    {
      "epoch": 0.548440065681445,
      "grad_norm": 0.004713200498372316,
      "learning_rate": 4.2420386840567e-06,
      "loss": 0.0002,
      "step": 1002
    },
    {
      "epoch": 0.5489874110563766,
      "grad_norm": 0.24642421305179596,
      "learning_rate": 4.233541490208448e-06,
      "loss": 0.0126,
      "step": 1003
    },
    {
      "epoch": 0.5495347564313081,
      "grad_norm": 0.003249788424000144,
      "learning_rate": 4.22504656262782e-06,
      "loss": 0.0002,
      "step": 1004
    },
    {
      "epoch": 0.5500821018062397,
      "grad_norm": 2.811911106109619,
      "learning_rate": 4.2165539264326495e-06,
      "loss": 0.5737,
      "step": 1005
    },
    {
      "epoch": 0.5506294471811713,
      "grad_norm": 0.0018355202628299594,
      "learning_rate": 4.208063606733999e-06,
      "loss": 0.0001,
      "step": 1006
    },
    {
      "epoch": 0.5511767925561029,
      "grad_norm": 0.010328040458261967,
      "learning_rate": 4.199575628636078e-06,
      "loss": 0.0006,
      "step": 1007
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.0012197336181998253,
      "learning_rate": 4.191090017236177e-06,
      "loss": 0.0001,
      "step": 1008
    },
    {
      "epoch": 0.5522714833059661,
      "grad_norm": 0.7546660900115967,
      "learning_rate": 4.182606797624585e-06,
      "loss": 0.1311,
      "step": 1009
    },
    {
      "epoch": 0.5528188286808976,
      "grad_norm": 0.0011327590327709913,
      "learning_rate": 4.1741259948845206e-06,
      "loss": 0.0001,
      "step": 1010
    },
    {
      "epoch": 0.5533661740558292,
      "grad_norm": 1.919417381286621,
      "learning_rate": 4.165647634092055e-06,
      "loss": 0.2677,
      "step": 1011
    },
    {
      "epoch": 0.5539135194307608,
      "grad_norm": 0.0059348223730921745,
      "learning_rate": 4.157171740316039e-06,
      "loss": 0.0003,
      "step": 1012
    },
    {
      "epoch": 0.5544608648056923,
      "grad_norm": 0.019596166908740997,
      "learning_rate": 4.148698338618031e-06,
      "loss": 0.0009,
      "step": 1013
    },
    {
      "epoch": 0.555008210180624,
      "grad_norm": 0.0008345222449861467,
      "learning_rate": 4.14022745405222e-06,
      "loss": 0.0001,
      "step": 1014
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.0026295967400074005,
      "learning_rate": 4.131759111665349e-06,
      "loss": 0.0001,
      "step": 1015
    },
    {
      "epoch": 0.5561029009304871,
      "grad_norm": 0.9461176991462708,
      "learning_rate": 4.123293336496651e-06,
      "loss": 0.0543,
      "step": 1016
    },
    {
      "epoch": 0.5566502463054187,
      "grad_norm": 0.0012206487590447068,
      "learning_rate": 4.114830153577759e-06,
      "loss": 0.0001,
      "step": 1017
    },
    {
      "epoch": 0.5571975916803503,
      "grad_norm": 0.046158261597156525,
      "learning_rate": 4.10636958793265e-06,
      "loss": 0.0032,
      "step": 1018
    },
    {
      "epoch": 0.5577449370552818,
      "grad_norm": 0.024245616048574448,
      "learning_rate": 4.0979116645775606e-06,
      "loss": 0.0002,
      "step": 1019
    },
    {
      "epoch": 0.5582922824302134,
      "grad_norm": 0.02930334582924843,
      "learning_rate": 4.089456408520908e-06,
      "loss": 0.0012,
      "step": 1020
    },
    {
      "epoch": 0.5588396278051451,
      "grad_norm": 4.483842849731445,
      "learning_rate": 4.0810038447632296e-06,
      "loss": 0.3299,
      "step": 1021
    },
    {
      "epoch": 0.5593869731800766,
      "grad_norm": 0.12888051569461823,
      "learning_rate": 4.072553998297103e-06,
      "loss": 0.0062,
      "step": 1022
    },
    {
      "epoch": 0.5599343185550082,
      "grad_norm": 0.008579583838582039,
      "learning_rate": 4.064106894107064e-06,
      "loss": 0.0004,
      "step": 1023
    },
    {
      "epoch": 0.5604816639299398,
      "grad_norm": 0.027332140132784843,
      "learning_rate": 4.055662557169545e-06,
      "loss": 0.0013,
      "step": 1024
    },
    {
      "epoch": 0.5610290093048714,
      "grad_norm": 0.292493611574173,
      "learning_rate": 4.047221012452798e-06,
      "loss": 0.0241,
      "step": 1025
    },
    {
      "epoch": 0.5615763546798029,
      "grad_norm": 0.000994612812064588,
      "learning_rate": 4.0387822849168165e-06,
      "loss": 0.0,
      "step": 1026
    },
    {
      "epoch": 0.5621237000547346,
      "grad_norm": 0.001369150704704225,
      "learning_rate": 4.030346399513261e-06,
      "loss": 0.0001,
      "step": 1027
    },
    {
      "epoch": 0.5626710454296662,
      "grad_norm": 0.001532485825009644,
      "learning_rate": 4.021913381185394e-06,
      "loss": 0.0001,
      "step": 1028
    },
    {
      "epoch": 0.5632183908045977,
      "grad_norm": 0.12731030583381653,
      "learning_rate": 4.013483254868001e-06,
      "loss": 0.0069,
      "step": 1029
    },
    {
      "epoch": 0.5637657361795293,
      "grad_norm": 6.287137508392334,
      "learning_rate": 4.005056045487307e-06,
      "loss": 0.2428,
      "step": 1030
    },
    {
      "epoch": 0.5643130815544609,
      "grad_norm": 0.07196670770645142,
      "learning_rate": 3.996631777960923e-06,
      "loss": 0.0052,
      "step": 1031
    },
    {
      "epoch": 0.5648604269293924,
      "grad_norm": 0.002613269491121173,
      "learning_rate": 3.9882104771977585e-06,
      "loss": 0.0001,
      "step": 1032
    },
    {
      "epoch": 0.565407772304324,
      "grad_norm": 0.05085465684533119,
      "learning_rate": 3.979792168097946e-06,
      "loss": 0.0024,
      "step": 1033
    },
    {
      "epoch": 0.5659551176792557,
      "grad_norm": 0.032987095415592194,
      "learning_rate": 3.971376875552777e-06,
      "loss": 0.0014,
      "step": 1034
    },
    {
      "epoch": 0.5665024630541872,
      "grad_norm": 0.0029627911280840635,
      "learning_rate": 3.962964624444625e-06,
      "loss": 0.0001,
      "step": 1035
    },
    {
      "epoch": 0.5670498084291188,
      "grad_norm": 0.0501064732670784,
      "learning_rate": 3.9545554396468655e-06,
      "loss": 0.0023,
      "step": 1036
    },
    {
      "epoch": 0.5675971538040504,
      "grad_norm": 0.0017705339705571532,
      "learning_rate": 3.946149346023811e-06,
      "loss": 0.0001,
      "step": 1037
    },
    {
      "epoch": 0.5681444991789819,
      "grad_norm": 0.0016968612326309085,
      "learning_rate": 3.937746368430633e-06,
      "loss": 0.0001,
      "step": 1038
    },
    {
      "epoch": 0.5686918445539135,
      "grad_norm": 0.19691023230552673,
      "learning_rate": 3.929346531713289e-06,
      "loss": 0.0092,
      "step": 1039
    },
    {
      "epoch": 0.5692391899288451,
      "grad_norm": 0.07609004527330399,
      "learning_rate": 3.920949860708452e-06,
      "loss": 0.0046,
      "step": 1040
    },
    {
      "epoch": 0.5697865353037767,
      "grad_norm": 0.0011704409262165427,
      "learning_rate": 3.912556380243431e-06,
      "loss": 0.0001,
      "step": 1041
    },
    {
      "epoch": 0.5703338806787083,
      "grad_norm": 0.008865013718605042,
      "learning_rate": 3.9041661151361045e-06,
      "loss": 0.0004,
      "step": 1042
    },
    {
      "epoch": 0.5708812260536399,
      "grad_norm": 0.005340239964425564,
      "learning_rate": 3.89577909019484e-06,
      "loss": 0.0003,
      "step": 1043
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.01579965464770794,
      "learning_rate": 3.887395330218429e-06,
      "loss": 0.0008,
      "step": 1044
    },
    {
      "epoch": 0.571975916803503,
      "grad_norm": 0.0026513512711972,
      "learning_rate": 3.879014859996006e-06,
      "loss": 0.0001,
      "step": 1045
    },
    {
      "epoch": 0.5725232621784346,
      "grad_norm": 3.3333933353424072,
      "learning_rate": 3.8706377043069785e-06,
      "loss": 0.2446,
      "step": 1046
    },
    {
      "epoch": 0.5730706075533661,
      "grad_norm": 0.014968456700444221,
      "learning_rate": 3.862263887920957e-06,
      "loss": 0.0009,
      "step": 1047
    },
    {
      "epoch": 0.5736179529282978,
      "grad_norm": 0.053027112036943436,
      "learning_rate": 3.853893435597673e-06,
      "loss": 0.0041,
      "step": 1048
    },
    {
      "epoch": 0.5741652983032294,
      "grad_norm": 0.0016080422792583704,
      "learning_rate": 3.8455263720869134e-06,
      "loss": 0.0001,
      "step": 1049
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 1.5250251293182373,
      "learning_rate": 3.8371627221284495e-06,
      "loss": 0.0733,
      "step": 1050
    },
    {
      "epoch": 0.5752599890530925,
      "grad_norm": 0.023328721523284912,
      "learning_rate": 3.82880251045195e-06,
      "loss": 0.0014,
      "step": 1051
    },
    {
      "epoch": 0.5758073344280241,
      "grad_norm": 0.0023568961769342422,
      "learning_rate": 3.820445761776925e-06,
      "loss": 0.0001,
      "step": 1052
    },
    {
      "epoch": 0.5763546798029556,
      "grad_norm": 1.2063764333724976,
      "learning_rate": 3.8120925008126457e-06,
      "loss": 0.0611,
      "step": 1053
    },
    {
      "epoch": 0.5769020251778872,
      "grad_norm": 0.00283458991907537,
      "learning_rate": 3.8037427522580627e-06,
      "loss": 0.0001,
      "step": 1054
    },
    {
      "epoch": 0.5774493705528189,
      "grad_norm": 0.32890039682388306,
      "learning_rate": 3.7953965408017483e-06,
      "loss": 0.0198,
      "step": 1055
    },
    {
      "epoch": 0.5779967159277504,
      "grad_norm": 0.11421054601669312,
      "learning_rate": 3.7870538911218176e-06,
      "loss": 0.007,
      "step": 1056
    },
    {
      "epoch": 0.578544061302682,
      "grad_norm": 0.2738316059112549,
      "learning_rate": 3.7787148278858453e-06,
      "loss": 0.0179,
      "step": 1057
    },
    {
      "epoch": 0.5790914066776136,
      "grad_norm": 0.0026325371582061052,
      "learning_rate": 3.77037937575081e-06,
      "loss": 0.0001,
      "step": 1058
    },
    {
      "epoch": 0.5796387520525451,
      "grad_norm": 1.050933599472046,
      "learning_rate": 3.762047559363013e-06,
      "loss": 0.0548,
      "step": 1059
    },
    {
      "epoch": 0.5801860974274767,
      "grad_norm": 0.7810535430908203,
      "learning_rate": 3.753719403357997e-06,
      "loss": 0.0445,
      "step": 1060
    },
    {
      "epoch": 0.5807334428024084,
      "grad_norm": 0.0031372911762446165,
      "learning_rate": 3.745394932360491e-06,
      "loss": 0.0002,
      "step": 1061
    },
    {
      "epoch": 0.5812807881773399,
      "grad_norm": 0.0023640862200409174,
      "learning_rate": 3.7370741709843263e-06,
      "loss": 0.0001,
      "step": 1062
    },
    {
      "epoch": 0.5818281335522715,
      "grad_norm": 0.0010642081033438444,
      "learning_rate": 3.728757143832359e-06,
      "loss": 0.0001,
      "step": 1063
    },
    {
      "epoch": 0.5823754789272031,
      "grad_norm": 0.02033339813351631,
      "learning_rate": 3.7204438754964113e-06,
      "loss": 0.001,
      "step": 1064
    },
    {
      "epoch": 0.5829228243021346,
      "grad_norm": 2.35357928276062,
      "learning_rate": 3.7121343905571897e-06,
      "loss": 0.3744,
      "step": 1065
    },
    {
      "epoch": 0.5834701696770662,
      "grad_norm": 0.0011923862621188164,
      "learning_rate": 3.70382871358421e-06,
      "loss": 0.0001,
      "step": 1066
    },
    {
      "epoch": 0.5840175150519978,
      "grad_norm": 0.04582935944199562,
      "learning_rate": 3.695526869135733e-06,
      "loss": 0.0024,
      "step": 1067
    },
    {
      "epoch": 0.5845648604269293,
      "grad_norm": 0.0009349542669951916,
      "learning_rate": 3.6872288817586883e-06,
      "loss": 0.0,
      "step": 1068
    },
    {
      "epoch": 0.585112205801861,
      "grad_norm": 0.33555668592453003,
      "learning_rate": 3.678934775988594e-06,
      "loss": 0.0205,
      "step": 1069
    },
    {
      "epoch": 0.5856595511767926,
      "grad_norm": 0.1617787629365921,
      "learning_rate": 3.6706445763494976e-06,
      "loss": 0.0091,
      "step": 1070
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 0.5646578073501587,
      "learning_rate": 3.662358307353897e-06,
      "loss": 0.0177,
      "step": 1071
    },
    {
      "epoch": 0.5867542419266557,
      "grad_norm": 0.012125184759497643,
      "learning_rate": 3.6540759935026627e-06,
      "loss": 0.0007,
      "step": 1072
    },
    {
      "epoch": 0.5873015873015873,
      "grad_norm": 0.009456817060709,
      "learning_rate": 3.6457976592849753e-06,
      "loss": 0.0005,
      "step": 1073
    },
    {
      "epoch": 0.5878489326765188,
      "grad_norm": 1.9018356800079346,
      "learning_rate": 3.637523329178247e-06,
      "loss": 0.1752,
      "step": 1074
    },
    {
      "epoch": 0.5883962780514504,
      "grad_norm": 0.002715671667829156,
      "learning_rate": 3.6292530276480493e-06,
      "loss": 0.0001,
      "step": 1075
    },
    {
      "epoch": 0.5889436234263821,
      "grad_norm": 0.02979108691215515,
      "learning_rate": 3.6209867791480446e-06,
      "loss": 0.0019,
      "step": 1076
    },
    {
      "epoch": 0.5894909688013136,
      "grad_norm": 1.0899358987808228,
      "learning_rate": 3.6127246081199107e-06,
      "loss": 0.0463,
      "step": 1077
    },
    {
      "epoch": 0.5900383141762452,
      "grad_norm": 0.03347780928015709,
      "learning_rate": 3.6044665389932663e-06,
      "loss": 0.0012,
      "step": 1078
    },
    {
      "epoch": 0.5905856595511768,
      "grad_norm": 0.0021594346035271883,
      "learning_rate": 3.596212596185603e-06,
      "loss": 0.0001,
      "step": 1079
    },
    {
      "epoch": 0.5911330049261084,
      "grad_norm": 3.2509613037109375,
      "learning_rate": 3.587962804102214e-06,
      "loss": 0.645,
      "step": 1080
    },
    {
      "epoch": 0.5916803503010399,
      "grad_norm": 0.009944343008100986,
      "learning_rate": 3.5797171871361203e-06,
      "loss": 0.0005,
      "step": 1081
    },
    {
      "epoch": 0.5922276956759716,
      "grad_norm": 0.0844244733452797,
      "learning_rate": 3.57147576966799e-06,
      "loss": 0.0028,
      "step": 1082
    },
    {
      "epoch": 0.5927750410509032,
      "grad_norm": 0.05854829028248787,
      "learning_rate": 3.5632385760660828e-06,
      "loss": 0.0028,
      "step": 1083
    },
    {
      "epoch": 0.5933223864258347,
      "grad_norm": 0.0009039297001436353,
      "learning_rate": 3.5550056306861667e-06,
      "loss": 0.0,
      "step": 1084
    },
    {
      "epoch": 0.5938697318007663,
      "grad_norm": 0.1424560695886612,
      "learning_rate": 3.5467769578714455e-06,
      "loss": 0.0045,
      "step": 1085
    },
    {
      "epoch": 0.5944170771756979,
      "grad_norm": 0.004798490554094315,
      "learning_rate": 3.5385525819524933e-06,
      "loss": 0.0002,
      "step": 1086
    },
    {
      "epoch": 0.5949644225506294,
      "grad_norm": 0.003912128042429686,
      "learning_rate": 3.530332527247181e-06,
      "loss": 0.0002,
      "step": 1087
    },
    {
      "epoch": 0.595511767925561,
      "grad_norm": 0.050953254103660583,
      "learning_rate": 3.5221168180605946e-06,
      "loss": 0.0028,
      "step": 1088
    },
    {
      "epoch": 0.5960591133004927,
      "grad_norm": 0.0018687569536268711,
      "learning_rate": 3.5139054786849787e-06,
      "loss": 0.0001,
      "step": 1089
    },
    {
      "epoch": 0.5966064586754242,
      "grad_norm": 0.004310886841267347,
      "learning_rate": 3.5056985333996566e-06,
      "loss": 0.0002,
      "step": 1090
    },
    {
      "epoch": 0.5971538040503558,
      "grad_norm": 0.007026190869510174,
      "learning_rate": 3.4974960064709534e-06,
      "loss": 0.0004,
      "step": 1091
    },
    {
      "epoch": 0.5977011494252874,
      "grad_norm": 1.5325748920440674,
      "learning_rate": 3.489297922152136e-06,
      "loss": 0.1477,
      "step": 1092
    },
    {
      "epoch": 0.5982484948002189,
      "grad_norm": 0.014671369455754757,
      "learning_rate": 3.4811043046833353e-06,
      "loss": 0.0008,
      "step": 1093
    },
    {
      "epoch": 0.5987958401751505,
      "grad_norm": 0.9215903878211975,
      "learning_rate": 3.4729151782914683e-06,
      "loss": 0.0739,
      "step": 1094
    },
    {
      "epoch": 0.5993431855500821,
      "grad_norm": 0.0008878909284248948,
      "learning_rate": 3.4647305671901797e-06,
      "loss": 0.0001,
      "step": 1095
    },
    {
      "epoch": 0.5998905309250137,
      "grad_norm": 0.031874462962150574,
      "learning_rate": 3.456550495579762e-06,
      "loss": 0.0015,
      "step": 1096
    },
    {
      "epoch": 0.6004378762999453,
      "grad_norm": 2.8385801315307617,
      "learning_rate": 3.44837498764708e-06,
      "loss": 0.3559,
      "step": 1097
    },
    {
      "epoch": 0.6009852216748769,
      "grad_norm": 0.5795418620109558,
      "learning_rate": 3.440204067565511e-06,
      "loss": 0.0336,
      "step": 1098
    },
    {
      "epoch": 0.6015325670498084,
      "grad_norm": 0.0006659762002527714,
      "learning_rate": 3.432037759494867e-06,
      "loss": 0.0,
      "step": 1099
    },
    {
      "epoch": 0.60207991242474,
      "grad_norm": 0.0005681522306986153,
      "learning_rate": 3.4238760875813155e-06,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.6026272577996716,
      "grad_norm": 3.1197798252105713,
      "learning_rate": 3.4157190759573243e-06,
      "loss": 0.8268,
      "step": 1101
    },
    {
      "epoch": 0.6031746031746031,
      "grad_norm": 0.10555985569953918,
      "learning_rate": 3.4075667487415785e-06,
      "loss": 0.0054,
      "step": 1102
    },
    {
      "epoch": 0.6037219485495348,
      "grad_norm": 0.042463574558496475,
      "learning_rate": 3.3994191300389103e-06,
      "loss": 0.0025,
      "step": 1103
    },
    {
      "epoch": 0.6042692939244664,
      "grad_norm": 0.013961915858089924,
      "learning_rate": 3.391276243940234e-06,
      "loss": 0.0008,
      "step": 1104
    },
    {
      "epoch": 0.6048166392993979,
      "grad_norm": 0.0006703858962282538,
      "learning_rate": 3.3831381145224667e-06,
      "loss": 0.0,
      "step": 1105
    },
    {
      "epoch": 0.6053639846743295,
      "grad_norm": 0.004580009263008833,
      "learning_rate": 3.375004765848463e-06,
      "loss": 0.0002,
      "step": 1106
    },
    {
      "epoch": 0.6059113300492611,
      "grad_norm": 0.06924161314964294,
      "learning_rate": 3.3668762219669393e-06,
      "loss": 0.0031,
      "step": 1107
    },
    {
      "epoch": 0.6064586754241926,
      "grad_norm": 1.6393234729766846,
      "learning_rate": 3.3587525069124093e-06,
      "loss": 0.0547,
      "step": 1108
    },
    {
      "epoch": 0.6070060207991242,
      "grad_norm": 0.0045270854607224464,
      "learning_rate": 3.350633644705107e-06,
      "loss": 0.0002,
      "step": 1109
    },
    {
      "epoch": 0.6075533661740559,
      "grad_norm": 0.025448216125369072,
      "learning_rate": 3.3425196593509135e-06,
      "loss": 0.0016,
      "step": 1110
    },
    {
      "epoch": 0.6081007115489874,
      "grad_norm": 1.729850172996521,
      "learning_rate": 3.334410574841298e-06,
      "loss": 0.0707,
      "step": 1111
    },
    {
      "epoch": 0.608648056923919,
      "grad_norm": 0.0009012650698423386,
      "learning_rate": 3.3263064151532303e-06,
      "loss": 0.0,
      "step": 1112
    },
    {
      "epoch": 0.6091954022988506,
      "grad_norm": 0.0217482540756464,
      "learning_rate": 3.3182072042491244e-06,
      "loss": 0.0013,
      "step": 1113
    },
    {
      "epoch": 0.6097427476737821,
      "grad_norm": 0.14530032873153687,
      "learning_rate": 3.310112966076762e-06,
      "loss": 0.0065,
      "step": 1114
    },
    {
      "epoch": 0.6102900930487137,
      "grad_norm": 0.0008395840995945036,
      "learning_rate": 3.3020237245692154e-06,
      "loss": 0.0001,
      "step": 1115
    },
    {
      "epoch": 0.6108374384236454,
      "grad_norm": 0.0009637104230932891,
      "learning_rate": 3.293939503644788e-06,
      "loss": 0.0001,
      "step": 1116
    },
    {
      "epoch": 0.6113847837985769,
      "grad_norm": 0.0018304293043911457,
      "learning_rate": 3.285860327206939e-06,
      "loss": 0.0001,
      "step": 1117
    },
    {
      "epoch": 0.6119321291735085,
      "grad_norm": 0.0008549802587367594,
      "learning_rate": 3.277786219144207e-06,
      "loss": 0.0,
      "step": 1118
    },
    {
      "epoch": 0.6124794745484401,
      "grad_norm": 0.026990270242094994,
      "learning_rate": 3.2697172033301485e-06,
      "loss": 0.0008,
      "step": 1119
    },
    {
      "epoch": 0.6130268199233716,
      "grad_norm": 0.042953602969646454,
      "learning_rate": 3.2616533036232635e-06,
      "loss": 0.0019,
      "step": 1120
    },
    {
      "epoch": 0.6135741652983032,
      "grad_norm": 0.0016492103459313512,
      "learning_rate": 3.2535945438669203e-06,
      "loss": 0.0001,
      "step": 1121
    },
    {
      "epoch": 0.6141215106732348,
      "grad_norm": 0.0010008412646129727,
      "learning_rate": 3.245540947889294e-06,
      "loss": 0.0,
      "step": 1122
    },
    {
      "epoch": 0.6146688560481663,
      "grad_norm": 0.0072636851109564304,
      "learning_rate": 3.2374925395032926e-06,
      "loss": 0.0004,
      "step": 1123
    },
    {
      "epoch": 0.615216201423098,
      "grad_norm": 0.004256677348166704,
      "learning_rate": 3.229449342506477e-06,
      "loss": 0.0002,
      "step": 1124
    },
    {
      "epoch": 0.6157635467980296,
      "grad_norm": 0.018590139225125313,
      "learning_rate": 3.2214113806810077e-06,
      "loss": 0.001,
      "step": 1125
    },
    {
      "epoch": 0.6163108921729611,
      "grad_norm": 0.0009449028293602169,
      "learning_rate": 3.2133786777935645e-06,
      "loss": 0.0001,
      "step": 1126
    },
    {
      "epoch": 0.6168582375478927,
      "grad_norm": 0.04207863658666611,
      "learning_rate": 3.205351257595272e-06,
      "loss": 0.0025,
      "step": 1127
    },
    {
      "epoch": 0.6174055829228243,
      "grad_norm": 0.000829450087621808,
      "learning_rate": 3.197329143821639e-06,
      "loss": 0.0,
      "step": 1128
    },
    {
      "epoch": 0.6179529282977558,
      "grad_norm": 5.556107044219971,
      "learning_rate": 3.189312360192489e-06,
      "loss": 0.412,
      "step": 1129
    },
    {
      "epoch": 0.6185002736726875,
      "grad_norm": 0.003381219459697604,
      "learning_rate": 3.181300930411874e-06,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 0.6190476190476191,
      "grad_norm": 0.06066957116127014,
      "learning_rate": 3.173294878168025e-06,
      "loss": 0.0022,
      "step": 1131
    },
    {
      "epoch": 0.6195949644225506,
      "grad_norm": 1.8072783946990967,
      "learning_rate": 3.165294227133271e-06,
      "loss": 0.1144,
      "step": 1132
    },
    {
      "epoch": 0.6201423097974822,
      "grad_norm": 0.0006970948306843638,
      "learning_rate": 3.157299000963966e-06,
      "loss": 0.0,
      "step": 1133
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.006777014117687941,
      "learning_rate": 3.149309223300428e-06,
      "loss": 0.0004,
      "step": 1134
    },
    {
      "epoch": 0.6212370005473454,
      "grad_norm": 0.522754430770874,
      "learning_rate": 3.141324917766866e-06,
      "loss": 0.0366,
      "step": 1135
    },
    {
      "epoch": 0.6217843459222769,
      "grad_norm": 0.0013250497868284583,
      "learning_rate": 3.1333461079713056e-06,
      "loss": 0.0001,
      "step": 1136
    },
    {
      "epoch": 0.6223316912972086,
      "grad_norm": 0.49142467975616455,
      "learning_rate": 3.1253728175055242e-06,
      "loss": 0.0273,
      "step": 1137
    },
    {
      "epoch": 0.6228790366721402,
      "grad_norm": 0.00683606555685401,
      "learning_rate": 3.1174050699449776e-06,
      "loss": 0.0004,
      "step": 1138
    },
    {
      "epoch": 0.6234263820470717,
      "grad_norm": 0.014793165028095245,
      "learning_rate": 3.109442888848736e-06,
      "loss": 0.0008,
      "step": 1139
    },
    {
      "epoch": 0.6239737274220033,
      "grad_norm": 0.032075993716716766,
      "learning_rate": 3.1014862977594083e-06,
      "loss": 0.0011,
      "step": 1140
    },
    {
      "epoch": 0.6245210727969349,
      "grad_norm": 0.0009118267334997654,
      "learning_rate": 3.093535320203074e-06,
      "loss": 0.0,
      "step": 1141
    },
    {
      "epoch": 0.6250684181718664,
      "grad_norm": 0.8017885088920593,
      "learning_rate": 3.0855899796892188e-06,
      "loss": 0.0374,
      "step": 1142
    },
    {
      "epoch": 0.625615763546798,
      "grad_norm": 0.0063584414310753345,
      "learning_rate": 3.0776502997106526e-06,
      "loss": 0.0003,
      "step": 1143
    },
    {
      "epoch": 0.6261631089217297,
      "grad_norm": 0.0015540060121566057,
      "learning_rate": 3.0697163037434573e-06,
      "loss": 0.0001,
      "step": 1144
    },
    {
      "epoch": 0.6267104542966612,
      "grad_norm": 0.005835267249494791,
      "learning_rate": 3.061788015246905e-06,
      "loss": 0.0003,
      "step": 1145
    },
    {
      "epoch": 0.6272577996715928,
      "grad_norm": 0.0051235174760222435,
      "learning_rate": 3.0538654576633865e-06,
      "loss": 0.0003,
      "step": 1146
    },
    {
      "epoch": 0.6278051450465244,
      "grad_norm": 0.040209539234638214,
      "learning_rate": 3.045948654418356e-06,
      "loss": 0.0016,
      "step": 1147
    },
    {
      "epoch": 0.6283524904214559,
      "grad_norm": 0.0020186405163258314,
      "learning_rate": 3.0380376289202497e-06,
      "loss": 0.0001,
      "step": 1148
    },
    {
      "epoch": 0.6288998357963875,
      "grad_norm": 0.008744911290705204,
      "learning_rate": 3.0301324045604163e-06,
      "loss": 0.0003,
      "step": 1149
    },
    {
      "epoch": 0.6294471811713191,
      "grad_norm": 0.001045871409587562,
      "learning_rate": 3.0222330047130572e-06,
      "loss": 0.0001,
      "step": 1150
    },
    {
      "epoch": 0.6299945265462507,
      "grad_norm": 0.0322137288749218,
      "learning_rate": 3.0143394527351522e-06,
      "loss": 0.0018,
      "step": 1151
    },
    {
      "epoch": 0.6305418719211823,
      "grad_norm": 0.0005980997812002897,
      "learning_rate": 3.0064517719663833e-06,
      "loss": 0.0,
      "step": 1152
    },
    {
      "epoch": 0.6310892172961139,
      "grad_norm": 2.1152279376983643,
      "learning_rate": 2.9985699857290788e-06,
      "loss": 0.3025,
      "step": 1153
    },
    {
      "epoch": 0.6316365626710454,
      "grad_norm": 0.00127549993339926,
      "learning_rate": 2.990694117328139e-06,
      "loss": 0.0001,
      "step": 1154
    },
    {
      "epoch": 0.632183908045977,
      "grad_norm": 3.6523447036743164,
      "learning_rate": 2.982824190050958e-06,
      "loss": 0.5705,
      "step": 1155
    },
    {
      "epoch": 0.6327312534209086,
      "grad_norm": 0.0007076715119183064,
      "learning_rate": 2.9749602271673717e-06,
      "loss": 0.0,
      "step": 1156
    },
    {
      "epoch": 0.6332785987958401,
      "grad_norm": 3.9442214965820312,
      "learning_rate": 2.967102251929579e-06,
      "loss": 0.3015,
      "step": 1157
    },
    {
      "epoch": 0.6338259441707718,
      "grad_norm": 1.8977831602096558,
      "learning_rate": 2.959250287572069e-06,
      "loss": 0.1217,
      "step": 1158
    },
    {
      "epoch": 0.6343732895457034,
      "grad_norm": 0.0004373769916128367,
      "learning_rate": 2.9514043573115635e-06,
      "loss": 0.0,
      "step": 1159
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 0.00648913811892271,
      "learning_rate": 2.9435644843469434e-06,
      "loss": 0.0004,
      "step": 1160
    },
    {
      "epoch": 0.6354679802955665,
      "grad_norm": 0.0014652154641225934,
      "learning_rate": 2.935730691859172e-06,
      "loss": 0.0001,
      "step": 1161
    },
    {
      "epoch": 0.6360153256704981,
      "grad_norm": 0.0006431420333683491,
      "learning_rate": 2.927903003011241e-06,
      "loss": 0.0,
      "step": 1162
    },
    {
      "epoch": 0.6365626710454296,
      "grad_norm": 0.0007981696981005371,
      "learning_rate": 2.920081440948094e-06,
      "loss": 0.0,
      "step": 1163
    },
    {
      "epoch": 0.6371100164203612,
      "grad_norm": 1.5789462327957153,
      "learning_rate": 2.912266028796554e-06,
      "loss": 0.065,
      "step": 1164
    },
    {
      "epoch": 0.6376573617952929,
      "grad_norm": 3.112351179122925,
      "learning_rate": 2.9044567896652666e-06,
      "loss": 0.4365,
      "step": 1165
    },
    {
      "epoch": 0.6382047071702244,
      "grad_norm": 0.1170198917388916,
      "learning_rate": 2.8966537466446186e-06,
      "loss": 0.0048,
      "step": 1166
    },
    {
      "epoch": 0.638752052545156,
      "grad_norm": 0.001080000656656921,
      "learning_rate": 2.888856922806682e-06,
      "loss": 0.0001,
      "step": 1167
    },
    {
      "epoch": 0.6392993979200876,
      "grad_norm": 1.4394481182098389,
      "learning_rate": 2.881066341205133e-06,
      "loss": 0.0386,
      "step": 1168
    },
    {
      "epoch": 0.6398467432950191,
      "grad_norm": 0.01096464041620493,
      "learning_rate": 2.8732820248752016e-06,
      "loss": 0.0008,
      "step": 1169
    },
    {
      "epoch": 0.6403940886699507,
      "grad_norm": 0.837445855140686,
      "learning_rate": 2.8655039968335774e-06,
      "loss": 0.2561,
      "step": 1170
    },
    {
      "epoch": 0.6409414340448824,
      "grad_norm": 2.5122902393341064,
      "learning_rate": 2.8577322800783717e-06,
      "loss": 0.5154,
      "step": 1171
    },
    {
      "epoch": 0.6414887794198139,
      "grad_norm": 0.002060462487861514,
      "learning_rate": 2.849966897589026e-06,
      "loss": 0.0001,
      "step": 1172
    },
    {
      "epoch": 0.6420361247947455,
      "grad_norm": 0.022700386121869087,
      "learning_rate": 2.842207872326255e-06,
      "loss": 0.0012,
      "step": 1173
    },
    {
      "epoch": 0.6425834701696771,
      "grad_norm": 0.023166757076978683,
      "learning_rate": 2.8344552272319727e-06,
      "loss": 0.0015,
      "step": 1174
    },
    {
      "epoch": 0.6431308155446086,
      "grad_norm": 0.7208672165870667,
      "learning_rate": 2.826708985229238e-06,
      "loss": 0.1403,
      "step": 1175
    },
    {
      "epoch": 0.6436781609195402,
      "grad_norm": 0.021994972601532936,
      "learning_rate": 2.8189691692221627e-06,
      "loss": 0.001,
      "step": 1176
    },
    {
      "epoch": 0.6442255062944718,
      "grad_norm": 1.0538862943649292,
      "learning_rate": 2.811235802095873e-06,
      "loss": 0.0558,
      "step": 1177
    },
    {
      "epoch": 0.6447728516694033,
      "grad_norm": 0.018231311812996864,
      "learning_rate": 2.803508906716417e-06,
      "loss": 0.0006,
      "step": 1178
    },
    {
      "epoch": 0.645320197044335,
      "grad_norm": 0.13934490084648132,
      "learning_rate": 2.7957885059307097e-06,
      "loss": 0.0066,
      "step": 1179
    },
    {
      "epoch": 0.6458675424192666,
      "grad_norm": 0.0012065928895026445,
      "learning_rate": 2.7880746225664623e-06,
      "loss": 0.0001,
      "step": 1180
    },
    {
      "epoch": 0.6464148877941981,
      "grad_norm": 0.024480832740664482,
      "learning_rate": 2.780367279432123e-06,
      "loss": 0.0015,
      "step": 1181
    },
    {
      "epoch": 0.6469622331691297,
      "grad_norm": 0.0008152654045261443,
      "learning_rate": 2.7726664993167864e-06,
      "loss": 0.0,
      "step": 1182
    },
    {
      "epoch": 0.6475095785440613,
      "grad_norm": 0.003212694777175784,
      "learning_rate": 2.7649723049901554e-06,
      "loss": 0.0001,
      "step": 1183
    },
    {
      "epoch": 0.6480569239189928,
      "grad_norm": 0.004557629581540823,
      "learning_rate": 2.7572847192024544e-06,
      "loss": 0.0003,
      "step": 1184
    },
    {
      "epoch": 0.6486042692939245,
      "grad_norm": 0.014070228673517704,
      "learning_rate": 2.749603764684367e-06,
      "loss": 0.0008,
      "step": 1185
    },
    {
      "epoch": 0.6491516146688561,
      "grad_norm": 0.008897247724235058,
      "learning_rate": 2.7419294641469718e-06,
      "loss": 0.0004,
      "step": 1186
    },
    {
      "epoch": 0.6496989600437876,
      "grad_norm": 0.001360671827569604,
      "learning_rate": 2.73426184028167e-06,
      "loss": 0.0001,
      "step": 1187
    },
    {
      "epoch": 0.6502463054187192,
      "grad_norm": 0.28629621863365173,
      "learning_rate": 2.7266009157601226e-06,
      "loss": 0.012,
      "step": 1188
    },
    {
      "epoch": 0.6507936507936508,
      "grad_norm": 0.0009117036825045943,
      "learning_rate": 2.718946713234185e-06,
      "loss": 0.0,
      "step": 1189
    },
    {
      "epoch": 0.6513409961685823,
      "grad_norm": 1.4064545631408691,
      "learning_rate": 2.711299255335833e-06,
      "loss": 0.1122,
      "step": 1190
    },
    {
      "epoch": 0.6518883415435139,
      "grad_norm": 0.5535867810249329,
      "learning_rate": 2.703658564677101e-06,
      "loss": 0.0186,
      "step": 1191
    },
    {
      "epoch": 0.6524356869184456,
      "grad_norm": 0.001408225973136723,
      "learning_rate": 2.696024663850013e-06,
      "loss": 0.0001,
      "step": 1192
    },
    {
      "epoch": 0.6529830322933772,
      "grad_norm": 0.010263749398291111,
      "learning_rate": 2.688397575426517e-06,
      "loss": 0.0005,
      "step": 1193
    },
    {
      "epoch": 0.6535303776683087,
      "grad_norm": 0.06269679218530655,
      "learning_rate": 2.680777321958424e-06,
      "loss": 0.0026,
      "step": 1194
    },
    {
      "epoch": 0.6540777230432403,
      "grad_norm": 3.432997703552246,
      "learning_rate": 2.6731639259773235e-06,
      "loss": 0.3758,
      "step": 1195
    },
    {
      "epoch": 0.6546250684181719,
      "grad_norm": 0.10158976167440414,
      "learning_rate": 2.6655574099945403e-06,
      "loss": 0.0038,
      "step": 1196
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 0.0006782903801649809,
      "learning_rate": 2.65795779650105e-06,
      "loss": 0.0,
      "step": 1197
    },
    {
      "epoch": 0.655719759168035,
      "grad_norm": 1.1062530279159546,
      "learning_rate": 2.6503651079674207e-06,
      "loss": 0.0548,
      "step": 1198
    },
    {
      "epoch": 0.6562671045429667,
      "grad_norm": 0.03376366198062897,
      "learning_rate": 2.642779366843743e-06,
      "loss": 0.002,
      "step": 1199
    },
    {
      "epoch": 0.6568144499178982,
      "grad_norm": 0.0006300812819972634,
      "learning_rate": 2.6352005955595715e-06,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.6573617952928298,
      "grad_norm": 0.1315162628889084,
      "learning_rate": 2.6276288165238416e-06,
      "loss": 0.0064,
      "step": 1201
    },
    {
      "epoch": 0.6579091406677614,
      "grad_norm": 0.015293885953724384,
      "learning_rate": 2.620064052124825e-06,
      "loss": 0.0009,
      "step": 1202
    },
    {
      "epoch": 0.6584564860426929,
      "grad_norm": 0.008067036978900433,
      "learning_rate": 2.612506324730046e-06,
      "loss": 0.0004,
      "step": 1203
    },
    {
      "epoch": 0.6590038314176245,
      "grad_norm": 0.0993763655424118,
      "learning_rate": 2.6049556566862234e-06,
      "loss": 0.0028,
      "step": 1204
    },
    {
      "epoch": 0.6595511767925561,
      "grad_norm": 0.008562246337532997,
      "learning_rate": 2.597412070319201e-06,
      "loss": 0.0005,
      "step": 1205
    },
    {
      "epoch": 0.6600985221674877,
      "grad_norm": 4.472264289855957,
      "learning_rate": 2.589875587933892e-06,
      "loss": 0.2946,
      "step": 1206
    },
    {
      "epoch": 0.6606458675424193,
      "grad_norm": 0.0009403002914041281,
      "learning_rate": 2.582346231814189e-06,
      "loss": 0.0001,
      "step": 1207
    },
    {
      "epoch": 0.6611932129173509,
      "grad_norm": 0.3145502209663391,
      "learning_rate": 2.57482402422293e-06,
      "loss": 0.0177,
      "step": 1208
    },
    {
      "epoch": 0.6617405582922824,
      "grad_norm": 0.003977443557232618,
      "learning_rate": 2.567308987401806e-06,
      "loss": 0.0002,
      "step": 1209
    },
    {
      "epoch": 0.662287903667214,
      "grad_norm": 0.010606780648231506,
      "learning_rate": 2.5598011435713077e-06,
      "loss": 0.0005,
      "step": 1210
    },
    {
      "epoch": 0.6628352490421456,
      "grad_norm": 0.09609939903020859,
      "learning_rate": 2.552300514930657e-06,
      "loss": 0.0039,
      "step": 1211
    },
    {
      "epoch": 0.6633825944170771,
      "grad_norm": 2.128418207168579,
      "learning_rate": 2.5448071236577493e-06,
      "loss": 0.1747,
      "step": 1212
    },
    {
      "epoch": 0.6639299397920088,
      "grad_norm": 0.00613319082185626,
      "learning_rate": 2.5373209919090657e-06,
      "loss": 0.0004,
      "step": 1213
    },
    {
      "epoch": 0.6644772851669404,
      "grad_norm": 0.003036897163838148,
      "learning_rate": 2.5298421418196363e-06,
      "loss": 0.0001,
      "step": 1214
    },
    {
      "epoch": 0.6650246305418719,
      "grad_norm": 0.007959477603435516,
      "learning_rate": 2.522370595502954e-06,
      "loss": 0.0004,
      "step": 1215
    },
    {
      "epoch": 0.6655719759168035,
      "grad_norm": 0.0008658524020574987,
      "learning_rate": 2.5149063750509166e-06,
      "loss": 0.0,
      "step": 1216
    },
    {
      "epoch": 0.6661193212917351,
      "grad_norm": 0.04872209578752518,
      "learning_rate": 2.507449502533762e-06,
      "loss": 0.0024,
      "step": 1217
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 3.2414846420288086,
      "learning_rate": 2.5000000000000015e-06,
      "loss": 0.138,
      "step": 1218
    },
    {
      "epoch": 0.6672140120415982,
      "grad_norm": 0.0013225555885583162,
      "learning_rate": 2.4925578894763524e-06,
      "loss": 0.0001,
      "step": 1219
    },
    {
      "epoch": 0.6677613574165299,
      "grad_norm": 0.01283380575478077,
      "learning_rate": 2.485123192967677e-06,
      "loss": 0.0009,
      "step": 1220
    },
    {
      "epoch": 0.6683087027914614,
      "grad_norm": 0.0009547397494316101,
      "learning_rate": 2.4776959324569193e-06,
      "loss": 0.0001,
      "step": 1221
    },
    {
      "epoch": 0.668856048166393,
      "grad_norm": 0.011014365591108799,
      "learning_rate": 2.4702761299050314e-06,
      "loss": 0.0007,
      "step": 1222
    },
    {
      "epoch": 0.6694033935413246,
      "grad_norm": 0.024741705507040024,
      "learning_rate": 2.462863807250915e-06,
      "loss": 0.0012,
      "step": 1223
    },
    {
      "epoch": 0.6699507389162561,
      "grad_norm": 0.001147823641076684,
      "learning_rate": 2.4554589864113566e-06,
      "loss": 0.0001,
      "step": 1224
    },
    {
      "epoch": 0.6704980842911877,
      "grad_norm": 3.3921384811401367,
      "learning_rate": 2.4480616892809593e-06,
      "loss": 0.2976,
      "step": 1225
    },
    {
      "epoch": 0.6710454296661194,
      "grad_norm": 1.1546399593353271,
      "learning_rate": 2.4406719377320808e-06,
      "loss": 0.0657,
      "step": 1226
    },
    {
      "epoch": 0.6715927750410509,
      "grad_norm": 0.0007737670093774796,
      "learning_rate": 2.4332897536147728e-06,
      "loss": 0.0,
      "step": 1227
    },
    {
      "epoch": 0.6721401204159825,
      "grad_norm": 0.021431464701890945,
      "learning_rate": 2.425915158756699e-06,
      "loss": 0.0014,
      "step": 1228
    },
    {
      "epoch": 0.6726874657909141,
      "grad_norm": 2.593400239944458,
      "learning_rate": 2.418548174963099e-06,
      "loss": 0.6058,
      "step": 1229
    },
    {
      "epoch": 0.6732348111658456,
      "grad_norm": 0.008258516900241375,
      "learning_rate": 2.411188824016697e-06,
      "loss": 0.0004,
      "step": 1230
    },
    {
      "epoch": 0.6737821565407772,
      "grad_norm": 0.0024169734679162502,
      "learning_rate": 2.4038371276776525e-06,
      "loss": 0.0001,
      "step": 1231
    },
    {
      "epoch": 0.6743295019157088,
      "grad_norm": 3.6016862392425537,
      "learning_rate": 2.396493107683488e-06,
      "loss": 1.0219,
      "step": 1232
    },
    {
      "epoch": 0.6748768472906403,
      "grad_norm": 0.0064880684949457645,
      "learning_rate": 2.3891567857490373e-06,
      "loss": 0.0004,
      "step": 1233
    },
    {
      "epoch": 0.675424192665572,
      "grad_norm": 2.9768924713134766,
      "learning_rate": 2.38182818356636e-06,
      "loss": 0.5994,
      "step": 1234
    },
    {
      "epoch": 0.6759715380405036,
      "grad_norm": 0.055848196148872375,
      "learning_rate": 2.374507322804702e-06,
      "loss": 0.0021,
      "step": 1235
    },
    {
      "epoch": 0.6765188834154351,
      "grad_norm": 1.6829864978790283,
      "learning_rate": 2.3671942251104125e-06,
      "loss": 0.1549,
      "step": 1236
    },
    {
      "epoch": 0.6770662287903667,
      "grad_norm": 0.0016899587353691459,
      "learning_rate": 2.359888912106888e-06,
      "loss": 0.0001,
      "step": 1237
    },
    {
      "epoch": 0.6776135741652983,
      "grad_norm": 0.0014465961139649153,
      "learning_rate": 2.3525914053945054e-06,
      "loss": 0.0001,
      "step": 1238
    },
    {
      "epoch": 0.6781609195402298,
      "grad_norm": 2.173952579498291,
      "learning_rate": 2.345301726550567e-06,
      "loss": 0.1167,
      "step": 1239
    },
    {
      "epoch": 0.6787082649151615,
      "grad_norm": 0.004451731685549021,
      "learning_rate": 2.3380198971292195e-06,
      "loss": 0.0002,
      "step": 1240
    },
    {
      "epoch": 0.6792556102900931,
      "grad_norm": 2.3947694301605225,
      "learning_rate": 2.3307459386614095e-06,
      "loss": 0.5009,
      "step": 1241
    },
    {
      "epoch": 0.6798029556650246,
      "grad_norm": 0.003937283996492624,
      "learning_rate": 2.323479872654805e-06,
      "loss": 0.0002,
      "step": 1242
    },
    {
      "epoch": 0.6803503010399562,
      "grad_norm": 0.019021490588784218,
      "learning_rate": 2.316221720593739e-06,
      "loss": 0.0006,
      "step": 1243
    },
    {
      "epoch": 0.6808976464148878,
      "grad_norm": 0.2992788553237915,
      "learning_rate": 2.3089715039391447e-06,
      "loss": 0.0129,
      "step": 1244
    },
    {
      "epoch": 0.6814449917898193,
      "grad_norm": 0.5707895159721375,
      "learning_rate": 2.301729244128496e-06,
      "loss": 0.0376,
      "step": 1245
    },
    {
      "epoch": 0.6819923371647509,
      "grad_norm": 0.06965388357639313,
      "learning_rate": 2.2944949625757295e-06,
      "loss": 0.003,
      "step": 1246
    },
    {
      "epoch": 0.6825396825396826,
      "grad_norm": 0.03102029860019684,
      "learning_rate": 2.2872686806712037e-06,
      "loss": 0.0019,
      "step": 1247
    },
    {
      "epoch": 0.6830870279146142,
      "grad_norm": 0.0020782784558832645,
      "learning_rate": 2.2800504197816147e-06,
      "loss": 0.0001,
      "step": 1248
    },
    {
      "epoch": 0.6836343732895457,
      "grad_norm": 0.0011645976919680834,
      "learning_rate": 2.2728402012499477e-06,
      "loss": 0.0001,
      "step": 1249
    },
    {
      "epoch": 0.6841817186644773,
      "grad_norm": 1.6610772609710693,
      "learning_rate": 2.265638046395405e-06,
      "loss": 0.0928,
      "step": 1250
    },
    {
      "epoch": 0.6847290640394089,
      "grad_norm": 2.653963088989258,
      "learning_rate": 2.2584439765133453e-06,
      "loss": 0.5788,
      "step": 1251
    },
    {
      "epoch": 0.6852764094143404,
      "grad_norm": 0.0019216006621718407,
      "learning_rate": 2.251258012875228e-06,
      "loss": 0.0001,
      "step": 1252
    },
    {
      "epoch": 0.685823754789272,
      "grad_norm": 1.77638578414917,
      "learning_rate": 2.244080176728536e-06,
      "loss": 0.0684,
      "step": 1253
    },
    {
      "epoch": 0.6863711001642037,
      "grad_norm": 1.5387606620788574,
      "learning_rate": 2.2369104892967253e-06,
      "loss": 0.0341,
      "step": 1254
    },
    {
      "epoch": 0.6869184455391352,
      "grad_norm": 1.127105474472046,
      "learning_rate": 2.229748971779157e-06,
      "loss": 0.1876,
      "step": 1255
    },
    {
      "epoch": 0.6874657909140668,
      "grad_norm": 0.001975011546164751,
      "learning_rate": 2.2225956453510345e-06,
      "loss": 0.0001,
      "step": 1256
    },
    {
      "epoch": 0.6880131362889984,
      "grad_norm": 1.3740874528884888,
      "learning_rate": 2.2154505311633406e-06,
      "loss": 0.3078,
      "step": 1257
    },
    {
      "epoch": 0.6885604816639299,
      "grad_norm": 0.7418197393417358,
      "learning_rate": 2.208313650342784e-06,
      "loss": 0.0341,
      "step": 1258
    },
    {
      "epoch": 0.6891078270388615,
      "grad_norm": 0.7016335725784302,
      "learning_rate": 2.2011850239917136e-06,
      "loss": 0.0706,
      "step": 1259
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.004330555442720652,
      "learning_rate": 2.1940646731880887e-06,
      "loss": 0.0002,
      "step": 1260
    },
    {
      "epoch": 0.6902025177887247,
      "grad_norm": 0.0011628969805315137,
      "learning_rate": 2.186952618985387e-06,
      "loss": 0.0001,
      "step": 1261
    },
    {
      "epoch": 0.6907498631636563,
      "grad_norm": 0.060933344066143036,
      "learning_rate": 2.1798488824125613e-06,
      "loss": 0.0033,
      "step": 1262
    },
    {
      "epoch": 0.6912972085385879,
      "grad_norm": 0.020503433421254158,
      "learning_rate": 2.1727534844739658e-06,
      "loss": 0.0011,
      "step": 1263
    },
    {
      "epoch": 0.6918445539135194,
      "grad_norm": 0.22790563106536865,
      "learning_rate": 2.1656664461493073e-06,
      "loss": 0.0123,
      "step": 1264
    },
    {
      "epoch": 0.692391899288451,
      "grad_norm": 0.07828984409570694,
      "learning_rate": 2.1585877883935617e-06,
      "loss": 0.0043,
      "step": 1265
    },
    {
      "epoch": 0.6929392446633826,
      "grad_norm": 0.0461246520280838,
      "learning_rate": 2.151517532136939e-06,
      "loss": 0.0025,
      "step": 1266
    },
    {
      "epoch": 0.6934865900383141,
      "grad_norm": 0.002597331302240491,
      "learning_rate": 2.1444556982847996e-06,
      "loss": 0.0001,
      "step": 1267
    },
    {
      "epoch": 0.6940339354132458,
      "grad_norm": 0.05110425129532814,
      "learning_rate": 2.137402307717602e-06,
      "loss": 0.0022,
      "step": 1268
    },
    {
      "epoch": 0.6945812807881774,
      "grad_norm": 0.6602419018745422,
      "learning_rate": 2.1303573812908383e-06,
      "loss": 0.0282,
      "step": 1269
    },
    {
      "epoch": 0.6951286261631089,
      "grad_norm": 0.07985714077949524,
      "learning_rate": 2.1233209398349817e-06,
      "loss": 0.0054,
      "step": 1270
    },
    {
      "epoch": 0.6956759715380405,
      "grad_norm": 0.01809125952422619,
      "learning_rate": 2.1162930041554026e-06,
      "loss": 0.0008,
      "step": 1271
    },
    {
      "epoch": 0.6962233169129721,
      "grad_norm": 0.00877376738935709,
      "learning_rate": 2.109273595032335e-06,
      "loss": 0.0006,
      "step": 1272
    },
    {
      "epoch": 0.6967706622879036,
      "grad_norm": 0.02569439634680748,
      "learning_rate": 2.1022627332207944e-06,
      "loss": 0.0013,
      "step": 1273
    },
    {
      "epoch": 0.6973180076628352,
      "grad_norm": 0.007469331845641136,
      "learning_rate": 2.095260439450526e-06,
      "loss": 0.0003,
      "step": 1274
    },
    {
      "epoch": 0.6978653530377669,
      "grad_norm": 0.002888189163058996,
      "learning_rate": 2.0882667344259384e-06,
      "loss": 0.0002,
      "step": 1275
    },
    {
      "epoch": 0.6984126984126984,
      "grad_norm": 0.04049229994416237,
      "learning_rate": 2.081281638826052e-06,
      "loss": 0.0021,
      "step": 1276
    },
    {
      "epoch": 0.69896004378763,
      "grad_norm": 0.954323410987854,
      "learning_rate": 2.0743051733044184e-06,
      "loss": 0.1537,
      "step": 1277
    },
    {
      "epoch": 0.6995073891625616,
      "grad_norm": 0.005480559077113867,
      "learning_rate": 2.0673373584890847e-06,
      "loss": 0.0002,
      "step": 1278
    },
    {
      "epoch": 0.7000547345374931,
      "grad_norm": 0.006532358471304178,
      "learning_rate": 2.0603782149825126e-06,
      "loss": 0.0003,
      "step": 1279
    },
    {
      "epoch": 0.7006020799124247,
      "grad_norm": 0.31922078132629395,
      "learning_rate": 2.053427763361525e-06,
      "loss": 0.0156,
      "step": 1280
    },
    {
      "epoch": 0.7011494252873564,
      "grad_norm": 0.002296839142218232,
      "learning_rate": 2.0464860241772454e-06,
      "loss": 0.0002,
      "step": 1281
    },
    {
      "epoch": 0.7016967706622879,
      "grad_norm": 0.7975578308105469,
      "learning_rate": 2.0395530179550365e-06,
      "loss": 0.0351,
      "step": 1282
    },
    {
      "epoch": 0.7022441160372195,
      "grad_norm": 0.014742017723619938,
      "learning_rate": 2.0326287651944392e-06,
      "loss": 0.0009,
      "step": 1283
    },
    {
      "epoch": 0.7027914614121511,
      "grad_norm": 3.4946162700653076,
      "learning_rate": 2.0257132863691108e-06,
      "loss": 0.5185,
      "step": 1284
    },
    {
      "epoch": 0.7033388067870826,
      "grad_norm": 0.6185206770896912,
      "learning_rate": 2.01880660192677e-06,
      "loss": 0.0438,
      "step": 1285
    },
    {
      "epoch": 0.7038861521620142,
      "grad_norm": 0.07605360448360443,
      "learning_rate": 2.011908732289127e-06,
      "loss": 0.0042,
      "step": 1286
    },
    {
      "epoch": 0.7044334975369458,
      "grad_norm": 0.003431935328990221,
      "learning_rate": 2.0050196978518323e-06,
      "loss": 0.0002,
      "step": 1287
    },
    {
      "epoch": 0.7049808429118773,
      "grad_norm": 3.3672118186950684,
      "learning_rate": 1.998139518984409e-06,
      "loss": 0.8986,
      "step": 1288
    },
    {
      "epoch": 0.705528188286809,
      "grad_norm": 1.7718101739883423,
      "learning_rate": 1.9912682160301986e-06,
      "loss": 0.3838,
      "step": 1289
    },
    {
      "epoch": 0.7060755336617406,
      "grad_norm": 2.2576417922973633,
      "learning_rate": 1.9844058093062962e-06,
      "loss": 0.2542,
      "step": 1290
    },
    {
      "epoch": 0.7066228790366721,
      "grad_norm": 0.014271312393248081,
      "learning_rate": 1.977552319103498e-06,
      "loss": 0.0007,
      "step": 1291
    },
    {
      "epoch": 0.7071702244116037,
      "grad_norm": 0.0023429556749761105,
      "learning_rate": 1.970707765686225e-06,
      "loss": 0.0001,
      "step": 1292
    },
    {
      "epoch": 0.7077175697865353,
      "grad_norm": 0.4507673382759094,
      "learning_rate": 1.963872169292486e-06,
      "loss": 0.0271,
      "step": 1293
    },
    {
      "epoch": 0.7082649151614668,
      "grad_norm": 0.15117564797401428,
      "learning_rate": 1.957045550133798e-06,
      "loss": 0.0075,
      "step": 1294
    },
    {
      "epoch": 0.7088122605363985,
      "grad_norm": 0.002511147176846862,
      "learning_rate": 1.9502279283951363e-06,
      "loss": 0.0001,
      "step": 1295
    },
    {
      "epoch": 0.7093596059113301,
      "grad_norm": 0.14167791604995728,
      "learning_rate": 1.943419324234871e-06,
      "loss": 0.0049,
      "step": 1296
    },
    {
      "epoch": 0.7099069512862616,
      "grad_norm": 0.01946140080690384,
      "learning_rate": 1.9366197577847144e-06,
      "loss": 0.0007,
      "step": 1297
    },
    {
      "epoch": 0.7104542966611932,
      "grad_norm": 0.0026365339290350676,
      "learning_rate": 1.929829249149646e-06,
      "loss": 0.0001,
      "step": 1298
    },
    {
      "epoch": 0.7110016420361248,
      "grad_norm": 0.003961374517530203,
      "learning_rate": 1.923047818407875e-06,
      "loss": 0.0002,
      "step": 1299
    },
    {
      "epoch": 0.7115489874110563,
      "grad_norm": 0.010394574142992496,
      "learning_rate": 1.916275485610761e-06,
      "loss": 0.0004,
      "step": 1300
    },
    {
      "epoch": 0.7120963327859879,
      "grad_norm": 0.7709653973579407,
      "learning_rate": 1.909512270782764e-06,
      "loss": 0.032,
      "step": 1301
    },
    {
      "epoch": 0.7126436781609196,
      "grad_norm": 0.015536746941506863,
      "learning_rate": 1.9027581939213852e-06,
      "loss": 0.0011,
      "step": 1302
    },
    {
      "epoch": 0.7131910235358512,
      "grad_norm": 0.23883715271949768,
      "learning_rate": 1.8960132749971077e-06,
      "loss": 0.0118,
      "step": 1303
    },
    {
      "epoch": 0.7137383689107827,
      "grad_norm": 0.0016502997605130076,
      "learning_rate": 1.8892775339533354e-06,
      "loss": 0.0001,
      "step": 1304
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.27878475189208984,
      "learning_rate": 1.8825509907063328e-06,
      "loss": 0.0144,
      "step": 1305
    },
    {
      "epoch": 0.7148330596606459,
      "grad_norm": 0.000827615731395781,
      "learning_rate": 1.8758336651451697e-06,
      "loss": 0.0001,
      "step": 1306
    },
    {
      "epoch": 0.7153804050355774,
      "grad_norm": 0.0011499974643811584,
      "learning_rate": 1.8691255771316664e-06,
      "loss": 0.0001,
      "step": 1307
    },
    {
      "epoch": 0.715927750410509,
      "grad_norm": 0.06183416023850441,
      "learning_rate": 1.8624267465003176e-06,
      "loss": 0.0036,
      "step": 1308
    },
    {
      "epoch": 0.7164750957854407,
      "grad_norm": 0.0010362998582422733,
      "learning_rate": 1.8557371930582579e-06,
      "loss": 0.0001,
      "step": 1309
    },
    {
      "epoch": 0.7170224411603722,
      "grad_norm": 0.002453848021104932,
      "learning_rate": 1.8490569365851846e-06,
      "loss": 0.0001,
      "step": 1310
    },
    {
      "epoch": 0.7175697865353038,
      "grad_norm": 0.005374426022171974,
      "learning_rate": 1.8423859968333063e-06,
      "loss": 0.0003,
      "step": 1311
    },
    {
      "epoch": 0.7181171319102354,
      "grad_norm": 0.07459474354982376,
      "learning_rate": 1.8357243935272856e-06,
      "loss": 0.004,
      "step": 1312
    },
    {
      "epoch": 0.7186644772851669,
      "grad_norm": 0.5315725803375244,
      "learning_rate": 1.8290721463641782e-06,
      "loss": 0.0539,
      "step": 1313
    },
    {
      "epoch": 0.7192118226600985,
      "grad_norm": 0.14318647980690002,
      "learning_rate": 1.8224292750133743e-06,
      "loss": 0.0089,
      "step": 1314
    },
    {
      "epoch": 0.7197591680350302,
      "grad_norm": 0.005509435664862394,
      "learning_rate": 1.8157957991165415e-06,
      "loss": 0.0003,
      "step": 1315
    },
    {
      "epoch": 0.7203065134099617,
      "grad_norm": 0.07603777199983597,
      "learning_rate": 1.8091717382875723e-06,
      "loss": 0.004,
      "step": 1316
    },
    {
      "epoch": 0.7208538587848933,
      "grad_norm": 0.03504149988293648,
      "learning_rate": 1.8025571121125141e-06,
      "loss": 0.0021,
      "step": 1317
    },
    {
      "epoch": 0.7214012041598249,
      "grad_norm": 0.0012832129141315818,
      "learning_rate": 1.7959519401495208e-06,
      "loss": 0.0001,
      "step": 1318
    },
    {
      "epoch": 0.7219485495347564,
      "grad_norm": 0.0007370725506916642,
      "learning_rate": 1.7893562419287908e-06,
      "loss": 0.0,
      "step": 1319
    },
    {
      "epoch": 0.722495894909688,
      "grad_norm": 0.0006343817221932113,
      "learning_rate": 1.7827700369525125e-06,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.7230432402846196,
      "grad_norm": 0.6762909293174744,
      "learning_rate": 1.7761933446948004e-06,
      "loss": 0.0244,
      "step": 1321
    },
    {
      "epoch": 0.7235905856595511,
      "grad_norm": 0.9174445271492004,
      "learning_rate": 1.7696261846016505e-06,
      "loss": 0.0641,
      "step": 1322
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 0.009342484176158905,
      "learning_rate": 1.7630685760908623e-06,
      "loss": 0.0003,
      "step": 1323
    },
    {
      "epoch": 0.7246852764094144,
      "grad_norm": 0.9322360754013062,
      "learning_rate": 1.756520538552003e-06,
      "loss": 0.038,
      "step": 1324
    },
    {
      "epoch": 0.7252326217843459,
      "grad_norm": 0.031656548380851746,
      "learning_rate": 1.749982091346335e-06,
      "loss": 0.0015,
      "step": 1325
    },
    {
      "epoch": 0.7257799671592775,
      "grad_norm": 0.0006891297525726259,
      "learning_rate": 1.7434532538067655e-06,
      "loss": 0.0,
      "step": 1326
    },
    {
      "epoch": 0.7263273125342091,
      "grad_norm": 0.001919314032420516,
      "learning_rate": 1.736934045237787e-06,
      "loss": 0.0001,
      "step": 1327
    },
    {
      "epoch": 0.7268746579091406,
      "grad_norm": 0.000864222995005548,
      "learning_rate": 1.7304244849154256e-06,
      "loss": 0.0,
      "step": 1328
    },
    {
      "epoch": 0.7274220032840722,
      "grad_norm": 0.0166192464530468,
      "learning_rate": 1.72392459208717e-06,
      "loss": 0.0009,
      "step": 1329
    },
    {
      "epoch": 0.7279693486590039,
      "grad_norm": 0.698124885559082,
      "learning_rate": 1.7174343859719334e-06,
      "loss": 0.0401,
      "step": 1330
    },
    {
      "epoch": 0.7285166940339354,
      "grad_norm": 0.02755209058523178,
      "learning_rate": 1.7109538857599829e-06,
      "loss": 0.0015,
      "step": 1331
    },
    {
      "epoch": 0.729064039408867,
      "grad_norm": 0.018184052780270576,
      "learning_rate": 1.7044831106128867e-06,
      "loss": 0.0008,
      "step": 1332
    },
    {
      "epoch": 0.7296113847837986,
      "grad_norm": 0.12116236984729767,
      "learning_rate": 1.6980220796634583e-06,
      "loss": 0.0052,
      "step": 1333
    },
    {
      "epoch": 0.7301587301587301,
      "grad_norm": 0.003317579161375761,
      "learning_rate": 1.6915708120157042e-06,
      "loss": 0.0002,
      "step": 1334
    },
    {
      "epoch": 0.7307060755336617,
      "grad_norm": 1.9849859476089478,
      "learning_rate": 1.6851293267447527e-06,
      "loss": 0.278,
      "step": 1335
    },
    {
      "epoch": 0.7312534209085934,
      "grad_norm": 0.2133462280035019,
      "learning_rate": 1.6786976428968188e-06,
      "loss": 0.0084,
      "step": 1336
    },
    {
      "epoch": 0.7318007662835249,
      "grad_norm": 0.44556769728660583,
      "learning_rate": 1.6722757794891287e-06,
      "loss": 0.0131,
      "step": 1337
    },
    {
      "epoch": 0.7323481116584565,
      "grad_norm": 0.023358473554253578,
      "learning_rate": 1.6658637555098744e-06,
      "loss": 0.0014,
      "step": 1338
    },
    {
      "epoch": 0.7328954570333881,
      "grad_norm": 0.8135833740234375,
      "learning_rate": 1.6594615899181526e-06,
      "loss": 0.0397,
      "step": 1339
    },
    {
      "epoch": 0.7334428024083196,
      "grad_norm": 0.0016425474314019084,
      "learning_rate": 1.653069301643918e-06,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 0.7339901477832512,
      "grad_norm": 0.004738492891192436,
      "learning_rate": 1.6466869095879079e-06,
      "loss": 0.0003,
      "step": 1341
    },
    {
      "epoch": 0.7345374931581828,
      "grad_norm": 0.0007509009446948767,
      "learning_rate": 1.6403144326216085e-06,
      "loss": 0.0,
      "step": 1342
    },
    {
      "epoch": 0.7350848385331143,
      "grad_norm": 4.083911895751953,
      "learning_rate": 1.6339518895871853e-06,
      "loss": 0.4117,
      "step": 1343
    },
    {
      "epoch": 0.735632183908046,
      "grad_norm": 0.0035884170792996883,
      "learning_rate": 1.627599299297431e-06,
      "loss": 0.0002,
      "step": 1344
    },
    {
      "epoch": 0.7361795292829776,
      "grad_norm": 0.015186971984803677,
      "learning_rate": 1.6212566805357094e-06,
      "loss": 0.0006,
      "step": 1345
    },
    {
      "epoch": 0.7367268746579091,
      "grad_norm": 0.0036465744487941265,
      "learning_rate": 1.6149240520559023e-06,
      "loss": 0.0002,
      "step": 1346
    },
    {
      "epoch": 0.7372742200328407,
      "grad_norm": 0.0007848521345295012,
      "learning_rate": 1.6086014325823485e-06,
      "loss": 0.0001,
      "step": 1347
    },
    {
      "epoch": 0.7378215654077723,
      "grad_norm": 0.027042943984270096,
      "learning_rate": 1.6022888408097991e-06,
      "loss": 0.0012,
      "step": 1348
    },
    {
      "epoch": 0.7383689107827038,
      "grad_norm": 0.0013250942574813962,
      "learning_rate": 1.5959862954033495e-06,
      "loss": 0.0001,
      "step": 1349
    },
    {
      "epoch": 0.7389162561576355,
      "grad_norm": 0.10463179647922516,
      "learning_rate": 1.589693814998391e-06,
      "loss": 0.0048,
      "step": 1350
    },
    {
      "epoch": 0.7394636015325671,
      "grad_norm": 2.2109789848327637,
      "learning_rate": 1.5834114182005544e-06,
      "loss": 0.4524,
      "step": 1351
    },
    {
      "epoch": 0.7400109469074986,
      "grad_norm": 3.0791380405426025,
      "learning_rate": 1.577139123585657e-06,
      "loss": 0.65,
      "step": 1352
    },
    {
      "epoch": 0.7405582922824302,
      "grad_norm": 0.0008084168657660484,
      "learning_rate": 1.5708769496996445e-06,
      "loss": 0.0,
      "step": 1353
    },
    {
      "epoch": 0.7411056376573618,
      "grad_norm": 0.005375112872570753,
      "learning_rate": 1.5646249150585368e-06,
      "loss": 0.0003,
      "step": 1354
    },
    {
      "epoch": 0.7416529830322933,
      "grad_norm": 0.055478792637586594,
      "learning_rate": 1.5583830381483789e-06,
      "loss": 0.003,
      "step": 1355
    },
    {
      "epoch": 0.7422003284072249,
      "grad_norm": 3.432192325592041,
      "learning_rate": 1.552151337425173e-06,
      "loss": 0.4656,
      "step": 1356
    },
    {
      "epoch": 0.7427476737821566,
      "grad_norm": 0.0025677646044641733,
      "learning_rate": 1.5459298313148402e-06,
      "loss": 0.0001,
      "step": 1357
    },
    {
      "epoch": 0.7432950191570882,
      "grad_norm": 0.29650184512138367,
      "learning_rate": 1.5397185382131524e-06,
      "loss": 0.0123,
      "step": 1358
    },
    {
      "epoch": 0.7438423645320197,
      "grad_norm": 0.004227287136018276,
      "learning_rate": 1.533517476485691e-06,
      "loss": 0.0002,
      "step": 1359
    },
    {
      "epoch": 0.7443897099069513,
      "grad_norm": 0.01521882601082325,
      "learning_rate": 1.5273266644677737e-06,
      "loss": 0.0007,
      "step": 1360
    },
    {
      "epoch": 0.7449370552818829,
      "grad_norm": 0.0014568038750439882,
      "learning_rate": 1.521146120464424e-06,
      "loss": 0.0001,
      "step": 1361
    },
    {
      "epoch": 0.7454844006568144,
      "grad_norm": 0.0051529319025576115,
      "learning_rate": 1.514975862750297e-06,
      "loss": 0.0002,
      "step": 1362
    },
    {
      "epoch": 0.746031746031746,
      "grad_norm": 0.012045003473758698,
      "learning_rate": 1.5088159095696365e-06,
      "loss": 0.0008,
      "step": 1363
    },
    {
      "epoch": 0.7465790914066777,
      "grad_norm": 0.042309921234846115,
      "learning_rate": 1.5026662791362145e-06,
      "loss": 0.0017,
      "step": 1364
    },
    {
      "epoch": 0.7471264367816092,
      "grad_norm": 0.008286736905574799,
      "learning_rate": 1.4965269896332884e-06,
      "loss": 0.0006,
      "step": 1365
    },
    {
      "epoch": 0.7476737821565408,
      "grad_norm": 0.006347342394292355,
      "learning_rate": 1.4903980592135281e-06,
      "loss": 0.0004,
      "step": 1366
    },
    {
      "epoch": 0.7482211275314724,
      "grad_norm": 0.006800222676247358,
      "learning_rate": 1.4842795059989845e-06,
      "loss": 0.0004,
      "step": 1367
    },
    {
      "epoch": 0.7487684729064039,
      "grad_norm": 0.01178108062595129,
      "learning_rate": 1.4781713480810184e-06,
      "loss": 0.0005,
      "step": 1368
    },
    {
      "epoch": 0.7493158182813355,
      "grad_norm": 0.004466665908694267,
      "learning_rate": 1.472073603520256e-06,
      "loss": 0.0002,
      "step": 1369
    },
    {
      "epoch": 0.7498631636562672,
      "grad_norm": 0.17852690815925598,
      "learning_rate": 1.4659862903465322e-06,
      "loss": 0.0088,
      "step": 1370
    },
    {
      "epoch": 0.7504105090311987,
      "grad_norm": 0.0065145790576934814,
      "learning_rate": 1.4599094265588432e-06,
      "loss": 0.0004,
      "step": 1371
    },
    {
      "epoch": 0.7509578544061303,
      "grad_norm": 0.13346223533153534,
      "learning_rate": 1.4538430301252783e-06,
      "loss": 0.0065,
      "step": 1372
    },
    {
      "epoch": 0.7515051997810619,
      "grad_norm": 0.03841231390833855,
      "learning_rate": 1.4477871189829872e-06,
      "loss": 0.0026,
      "step": 1373
    },
    {
      "epoch": 0.7520525451559934,
      "grad_norm": 3.144253730773926,
      "learning_rate": 1.4417417110381126e-06,
      "loss": 0.5233,
      "step": 1374
    },
    {
      "epoch": 0.752599890530925,
      "grad_norm": 0.0025351098738610744,
      "learning_rate": 1.4357068241657396e-06,
      "loss": 0.0001,
      "step": 1375
    },
    {
      "epoch": 0.7531472359058566,
      "grad_norm": 0.03487517312169075,
      "learning_rate": 1.4296824762098465e-06,
      "loss": 0.0022,
      "step": 1376
    },
    {
      "epoch": 0.7536945812807881,
      "grad_norm": 0.03190595284104347,
      "learning_rate": 1.4236686849832497e-06,
      "loss": 0.0022,
      "step": 1377
    },
    {
      "epoch": 0.7542419266557198,
      "grad_norm": 3.067796468734741,
      "learning_rate": 1.4176654682675518e-06,
      "loss": 0.5101,
      "step": 1378
    },
    {
      "epoch": 0.7547892720306514,
      "grad_norm": 0.013497794978320599,
      "learning_rate": 1.411672843813086e-06,
      "loss": 0.0006,
      "step": 1379
    },
    {
      "epoch": 0.7553366174055829,
      "grad_norm": 0.028866702690720558,
      "learning_rate": 1.405690829338872e-06,
      "loss": 0.0013,
      "step": 1380
    },
    {
      "epoch": 0.7558839627805145,
      "grad_norm": 0.0026390000712126493,
      "learning_rate": 1.3997194425325533e-06,
      "loss": 0.0001,
      "step": 1381
    },
    {
      "epoch": 0.7564313081554461,
      "grad_norm": 0.2384168654680252,
      "learning_rate": 1.39375870105035e-06,
      "loss": 0.0112,
      "step": 1382
    },
    {
      "epoch": 0.7569786535303776,
      "grad_norm": 0.0034003693144768476,
      "learning_rate": 1.3878086225170067e-06,
      "loss": 0.0002,
      "step": 1383
    },
    {
      "epoch": 0.7575259989053093,
      "grad_norm": 0.733676016330719,
      "learning_rate": 1.3818692245257398e-06,
      "loss": 0.0274,
      "step": 1384
    },
    {
      "epoch": 0.7580733442802409,
      "grad_norm": 0.046177562326192856,
      "learning_rate": 1.3759405246381841e-06,
      "loss": 0.0025,
      "step": 1385
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.21519514918327332,
      "learning_rate": 1.370022540384347e-06,
      "loss": 0.0116,
      "step": 1386
    },
    {
      "epoch": 0.759168035030104,
      "grad_norm": 0.0016039699548855424,
      "learning_rate": 1.364115289262543e-06,
      "loss": 0.0001,
      "step": 1387
    },
    {
      "epoch": 0.7597153804050356,
      "grad_norm": 0.0020269814413040876,
      "learning_rate": 1.358218788739361e-06,
      "loss": 0.0001,
      "step": 1388
    },
    {
      "epoch": 0.7602627257799671,
      "grad_norm": 0.01608540490269661,
      "learning_rate": 1.352333056249595e-06,
      "loss": 0.0009,
      "step": 1389
    },
    {
      "epoch": 0.7608100711548987,
      "grad_norm": 0.010801028460264206,
      "learning_rate": 1.3464581091962037e-06,
      "loss": 0.0006,
      "step": 1390
    },
    {
      "epoch": 0.7613574165298304,
      "grad_norm": 0.3949987590312958,
      "learning_rate": 1.340593964950252e-06,
      "loss": 0.031,
      "step": 1391
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 0.005434565246105194,
      "learning_rate": 1.3347406408508695e-06,
      "loss": 0.0003,
      "step": 1392
    },
    {
      "epoch": 0.7624521072796935,
      "grad_norm": 0.02001998759806156,
      "learning_rate": 1.3288981542051844e-06,
      "loss": 0.0007,
      "step": 1393
    },
    {
      "epoch": 0.7629994526546251,
      "grad_norm": 0.00965130515396595,
      "learning_rate": 1.3230665222882872e-06,
      "loss": 0.0005,
      "step": 1394
    },
    {
      "epoch": 0.7635467980295566,
      "grad_norm": 0.03369942680001259,
      "learning_rate": 1.3172457623431706e-06,
      "loss": 0.0021,
      "step": 1395
    },
    {
      "epoch": 0.7640941434044882,
      "grad_norm": 0.04988248646259308,
      "learning_rate": 1.3114358915806808e-06,
      "loss": 0.0026,
      "step": 1396
    },
    {
      "epoch": 0.7646414887794198,
      "grad_norm": 0.04337434843182564,
      "learning_rate": 1.3056369271794656e-06,
      "loss": 0.0024,
      "step": 1397
    },
    {
      "epoch": 0.7651888341543513,
      "grad_norm": 0.0014438359066843987,
      "learning_rate": 1.2998488862859305e-06,
      "loss": 0.0001,
      "step": 1398
    },
    {
      "epoch": 0.765736179529283,
      "grad_norm": 0.23984575271606445,
      "learning_rate": 1.2940717860141734e-06,
      "loss": 0.0136,
      "step": 1399
    },
    {
      "epoch": 0.7662835249042146,
      "grad_norm": 0.0034917243756353855,
      "learning_rate": 1.2883056434459506e-06,
      "loss": 0.0002,
      "step": 1400
    },
    {
      "epoch": 0.7668308702791461,
      "grad_norm": 0.19016461074352264,
      "learning_rate": 1.2825504756306156e-06,
      "loss": 0.0087,
      "step": 1401
    },
    {
      "epoch": 0.7673782156540777,
      "grad_norm": 0.0013814478879794478,
      "learning_rate": 1.2768062995850716e-06,
      "loss": 0.0001,
      "step": 1402
    },
    {
      "epoch": 0.7679255610290093,
      "grad_norm": 0.006246261764317751,
      "learning_rate": 1.2710731322937198e-06,
      "loss": 0.0003,
      "step": 1403
    },
    {
      "epoch": 0.7684729064039408,
      "grad_norm": 0.046173110604286194,
      "learning_rate": 1.2653509907084171e-06,
      "loss": 0.0023,
      "step": 1404
    },
    {
      "epoch": 0.7690202517788725,
      "grad_norm": 0.002551480196416378,
      "learning_rate": 1.2596398917484088e-06,
      "loss": 0.0001,
      "step": 1405
    },
    {
      "epoch": 0.7695675971538041,
      "grad_norm": 0.03638076037168503,
      "learning_rate": 1.2539398523003e-06,
      "loss": 0.0025,
      "step": 1406
    },
    {
      "epoch": 0.7701149425287356,
      "grad_norm": 0.02801232412457466,
      "learning_rate": 1.2482508892179884e-06,
      "loss": 0.0016,
      "step": 1407
    },
    {
      "epoch": 0.7706622879036672,
      "grad_norm": 0.05372967943549156,
      "learning_rate": 1.2425730193226237e-06,
      "loss": 0.0023,
      "step": 1408
    },
    {
      "epoch": 0.7712096332785988,
      "grad_norm": 0.00274409307166934,
      "learning_rate": 1.2369062594025549e-06,
      "loss": 0.0002,
      "step": 1409
    },
    {
      "epoch": 0.7717569786535303,
      "grad_norm": 0.05687229335308075,
      "learning_rate": 1.2312506262132795e-06,
      "loss": 0.0032,
      "step": 1410
    },
    {
      "epoch": 0.7723043240284619,
      "grad_norm": 0.0010062531800940633,
      "learning_rate": 1.2256061364773958e-06,
      "loss": 0.0001,
      "step": 1411
    },
    {
      "epoch": 0.7728516694033936,
      "grad_norm": 0.009086270816624165,
      "learning_rate": 1.2199728068845574e-06,
      "loss": 0.0004,
      "step": 1412
    },
    {
      "epoch": 0.7733990147783252,
      "grad_norm": 0.02967224456369877,
      "learning_rate": 1.214350654091413e-06,
      "loss": 0.0016,
      "step": 1413
    },
    {
      "epoch": 0.7739463601532567,
      "grad_norm": 0.27046963572502136,
      "learning_rate": 1.2087396947215678e-06,
      "loss": 0.0163,
      "step": 1414
    },
    {
      "epoch": 0.7744937055281883,
      "grad_norm": 0.015116507187485695,
      "learning_rate": 1.2031399453655296e-06,
      "loss": 0.0007,
      "step": 1415
    },
    {
      "epoch": 0.7750410509031199,
      "grad_norm": 0.06837212294340134,
      "learning_rate": 1.1975514225806573e-06,
      "loss": 0.0041,
      "step": 1416
    },
    {
      "epoch": 0.7755883962780514,
      "grad_norm": 0.010858909226953983,
      "learning_rate": 1.191974142891123e-06,
      "loss": 0.0004,
      "step": 1417
    },
    {
      "epoch": 0.776135741652983,
      "grad_norm": 0.22142855823040009,
      "learning_rate": 1.1864081227878438e-06,
      "loss": 0.0185,
      "step": 1418
    },
    {
      "epoch": 0.7766830870279147,
      "grad_norm": 0.8401796221733093,
      "learning_rate": 1.1808533787284543e-06,
      "loss": 0.1723,
      "step": 1419
    },
    {
      "epoch": 0.7772304324028462,
      "grad_norm": 0.01572483964264393,
      "learning_rate": 1.1753099271372432e-06,
      "loss": 0.0006,
      "step": 1420
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.0009659607312642038,
      "learning_rate": 1.1697777844051105e-06,
      "loss": 0.0001,
      "step": 1421
    },
    {
      "epoch": 0.7783251231527094,
      "grad_norm": 0.001128873322159052,
      "learning_rate": 1.1642569668895171e-06,
      "loss": 0.0001,
      "step": 1422
    },
    {
      "epoch": 0.7788724685276409,
      "grad_norm": 0.0018599751638248563,
      "learning_rate": 1.1587474909144419e-06,
      "loss": 0.0001,
      "step": 1423
    },
    {
      "epoch": 0.7794198139025725,
      "grad_norm": 0.08965079486370087,
      "learning_rate": 1.1532493727703214e-06,
      "loss": 0.0039,
      "step": 1424
    },
    {
      "epoch": 0.7799671592775042,
      "grad_norm": 0.09808063507080078,
      "learning_rate": 1.1477626287140164e-06,
      "loss": 0.004,
      "step": 1425
    },
    {
      "epoch": 0.7805145046524357,
      "grad_norm": 0.036301784217357635,
      "learning_rate": 1.1422872749687542e-06,
      "loss": 0.0026,
      "step": 1426
    },
    {
      "epoch": 0.7810618500273673,
      "grad_norm": 0.003069766331464052,
      "learning_rate": 1.136823327724081e-06,
      "loss": 0.0001,
      "step": 1427
    },
    {
      "epoch": 0.7816091954022989,
      "grad_norm": 0.9233055710792542,
      "learning_rate": 1.1313708031358183e-06,
      "loss": 0.0309,
      "step": 1428
    },
    {
      "epoch": 0.7821565407772304,
      "grad_norm": 0.037566784769296646,
      "learning_rate": 1.1259297173260158e-06,
      "loss": 0.0017,
      "step": 1429
    },
    {
      "epoch": 0.782703886152162,
      "grad_norm": 0.015362787991762161,
      "learning_rate": 1.1205000863828936e-06,
      "loss": 0.0011,
      "step": 1430
    },
    {
      "epoch": 0.7832512315270936,
      "grad_norm": 0.0006184173398651183,
      "learning_rate": 1.1150819263608098e-06,
      "loss": 0.0,
      "step": 1431
    },
    {
      "epoch": 0.7837985769020251,
      "grad_norm": 0.006904145237058401,
      "learning_rate": 1.1096752532802007e-06,
      "loss": 0.0003,
      "step": 1432
    },
    {
      "epoch": 0.7843459222769568,
      "grad_norm": 0.01761559769511223,
      "learning_rate": 1.104280083127539e-06,
      "loss": 0.0008,
      "step": 1433
    },
    {
      "epoch": 0.7848932676518884,
      "grad_norm": 1.3474407196044922,
      "learning_rate": 1.0988964318552848e-06,
      "loss": 0.0642,
      "step": 1434
    },
    {
      "epoch": 0.7854406130268199,
      "grad_norm": 0.005172345321625471,
      "learning_rate": 1.0935243153818437e-06,
      "loss": 0.0003,
      "step": 1435
    },
    {
      "epoch": 0.7859879584017515,
      "grad_norm": 1.6697146892547607,
      "learning_rate": 1.0881637495915055e-06,
      "loss": 0.2606,
      "step": 1436
    },
    {
      "epoch": 0.7865353037766831,
      "grad_norm": 0.002971518086269498,
      "learning_rate": 1.0828147503344177e-06,
      "loss": 0.0002,
      "step": 1437
    },
    {
      "epoch": 0.7870826491516146,
      "grad_norm": 0.0016321121947839856,
      "learning_rate": 1.077477333426521e-06,
      "loss": 0.0001,
      "step": 1438
    },
    {
      "epoch": 0.7876299945265463,
      "grad_norm": 1.1404362916946411,
      "learning_rate": 1.072151514649512e-06,
      "loss": 0.0959,
      "step": 1439
    },
    {
      "epoch": 0.7881773399014779,
      "grad_norm": 0.0009243342792615294,
      "learning_rate": 1.0668373097507922e-06,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.7887246852764094,
      "grad_norm": 0.210483118891716,
      "learning_rate": 1.061534734443425e-06,
      "loss": 0.0127,
      "step": 1441
    },
    {
      "epoch": 0.789272030651341,
      "grad_norm": 2.0463616847991943,
      "learning_rate": 1.0562438044060846e-06,
      "loss": 0.1315,
      "step": 1442
    },
    {
      "epoch": 0.7898193760262726,
      "grad_norm": 0.0009276282507926226,
      "learning_rate": 1.0509645352830178e-06,
      "loss": 0.0,
      "step": 1443
    },
    {
      "epoch": 0.7903667214012041,
      "grad_norm": 0.03256569430232048,
      "learning_rate": 1.0456969426839869e-06,
      "loss": 0.0019,
      "step": 1444
    },
    {
      "epoch": 0.7909140667761357,
      "grad_norm": 3.304903030395508,
      "learning_rate": 1.040441042184231e-06,
      "loss": 0.2805,
      "step": 1445
    },
    {
      "epoch": 0.7914614121510674,
      "grad_norm": 0.0017810609424486756,
      "learning_rate": 1.035196849324418e-06,
      "loss": 0.0001,
      "step": 1446
    },
    {
      "epoch": 0.7920087575259989,
      "grad_norm": 2.163391351699829,
      "learning_rate": 1.0299643796105985e-06,
      "loss": 0.1309,
      "step": 1447
    },
    {
      "epoch": 0.7925561029009305,
      "grad_norm": 0.0015537800500169396,
      "learning_rate": 1.0247436485141605e-06,
      "loss": 0.0001,
      "step": 1448
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 0.040976010262966156,
      "learning_rate": 1.0195346714717813e-06,
      "loss": 0.0015,
      "step": 1449
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 2.1554665565490723,
      "learning_rate": 1.0143374638853892e-06,
      "loss": 0.4947,
      "step": 1450
    },
    {
      "epoch": 0.7941981390257252,
      "grad_norm": 0.0017153465887531638,
      "learning_rate": 1.0091520411221028e-06,
      "loss": 0.0001,
      "step": 1451
    },
    {
      "epoch": 0.7947454844006568,
      "grad_norm": 0.0012929677031934261,
      "learning_rate": 1.0039784185142065e-06,
      "loss": 0.0001,
      "step": 1452
    },
    {
      "epoch": 0.7952928297755884,
      "grad_norm": 0.0006141969934105873,
      "learning_rate": 9.988166113590857e-07,
      "loss": 0.0,
      "step": 1453
    },
    {
      "epoch": 0.79584017515052,
      "grad_norm": 0.9585891962051392,
      "learning_rate": 9.936666349191936e-07,
      "loss": 0.044,
      "step": 1454
    },
    {
      "epoch": 0.7963875205254516,
      "grad_norm": 1.0407382249832153,
      "learning_rate": 9.88528504422e-07,
      "loss": 0.0591,
      "step": 1455
    },
    {
      "epoch": 0.7969348659003831,
      "grad_norm": 0.0013447270030155778,
      "learning_rate": 9.834022350599538e-07,
      "loss": 0.0001,
      "step": 1456
    },
    {
      "epoch": 0.7974822112753147,
      "grad_norm": 0.00128100102301687,
      "learning_rate": 9.78287841990423e-07,
      "loss": 0.0,
      "step": 1457
    },
    {
      "epoch": 0.7980295566502463,
      "grad_norm": 0.05573265999555588,
      "learning_rate": 9.731853403356705e-07,
      "loss": 0.0031,
      "step": 1458
    },
    {
      "epoch": 0.7985769020251778,
      "grad_norm": 0.0011034153867512941,
      "learning_rate": 9.68094745182792e-07,
      "loss": 0.0001,
      "step": 1459
    },
    {
      "epoch": 0.7991242474001095,
      "grad_norm": 1.2505571842193604,
      "learning_rate": 9.630160715836805e-07,
      "loss": 0.2638,
      "step": 1460
    },
    {
      "epoch": 0.7996715927750411,
      "grad_norm": 0.036295827478170395,
      "learning_rate": 9.579493345549772e-07,
      "loss": 0.002,
      "step": 1461
    },
    {
      "epoch": 0.8002189381499726,
      "grad_norm": 0.0031462402548640966,
      "learning_rate": 9.528945490780339e-07,
      "loss": 0.0002,
      "step": 1462
    },
    {
      "epoch": 0.8007662835249042,
      "grad_norm": 0.008574184030294418,
      "learning_rate": 9.47851730098856e-07,
      "loss": 0.0003,
      "step": 1463
    },
    {
      "epoch": 0.8013136288998358,
      "grad_norm": 0.8306803107261658,
      "learning_rate": 9.428208925280746e-07,
      "loss": 0.0917,
      "step": 1464
    },
    {
      "epoch": 0.8018609742747673,
      "grad_norm": 1.5476640462875366,
      "learning_rate": 9.378020512408903e-07,
      "loss": 0.087,
      "step": 1465
    },
    {
      "epoch": 0.8024083196496989,
      "grad_norm": 2.7804737091064453,
      "learning_rate": 9.327952210770319e-07,
      "loss": 0.0584,
      "step": 1466
    },
    {
      "epoch": 0.8029556650246306,
      "grad_norm": 0.06402420997619629,
      "learning_rate": 9.278004168407151e-07,
      "loss": 0.0036,
      "step": 1467
    },
    {
      "epoch": 0.8035030103995622,
      "grad_norm": 0.0016514533199369907,
      "learning_rate": 9.228176533005984e-07,
      "loss": 0.0001,
      "step": 1468
    },
    {
      "epoch": 0.8040503557744937,
      "grad_norm": 0.0015181918861344457,
      "learning_rate": 9.178469451897376e-07,
      "loss": 0.0001,
      "step": 1469
    },
    {
      "epoch": 0.8045977011494253,
      "grad_norm": 0.005936149042099714,
      "learning_rate": 9.128883072055411e-07,
      "loss": 0.0002,
      "step": 1470
    },
    {
      "epoch": 0.8051450465243569,
      "grad_norm": 3.657533645629883,
      "learning_rate": 9.079417540097307e-07,
      "loss": 0.6827,
      "step": 1471
    },
    {
      "epoch": 0.8056923918992884,
      "grad_norm": 0.005069694481790066,
      "learning_rate": 9.030073002282941e-07,
      "loss": 0.0002,
      "step": 1472
    },
    {
      "epoch": 0.80623973727422,
      "grad_norm": 0.0051105129532516,
      "learning_rate": 8.980849604514453e-07,
      "loss": 0.0003,
      "step": 1473
    },
    {
      "epoch": 0.8067870826491517,
      "grad_norm": 0.32357117533683777,
      "learning_rate": 8.931747492335758e-07,
      "loss": 0.0194,
      "step": 1474
    },
    {
      "epoch": 0.8073344280240832,
      "grad_norm": 1.160659670829773,
      "learning_rate": 8.882766810932214e-07,
      "loss": 0.0461,
      "step": 1475
    },
    {
      "epoch": 0.8078817733990148,
      "grad_norm": 0.0010542860254645348,
      "learning_rate": 8.833907705130091e-07,
      "loss": 0.0001,
      "step": 1476
    },
    {
      "epoch": 0.8084291187739464,
      "grad_norm": 0.004155644681304693,
      "learning_rate": 8.785170319396174e-07,
      "loss": 0.0002,
      "step": 1477
    },
    {
      "epoch": 0.8089764641488779,
      "grad_norm": 0.004001829773187637,
      "learning_rate": 8.736554797837376e-07,
      "loss": 0.0002,
      "step": 1478
    },
    {
      "epoch": 0.8095238095238095,
      "grad_norm": 0.0010843358468264341,
      "learning_rate": 8.688061284200266e-07,
      "loss": 0.0001,
      "step": 1479
    },
    {
      "epoch": 0.8100711548987412,
      "grad_norm": 2.392207384109497,
      "learning_rate": 8.639689921870642e-07,
      "loss": 0.134,
      "step": 1480
    },
    {
      "epoch": 0.8106185002736727,
      "grad_norm": 0.001364177092909813,
      "learning_rate": 8.591440853873184e-07,
      "loss": 0.0001,
      "step": 1481
    },
    {
      "epoch": 0.8111658456486043,
      "grad_norm": 0.005867473781108856,
      "learning_rate": 8.543314222870891e-07,
      "loss": 0.0003,
      "step": 1482
    },
    {
      "epoch": 0.8117131910235359,
      "grad_norm": 1.3205195665359497,
      "learning_rate": 8.495310171164805e-07,
      "loss": 0.1287,
      "step": 1483
    },
    {
      "epoch": 0.8122605363984674,
      "grad_norm": 0.8930397629737854,
      "learning_rate": 8.447428840693489e-07,
      "loss": 0.2182,
      "step": 1484
    },
    {
      "epoch": 0.812807881773399,
      "grad_norm": 0.00321182026527822,
      "learning_rate": 8.399670373032665e-07,
      "loss": 0.0002,
      "step": 1485
    },
    {
      "epoch": 0.8133552271483306,
      "grad_norm": 0.002833436941727996,
      "learning_rate": 8.35203490939474e-07,
      "loss": 0.0001,
      "step": 1486
    },
    {
      "epoch": 0.8139025725232621,
      "grad_norm": 0.0029739011079072952,
      "learning_rate": 8.304522590628489e-07,
      "loss": 0.0002,
      "step": 1487
    },
    {
      "epoch": 0.8144499178981938,
      "grad_norm": 0.0469060055911541,
      "learning_rate": 8.257133557218471e-07,
      "loss": 0.0024,
      "step": 1488
    },
    {
      "epoch": 0.8149972632731254,
      "grad_norm": 0.028883071616292,
      "learning_rate": 8.209867949284822e-07,
      "loss": 0.0016,
      "step": 1489
    },
    {
      "epoch": 0.8155446086480569,
      "grad_norm": 1.0808087587356567,
      "learning_rate": 8.162725906582658e-07,
      "loss": 0.2637,
      "step": 1490
    },
    {
      "epoch": 0.8160919540229885,
      "grad_norm": 0.005766118410974741,
      "learning_rate": 8.115707568501768e-07,
      "loss": 0.0003,
      "step": 1491
    },
    {
      "epoch": 0.8166392993979201,
      "grad_norm": 0.4105449616909027,
      "learning_rate": 8.068813074066151e-07,
      "loss": 0.0199,
      "step": 1492
    },
    {
      "epoch": 0.8171866447728516,
      "grad_norm": 0.03454564884305,
      "learning_rate": 8.022042561933674e-07,
      "loss": 0.0023,
      "step": 1493
    },
    {
      "epoch": 0.8177339901477833,
      "grad_norm": 0.021490473300218582,
      "learning_rate": 7.975396170395522e-07,
      "loss": 0.001,
      "step": 1494
    },
    {
      "epoch": 0.8182813355227149,
      "grad_norm": 2.4110379219055176,
      "learning_rate": 7.928874037375983e-07,
      "loss": 0.2218,
      "step": 1495
    },
    {
      "epoch": 0.8188286808976464,
      "grad_norm": 0.004845433868467808,
      "learning_rate": 7.882476300431868e-07,
      "loss": 0.0002,
      "step": 1496
    },
    {
      "epoch": 0.819376026272578,
      "grad_norm": 0.9504294991493225,
      "learning_rate": 7.836203096752193e-07,
      "loss": 0.0397,
      "step": 1497
    },
    {
      "epoch": 0.8199233716475096,
      "grad_norm": 0.921310305595398,
      "learning_rate": 7.790054563157745e-07,
      "loss": 0.2402,
      "step": 1498
    },
    {
      "epoch": 0.8204707170224411,
      "grad_norm": 0.006084836088120937,
      "learning_rate": 7.744030836100724e-07,
      "loss": 0.0004,
      "step": 1499
    },
    {
      "epoch": 0.8210180623973727,
      "grad_norm": 0.0074606891721487045,
      "learning_rate": 7.698132051664236e-07,
      "loss": 0.0003,
      "step": 1500
    },
    {
      "epoch": 0.8215654077723044,
      "grad_norm": 1.234869122505188,
      "learning_rate": 7.652358345562016e-07,
      "loss": 0.1157,
      "step": 1501
    },
    {
      "epoch": 0.8221127531472359,
      "grad_norm": 0.0013772393576800823,
      "learning_rate": 7.606709853137939e-07,
      "loss": 0.0001,
      "step": 1502
    },
    {
      "epoch": 0.8226600985221675,
      "grad_norm": 0.0027342780958861113,
      "learning_rate": 7.561186709365653e-07,
      "loss": 0.0001,
      "step": 1503
    },
    {
      "epoch": 0.8232074438970991,
      "grad_norm": 0.5295846462249756,
      "learning_rate": 7.515789048848171e-07,
      "loss": 0.0364,
      "step": 1504
    },
    {
      "epoch": 0.8237547892720306,
      "grad_norm": 0.004774013534188271,
      "learning_rate": 7.470517005817473e-07,
      "loss": 0.0002,
      "step": 1505
    },
    {
      "epoch": 0.8243021346469622,
      "grad_norm": 0.000770098646171391,
      "learning_rate": 7.425370714134122e-07,
      "loss": 0.0,
      "step": 1506
    },
    {
      "epoch": 0.8248494800218938,
      "grad_norm": 0.0011116163805127144,
      "learning_rate": 7.380350307286865e-07,
      "loss": 0.0,
      "step": 1507
    },
    {
      "epoch": 0.8253968253968254,
      "grad_norm": 0.02639359049499035,
      "learning_rate": 7.33545591839222e-07,
      "loss": 0.0012,
      "step": 1508
    },
    {
      "epoch": 0.825944170771757,
      "grad_norm": 0.014378324151039124,
      "learning_rate": 7.290687680194092e-07,
      "loss": 0.0006,
      "step": 1509
    },
    {
      "epoch": 0.8264915161466886,
      "grad_norm": 1.532553791999817,
      "learning_rate": 7.246045725063394e-07,
      "loss": 0.2648,
      "step": 1510
    },
    {
      "epoch": 0.8270388615216201,
      "grad_norm": 0.0023930107709020376,
      "learning_rate": 7.201530184997635e-07,
      "loss": 0.0001,
      "step": 1511
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.006641220301389694,
      "learning_rate": 7.157141191620548e-07,
      "loss": 0.0004,
      "step": 1512
    },
    {
      "epoch": 0.8281335522714833,
      "grad_norm": 0.18605098128318787,
      "learning_rate": 7.112878876181673e-07,
      "loss": 0.0078,
      "step": 1513
    },
    {
      "epoch": 0.8286808976464148,
      "grad_norm": 0.007019322365522385,
      "learning_rate": 7.068743369556042e-07,
      "loss": 0.0004,
      "step": 1514
    },
    {
      "epoch": 0.8292282430213465,
      "grad_norm": 0.005443633999675512,
      "learning_rate": 7.024734802243649e-07,
      "loss": 0.0003,
      "step": 1515
    },
    {
      "epoch": 0.8297755883962781,
      "grad_norm": 0.4817304313182831,
      "learning_rate": 6.980853304369239e-07,
      "loss": 0.0349,
      "step": 1516
    },
    {
      "epoch": 0.8303229337712096,
      "grad_norm": 0.001917894696816802,
      "learning_rate": 6.937099005681792e-07,
      "loss": 0.0001,
      "step": 1517
    },
    {
      "epoch": 0.8308702791461412,
      "grad_norm": 0.001966349547728896,
      "learning_rate": 6.8934720355542e-07,
      "loss": 0.0001,
      "step": 1518
    },
    {
      "epoch": 0.8314176245210728,
      "grad_norm": 1.8793052434921265,
      "learning_rate": 6.849972522982845e-07,
      "loss": 0.2114,
      "step": 1519
    },
    {
      "epoch": 0.8319649698960043,
      "grad_norm": 0.0010990541195496917,
      "learning_rate": 6.806600596587299e-07,
      "loss": 0.0001,
      "step": 1520
    },
    {
      "epoch": 0.8325123152709359,
      "grad_norm": 0.0007368365186266601,
      "learning_rate": 6.763356384609809e-07,
      "loss": 0.0,
      "step": 1521
    },
    {
      "epoch": 0.8330596606458676,
      "grad_norm": 0.001176101854071021,
      "learning_rate": 6.720240014915063e-07,
      "loss": 0.0001,
      "step": 1522
    },
    {
      "epoch": 0.8336070060207992,
      "grad_norm": 0.4460492432117462,
      "learning_rate": 6.677251614989699e-07,
      "loss": 0.0239,
      "step": 1523
    },
    {
      "epoch": 0.8341543513957307,
      "grad_norm": 1.373496651649475,
      "learning_rate": 6.634391311942024e-07,
      "loss": 0.0518,
      "step": 1524
    },
    {
      "epoch": 0.8347016967706623,
      "grad_norm": 1.4565794467926025,
      "learning_rate": 6.591659232501507e-07,
      "loss": 0.0702,
      "step": 1525
    },
    {
      "epoch": 0.8352490421455939,
      "grad_norm": 0.01928449235856533,
      "learning_rate": 6.549055503018575e-07,
      "loss": 0.0014,
      "step": 1526
    },
    {
      "epoch": 0.8357963875205254,
      "grad_norm": 0.00919499434530735,
      "learning_rate": 6.506580249464089e-07,
      "loss": 0.0006,
      "step": 1527
    },
    {
      "epoch": 0.836343732895457,
      "grad_norm": 0.44988390803337097,
      "learning_rate": 6.464233597429054e-07,
      "loss": 0.0191,
      "step": 1528
    },
    {
      "epoch": 0.8368910782703887,
      "grad_norm": 0.1353072226047516,
      "learning_rate": 6.42201567212421e-07,
      "loss": 0.0043,
      "step": 1529
    },
    {
      "epoch": 0.8374384236453202,
      "grad_norm": 0.119353286921978,
      "learning_rate": 6.379926598379727e-07,
      "loss": 0.0064,
      "step": 1530
    },
    {
      "epoch": 0.8379857690202518,
      "grad_norm": 0.0006970764952711761,
      "learning_rate": 6.337966500644699e-07,
      "loss": 0.0,
      "step": 1531
    },
    {
      "epoch": 0.8385331143951834,
      "grad_norm": 0.07533805072307587,
      "learning_rate": 6.296135502986944e-07,
      "loss": 0.005,
      "step": 1532
    },
    {
      "epoch": 0.8390804597701149,
      "grad_norm": 0.003108327044174075,
      "learning_rate": 6.254433729092518e-07,
      "loss": 0.0002,
      "step": 1533
    },
    {
      "epoch": 0.8396278051450465,
      "grad_norm": 0.0014436397468671203,
      "learning_rate": 6.212861302265393e-07,
      "loss": 0.0001,
      "step": 1534
    },
    {
      "epoch": 0.8401751505199782,
      "grad_norm": 0.03582088276743889,
      "learning_rate": 6.171418345427088e-07,
      "loss": 0.0021,
      "step": 1535
    },
    {
      "epoch": 0.8407224958949097,
      "grad_norm": 2.3063669204711914,
      "learning_rate": 6.130104981116314e-07,
      "loss": 0.2883,
      "step": 1536
    },
    {
      "epoch": 0.8412698412698413,
      "grad_norm": 0.0008372246520593762,
      "learning_rate": 6.088921331488568e-07,
      "loss": 0.0,
      "step": 1537
    },
    {
      "epoch": 0.8418171866447729,
      "grad_norm": 0.16179564595222473,
      "learning_rate": 6.04786751831587e-07,
      "loss": 0.0078,
      "step": 1538
    },
    {
      "epoch": 0.8423645320197044,
      "grad_norm": 0.000870110874529928,
      "learning_rate": 6.006943662986275e-07,
      "loss": 0.0001,
      "step": 1539
    },
    {
      "epoch": 0.842911877394636,
      "grad_norm": 1.425437092781067,
      "learning_rate": 5.966149886503614e-07,
      "loss": 0.1691,
      "step": 1540
    },
    {
      "epoch": 0.8434592227695676,
      "grad_norm": 0.002407242776826024,
      "learning_rate": 5.925486309487083e-07,
      "loss": 0.0001,
      "step": 1541
    },
    {
      "epoch": 0.8440065681444991,
      "grad_norm": 0.005030855070799589,
      "learning_rate": 5.884953052170917e-07,
      "loss": 0.0003,
      "step": 1542
    },
    {
      "epoch": 0.8445539135194308,
      "grad_norm": 0.11077903211116791,
      "learning_rate": 5.844550234404012e-07,
      "loss": 0.003,
      "step": 1543
    },
    {
      "epoch": 0.8451012588943624,
      "grad_norm": 0.0020904638804495335,
      "learning_rate": 5.804277975649574e-07,
      "loss": 0.0001,
      "step": 1544
    },
    {
      "epoch": 0.8456486042692939,
      "grad_norm": 0.018212052062153816,
      "learning_rate": 5.764136394984809e-07,
      "loss": 0.0008,
      "step": 1545
    },
    {
      "epoch": 0.8461959496442255,
      "grad_norm": 0.07604849338531494,
      "learning_rate": 5.724125611100467e-07,
      "loss": 0.0038,
      "step": 1546
    },
    {
      "epoch": 0.8467432950191571,
      "grad_norm": 0.002695221221074462,
      "learning_rate": 5.684245742300625e-07,
      "loss": 0.0002,
      "step": 1547
    },
    {
      "epoch": 0.8472906403940886,
      "grad_norm": 0.008823254145681858,
      "learning_rate": 5.644496906502233e-07,
      "loss": 0.0005,
      "step": 1548
    },
    {
      "epoch": 0.8478379857690203,
      "grad_norm": 2.02435302734375,
      "learning_rate": 5.60487922123481e-07,
      "loss": 0.1352,
      "step": 1549
    },
    {
      "epoch": 0.8483853311439519,
      "grad_norm": 0.01689845137298107,
      "learning_rate": 5.565392803640069e-07,
      "loss": 0.0006,
      "step": 1550
    },
    {
      "epoch": 0.8489326765188834,
      "grad_norm": 0.16562284529209137,
      "learning_rate": 5.526037770471649e-07,
      "loss": 0.0084,
      "step": 1551
    },
    {
      "epoch": 0.849480021893815,
      "grad_norm": 0.07373237609863281,
      "learning_rate": 5.486814238094629e-07,
      "loss": 0.0036,
      "step": 1552
    },
    {
      "epoch": 0.8500273672687466,
      "grad_norm": 0.01583111472427845,
      "learning_rate": 5.447722322485333e-07,
      "loss": 0.0006,
      "step": 1553
    },
    {
      "epoch": 0.8505747126436781,
      "grad_norm": 0.0010682566789910197,
      "learning_rate": 5.408762139230889e-07,
      "loss": 0.0,
      "step": 1554
    },
    {
      "epoch": 0.8511220580186097,
      "grad_norm": 0.14454738795757294,
      "learning_rate": 5.369933803528926e-07,
      "loss": 0.0059,
      "step": 1555
    },
    {
      "epoch": 0.8516694033935414,
      "grad_norm": 1.1277968883514404,
      "learning_rate": 5.331237430187214e-07,
      "loss": 0.025,
      "step": 1556
    },
    {
      "epoch": 0.8522167487684729,
      "grad_norm": 0.005529384128749371,
      "learning_rate": 5.292673133623372e-07,
      "loss": 0.0003,
      "step": 1557
    },
    {
      "epoch": 0.8527640941434045,
      "grad_norm": 0.0024228382389992476,
      "learning_rate": 5.254241027864432e-07,
      "loss": 0.0001,
      "step": 1558
    },
    {
      "epoch": 0.8533114395183361,
      "grad_norm": 0.1500295102596283,
      "learning_rate": 5.215941226546628e-07,
      "loss": 0.0084,
      "step": 1559
    },
    {
      "epoch": 0.8538587848932676,
      "grad_norm": 0.00548445712774992,
      "learning_rate": 5.177773842914963e-07,
      "loss": 0.0003,
      "step": 1560
    },
    {
      "epoch": 0.8544061302681992,
      "grad_norm": 0.001336822984740138,
      "learning_rate": 5.139738989822901e-07,
      "loss": 0.0001,
      "step": 1561
    },
    {
      "epoch": 0.8549534756431308,
      "grad_norm": 0.019387034699320793,
      "learning_rate": 5.101836779732044e-07,
      "loss": 0.001,
      "step": 1562
    },
    {
      "epoch": 0.8555008210180624,
      "grad_norm": 0.09986677020788193,
      "learning_rate": 5.064067324711836e-07,
      "loss": 0.0055,
      "step": 1563
    },
    {
      "epoch": 0.856048166392994,
      "grad_norm": 3.283087730407715,
      "learning_rate": 5.026430736439102e-07,
      "loss": 0.3564,
      "step": 1564
    },
    {
      "epoch": 0.8565955117679256,
      "grad_norm": 0.03182658553123474,
      "learning_rate": 4.988927126197901e-07,
      "loss": 0.0016,
      "step": 1565
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.0011267211521044374,
      "learning_rate": 4.951556604879049e-07,
      "loss": 0.0001,
      "step": 1566
    },
    {
      "epoch": 0.8576902025177887,
      "grad_norm": 0.02494209073483944,
      "learning_rate": 4.91431928297984e-07,
      "loss": 0.0009,
      "step": 1567
    },
    {
      "epoch": 0.8582375478927203,
      "grad_norm": 0.0007895384333096445,
      "learning_rate": 4.877215270603752e-07,
      "loss": 0.0,
      "step": 1568
    },
    {
      "epoch": 0.8587848932676518,
      "grad_norm": 3.6091201305389404,
      "learning_rate": 4.840244677460076e-07,
      "loss": 0.3354,
      "step": 1569
    },
    {
      "epoch": 0.8593322386425835,
      "grad_norm": 0.0832236260175705,
      "learning_rate": 4.803407612863603e-07,
      "loss": 0.0046,
      "step": 1570
    },
    {
      "epoch": 0.8598795840175151,
      "grad_norm": 0.004446066915988922,
      "learning_rate": 4.7667041857343276e-07,
      "loss": 0.0003,
      "step": 1571
    },
    {
      "epoch": 0.8604269293924466,
      "grad_norm": 0.0038263245951384306,
      "learning_rate": 4.730134504597084e-07,
      "loss": 0.0002,
      "step": 1572
    },
    {
      "epoch": 0.8609742747673782,
      "grad_norm": 0.021134914830327034,
      "learning_rate": 4.69369867758126e-07,
      "loss": 0.0012,
      "step": 1573
    },
    {
      "epoch": 0.8615216201423098,
      "grad_norm": 0.009342621080577374,
      "learning_rate": 4.6573968124204506e-07,
      "loss": 0.0006,
      "step": 1574
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.02796771377325058,
      "learning_rate": 4.6212290164521554e-07,
      "loss": 0.0012,
      "step": 1575
    },
    {
      "epoch": 0.8626163108921729,
      "grad_norm": 3.130685806274414,
      "learning_rate": 4.585195396617464e-07,
      "loss": 0.5505,
      "step": 1576
    },
    {
      "epoch": 0.8631636562671046,
      "grad_norm": 0.0015311005990952253,
      "learning_rate": 4.549296059460717e-07,
      "loss": 0.0001,
      "step": 1577
    },
    {
      "epoch": 0.8637110016420362,
      "grad_norm": 1.0687007904052734,
      "learning_rate": 4.5135311111292435e-07,
      "loss": 0.0566,
      "step": 1578
    },
    {
      "epoch": 0.8642583470169677,
      "grad_norm": 0.000859707361087203,
      "learning_rate": 4.477900657372969e-07,
      "loss": 0.0,
      "step": 1579
    },
    {
      "epoch": 0.8648056923918993,
      "grad_norm": 0.15521958470344543,
      "learning_rate": 4.442404803544176e-07,
      "loss": 0.0054,
      "step": 1580
    },
    {
      "epoch": 0.8653530377668309,
      "grad_norm": 0.0013013661373406649,
      "learning_rate": 4.407043654597126e-07,
      "loss": 0.0001,
      "step": 1581
    },
    {
      "epoch": 0.8659003831417624,
      "grad_norm": 0.0026311189867556095,
      "learning_rate": 4.371817315087845e-07,
      "loss": 0.0001,
      "step": 1582
    },
    {
      "epoch": 0.866447728516694,
      "grad_norm": 1.124261498451233,
      "learning_rate": 4.336725889173676e-07,
      "loss": 0.2038,
      "step": 1583
    },
    {
      "epoch": 0.8669950738916257,
      "grad_norm": 0.0021151467226445675,
      "learning_rate": 4.3017694806131163e-07,
      "loss": 0.0001,
      "step": 1584
    },
    {
      "epoch": 0.8675424192665572,
      "grad_norm": 0.0015626264503225684,
      "learning_rate": 4.266948192765402e-07,
      "loss": 0.0001,
      "step": 1585
    },
    {
      "epoch": 0.8680897646414888,
      "grad_norm": 0.047082699835300446,
      "learning_rate": 4.2322621285902697e-07,
      "loss": 0.0026,
      "step": 1586
    },
    {
      "epoch": 0.8686371100164204,
      "grad_norm": 0.0014279431197792292,
      "learning_rate": 4.1977113906475965e-07,
      "loss": 0.0001,
      "step": 1587
    },
    {
      "epoch": 0.8691844553913519,
      "grad_norm": 0.005334758665412664,
      "learning_rate": 4.163296081097168e-07,
      "loss": 0.0003,
      "step": 1588
    },
    {
      "epoch": 0.8697318007662835,
      "grad_norm": 0.002800790360197425,
      "learning_rate": 4.1290163016982855e-07,
      "loss": 0.0002,
      "step": 1589
    },
    {
      "epoch": 0.8702791461412152,
      "grad_norm": 0.0009118798188865185,
      "learning_rate": 4.0948721538095593e-07,
      "loss": 0.0,
      "step": 1590
    },
    {
      "epoch": 0.8708264915161467,
      "grad_norm": 0.3546822667121887,
      "learning_rate": 4.060863738388532e-07,
      "loss": 0.0175,
      "step": 1591
    },
    {
      "epoch": 0.8713738368910783,
      "grad_norm": 0.003551200730726123,
      "learning_rate": 4.026991155991433e-07,
      "loss": 0.0002,
      "step": 1592
    },
    {
      "epoch": 0.8719211822660099,
      "grad_norm": 0.011092441156506538,
      "learning_rate": 3.9932545067728366e-07,
      "loss": 0.0008,
      "step": 1593
    },
    {
      "epoch": 0.8724685276409414,
      "grad_norm": 0.0397016741335392,
      "learning_rate": 3.9596538904854263e-07,
      "loss": 0.0027,
      "step": 1594
    },
    {
      "epoch": 0.873015873015873,
      "grad_norm": 0.07381250709295273,
      "learning_rate": 3.9261894064796136e-07,
      "loss": 0.0046,
      "step": 1595
    },
    {
      "epoch": 0.8735632183908046,
      "grad_norm": 0.0005202413885854185,
      "learning_rate": 3.8928611537033424e-07,
      "loss": 0.0,
      "step": 1596
    },
    {
      "epoch": 0.8741105637657361,
      "grad_norm": 0.0017909639282152057,
      "learning_rate": 3.859669230701718e-07,
      "loss": 0.0001,
      "step": 1597
    },
    {
      "epoch": 0.8746579091406678,
      "grad_norm": 0.11845830082893372,
      "learning_rate": 3.8266137356167466e-07,
      "loss": 0.0081,
      "step": 1598
    },
    {
      "epoch": 0.8752052545155994,
      "grad_norm": 0.0012911782832816243,
      "learning_rate": 3.7936947661870616e-07,
      "loss": 0.0001,
      "step": 1599
    },
    {
      "epoch": 0.8757525998905309,
      "grad_norm": 0.00783374160528183,
      "learning_rate": 3.760912419747592e-07,
      "loss": 0.0005,
      "step": 1600
    },
    {
      "epoch": 0.8762999452654625,
      "grad_norm": 0.27052271366119385,
      "learning_rate": 3.728266793229307e-07,
      "loss": 0.0106,
      "step": 1601
    },
    {
      "epoch": 0.8768472906403941,
      "grad_norm": 4.550227642059326,
      "learning_rate": 3.695757983158954e-07,
      "loss": 0.5924,
      "step": 1602
    },
    {
      "epoch": 0.8773946360153256,
      "grad_norm": 0.001323746400885284,
      "learning_rate": 3.663386085658693e-07,
      "loss": 0.0001,
      "step": 1603
    },
    {
      "epoch": 0.8779419813902573,
      "grad_norm": 0.5580865144729614,
      "learning_rate": 3.631151196445887e-07,
      "loss": 0.0132,
      "step": 1604
    },
    {
      "epoch": 0.8784893267651889,
      "grad_norm": 0.0004332675307523459,
      "learning_rate": 3.5990534108327926e-07,
      "loss": 0.0,
      "step": 1605
    },
    {
      "epoch": 0.8790366721401204,
      "grad_norm": 0.016855021938681602,
      "learning_rate": 3.567092823726259e-07,
      "loss": 0.0011,
      "step": 1606
    },
    {
      "epoch": 0.879584017515052,
      "grad_norm": 0.143702432513237,
      "learning_rate": 3.5352695296274884e-07,
      "loss": 0.008,
      "step": 1607
    },
    {
      "epoch": 0.8801313628899836,
      "grad_norm": 0.0017894726479426026,
      "learning_rate": 3.5035836226317177e-07,
      "loss": 0.0001,
      "step": 1608
    },
    {
      "epoch": 0.8806787082649151,
      "grad_norm": 3.967972993850708,
      "learning_rate": 3.4720351964279863e-07,
      "loss": 0.3184,
      "step": 1609
    },
    {
      "epoch": 0.8812260536398467,
      "grad_norm": 0.007289699744433165,
      "learning_rate": 3.4406243442987765e-07,
      "loss": 0.0003,
      "step": 1610
    },
    {
      "epoch": 0.8817733990147784,
      "grad_norm": 0.003978394903242588,
      "learning_rate": 3.409351159119845e-07,
      "loss": 0.0002,
      "step": 1611
    },
    {
      "epoch": 0.8823207443897099,
      "grad_norm": 0.0027001143898814917,
      "learning_rate": 3.3782157333598687e-07,
      "loss": 0.0002,
      "step": 1612
    },
    {
      "epoch": 0.8828680897646415,
      "grad_norm": 0.001392848091199994,
      "learning_rate": 3.347218159080201e-07,
      "loss": 0.0001,
      "step": 1613
    },
    {
      "epoch": 0.8834154351395731,
      "grad_norm": 0.2904432713985443,
      "learning_rate": 3.3163585279345823e-07,
      "loss": 0.0168,
      "step": 1614
    },
    {
      "epoch": 0.8839627805145046,
      "grad_norm": 0.12866921722888947,
      "learning_rate": 3.2856369311689174e-07,
      "loss": 0.0084,
      "step": 1615
    },
    {
      "epoch": 0.8845101258894362,
      "grad_norm": 0.0019181475508958101,
      "learning_rate": 3.2550534596209217e-07,
      "loss": 0.0001,
      "step": 1616
    },
    {
      "epoch": 0.8850574712643678,
      "grad_norm": 5.3930583000183105,
      "learning_rate": 3.224608203719953e-07,
      "loss": 0.1604,
      "step": 1617
    },
    {
      "epoch": 0.8856048166392994,
      "grad_norm": 1.4229497909545898,
      "learning_rate": 3.1943012534866536e-07,
      "loss": 0.3214,
      "step": 1618
    },
    {
      "epoch": 0.886152162014231,
      "grad_norm": 3.202608346939087,
      "learning_rate": 3.164132698532735e-07,
      "loss": 0.4288,
      "step": 1619
    },
    {
      "epoch": 0.8866995073891626,
      "grad_norm": 0.0198553204536438,
      "learning_rate": 3.134102628060698e-07,
      "loss": 0.0012,
      "step": 1620
    },
    {
      "epoch": 0.8872468527640941,
      "grad_norm": 0.014188609085977077,
      "learning_rate": 3.1042111308636047e-07,
      "loss": 0.0005,
      "step": 1621
    },
    {
      "epoch": 0.8877941981390257,
      "grad_norm": 0.5998849868774414,
      "learning_rate": 3.074458295324717e-07,
      "loss": 0.037,
      "step": 1622
    },
    {
      "epoch": 0.8883415435139573,
      "grad_norm": 0.025491988286376,
      "learning_rate": 3.0448442094173634e-07,
      "loss": 0.0014,
      "step": 1623
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.4333273768424988,
      "learning_rate": 3.015368960704584e-07,
      "loss": 0.0318,
      "step": 1624
    },
    {
      "epoch": 0.8894362342638205,
      "grad_norm": 0.056353479623794556,
      "learning_rate": 2.98603263633892e-07,
      "loss": 0.0029,
      "step": 1625
    },
    {
      "epoch": 0.8899835796387521,
      "grad_norm": 0.02181403897702694,
      "learning_rate": 2.9568353230621185e-07,
      "loss": 0.0012,
      "step": 1626
    },
    {
      "epoch": 0.8905309250136836,
      "grad_norm": 0.026894887909293175,
      "learning_rate": 2.9277771072049433e-07,
      "loss": 0.0012,
      "step": 1627
    },
    {
      "epoch": 0.8910782703886152,
      "grad_norm": 0.0038852733559906483,
      "learning_rate": 2.898858074686806e-07,
      "loss": 0.0002,
      "step": 1628
    },
    {
      "epoch": 0.8916256157635468,
      "grad_norm": 4.922279357910156,
      "learning_rate": 2.8700783110156507e-07,
      "loss": 1.0984,
      "step": 1629
    },
    {
      "epoch": 0.8921729611384783,
      "grad_norm": 2.938300132751465,
      "learning_rate": 2.841437901287586e-07,
      "loss": 0.3779,
      "step": 1630
    },
    {
      "epoch": 0.89272030651341,
      "grad_norm": 0.13576510548591614,
      "learning_rate": 2.812936930186688e-07,
      "loss": 0.0044,
      "step": 1631
    },
    {
      "epoch": 0.8932676518883416,
      "grad_norm": 0.020039185881614685,
      "learning_rate": 2.784575481984747e-07,
      "loss": 0.0012,
      "step": 1632
    },
    {
      "epoch": 0.8938149972632731,
      "grad_norm": 3.0727877616882324,
      "learning_rate": 2.756353640541021e-07,
      "loss": 0.4797,
      "step": 1633
    },
    {
      "epoch": 0.8943623426382047,
      "grad_norm": 1.0367286205291748,
      "learning_rate": 2.728271489301937e-07,
      "loss": 0.0883,
      "step": 1634
    },
    {
      "epoch": 0.8949096880131363,
      "grad_norm": 0.10197547823190689,
      "learning_rate": 2.700329111300937e-07,
      "loss": 0.0033,
      "step": 1635
    },
    {
      "epoch": 0.8954570333880679,
      "grad_norm": 0.0006226112018339336,
      "learning_rate": 2.672526589158153e-07,
      "loss": 0.0,
      "step": 1636
    },
    {
      "epoch": 0.8960043787629994,
      "grad_norm": 0.029636362567543983,
      "learning_rate": 2.644864005080183e-07,
      "loss": 0.0015,
      "step": 1637
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.0013220414984971285,
      "learning_rate": 2.617341440859883e-07,
      "loss": 0.0001,
      "step": 1638
    },
    {
      "epoch": 0.8970990695128627,
      "grad_norm": 4.382612705230713,
      "learning_rate": 2.5899589778760614e-07,
      "loss": 0.5229,
      "step": 1639
    },
    {
      "epoch": 0.8976464148877942,
      "grad_norm": 0.59869784116745,
      "learning_rate": 2.5627166970933257e-07,
      "loss": 0.018,
      "step": 1640
    },
    {
      "epoch": 0.8981937602627258,
      "grad_norm": 0.005435081198811531,
      "learning_rate": 2.535614679061732e-07,
      "loss": 0.0003,
      "step": 1641
    },
    {
      "epoch": 0.8987411056376574,
      "grad_norm": 3.979936361312866,
      "learning_rate": 2.5086530039166615e-07,
      "loss": 0.5066,
      "step": 1642
    },
    {
      "epoch": 0.8992884510125889,
      "grad_norm": 0.16159893572330475,
      "learning_rate": 2.4818317513784886e-07,
      "loss": 0.0072,
      "step": 1643
    },
    {
      "epoch": 0.8998357963875205,
      "grad_norm": 0.0013100486248731613,
      "learning_rate": 2.4551510007524035e-07,
      "loss": 0.0001,
      "step": 1644
    },
    {
      "epoch": 0.9003831417624522,
      "grad_norm": 3.6564407348632812,
      "learning_rate": 2.428610830928152e-07,
      "loss": 0.5519,
      "step": 1645
    },
    {
      "epoch": 0.9009304871373837,
      "grad_norm": 0.006347591523081064,
      "learning_rate": 2.402211320379838e-07,
      "loss": 0.0003,
      "step": 1646
    },
    {
      "epoch": 0.9014778325123153,
      "grad_norm": 0.022770870476961136,
      "learning_rate": 2.3759525471656163e-07,
      "loss": 0.0009,
      "step": 1647
    },
    {
      "epoch": 0.9020251778872469,
      "grad_norm": 0.03970279172062874,
      "learning_rate": 2.3498345889275465e-07,
      "loss": 0.0024,
      "step": 1648
    },
    {
      "epoch": 0.9025725232621784,
      "grad_norm": 0.026755042374134064,
      "learning_rate": 2.3238575228913152e-07,
      "loss": 0.0014,
      "step": 1649
    },
    {
      "epoch": 0.90311986863711,
      "grad_norm": 0.24361871182918549,
      "learning_rate": 2.2980214258660038e-07,
      "loss": 0.0099,
      "step": 1650
    },
    {
      "epoch": 0.9036672140120416,
      "grad_norm": 0.010404447093605995,
      "learning_rate": 2.2723263742438938e-07,
      "loss": 0.0006,
      "step": 1651
    },
    {
      "epoch": 0.9042145593869731,
      "grad_norm": 0.003072150517255068,
      "learning_rate": 2.2467724440002336e-07,
      "loss": 0.0002,
      "step": 1652
    },
    {
      "epoch": 0.9047619047619048,
      "grad_norm": 0.22988516092300415,
      "learning_rate": 2.2213597106929608e-07,
      "loss": 0.0073,
      "step": 1653
    },
    {
      "epoch": 0.9053092501368364,
      "grad_norm": 4.157158374786377,
      "learning_rate": 2.1960882494625692e-07,
      "loss": 0.6525,
      "step": 1654
    },
    {
      "epoch": 0.9058565955117679,
      "grad_norm": 0.006719620432704687,
      "learning_rate": 2.1709581350318089e-07,
      "loss": 0.0002,
      "step": 1655
    },
    {
      "epoch": 0.9064039408866995,
      "grad_norm": 0.05124837905168533,
      "learning_rate": 2.1459694417055033e-07,
      "loss": 0.0029,
      "step": 1656
    },
    {
      "epoch": 0.9069512862616311,
      "grad_norm": 1.7451118230819702,
      "learning_rate": 2.1211222433703217e-07,
      "loss": 0.0461,
      "step": 1657
    },
    {
      "epoch": 0.9074986316365626,
      "grad_norm": 0.0006388374604284763,
      "learning_rate": 2.0964166134945674e-07,
      "loss": 0.0,
      "step": 1658
    },
    {
      "epoch": 0.9080459770114943,
      "grad_norm": 0.0027861613780260086,
      "learning_rate": 2.0718526251279346e-07,
      "loss": 0.0002,
      "step": 1659
    },
    {
      "epoch": 0.9085933223864259,
      "grad_norm": 0.0051586562767624855,
      "learning_rate": 2.0474303509013361e-07,
      "loss": 0.0003,
      "step": 1660
    },
    {
      "epoch": 0.9091406677613574,
      "grad_norm": 0.028800444677472115,
      "learning_rate": 2.0231498630266467e-07,
      "loss": 0.0017,
      "step": 1661
    },
    {
      "epoch": 0.909688013136289,
      "grad_norm": 0.007612964138388634,
      "learning_rate": 1.999011233296505e-07,
      "loss": 0.0004,
      "step": 1662
    },
    {
      "epoch": 0.9102353585112206,
      "grad_norm": 0.0005598650895990431,
      "learning_rate": 1.9750145330841186e-07,
      "loss": 0.0,
      "step": 1663
    },
    {
      "epoch": 0.9107827038861521,
      "grad_norm": 0.0033948025666177273,
      "learning_rate": 1.9511598333430194e-07,
      "loss": 0.0001,
      "step": 1664
    },
    {
      "epoch": 0.9113300492610837,
      "grad_norm": 0.0011932599591091275,
      "learning_rate": 1.9274472046068805e-07,
      "loss": 0.0,
      "step": 1665
    },
    {
      "epoch": 0.9118773946360154,
      "grad_norm": 0.087752565741539,
      "learning_rate": 1.9038767169893058e-07,
      "loss": 0.005,
      "step": 1666
    },
    {
      "epoch": 0.9124247400109469,
      "grad_norm": 0.0008228141232393682,
      "learning_rate": 1.8804484401836077e-07,
      "loss": 0.0,
      "step": 1667
    },
    {
      "epoch": 0.9129720853858785,
      "grad_norm": 0.005488018039613962,
      "learning_rate": 1.857162443462601e-07,
      "loss": 0.0003,
      "step": 1668
    },
    {
      "epoch": 0.9135194307608101,
      "grad_norm": 0.002274312311783433,
      "learning_rate": 1.834018795678427e-07,
      "loss": 0.0001,
      "step": 1669
    },
    {
      "epoch": 0.9140667761357416,
      "grad_norm": 0.0014023897238075733,
      "learning_rate": 1.8110175652623075e-07,
      "loss": 0.0001,
      "step": 1670
    },
    {
      "epoch": 0.9146141215106732,
      "grad_norm": 1.4514551162719727,
      "learning_rate": 1.7881588202243782e-07,
      "loss": 0.2972,
      "step": 1671
    },
    {
      "epoch": 0.9151614668856048,
      "grad_norm": 0.03509846702218056,
      "learning_rate": 1.7654426281534576e-07,
      "loss": 0.0012,
      "step": 1672
    },
    {
      "epoch": 0.9157088122605364,
      "grad_norm": 0.12984243035316467,
      "learning_rate": 1.7428690562169003e-07,
      "loss": 0.0047,
      "step": 1673
    },
    {
      "epoch": 0.916256157635468,
      "grad_norm": 0.004213547334074974,
      "learning_rate": 1.7204381711603046e-07,
      "loss": 0.0003,
      "step": 1674
    },
    {
      "epoch": 0.9168035030103996,
      "grad_norm": 0.039448246359825134,
      "learning_rate": 1.698150039307428e-07,
      "loss": 0.0029,
      "step": 1675
    },
    {
      "epoch": 0.9173508483853311,
      "grad_norm": 0.033028312027454376,
      "learning_rate": 1.6760047265598933e-07,
      "loss": 0.0018,
      "step": 1676
    },
    {
      "epoch": 0.9178981937602627,
      "grad_norm": 0.3258588910102844,
      "learning_rate": 1.6540022983970505e-07,
      "loss": 0.0116,
      "step": 1677
    },
    {
      "epoch": 0.9184455391351943,
      "grad_norm": 0.019775962457060814,
      "learning_rate": 1.632142819875776e-07,
      "loss": 0.0009,
      "step": 1678
    },
    {
      "epoch": 0.9189928845101258,
      "grad_norm": 0.08251109719276428,
      "learning_rate": 1.610426355630268e-07,
      "loss": 0.0044,
      "step": 1679
    },
    {
      "epoch": 0.9195402298850575,
      "grad_norm": 0.0033483237493783236,
      "learning_rate": 1.5888529698718347e-07,
      "loss": 0.0002,
      "step": 1680
    },
    {
      "epoch": 0.9200875752599891,
      "grad_norm": 0.28158387541770935,
      "learning_rate": 1.5674227263887732e-07,
      "loss": 0.0152,
      "step": 1681
    },
    {
      "epoch": 0.9206349206349206,
      "grad_norm": 0.6776902079582214,
      "learning_rate": 1.5461356885461077e-07,
      "loss": 0.0385,
      "step": 1682
    },
    {
      "epoch": 0.9211822660098522,
      "grad_norm": 0.8400164246559143,
      "learning_rate": 1.524991919285429e-07,
      "loss": 0.0311,
      "step": 1683
    },
    {
      "epoch": 0.9217296113847838,
      "grad_norm": 0.11295659095048904,
      "learning_rate": 1.503991481124728e-07,
      "loss": 0.0035,
      "step": 1684
    },
    {
      "epoch": 0.9222769567597153,
      "grad_norm": 0.01587807945907116,
      "learning_rate": 1.48313443615819e-07,
      "loss": 0.0007,
      "step": 1685
    },
    {
      "epoch": 0.922824302134647,
      "grad_norm": 2.037874460220337,
      "learning_rate": 1.4624208460559897e-07,
      "loss": 0.0873,
      "step": 1686
    },
    {
      "epoch": 0.9233716475095786,
      "grad_norm": 0.0010770183289423585,
      "learning_rate": 1.4418507720641794e-07,
      "loss": 0.0001,
      "step": 1687
    },
    {
      "epoch": 0.9239189928845101,
      "grad_norm": 0.007609673775732517,
      "learning_rate": 1.4214242750044238e-07,
      "loss": 0.0005,
      "step": 1688
    },
    {
      "epoch": 0.9244663382594417,
      "grad_norm": 0.00876455195248127,
      "learning_rate": 1.401141415273871e-07,
      "loss": 0.0006,
      "step": 1689
    },
    {
      "epoch": 0.9250136836343733,
      "grad_norm": 0.0027760507073253393,
      "learning_rate": 1.3810022528449597e-07,
      "loss": 0.0001,
      "step": 1690
    },
    {
      "epoch": 0.9255610290093049,
      "grad_norm": 0.03382062166929245,
      "learning_rate": 1.3610068472652615e-07,
      "loss": 0.0011,
      "step": 1691
    },
    {
      "epoch": 0.9261083743842364,
      "grad_norm": 1.782102108001709,
      "learning_rate": 1.3411552576572562e-07,
      "loss": 0.4096,
      "step": 1692
    },
    {
      "epoch": 0.926655719759168,
      "grad_norm": 0.0008573036757297814,
      "learning_rate": 1.3214475427182182e-07,
      "loss": 0.0,
      "step": 1693
    },
    {
      "epoch": 0.9272030651340997,
      "grad_norm": 1.566433310508728,
      "learning_rate": 1.3018837607199909e-07,
      "loss": 0.2049,
      "step": 1694
    },
    {
      "epoch": 0.9277504105090312,
      "grad_norm": 0.052711378782987595,
      "learning_rate": 1.2824639695088403e-07,
      "loss": 0.0028,
      "step": 1695
    },
    {
      "epoch": 0.9282977558839628,
      "grad_norm": 0.0007691635983064771,
      "learning_rate": 1.2631882265052908e-07,
      "loss": 0.0,
      "step": 1696
    },
    {
      "epoch": 0.9288451012588944,
      "grad_norm": 0.010947825387120247,
      "learning_rate": 1.2440565887039347e-07,
      "loss": 0.0005,
      "step": 1697
    },
    {
      "epoch": 0.9293924466338259,
      "grad_norm": 0.0009539147722534835,
      "learning_rate": 1.2250691126732772e-07,
      "loss": 0.0001,
      "step": 1698
    },
    {
      "epoch": 0.9299397920087575,
      "grad_norm": 0.010536203160881996,
      "learning_rate": 1.2062258545555649e-07,
      "loss": 0.0006,
      "step": 1699
    },
    {
      "epoch": 0.9304871373836892,
      "grad_norm": 6.254275321960449,
      "learning_rate": 1.1875268700666187e-07,
      "loss": 0.3003,
      "step": 1700
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 0.08161147683858871,
      "learning_rate": 1.1689722144956672e-07,
      "loss": 0.0054,
      "step": 1701
    },
    {
      "epoch": 0.9315818281335523,
      "grad_norm": 0.01926364190876484,
      "learning_rate": 1.1505619427051973e-07,
      "loss": 0.0012,
      "step": 1702
    },
    {
      "epoch": 0.9321291735084839,
      "grad_norm": 0.018422039225697517,
      "learning_rate": 1.1322961091307705e-07,
      "loss": 0.001,
      "step": 1703
    },
    {
      "epoch": 0.9326765188834154,
      "grad_norm": 0.0034140327479690313,
      "learning_rate": 1.1141747677808845e-07,
      "loss": 0.0002,
      "step": 1704
    },
    {
      "epoch": 0.933223864258347,
      "grad_norm": 0.0008653368568047881,
      "learning_rate": 1.0961979722367789e-07,
      "loss": 0.0,
      "step": 1705
    },
    {
      "epoch": 0.9337712096332786,
      "grad_norm": 0.002840543631464243,
      "learning_rate": 1.0783657756523347e-07,
      "loss": 0.0001,
      "step": 1706
    },
    {
      "epoch": 0.9343185550082101,
      "grad_norm": 0.0012955272104591131,
      "learning_rate": 1.0606782307538532e-07,
      "loss": 0.0001,
      "step": 1707
    },
    {
      "epoch": 0.9348659003831418,
      "grad_norm": 0.001224744482897222,
      "learning_rate": 1.0431353898399388e-07,
      "loss": 0.0001,
      "step": 1708
    },
    {
      "epoch": 0.9354132457580734,
      "grad_norm": 0.022151721641421318,
      "learning_rate": 1.0257373047813324e-07,
      "loss": 0.0007,
      "step": 1709
    },
    {
      "epoch": 0.9359605911330049,
      "grad_norm": 0.008427082560956478,
      "learning_rate": 1.008484027020773e-07,
      "loss": 0.0005,
      "step": 1710
    },
    {
      "epoch": 0.9365079365079365,
      "grad_norm": 0.3798167109489441,
      "learning_rate": 9.913756075728088e-08,
      "loss": 0.0147,
      "step": 1711
    },
    {
      "epoch": 0.9370552818828681,
      "grad_norm": 0.0053103105165064335,
      "learning_rate": 9.744120970236914e-08,
      "loss": 0.0003,
      "step": 1712
    },
    {
      "epoch": 0.9376026272577996,
      "grad_norm": 4.054203510284424,
      "learning_rate": 9.575935455311935e-08,
      "loss": 0.3251,
      "step": 1713
    },
    {
      "epoch": 0.9381499726327313,
      "grad_norm": 0.001452941563911736,
      "learning_rate": 9.409200028244803e-08,
      "loss": 0.0001,
      "step": 1714
    },
    {
      "epoch": 0.9386973180076629,
      "grad_norm": 0.0011977003887295723,
      "learning_rate": 9.243915182039431e-08,
      "loss": 0.0001,
      "step": 1715
    },
    {
      "epoch": 0.9392446633825944,
      "grad_norm": 3.095736026763916,
      "learning_rate": 9.08008140541089e-08,
      "loss": 0.1786,
      "step": 1716
    },
    {
      "epoch": 0.939792008757526,
      "grad_norm": 1.6311109066009521,
      "learning_rate": 8.917699182783346e-08,
      "loss": 0.2765,
      "step": 1717
    },
    {
      "epoch": 0.9403393541324576,
      "grad_norm": 0.016161996871232986,
      "learning_rate": 8.756768994289289e-08,
      "loss": 0.0011,
      "step": 1718
    },
    {
      "epoch": 0.9408866995073891,
      "grad_norm": 0.015358857810497284,
      "learning_rate": 8.597291315767808e-08,
      "loss": 0.0008,
      "step": 1719
    },
    {
      "epoch": 0.9414340448823207,
      "grad_norm": 1.0744004249572754,
      "learning_rate": 8.439266618763098e-08,
      "loss": 0.0811,
      "step": 1720
    },
    {
      "epoch": 0.9419813902572524,
      "grad_norm": 0.11458490043878555,
      "learning_rate": 8.282695370523175e-08,
      "loss": 0.0063,
      "step": 1721
    },
    {
      "epoch": 0.9425287356321839,
      "grad_norm": 0.001683459966443479,
      "learning_rate": 8.127578033998663e-08,
      "loss": 0.0001,
      "step": 1722
    },
    {
      "epoch": 0.9430760810071155,
      "grad_norm": 0.5108358263969421,
      "learning_rate": 7.973915067840954e-08,
      "loss": 0.0263,
      "step": 1723
    },
    {
      "epoch": 0.9436234263820471,
      "grad_norm": 0.005935182794928551,
      "learning_rate": 7.821706926401496e-08,
      "loss": 0.0004,
      "step": 1724
    },
    {
      "epoch": 0.9441707717569786,
      "grad_norm": 0.03265650197863579,
      "learning_rate": 7.670954059729896e-08,
      "loss": 0.0013,
      "step": 1725
    },
    {
      "epoch": 0.9447181171319102,
      "grad_norm": 1.2190282344818115,
      "learning_rate": 7.521656913572817e-08,
      "loss": 0.2014,
      "step": 1726
    },
    {
      "epoch": 0.9452654625068418,
      "grad_norm": 2.4581522941589355,
      "learning_rate": 7.373815929372586e-08,
      "loss": 0.5768,
      "step": 1727
    },
    {
      "epoch": 0.9458128078817734,
      "grad_norm": 0.7839835286140442,
      "learning_rate": 7.227431544266194e-08,
      "loss": 0.0284,
      "step": 1728
    },
    {
      "epoch": 0.946360153256705,
      "grad_norm": 0.002155567519366741,
      "learning_rate": 7.082504191083417e-08,
      "loss": 0.0001,
      "step": 1729
    },
    {
      "epoch": 0.9469074986316366,
      "grad_norm": 0.0014205016195774078,
      "learning_rate": 6.939034298346192e-08,
      "loss": 0.0001,
      "step": 1730
    },
    {
      "epoch": 0.9474548440065681,
      "grad_norm": 0.000641017162706703,
      "learning_rate": 6.797022290266741e-08,
      "loss": 0.0,
      "step": 1731
    },
    {
      "epoch": 0.9480021893814997,
      "grad_norm": 0.024563712999224663,
      "learning_rate": 6.656468586746789e-08,
      "loss": 0.0013,
      "step": 1732
    },
    {
      "epoch": 0.9485495347564313,
      "grad_norm": 0.021805228665471077,
      "learning_rate": 6.517373603376176e-08,
      "loss": 0.0011,
      "step": 1733
    },
    {
      "epoch": 0.9490968801313628,
      "grad_norm": 0.9313660264015198,
      "learning_rate": 6.379737751431415e-08,
      "loss": 0.0529,
      "step": 1734
    },
    {
      "epoch": 0.9496442255062945,
      "grad_norm": 0.4440961480140686,
      "learning_rate": 6.243561437874745e-08,
      "loss": 0.0238,
      "step": 1735
    },
    {
      "epoch": 0.9501915708812261,
      "grad_norm": 0.03154875710606575,
      "learning_rate": 6.108845065352864e-08,
      "loss": 0.0018,
      "step": 1736
    },
    {
      "epoch": 0.9507389162561576,
      "grad_norm": 0.28971919417381287,
      "learning_rate": 5.97558903219575e-08,
      "loss": 0.0182,
      "step": 1737
    },
    {
      "epoch": 0.9512862616310892,
      "grad_norm": 0.0009574362775310874,
      "learning_rate": 5.843793732415282e-08,
      "loss": 0.0,
      "step": 1738
    },
    {
      "epoch": 0.9518336070060208,
      "grad_norm": 0.002614244818687439,
      "learning_rate": 5.713459555704404e-08,
      "loss": 0.0001,
      "step": 1739
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 3.2332825660705566,
      "learning_rate": 5.584586887435739e-08,
      "loss": 0.23,
      "step": 1740
    },
    {
      "epoch": 0.952928297755884,
      "grad_norm": 5.63487434387207,
      "learning_rate": 5.457176108660478e-08,
      "loss": 0.2531,
      "step": 1741
    },
    {
      "epoch": 0.9534756431308156,
      "grad_norm": 0.010243356227874756,
      "learning_rate": 5.331227596107325e-08,
      "loss": 0.0004,
      "step": 1742
    },
    {
      "epoch": 0.9540229885057471,
      "grad_norm": 0.031386617571115494,
      "learning_rate": 5.206741722181385e-08,
      "loss": 0.0015,
      "step": 1743
    },
    {
      "epoch": 0.9545703338806787,
      "grad_norm": 2.4586405754089355,
      "learning_rate": 5.0837188549628934e-08,
      "loss": 0.1345,
      "step": 1744
    },
    {
      "epoch": 0.9551176792556103,
      "grad_norm": 0.045660268515348434,
      "learning_rate": 4.9621593582065416e-08,
      "loss": 0.0018,
      "step": 1745
    },
    {
      "epoch": 0.9556650246305419,
      "grad_norm": 1.7174708843231201,
      "learning_rate": 4.842063591339763e-08,
      "loss": 0.3256,
      "step": 1746
    },
    {
      "epoch": 0.9562123700054734,
      "grad_norm": 0.02013416960835457,
      "learning_rate": 4.723431909462339e-08,
      "loss": 0.001,
      "step": 1747
    },
    {
      "epoch": 0.956759715380405,
      "grad_norm": 0.0008912984631024301,
      "learning_rate": 4.606264663344851e-08,
      "loss": 0.0,
      "step": 1748
    },
    {
      "epoch": 0.9573070607553367,
      "grad_norm": 0.02634555846452713,
      "learning_rate": 4.490562199427839e-08,
      "loss": 0.001,
      "step": 1749
    },
    {
      "epoch": 0.9578544061302682,
      "grad_norm": 4.690926551818848,
      "learning_rate": 4.376324859820924e-08,
      "loss": 0.2998,
      "step": 1750
    },
    {
      "epoch": 0.9584017515051998,
      "grad_norm": 2.2932326793670654,
      "learning_rate": 4.2635529823014664e-08,
      "loss": 0.6258,
      "step": 1751
    },
    {
      "epoch": 0.9589490968801314,
      "grad_norm": 0.6182961463928223,
      "learning_rate": 4.1522469003137946e-08,
      "loss": 0.0248,
      "step": 1752
    },
    {
      "epoch": 0.9594964422550629,
      "grad_norm": 1.0007909536361694,
      "learning_rate": 4.0424069429682024e-08,
      "loss": 0.1749,
      "step": 1753
    },
    {
      "epoch": 0.9600437876299945,
      "grad_norm": 0.002399125136435032,
      "learning_rate": 3.9340334350399525e-08,
      "loss": 0.0001,
      "step": 1754
    },
    {
      "epoch": 0.9605911330049262,
      "grad_norm": 0.0005782158696092665,
      "learning_rate": 3.82712669696822e-08,
      "loss": 0.0,
      "step": 1755
    },
    {
      "epoch": 0.9611384783798577,
      "grad_norm": 1.5702521800994873,
      "learning_rate": 3.721687044855315e-08,
      "loss": 0.055,
      "step": 1756
    },
    {
      "epoch": 0.9616858237547893,
      "grad_norm": 0.06594853103160858,
      "learning_rate": 3.617714790465576e-08,
      "loss": 0.0031,
      "step": 1757
    },
    {
      "epoch": 0.9622331691297209,
      "grad_norm": 3.024033546447754,
      "learning_rate": 3.515210241224698e-08,
      "loss": 0.4646,
      "step": 1758
    },
    {
      "epoch": 0.9627805145046524,
      "grad_norm": 0.04730607941746712,
      "learning_rate": 3.4141737002184036e-08,
      "loss": 0.0019,
      "step": 1759
    },
    {
      "epoch": 0.963327859879584,
      "grad_norm": 0.03040263056755066,
      "learning_rate": 3.3146054661920556e-08,
      "loss": 0.0019,
      "step": 1760
    },
    {
      "epoch": 0.9638752052545156,
      "grad_norm": 0.07518827170133591,
      "learning_rate": 3.216505833549377e-08,
      "loss": 0.0033,
      "step": 1761
    },
    {
      "epoch": 0.9644225506294472,
      "grad_norm": 0.038722746074199677,
      "learning_rate": 3.1198750923517316e-08,
      "loss": 0.0022,
      "step": 1762
    },
    {
      "epoch": 0.9649698960043788,
      "grad_norm": 0.003773486241698265,
      "learning_rate": 3.0247135283172914e-08,
      "loss": 0.0002,
      "step": 1763
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.0022057429887354374,
      "learning_rate": 2.9310214228202016e-08,
      "loss": 0.0001,
      "step": 1764
    },
    {
      "epoch": 0.9660645867542419,
      "grad_norm": 0.06985051184892654,
      "learning_rate": 2.8387990528896404e-08,
      "loss": 0.0031,
      "step": 1765
    },
    {
      "epoch": 0.9666119321291735,
      "grad_norm": 0.00789449829608202,
      "learning_rate": 2.7480466912090386e-08,
      "loss": 0.0005,
      "step": 1766
    },
    {
      "epoch": 0.9671592775041051,
      "grad_norm": 0.018482856452465057,
      "learning_rate": 2.6587646061153604e-08,
      "loss": 0.0009,
      "step": 1767
    },
    {
      "epoch": 0.9677066228790366,
      "grad_norm": 0.07023067027330399,
      "learning_rate": 2.5709530615983246e-08,
      "loss": 0.0039,
      "step": 1768
    },
    {
      "epoch": 0.9682539682539683,
      "grad_norm": 0.011661780066788197,
      "learning_rate": 2.4846123172992953e-08,
      "loss": 0.0006,
      "step": 1769
    },
    {
      "epoch": 0.9688013136288999,
      "grad_norm": 0.4181528091430664,
      "learning_rate": 2.3997426285110592e-08,
      "loss": 0.0277,
      "step": 1770
    },
    {
      "epoch": 0.9693486590038314,
      "grad_norm": 0.017250986769795418,
      "learning_rate": 2.3163442461766604e-08,
      "loss": 0.001,
      "step": 1771
    },
    {
      "epoch": 0.969896004378763,
      "grad_norm": 0.004024025518447161,
      "learning_rate": 2.2344174168887346e-08,
      "loss": 0.0002,
      "step": 1772
    },
    {
      "epoch": 0.9704433497536946,
      "grad_norm": 0.00603523338213563,
      "learning_rate": 2.153962382888841e-08,
      "loss": 0.0004,
      "step": 1773
    },
    {
      "epoch": 0.9709906951286261,
      "grad_norm": 1.8922260999679565,
      "learning_rate": 2.0749793820667995e-08,
      "loss": 0.2578,
      "step": 1774
    },
    {
      "epoch": 0.9715380405035577,
      "grad_norm": 0.006764622870832682,
      "learning_rate": 1.9974686479597993e-08,
      "loss": 0.0004,
      "step": 1775
    },
    {
      "epoch": 0.9720853858784894,
      "grad_norm": 0.03476600721478462,
      "learning_rate": 1.921430409752012e-08,
      "loss": 0.0015,
      "step": 1776
    },
    {
      "epoch": 0.9726327312534209,
      "grad_norm": 0.004455631133168936,
      "learning_rate": 1.846864892273481e-08,
      "loss": 0.0002,
      "step": 1777
    },
    {
      "epoch": 0.9731800766283525,
      "grad_norm": 0.09583649039268494,
      "learning_rate": 1.7737723159999e-08,
      "loss": 0.0043,
      "step": 1778
    },
    {
      "epoch": 0.9737274220032841,
      "grad_norm": 0.1666216254234314,
      "learning_rate": 1.702152897051612e-08,
      "loss": 0.0085,
      "step": 1779
    },
    {
      "epoch": 0.9742747673782156,
      "grad_norm": 0.0008875175262801349,
      "learning_rate": 1.632006847193335e-08,
      "loss": 0.0,
      "step": 1780
    },
    {
      "epoch": 0.9748221127531472,
      "grad_norm": 0.00766382971778512,
      "learning_rate": 1.563334373833103e-08,
      "loss": 0.0005,
      "step": 1781
    },
    {
      "epoch": 0.9753694581280788,
      "grad_norm": 0.2941034436225891,
      "learning_rate": 1.496135680021993e-08,
      "loss": 0.0192,
      "step": 1782
    },
    {
      "epoch": 0.9759168035030104,
      "grad_norm": 0.004084579646587372,
      "learning_rate": 1.4304109644533438e-08,
      "loss": 0.0002,
      "step": 1783
    },
    {
      "epoch": 0.976464148877942,
      "grad_norm": 0.0003124140202999115,
      "learning_rate": 1.3661604214623147e-08,
      "loss": 0.0,
      "step": 1784
    },
    {
      "epoch": 0.9770114942528736,
      "grad_norm": 0.0011423639953136444,
      "learning_rate": 1.3033842410251074e-08,
      "loss": 0.0001,
      "step": 1785
    },
    {
      "epoch": 0.9775588396278051,
      "grad_norm": 2.3095178604125977,
      "learning_rate": 1.2420826087586324e-08,
      "loss": 0.4399,
      "step": 1786
    },
    {
      "epoch": 0.9781061850027367,
      "grad_norm": 0.008070394396781921,
      "learning_rate": 1.182255705919788e-08,
      "loss": 0.0005,
      "step": 1787
    },
    {
      "epoch": 0.9786535303776683,
      "grad_norm": 0.002078648889437318,
      "learning_rate": 1.123903709404961e-08,
      "loss": 0.0001,
      "step": 1788
    },
    {
      "epoch": 0.9792008757525998,
      "grad_norm": 1.312968373298645,
      "learning_rate": 1.0670267917496923e-08,
      "loss": 0.2967,
      "step": 1789
    },
    {
      "epoch": 0.9797482211275315,
      "grad_norm": 0.04433206096291542,
      "learning_rate": 1.011625121127735e-08,
      "loss": 0.0031,
      "step": 1790
    },
    {
      "epoch": 0.9802955665024631,
      "grad_norm": 0.057536352425813675,
      "learning_rate": 9.576988613511084e-09,
      "loss": 0.0029,
      "step": 1791
    },
    {
      "epoch": 0.9808429118773946,
      "grad_norm": 0.010305561125278473,
      "learning_rate": 9.052481718690998e-09,
      "loss": 0.0004,
      "step": 1792
    },
    {
      "epoch": 0.9813902572523262,
      "grad_norm": 0.037875037640333176,
      "learning_rate": 8.542732077680971e-09,
      "loss": 0.0014,
      "step": 1793
    },
    {
      "epoch": 0.9819376026272578,
      "grad_norm": 0.0032763571944087744,
      "learning_rate": 8.04774119771201e-09,
      "loss": 0.0001,
      "step": 1794
    },
    {
      "epoch": 0.9824849480021893,
      "grad_norm": 0.000763208547141403,
      "learning_rate": 7.567510542373923e-09,
      "loss": 0.0,
      "step": 1795
    },
    {
      "epoch": 0.983032293377121,
      "grad_norm": 0.4320652186870575,
      "learning_rate": 7.102041531615867e-09,
      "loss": 0.0187,
      "step": 1796
    },
    {
      "epoch": 0.9835796387520526,
      "grad_norm": 0.0013821965549141169,
      "learning_rate": 6.65133554173747e-09,
      "loss": 0.0001,
      "step": 1797
    },
    {
      "epoch": 0.9841269841269841,
      "grad_norm": 0.03630411624908447,
      "learning_rate": 6.215393905388278e-09,
      "loss": 0.0022,
      "step": 1798
    },
    {
      "epoch": 0.9846743295019157,
      "grad_norm": 0.012762166559696198,
      "learning_rate": 5.794217911562205e-09,
      "loss": 0.0006,
      "step": 1799
    },
    {
      "epoch": 0.9852216748768473,
      "grad_norm": 0.08867999166250229,
      "learning_rate": 5.387808805594752e-09,
      "loss": 0.0039,
      "step": 1800
    },
    {
      "epoch": 0.9857690202517789,
      "grad_norm": 0.3025924265384674,
      "learning_rate": 4.996167789157457e-09,
      "loss": 0.0127,
      "step": 1801
    },
    {
      "epoch": 0.9863163656267104,
      "grad_norm": 1.7675840854644775,
      "learning_rate": 4.619296020256236e-09,
      "loss": 0.435,
      "step": 1802
    },
    {
      "epoch": 0.986863711001642,
      "grad_norm": 0.0012528208317235112,
      "learning_rate": 4.257194613226379e-09,
      "loss": 0.0,
      "step": 1803
    },
    {
      "epoch": 0.9874110563765737,
      "grad_norm": 0.003161042695865035,
      "learning_rate": 3.9098646387319974e-09,
      "loss": 0.0001,
      "step": 1804
    },
    {
      "epoch": 0.9879584017515052,
      "grad_norm": 0.03328360989689827,
      "learning_rate": 3.577307123759366e-09,
      "loss": 0.0016,
      "step": 1805
    },
    {
      "epoch": 0.9885057471264368,
      "grad_norm": 0.005455352831631899,
      "learning_rate": 3.2595230516152543e-09,
      "loss": 0.0003,
      "step": 1806
    },
    {
      "epoch": 0.9890530925013684,
      "grad_norm": 8.356744766235352,
      "learning_rate": 2.956513361925262e-09,
      "loss": 0.1842,
      "step": 1807
    },
    {
      "epoch": 0.9896004378762999,
      "grad_norm": 0.22174571454524994,
      "learning_rate": 2.6682789506299322e-09,
      "loss": 0.0114,
      "step": 1808
    },
    {
      "epoch": 0.9901477832512315,
      "grad_norm": 0.002981710247695446,
      "learning_rate": 2.3948206699819787e-09,
      "loss": 0.0001,
      "step": 1809
    },
    {
      "epoch": 0.9906951286261632,
      "grad_norm": 0.020548971369862556,
      "learning_rate": 2.136139328543507e-09,
      "loss": 0.0008,
      "step": 1810
    },
    {
      "epoch": 0.9912424740010947,
      "grad_norm": 0.004353484604507685,
      "learning_rate": 1.892235691184907e-09,
      "loss": 0.0001,
      "step": 1811
    },
    {
      "epoch": 0.9917898193760263,
      "grad_norm": 0.0005210565286688507,
      "learning_rate": 1.6631104790809648e-09,
      "loss": 0.0,
      "step": 1812
    },
    {
      "epoch": 0.9923371647509579,
      "grad_norm": 0.0539797767996788,
      "learning_rate": 1.4487643697103092e-09,
      "loss": 0.0028,
      "step": 1813
    },
    {
      "epoch": 0.9928845101258894,
      "grad_norm": 0.022561270743608475,
      "learning_rate": 1.2491979968526358e-09,
      "loss": 0.0012,
      "step": 1814
    },
    {
      "epoch": 0.993431855500821,
      "grad_norm": 0.02872794307768345,
      "learning_rate": 1.0644119505864858e-09,
      "loss": 0.001,
      "step": 1815
    },
    {
      "epoch": 0.9939792008757526,
      "grad_norm": 0.0006542292539961636,
      "learning_rate": 8.944067772881371e-10,
      "loss": 0.0,
      "step": 1816
    },
    {
      "epoch": 0.9945265462506842,
      "grad_norm": 0.05100705847144127,
      "learning_rate": 7.391829796288275e-10,
      "loss": 0.0031,
      "step": 1817
    },
    {
      "epoch": 0.9950738916256158,
      "grad_norm": 0.0012361514382064342,
      "learning_rate": 5.987410165758656e-10,
      "loss": 0.0001,
      "step": 1818
    },
    {
      "epoch": 0.9956212370005474,
      "grad_norm": 0.036499034613370895,
      "learning_rate": 4.730813033881898e-10,
      "loss": 0.0017,
      "step": 1819
    },
    {
      "epoch": 0.9961685823754789,
      "grad_norm": 0.010170308873057365,
      "learning_rate": 3.6220421161692333e-10,
      "loss": 0.0008,
      "step": 1820
    },
    {
      "epoch": 0.9967159277504105,
      "grad_norm": 0.02347932569682598,
      "learning_rate": 2.6611006910370884e-10,
      "loss": 0.0013,
      "step": 1821
    },
    {
      "epoch": 0.9972632731253421,
      "grad_norm": 0.37275564670562744,
      "learning_rate": 1.847991599801535e-10,
      "loss": 0.0164,
      "step": 1822
    },
    {
      "epoch": 0.9978106185002736,
      "grad_norm": 0.1017678752541542,
      "learning_rate": 1.1827172466727376e-10,
      "loss": 0.0044,
      "step": 1823
    },
    {
      "epoch": 0.9983579638752053,
      "grad_norm": 0.005166756454855204,
      "learning_rate": 6.652795987271975e-11,
      "loss": 0.0003,
      "step": 1824
    },
    {
      "epoch": 0.9989053092501369,
      "grad_norm": 0.00460553914308548,
      "learning_rate": 2.9568018593550965e-11,
      "loss": 0.0002,
      "step": 1825
    },
    {
      "epoch": 0.9994526546250684,
      "grad_norm": 0.9095092415809631,
      "learning_rate": 7.392010112350356e-12,
      "loss": 0.0584,
      "step": 1826
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.01001779641956091,
      "learning_rate": 0.0,
      "loss": 0.0004,
      "step": 1827
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4950980392156863,
      "eval_loss": 0.03592957556247711,
      "eval_runtime": 1062.8351,
      "eval_samples_per_second": 0.192,
      "eval_steps_per_second": 0.192,
      "step": 1827
    }
  ],
  "logging_steps": 1,
  "max_steps": 1827,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.437810384269312e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
