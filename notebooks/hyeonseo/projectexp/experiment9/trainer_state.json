{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 914,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002188183807439825,
      "grad_norm": 21.92169952392578,
      "learning_rate": 1.0869565217391305e-07,
      "loss": 4.23,
      "step": 1
    },
    {
      "epoch": 0.00437636761487965,
      "grad_norm": 26.026044845581055,
      "learning_rate": 2.173913043478261e-07,
      "loss": 4.3188,
      "step": 2
    },
    {
      "epoch": 0.006564551422319475,
      "grad_norm": 23.51215934753418,
      "learning_rate": 3.2608695652173915e-07,
      "loss": 4.4454,
      "step": 3
    },
    {
      "epoch": 0.0087527352297593,
      "grad_norm": 23.570011138916016,
      "learning_rate": 4.347826086956522e-07,
      "loss": 4.7674,
      "step": 4
    },
    {
      "epoch": 0.010940919037199124,
      "grad_norm": 21.65768051147461,
      "learning_rate": 5.434782608695653e-07,
      "loss": 4.3347,
      "step": 5
    },
    {
      "epoch": 0.01312910284463895,
      "grad_norm": 25.191184997558594,
      "learning_rate": 6.521739130434783e-07,
      "loss": 4.3871,
      "step": 6
    },
    {
      "epoch": 0.015317286652078774,
      "grad_norm": 29.510009765625,
      "learning_rate": 7.608695652173914e-07,
      "loss": 4.3269,
      "step": 7
    },
    {
      "epoch": 0.0175054704595186,
      "grad_norm": 26.61124610900879,
      "learning_rate": 8.695652173913044e-07,
      "loss": 4.2808,
      "step": 8
    },
    {
      "epoch": 0.019693654266958426,
      "grad_norm": 28.173067092895508,
      "learning_rate": 9.782608695652175e-07,
      "loss": 3.9001,
      "step": 9
    },
    {
      "epoch": 0.02188183807439825,
      "grad_norm": 24.299726486206055,
      "learning_rate": 1.0869565217391306e-06,
      "loss": 3.8161,
      "step": 10
    },
    {
      "epoch": 0.024070021881838075,
      "grad_norm": 24.23542022705078,
      "learning_rate": 1.1956521739130436e-06,
      "loss": 3.6201,
      "step": 11
    },
    {
      "epoch": 0.0262582056892779,
      "grad_norm": 25.652372360229492,
      "learning_rate": 1.3043478260869566e-06,
      "loss": 3.633,
      "step": 12
    },
    {
      "epoch": 0.028446389496717725,
      "grad_norm": 30.208736419677734,
      "learning_rate": 1.4130434782608697e-06,
      "loss": 3.7734,
      "step": 13
    },
    {
      "epoch": 0.030634573304157548,
      "grad_norm": 28.77434730529785,
      "learning_rate": 1.521739130434783e-06,
      "loss": 3.9839,
      "step": 14
    },
    {
      "epoch": 0.03282275711159737,
      "grad_norm": 37.542110443115234,
      "learning_rate": 1.6304347826086957e-06,
      "loss": 3.4631,
      "step": 15
    },
    {
      "epoch": 0.0350109409190372,
      "grad_norm": 29.25891876220703,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 2.805,
      "step": 16
    },
    {
      "epoch": 0.037199124726477024,
      "grad_norm": 24.443220138549805,
      "learning_rate": 1.8478260869565218e-06,
      "loss": 3.1836,
      "step": 17
    },
    {
      "epoch": 0.03938730853391685,
      "grad_norm": 28.21834373474121,
      "learning_rate": 1.956521739130435e-06,
      "loss": 2.83,
      "step": 18
    },
    {
      "epoch": 0.04157549234135667,
      "grad_norm": 25.189159393310547,
      "learning_rate": 2.065217391304348e-06,
      "loss": 1.7317,
      "step": 19
    },
    {
      "epoch": 0.0437636761487965,
      "grad_norm": 18.42010498046875,
      "learning_rate": 2.173913043478261e-06,
      "loss": 2.2329,
      "step": 20
    },
    {
      "epoch": 0.045951859956236324,
      "grad_norm": 19.25421905517578,
      "learning_rate": 2.282608695652174e-06,
      "loss": 1.4282,
      "step": 21
    },
    {
      "epoch": 0.04814004376367615,
      "grad_norm": 18.170705795288086,
      "learning_rate": 2.391304347826087e-06,
      "loss": 1.2439,
      "step": 22
    },
    {
      "epoch": 0.05032822757111598,
      "grad_norm": 15.09523868560791,
      "learning_rate": 2.5e-06,
      "loss": 1.7597,
      "step": 23
    },
    {
      "epoch": 0.0525164113785558,
      "grad_norm": 13.439866065979004,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 1.2792,
      "step": 24
    },
    {
      "epoch": 0.05470459518599562,
      "grad_norm": 12.3915376663208,
      "learning_rate": 2.7173913043478263e-06,
      "loss": 0.8122,
      "step": 25
    },
    {
      "epoch": 0.05689277899343545,
      "grad_norm": 11.340263366699219,
      "learning_rate": 2.8260869565217393e-06,
      "loss": 0.8843,
      "step": 26
    },
    {
      "epoch": 0.05908096280087528,
      "grad_norm": 14.174553871154785,
      "learning_rate": 2.9347826086956528e-06,
      "loss": 0.8225,
      "step": 27
    },
    {
      "epoch": 0.061269146608315096,
      "grad_norm": 12.220551490783691,
      "learning_rate": 3.043478260869566e-06,
      "loss": 0.7445,
      "step": 28
    },
    {
      "epoch": 0.06345733041575492,
      "grad_norm": 11.536544799804688,
      "learning_rate": 3.152173913043479e-06,
      "loss": 0.8399,
      "step": 29
    },
    {
      "epoch": 0.06564551422319474,
      "grad_norm": 8.447307586669922,
      "learning_rate": 3.2608695652173914e-06,
      "loss": 0.324,
      "step": 30
    },
    {
      "epoch": 0.06783369803063458,
      "grad_norm": 7.784756660461426,
      "learning_rate": 3.3695652173913045e-06,
      "loss": 0.403,
      "step": 31
    },
    {
      "epoch": 0.0700218818380744,
      "grad_norm": 7.731598377227783,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.2715,
      "step": 32
    },
    {
      "epoch": 0.07221006564551423,
      "grad_norm": 2.521393299102783,
      "learning_rate": 3.5869565217391305e-06,
      "loss": 0.0793,
      "step": 33
    },
    {
      "epoch": 0.07439824945295405,
      "grad_norm": 4.356139183044434,
      "learning_rate": 3.6956521739130436e-06,
      "loss": 0.1297,
      "step": 34
    },
    {
      "epoch": 0.07658643326039387,
      "grad_norm": 7.290046215057373,
      "learning_rate": 3.804347826086957e-06,
      "loss": 0.7816,
      "step": 35
    },
    {
      "epoch": 0.0787746170678337,
      "grad_norm": 4.509263515472412,
      "learning_rate": 3.91304347826087e-06,
      "loss": 0.1902,
      "step": 36
    },
    {
      "epoch": 0.08096280087527352,
      "grad_norm": 4.0476884841918945,
      "learning_rate": 4.021739130434783e-06,
      "loss": 0.094,
      "step": 37
    },
    {
      "epoch": 0.08315098468271334,
      "grad_norm": 0.1850305050611496,
      "learning_rate": 4.130434782608696e-06,
      "loss": 0.0053,
      "step": 38
    },
    {
      "epoch": 0.08533916849015317,
      "grad_norm": 0.7134180068969727,
      "learning_rate": 4.239130434782609e-06,
      "loss": 0.0118,
      "step": 39
    },
    {
      "epoch": 0.087527352297593,
      "grad_norm": 3.846184253692627,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.4469,
      "step": 40
    },
    {
      "epoch": 0.08971553610503283,
      "grad_norm": 3.582517623901367,
      "learning_rate": 4.456521739130435e-06,
      "loss": 0.0058,
      "step": 41
    },
    {
      "epoch": 0.09190371991247265,
      "grad_norm": 0.02784961834549904,
      "learning_rate": 4.565217391304348e-06,
      "loss": 0.0007,
      "step": 42
    },
    {
      "epoch": 0.09409190371991247,
      "grad_norm": 4.695168495178223,
      "learning_rate": 4.673913043478261e-06,
      "loss": 0.1076,
      "step": 43
    },
    {
      "epoch": 0.0962800875273523,
      "grad_norm": 8.55430793762207,
      "learning_rate": 4.782608695652174e-06,
      "loss": 0.219,
      "step": 44
    },
    {
      "epoch": 0.09846827133479212,
      "grad_norm": 0.02668142132461071,
      "learning_rate": 4.891304347826087e-06,
      "loss": 0.0003,
      "step": 45
    },
    {
      "epoch": 0.10065645514223195,
      "grad_norm": 1.1315202713012695,
      "learning_rate": 5e-06,
      "loss": 0.0179,
      "step": 46
    },
    {
      "epoch": 0.10284463894967177,
      "grad_norm": 6.05073356628418,
      "learning_rate": 5.108695652173914e-06,
      "loss": 0.0283,
      "step": 47
    },
    {
      "epoch": 0.1050328227571116,
      "grad_norm": 0.02583625540137291,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.0006,
      "step": 48
    },
    {
      "epoch": 0.10722100656455143,
      "grad_norm": 0.00762923713773489,
      "learning_rate": 5.3260869565217395e-06,
      "loss": 0.0003,
      "step": 49
    },
    {
      "epoch": 0.10940919037199125,
      "grad_norm": 3.0636379718780518,
      "learning_rate": 5.4347826086956525e-06,
      "loss": 0.1377,
      "step": 50
    },
    {
      "epoch": 0.11159737417943107,
      "grad_norm": 0.008876768872141838,
      "learning_rate": 5.543478260869566e-06,
      "loss": 0.0003,
      "step": 51
    },
    {
      "epoch": 0.1137855579868709,
      "grad_norm": 1.1159427165985107,
      "learning_rate": 5.652173913043479e-06,
      "loss": 0.008,
      "step": 52
    },
    {
      "epoch": 0.11597374179431072,
      "grad_norm": 5.815639019012451,
      "learning_rate": 5.760869565217392e-06,
      "loss": 0.0304,
      "step": 53
    },
    {
      "epoch": 0.11816192560175055,
      "grad_norm": 5.290447235107422,
      "learning_rate": 5.8695652173913055e-06,
      "loss": 0.2619,
      "step": 54
    },
    {
      "epoch": 0.12035010940919037,
      "grad_norm": 4.20110559463501,
      "learning_rate": 5.978260869565218e-06,
      "loss": 0.1499,
      "step": 55
    },
    {
      "epoch": 0.12253829321663019,
      "grad_norm": 4.0314202308654785,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.2574,
      "step": 56
    },
    {
      "epoch": 0.12472647702407003,
      "grad_norm": 1.4957077503204346,
      "learning_rate": 6.195652173913044e-06,
      "loss": 0.0234,
      "step": 57
    },
    {
      "epoch": 0.12691466083150985,
      "grad_norm": 6.073808193206787,
      "learning_rate": 6.304347826086958e-06,
      "loss": 0.4651,
      "step": 58
    },
    {
      "epoch": 0.12910284463894967,
      "grad_norm": 3.75553560256958,
      "learning_rate": 6.41304347826087e-06,
      "loss": 0.2945,
      "step": 59
    },
    {
      "epoch": 0.13129102844638948,
      "grad_norm": 2.4902987480163574,
      "learning_rate": 6.521739130434783e-06,
      "loss": 0.2868,
      "step": 60
    },
    {
      "epoch": 0.13347921225382933,
      "grad_norm": 3.71418833732605,
      "learning_rate": 6.630434782608696e-06,
      "loss": 0.2579,
      "step": 61
    },
    {
      "epoch": 0.13566739606126915,
      "grad_norm": 0.03424016758799553,
      "learning_rate": 6.739130434782609e-06,
      "loss": 0.0007,
      "step": 62
    },
    {
      "epoch": 0.13785557986870897,
      "grad_norm": 2.8738279342651367,
      "learning_rate": 6.847826086956523e-06,
      "loss": 0.2375,
      "step": 63
    },
    {
      "epoch": 0.1400437636761488,
      "grad_norm": 3.712216377258301,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.0981,
      "step": 64
    },
    {
      "epoch": 0.1422319474835886,
      "grad_norm": 0.948320746421814,
      "learning_rate": 7.065217391304349e-06,
      "loss": 0.0241,
      "step": 65
    },
    {
      "epoch": 0.14442013129102846,
      "grad_norm": 3.3651909828186035,
      "learning_rate": 7.173913043478261e-06,
      "loss": 0.3171,
      "step": 66
    },
    {
      "epoch": 0.14660831509846828,
      "grad_norm": 1.713239312171936,
      "learning_rate": 7.282608695652175e-06,
      "loss": 0.0434,
      "step": 67
    },
    {
      "epoch": 0.1487964989059081,
      "grad_norm": 0.2164396345615387,
      "learning_rate": 7.391304347826087e-06,
      "loss": 0.0063,
      "step": 68
    },
    {
      "epoch": 0.15098468271334792,
      "grad_norm": 0.29880690574645996,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0072,
      "step": 69
    },
    {
      "epoch": 0.15317286652078774,
      "grad_norm": 0.16391891241073608,
      "learning_rate": 7.608695652173914e-06,
      "loss": 0.0059,
      "step": 70
    },
    {
      "epoch": 0.15536105032822758,
      "grad_norm": 3.569581985473633,
      "learning_rate": 7.717391304347827e-06,
      "loss": 0.1553,
      "step": 71
    },
    {
      "epoch": 0.1575492341356674,
      "grad_norm": 2.129352569580078,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.1226,
      "step": 72
    },
    {
      "epoch": 0.15973741794310722,
      "grad_norm": 0.2839913070201874,
      "learning_rate": 7.934782608695653e-06,
      "loss": 0.0091,
      "step": 73
    },
    {
      "epoch": 0.16192560175054704,
      "grad_norm": 0.5524371266365051,
      "learning_rate": 8.043478260869566e-06,
      "loss": 0.0188,
      "step": 74
    },
    {
      "epoch": 0.16411378555798686,
      "grad_norm": 0.3273867070674896,
      "learning_rate": 8.15217391304348e-06,
      "loss": 0.0102,
      "step": 75
    },
    {
      "epoch": 0.16630196936542668,
      "grad_norm": 1.1167811155319214,
      "learning_rate": 8.260869565217392e-06,
      "loss": 0.0229,
      "step": 76
    },
    {
      "epoch": 0.16849015317286653,
      "grad_norm": 0.3959013819694519,
      "learning_rate": 8.369565217391305e-06,
      "loss": 0.0135,
      "step": 77
    },
    {
      "epoch": 0.17067833698030635,
      "grad_norm": 0.3263627886772156,
      "learning_rate": 8.478260869565218e-06,
      "loss": 0.0129,
      "step": 78
    },
    {
      "epoch": 0.17286652078774617,
      "grad_norm": 0.2119074910879135,
      "learning_rate": 8.586956521739131e-06,
      "loss": 0.0079,
      "step": 79
    },
    {
      "epoch": 0.175054704595186,
      "grad_norm": 0.9144782423973083,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0792,
      "step": 80
    },
    {
      "epoch": 0.1772428884026258,
      "grad_norm": 0.07093604654073715,
      "learning_rate": 8.804347826086957e-06,
      "loss": 0.0025,
      "step": 81
    },
    {
      "epoch": 0.17943107221006566,
      "grad_norm": 0.8022505640983582,
      "learning_rate": 8.91304347826087e-06,
      "loss": 0.0112,
      "step": 82
    },
    {
      "epoch": 0.18161925601750548,
      "grad_norm": 0.145287424325943,
      "learning_rate": 9.021739130434784e-06,
      "loss": 0.0045,
      "step": 83
    },
    {
      "epoch": 0.1838074398249453,
      "grad_norm": 1.6540549993515015,
      "learning_rate": 9.130434782608697e-06,
      "loss": 0.2173,
      "step": 84
    },
    {
      "epoch": 0.18599562363238512,
      "grad_norm": 1.604325771331787,
      "learning_rate": 9.23913043478261e-06,
      "loss": 0.1706,
      "step": 85
    },
    {
      "epoch": 0.18818380743982493,
      "grad_norm": 3.446460008621216,
      "learning_rate": 9.347826086956523e-06,
      "loss": 0.1711,
      "step": 86
    },
    {
      "epoch": 0.19037199124726478,
      "grad_norm": 2.3221254348754883,
      "learning_rate": 9.456521739130436e-06,
      "loss": 0.0612,
      "step": 87
    },
    {
      "epoch": 0.1925601750547046,
      "grad_norm": 0.09616374224424362,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0028,
      "step": 88
    },
    {
      "epoch": 0.19474835886214442,
      "grad_norm": 0.8513073325157166,
      "learning_rate": 9.673913043478262e-06,
      "loss": 0.0951,
      "step": 89
    },
    {
      "epoch": 0.19693654266958424,
      "grad_norm": 1.975714921951294,
      "learning_rate": 9.782608695652175e-06,
      "loss": 0.06,
      "step": 90
    },
    {
      "epoch": 0.19912472647702406,
      "grad_norm": 0.0585392601788044,
      "learning_rate": 9.891304347826088e-06,
      "loss": 0.0017,
      "step": 91
    },
    {
      "epoch": 0.2013129102844639,
      "grad_norm": 3.32110333442688,
      "learning_rate": 1e-05,
      "loss": 0.1381,
      "step": 92
    },
    {
      "epoch": 0.20350109409190373,
      "grad_norm": 7.79399299621582,
      "learning_rate": 9.999963482958057e-06,
      "loss": 0.1218,
      "step": 93
    },
    {
      "epoch": 0.20568927789934355,
      "grad_norm": 0.09784691035747528,
      "learning_rate": 9.999853932365623e-06,
      "loss": 0.0036,
      "step": 94
    },
    {
      "epoch": 0.20787746170678337,
      "grad_norm": 0.8106443881988525,
      "learning_rate": 9.999671349822887e-06,
      "loss": 0.0218,
      "step": 95
    },
    {
      "epoch": 0.2100656455142232,
      "grad_norm": 0.26211073994636536,
      "learning_rate": 9.999415737996795e-06,
      "loss": 0.0082,
      "step": 96
    },
    {
      "epoch": 0.212253829321663,
      "grad_norm": 0.07968001067638397,
      "learning_rate": 9.999087100621024e-06,
      "loss": 0.0023,
      "step": 97
    },
    {
      "epoch": 0.21444201312910285,
      "grad_norm": 1.669019341468811,
      "learning_rate": 9.998685442495921e-06,
      "loss": 0.1066,
      "step": 98
    },
    {
      "epoch": 0.21663019693654267,
      "grad_norm": 2.091339588165283,
      "learning_rate": 9.99821076948843e-06,
      "loss": 0.1313,
      "step": 99
    },
    {
      "epoch": 0.2188183807439825,
      "grad_norm": 0.7443447113037109,
      "learning_rate": 9.997663088532015e-06,
      "loss": 0.015,
      "step": 100
    },
    {
      "epoch": 0.2210065645514223,
      "grad_norm": 4.857107639312744,
      "learning_rate": 9.99704240762655e-06,
      "loss": 0.0896,
      "step": 101
    },
    {
      "epoch": 0.22319474835886213,
      "grad_norm": 1.5962547063827515,
      "learning_rate": 9.996348735838207e-06,
      "loss": 0.0905,
      "step": 102
    },
    {
      "epoch": 0.22538293216630198,
      "grad_norm": 1.827211618423462,
      "learning_rate": 9.995582083299323e-06,
      "loss": 0.0252,
      "step": 103
    },
    {
      "epoch": 0.2275711159737418,
      "grad_norm": 0.30125245451927185,
      "learning_rate": 9.994742461208251e-06,
      "loss": 0.0113,
      "step": 104
    },
    {
      "epoch": 0.22975929978118162,
      "grad_norm": 0.7719400525093079,
      "learning_rate": 9.9938298818292e-06,
      "loss": 0.0191,
      "step": 105
    },
    {
      "epoch": 0.23194748358862144,
      "grad_norm": 4.972741603851318,
      "learning_rate": 9.992844358492045e-06,
      "loss": 0.2713,
      "step": 106
    },
    {
      "epoch": 0.23413566739606126,
      "grad_norm": 0.6459964513778687,
      "learning_rate": 9.991785905592149e-06,
      "loss": 0.0176,
      "step": 107
    },
    {
      "epoch": 0.2363238512035011,
      "grad_norm": 0.10298965871334076,
      "learning_rate": 9.990654538590136e-06,
      "loss": 0.0044,
      "step": 108
    },
    {
      "epoch": 0.23851203501094093,
      "grad_norm": 1.7044460773468018,
      "learning_rate": 9.98945027401168e-06,
      "loss": 0.0176,
      "step": 109
    },
    {
      "epoch": 0.24070021881838075,
      "grad_norm": 1.6271607875823975,
      "learning_rate": 9.988173129447251e-06,
      "loss": 0.0215,
      "step": 110
    },
    {
      "epoch": 0.24288840262582057,
      "grad_norm": 0.009151516482234001,
      "learning_rate": 9.986823123551865e-06,
      "loss": 0.0004,
      "step": 111
    },
    {
      "epoch": 0.24507658643326038,
      "grad_norm": 5.363443851470947,
      "learning_rate": 9.985400276044811e-06,
      "loss": 0.047,
      "step": 112
    },
    {
      "epoch": 0.24726477024070023,
      "grad_norm": 4.495186805725098,
      "learning_rate": 9.983904607709365e-06,
      "loss": 0.0816,
      "step": 113
    },
    {
      "epoch": 0.24945295404814005,
      "grad_norm": 0.1768520027399063,
      "learning_rate": 9.982336140392476e-06,
      "loss": 0.0048,
      "step": 114
    },
    {
      "epoch": 0.25164113785557984,
      "grad_norm": 0.09187545627355576,
      "learning_rate": 9.980694897004462e-06,
      "loss": 0.0028,
      "step": 115
    },
    {
      "epoch": 0.2538293216630197,
      "grad_norm": 0.015799526125192642,
      "learning_rate": 9.978980901518663e-06,
      "loss": 0.0006,
      "step": 116
    },
    {
      "epoch": 0.25601750547045954,
      "grad_norm": 1.5121122598648071,
      "learning_rate": 9.977194178971098e-06,
      "loss": 0.196,
      "step": 117
    },
    {
      "epoch": 0.25820568927789933,
      "grad_norm": 1.6397640705108643,
      "learning_rate": 9.975334755460092e-06,
      "loss": 0.0999,
      "step": 118
    },
    {
      "epoch": 0.2603938730853392,
      "grad_norm": 1.7495745420455933,
      "learning_rate": 9.973402658145908e-06,
      "loss": 0.0792,
      "step": 119
    },
    {
      "epoch": 0.26258205689277897,
      "grad_norm": 0.4255240261554718,
      "learning_rate": 9.971397915250336e-06,
      "loss": 0.0072,
      "step": 120
    },
    {
      "epoch": 0.2647702407002188,
      "grad_norm": 1.6011850833892822,
      "learning_rate": 9.969320556056287e-06,
      "loss": 0.1838,
      "step": 121
    },
    {
      "epoch": 0.26695842450765866,
      "grad_norm": 0.14655138552188873,
      "learning_rate": 9.96717061090737e-06,
      "loss": 0.0052,
      "step": 122
    },
    {
      "epoch": 0.26914660831509846,
      "grad_norm": 0.19067755341529846,
      "learning_rate": 9.964948111207435e-06,
      "loss": 0.0085,
      "step": 123
    },
    {
      "epoch": 0.2713347921225383,
      "grad_norm": 1.255624532699585,
      "learning_rate": 9.962653089420132e-06,
      "loss": 0.1059,
      "step": 124
    },
    {
      "epoch": 0.2735229759299781,
      "grad_norm": 0.021253552287817,
      "learning_rate": 9.960285579068419e-06,
      "loss": 0.001,
      "step": 125
    },
    {
      "epoch": 0.27571115973741794,
      "grad_norm": 2.3604700565338135,
      "learning_rate": 9.95784561473409e-06,
      "loss": 0.2022,
      "step": 126
    },
    {
      "epoch": 0.2778993435448578,
      "grad_norm": 2.3471944332122803,
      "learning_rate": 9.955333232057256e-06,
      "loss": 0.0781,
      "step": 127
    },
    {
      "epoch": 0.2800875273522976,
      "grad_norm": 1.601385474205017,
      "learning_rate": 9.95274846773583e-06,
      "loss": 0.1158,
      "step": 128
    },
    {
      "epoch": 0.28227571115973743,
      "grad_norm": 0.45373260974884033,
      "learning_rate": 9.950091359524991e-06,
      "loss": 0.0193,
      "step": 129
    },
    {
      "epoch": 0.2844638949671772,
      "grad_norm": 0.8206059336662292,
      "learning_rate": 9.947361946236632e-06,
      "loss": 0.036,
      "step": 130
    },
    {
      "epoch": 0.28665207877461707,
      "grad_norm": 0.8059540390968323,
      "learning_rate": 9.944560267738792e-06,
      "loss": 0.0842,
      "step": 131
    },
    {
      "epoch": 0.2888402625820569,
      "grad_norm": 0.197442889213562,
      "learning_rate": 9.941686364955077e-06,
      "loss": 0.0089,
      "step": 132
    },
    {
      "epoch": 0.2910284463894967,
      "grad_norm": 0.19427786767482758,
      "learning_rate": 9.938740279864056e-06,
      "loss": 0.0106,
      "step": 133
    },
    {
      "epoch": 0.29321663019693656,
      "grad_norm": 1.2453633546829224,
      "learning_rate": 9.935722055498655e-06,
      "loss": 0.0277,
      "step": 134
    },
    {
      "epoch": 0.29540481400437635,
      "grad_norm": 0.6607263088226318,
      "learning_rate": 9.932631735945527e-06,
      "loss": 0.0817,
      "step": 135
    },
    {
      "epoch": 0.2975929978118162,
      "grad_norm": 1.0865117311477661,
      "learning_rate": 9.929469366344401e-06,
      "loss": 0.1262,
      "step": 136
    },
    {
      "epoch": 0.29978118161925604,
      "grad_norm": 0.3555825352668762,
      "learning_rate": 9.92623499288743e-06,
      "loss": 0.0226,
      "step": 137
    },
    {
      "epoch": 0.30196936542669583,
      "grad_norm": 0.23188722133636475,
      "learning_rate": 9.922928662818515e-06,
      "loss": 0.0128,
      "step": 138
    },
    {
      "epoch": 0.3041575492341357,
      "grad_norm": 1.323904037475586,
      "learning_rate": 9.919550424432615e-06,
      "loss": 0.1633,
      "step": 139
    },
    {
      "epoch": 0.3063457330415755,
      "grad_norm": 1.1618543863296509,
      "learning_rate": 9.916100327075038e-06,
      "loss": 0.1081,
      "step": 140
    },
    {
      "epoch": 0.3085339168490153,
      "grad_norm": 1.970633625984192,
      "learning_rate": 9.912578421140723e-06,
      "loss": 0.1511,
      "step": 141
    },
    {
      "epoch": 0.31072210065645517,
      "grad_norm": 0.7538572549819946,
      "learning_rate": 9.908984758073506e-06,
      "loss": 0.0202,
      "step": 142
    },
    {
      "epoch": 0.31291028446389496,
      "grad_norm": 0.6266758441925049,
      "learning_rate": 9.905319390365364e-06,
      "loss": 0.1434,
      "step": 143
    },
    {
      "epoch": 0.3150984682713348,
      "grad_norm": 0.3137471079826355,
      "learning_rate": 9.901582371555652e-06,
      "loss": 0.0177,
      "step": 144
    },
    {
      "epoch": 0.3172866520787746,
      "grad_norm": 0.14536072313785553,
      "learning_rate": 9.89777375623032e-06,
      "loss": 0.0076,
      "step": 145
    },
    {
      "epoch": 0.31947483588621445,
      "grad_norm": 0.3245254158973694,
      "learning_rate": 9.893893600021112e-06,
      "loss": 0.018,
      "step": 146
    },
    {
      "epoch": 0.32166301969365424,
      "grad_norm": 1.08269202709198,
      "learning_rate": 9.889941959604761e-06,
      "loss": 0.17,
      "step": 147
    },
    {
      "epoch": 0.3238512035010941,
      "grad_norm": 0.09603867679834366,
      "learning_rate": 9.885918892702154e-06,
      "loss": 0.0037,
      "step": 148
    },
    {
      "epoch": 0.32603938730853393,
      "grad_norm": 0.8907763957977295,
      "learning_rate": 9.881824458077491e-06,
      "loss": 0.0617,
      "step": 149
    },
    {
      "epoch": 0.3282275711159737,
      "grad_norm": 0.5579090118408203,
      "learning_rate": 9.877658715537429e-06,
      "loss": 0.1021,
      "step": 150
    },
    {
      "epoch": 0.3304157549234136,
      "grad_norm": 0.23596210777759552,
      "learning_rate": 9.873421725930207e-06,
      "loss": 0.0131,
      "step": 151
    },
    {
      "epoch": 0.33260393873085337,
      "grad_norm": 0.3372742533683777,
      "learning_rate": 9.869113551144754e-06,
      "loss": 0.014,
      "step": 152
    },
    {
      "epoch": 0.3347921225382932,
      "grad_norm": 1.7033387422561646,
      "learning_rate": 9.864734254109793e-06,
      "loss": 0.1733,
      "step": 153
    },
    {
      "epoch": 0.33698030634573306,
      "grad_norm": 0.24345605075359344,
      "learning_rate": 9.860283898792908e-06,
      "loss": 0.0137,
      "step": 154
    },
    {
      "epoch": 0.33916849015317285,
      "grad_norm": 1.408700704574585,
      "learning_rate": 9.85576255019963e-06,
      "loss": 0.1079,
      "step": 155
    },
    {
      "epoch": 0.3413566739606127,
      "grad_norm": 0.6713988780975342,
      "learning_rate": 9.851170274372465e-06,
      "loss": 0.0726,
      "step": 156
    },
    {
      "epoch": 0.3435448577680525,
      "grad_norm": 0.6390308737754822,
      "learning_rate": 9.846507138389948e-06,
      "loss": 0.0296,
      "step": 157
    },
    {
      "epoch": 0.34573304157549234,
      "grad_norm": 0.1809254139661789,
      "learning_rate": 9.841773210365646e-06,
      "loss": 0.0028,
      "step": 158
    },
    {
      "epoch": 0.3479212253829322,
      "grad_norm": 0.10859216749668121,
      "learning_rate": 9.836968559447184e-06,
      "loss": 0.0029,
      "step": 159
    },
    {
      "epoch": 0.350109409190372,
      "grad_norm": 0.353933721780777,
      "learning_rate": 9.832093255815217e-06,
      "loss": 0.0089,
      "step": 160
    },
    {
      "epoch": 0.3522975929978118,
      "grad_norm": 0.48780518770217896,
      "learning_rate": 9.82714737068241e-06,
      "loss": 0.0154,
      "step": 161
    },
    {
      "epoch": 0.3544857768052516,
      "grad_norm": 0.1639184057712555,
      "learning_rate": 9.822130976292402e-06,
      "loss": 0.0075,
      "step": 162
    },
    {
      "epoch": 0.35667396061269147,
      "grad_norm": 0.5431364178657532,
      "learning_rate": 9.817044145918747e-06,
      "loss": 0.0196,
      "step": 163
    },
    {
      "epoch": 0.3588621444201313,
      "grad_norm": 3.208573818206787,
      "learning_rate": 9.811886953863841e-06,
      "loss": 0.1383,
      "step": 164
    },
    {
      "epoch": 0.3610503282275711,
      "grad_norm": 0.16005805134773254,
      "learning_rate": 9.806659475457849e-06,
      "loss": 0.0077,
      "step": 165
    },
    {
      "epoch": 0.36323851203501095,
      "grad_norm": 0.08056265860795975,
      "learning_rate": 9.801361787057586e-06,
      "loss": 0.0027,
      "step": 166
    },
    {
      "epoch": 0.36542669584245074,
      "grad_norm": 0.2320316731929779,
      "learning_rate": 9.795993966045418e-06,
      "loss": 0.0071,
      "step": 167
    },
    {
      "epoch": 0.3676148796498906,
      "grad_norm": 0.07097921520471573,
      "learning_rate": 9.790556090828121e-06,
      "loss": 0.0026,
      "step": 168
    },
    {
      "epoch": 0.36980306345733044,
      "grad_norm": 2.1266441345214844,
      "learning_rate": 9.785048240835745e-06,
      "loss": 0.1841,
      "step": 169
    },
    {
      "epoch": 0.37199124726477023,
      "grad_norm": 1.468055248260498,
      "learning_rate": 9.779470496520442e-06,
      "loss": 0.114,
      "step": 170
    },
    {
      "epoch": 0.3741794310722101,
      "grad_norm": 1.1619718074798584,
      "learning_rate": 9.773822939355305e-06,
      "loss": 0.0958,
      "step": 171
    },
    {
      "epoch": 0.37636761487964987,
      "grad_norm": 0.09561937302350998,
      "learning_rate": 9.768105651833162e-06,
      "loss": 0.0026,
      "step": 172
    },
    {
      "epoch": 0.3785557986870897,
      "grad_norm": 3.5317533016204834,
      "learning_rate": 9.76231871746539e-06,
      "loss": 0.1931,
      "step": 173
    },
    {
      "epoch": 0.38074398249452956,
      "grad_norm": 1.163897156715393,
      "learning_rate": 9.756462220780674e-06,
      "loss": 0.1268,
      "step": 174
    },
    {
      "epoch": 0.38293216630196936,
      "grad_norm": 1.2844792604446411,
      "learning_rate": 9.750536247323791e-06,
      "loss": 0.1151,
      "step": 175
    },
    {
      "epoch": 0.3851203501094092,
      "grad_norm": 1.2339881658554077,
      "learning_rate": 9.744540883654348e-06,
      "loss": 0.1132,
      "step": 176
    },
    {
      "epoch": 0.387308533916849,
      "grad_norm": 1.0875202417373657,
      "learning_rate": 9.738476217345525e-06,
      "loss": 0.1175,
      "step": 177
    },
    {
      "epoch": 0.38949671772428884,
      "grad_norm": 0.860252857208252,
      "learning_rate": 9.732342336982791e-06,
      "loss": 0.0461,
      "step": 178
    },
    {
      "epoch": 0.3916849015317287,
      "grad_norm": 0.43016377091407776,
      "learning_rate": 9.726139332162613e-06,
      "loss": 0.0229,
      "step": 179
    },
    {
      "epoch": 0.3938730853391685,
      "grad_norm": 0.2594497501850128,
      "learning_rate": 9.719867293491146e-06,
      "loss": 0.0141,
      "step": 180
    },
    {
      "epoch": 0.39606126914660833,
      "grad_norm": 2.277158260345459,
      "learning_rate": 9.713526312582909e-06,
      "loss": 0.0598,
      "step": 181
    },
    {
      "epoch": 0.3982494529540481,
      "grad_norm": 0.49194255471229553,
      "learning_rate": 9.707116482059447e-06,
      "loss": 0.0181,
      "step": 182
    },
    {
      "epoch": 0.40043763676148797,
      "grad_norm": 1.2519595623016357,
      "learning_rate": 9.70063789554798e-06,
      "loss": 0.1113,
      "step": 183
    },
    {
      "epoch": 0.4026258205689278,
      "grad_norm": 0.8711631298065186,
      "learning_rate": 9.694090647680038e-06,
      "loss": 0.0529,
      "step": 184
    },
    {
      "epoch": 0.4048140043763676,
      "grad_norm": 0.09224312752485275,
      "learning_rate": 9.68747483409007e-06,
      "loss": 0.0039,
      "step": 185
    },
    {
      "epoch": 0.40700218818380746,
      "grad_norm": 0.07364127784967422,
      "learning_rate": 9.680790551414047e-06,
      "loss": 0.002,
      "step": 186
    },
    {
      "epoch": 0.40919037199124725,
      "grad_norm": 2.5319180488586426,
      "learning_rate": 9.674037897288068e-06,
      "loss": 0.0393,
      "step": 187
    },
    {
      "epoch": 0.4113785557986871,
      "grad_norm": 1.2339311838150024,
      "learning_rate": 9.667216970346916e-06,
      "loss": 0.065,
      "step": 188
    },
    {
      "epoch": 0.4135667396061269,
      "grad_norm": 0.09381360560655594,
      "learning_rate": 9.660327870222614e-06,
      "loss": 0.0041,
      "step": 189
    },
    {
      "epoch": 0.41575492341356673,
      "grad_norm": 0.9039261937141418,
      "learning_rate": 9.653370697542988e-06,
      "loss": 0.0732,
      "step": 190
    },
    {
      "epoch": 0.4179431072210066,
      "grad_norm": 1.5790388584136963,
      "learning_rate": 9.646345553930187e-06,
      "loss": 0.0335,
      "step": 191
    },
    {
      "epoch": 0.4201312910284464,
      "grad_norm": 0.2785559296607971,
      "learning_rate": 9.639252541999196e-06,
      "loss": 0.0044,
      "step": 192
    },
    {
      "epoch": 0.4223194748358862,
      "grad_norm": 0.1337122768163681,
      "learning_rate": 9.632091765356338e-06,
      "loss": 0.0068,
      "step": 193
    },
    {
      "epoch": 0.424507658643326,
      "grad_norm": 1.0661392211914062,
      "learning_rate": 9.624863328597767e-06,
      "loss": 0.1229,
      "step": 194
    },
    {
      "epoch": 0.42669584245076586,
      "grad_norm": 0.33627286553382874,
      "learning_rate": 9.617567337307934e-06,
      "loss": 0.0188,
      "step": 195
    },
    {
      "epoch": 0.4288840262582057,
      "grad_norm": 1.0734790563583374,
      "learning_rate": 9.610203898058049e-06,
      "loss": 0.1366,
      "step": 196
    },
    {
      "epoch": 0.4310722100656455,
      "grad_norm": 0.15494021773338318,
      "learning_rate": 9.602773118404518e-06,
      "loss": 0.007,
      "step": 197
    },
    {
      "epoch": 0.43326039387308535,
      "grad_norm": 0.3554459512233734,
      "learning_rate": 9.595275106887378e-06,
      "loss": 0.0226,
      "step": 198
    },
    {
      "epoch": 0.43544857768052514,
      "grad_norm": 0.10074296593666077,
      "learning_rate": 9.58770997302871e-06,
      "loss": 0.0048,
      "step": 199
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 1.288825511932373,
      "learning_rate": 9.580077827331038e-06,
      "loss": 0.0633,
      "step": 200
    },
    {
      "epoch": 0.43982494529540483,
      "grad_norm": 1.2166872024536133,
      "learning_rate": 9.572378781275714e-06,
      "loss": 0.0963,
      "step": 201
    },
    {
      "epoch": 0.4420131291028446,
      "grad_norm": 1.064192771911621,
      "learning_rate": 9.564612947321297e-06,
      "loss": 0.0646,
      "step": 202
    },
    {
      "epoch": 0.4442013129102845,
      "grad_norm": 0.17834047973155975,
      "learning_rate": 9.556780438901899e-06,
      "loss": 0.005,
      "step": 203
    },
    {
      "epoch": 0.44638949671772427,
      "grad_norm": 0.10526902228593826,
      "learning_rate": 9.548881370425532e-06,
      "loss": 0.0022,
      "step": 204
    },
    {
      "epoch": 0.4485776805251641,
      "grad_norm": 0.26010721921920776,
      "learning_rate": 9.540915857272445e-06,
      "loss": 0.0144,
      "step": 205
    },
    {
      "epoch": 0.45076586433260396,
      "grad_norm": 0.3317566215991974,
      "learning_rate": 9.532884015793432e-06,
      "loss": 0.0166,
      "step": 206
    },
    {
      "epoch": 0.45295404814004375,
      "grad_norm": 0.9699148535728455,
      "learning_rate": 9.524785963308126e-06,
      "loss": 0.0876,
      "step": 207
    },
    {
      "epoch": 0.4551422319474836,
      "grad_norm": 0.6401866674423218,
      "learning_rate": 9.516621818103295e-06,
      "loss": 0.0181,
      "step": 208
    },
    {
      "epoch": 0.4573304157549234,
      "grad_norm": 0.8558279871940613,
      "learning_rate": 9.508391699431114e-06,
      "loss": 0.0243,
      "step": 209
    },
    {
      "epoch": 0.45951859956236324,
      "grad_norm": 0.5781229138374329,
      "learning_rate": 9.50009572750742e-06,
      "loss": 0.0251,
      "step": 210
    },
    {
      "epoch": 0.4617067833698031,
      "grad_norm": 1.2333378791809082,
      "learning_rate": 9.491734023509952e-06,
      "loss": 0.0936,
      "step": 211
    },
    {
      "epoch": 0.4638949671772429,
      "grad_norm": 1.9618113040924072,
      "learning_rate": 9.48330670957659e-06,
      "loss": 0.0424,
      "step": 212
    },
    {
      "epoch": 0.4660831509846827,
      "grad_norm": 0.09318448603153229,
      "learning_rate": 9.474813908803565e-06,
      "loss": 0.0032,
      "step": 213
    },
    {
      "epoch": 0.4682713347921225,
      "grad_norm": 0.5289178490638733,
      "learning_rate": 9.46625574524366e-06,
      "loss": 0.0213,
      "step": 214
    },
    {
      "epoch": 0.47045951859956237,
      "grad_norm": 2.1766743659973145,
      "learning_rate": 9.457632343904404e-06,
      "loss": 0.0424,
      "step": 215
    },
    {
      "epoch": 0.4726477024070022,
      "grad_norm": 1.7345855236053467,
      "learning_rate": 9.448943830746238e-06,
      "loss": 0.1169,
      "step": 216
    },
    {
      "epoch": 0.474835886214442,
      "grad_norm": 1.19883394241333,
      "learning_rate": 9.440190332680683e-06,
      "loss": 0.06,
      "step": 217
    },
    {
      "epoch": 0.47702407002188185,
      "grad_norm": 1.4258489608764648,
      "learning_rate": 9.431371977568483e-06,
      "loss": 0.0243,
      "step": 218
    },
    {
      "epoch": 0.47921225382932164,
      "grad_norm": 0.7490646243095398,
      "learning_rate": 9.422488894217733e-06,
      "loss": 0.0458,
      "step": 219
    },
    {
      "epoch": 0.4814004376367615,
      "grad_norm": 1.145012378692627,
      "learning_rate": 9.413541212382005e-06,
      "loss": 0.0174,
      "step": 220
    },
    {
      "epoch": 0.48358862144420134,
      "grad_norm": 0.05832920968532562,
      "learning_rate": 9.404529062758447e-06,
      "loss": 0.0023,
      "step": 221
    },
    {
      "epoch": 0.48577680525164113,
      "grad_norm": 0.31158000230789185,
      "learning_rate": 9.39545257698588e-06,
      "loss": 0.0082,
      "step": 222
    },
    {
      "epoch": 0.487964989059081,
      "grad_norm": 0.9186124205589294,
      "learning_rate": 9.386311887642867e-06,
      "loss": 0.0763,
      "step": 223
    },
    {
      "epoch": 0.49015317286652077,
      "grad_norm": 0.00419131712988019,
      "learning_rate": 9.377107128245782e-06,
      "loss": 0.0001,
      "step": 224
    },
    {
      "epoch": 0.4923413566739606,
      "grad_norm": 0.010593675076961517,
      "learning_rate": 9.367838433246859e-06,
      "loss": 0.0003,
      "step": 225
    },
    {
      "epoch": 0.49452954048140046,
      "grad_norm": 0.031142959371209145,
      "learning_rate": 9.358505938032227e-06,
      "loss": 0.0012,
      "step": 226
    },
    {
      "epoch": 0.49671772428884026,
      "grad_norm": 1.3976958990097046,
      "learning_rate": 9.349109778919938e-06,
      "loss": 0.2101,
      "step": 227
    },
    {
      "epoch": 0.4989059080962801,
      "grad_norm": 0.03454679250717163,
      "learning_rate": 9.339650093157959e-06,
      "loss": 0.0011,
      "step": 228
    },
    {
      "epoch": 0.5010940919037199,
      "grad_norm": 1.828132152557373,
      "learning_rate": 9.330127018922195e-06,
      "loss": 0.3252,
      "step": 229
    },
    {
      "epoch": 0.5032822757111597,
      "grad_norm": 0.2948853075504303,
      "learning_rate": 9.32054069531444e-06,
      "loss": 0.0078,
      "step": 230
    },
    {
      "epoch": 0.5054704595185996,
      "grad_norm": 0.029109308496117592,
      "learning_rate": 9.31089126236037e-06,
      "loss": 0.0012,
      "step": 231
    },
    {
      "epoch": 0.5076586433260394,
      "grad_norm": 0.9682180285453796,
      "learning_rate": 9.301178861007483e-06,
      "loss": 0.0246,
      "step": 232
    },
    {
      "epoch": 0.5098468271334792,
      "grad_norm": 2.560122489929199,
      "learning_rate": 9.291403633123046e-06,
      "loss": 0.2355,
      "step": 233
    },
    {
      "epoch": 0.5120350109409191,
      "grad_norm": 0.004058727528899908,
      "learning_rate": 9.281565721492023e-06,
      "loss": 0.0002,
      "step": 234
    },
    {
      "epoch": 0.5142231947483589,
      "grad_norm": 0.006520760711282492,
      "learning_rate": 9.271665269814984e-06,
      "loss": 0.0003,
      "step": 235
    },
    {
      "epoch": 0.5164113785557987,
      "grad_norm": 0.9194096326828003,
      "learning_rate": 9.261702422706014e-06,
      "loss": 0.1264,
      "step": 236
    },
    {
      "epoch": 0.5185995623632386,
      "grad_norm": 0.017028359696269035,
      "learning_rate": 9.251677325690596e-06,
      "loss": 0.0005,
      "step": 237
    },
    {
      "epoch": 0.5207877461706784,
      "grad_norm": 0.13760533928871155,
      "learning_rate": 9.241590125203486e-06,
      "loss": 0.0041,
      "step": 238
    },
    {
      "epoch": 0.5229759299781181,
      "grad_norm": 0.7649739384651184,
      "learning_rate": 9.231440968586572e-06,
      "loss": 0.0144,
      "step": 239
    },
    {
      "epoch": 0.5251641137855579,
      "grad_norm": 2.0086145401000977,
      "learning_rate": 9.221230004086723e-06,
      "loss": 0.0769,
      "step": 240
    },
    {
      "epoch": 0.5273522975929978,
      "grad_norm": 2.420017957687378,
      "learning_rate": 9.210957380853631e-06,
      "loss": 0.1572,
      "step": 241
    },
    {
      "epoch": 0.5295404814004376,
      "grad_norm": 0.02879962883889675,
      "learning_rate": 9.200623248937619e-06,
      "loss": 0.0011,
      "step": 242
    },
    {
      "epoch": 0.5317286652078774,
      "grad_norm": 0.06514724344015121,
      "learning_rate": 9.190227759287459e-06,
      "loss": 0.0024,
      "step": 243
    },
    {
      "epoch": 0.5339168490153173,
      "grad_norm": 2.93902850151062,
      "learning_rate": 9.17977106374816e-06,
      "loss": 0.0532,
      "step": 244
    },
    {
      "epoch": 0.5361050328227571,
      "grad_norm": 2.0761449337005615,
      "learning_rate": 9.169253315058764e-06,
      "loss": 0.0577,
      "step": 245
    },
    {
      "epoch": 0.5382932166301969,
      "grad_norm": 0.940010130405426,
      "learning_rate": 9.158674666850096e-06,
      "loss": 0.0475,
      "step": 246
    },
    {
      "epoch": 0.5404814004376368,
      "grad_norm": 4.074369430541992,
      "learning_rate": 9.148035273642532e-06,
      "loss": 0.3776,
      "step": 247
    },
    {
      "epoch": 0.5426695842450766,
      "grad_norm": 1.2472567558288574,
      "learning_rate": 9.13733529084374e-06,
      "loss": 0.0612,
      "step": 248
    },
    {
      "epoch": 0.5448577680525164,
      "grad_norm": 0.8316018581390381,
      "learning_rate": 9.126574874746407e-06,
      "loss": 0.1029,
      "step": 249
    },
    {
      "epoch": 0.5470459518599562,
      "grad_norm": 0.7851415872573853,
      "learning_rate": 9.115754182525962e-06,
      "loss": 0.0274,
      "step": 250
    },
    {
      "epoch": 0.5492341356673961,
      "grad_norm": 0.19272378087043762,
      "learning_rate": 9.104873372238269e-06,
      "loss": 0.0096,
      "step": 251
    },
    {
      "epoch": 0.5514223194748359,
      "grad_norm": 0.9598011374473572,
      "learning_rate": 9.093932602817335e-06,
      "loss": 0.1126,
      "step": 252
    },
    {
      "epoch": 0.5536105032822757,
      "grad_norm": 1.346907377243042,
      "learning_rate": 9.082932034072971e-06,
      "loss": 0.1069,
      "step": 253
    },
    {
      "epoch": 0.5557986870897156,
      "grad_norm": 0.6371232271194458,
      "learning_rate": 9.071871826688472e-06,
      "loss": 0.0426,
      "step": 254
    },
    {
      "epoch": 0.5579868708971554,
      "grad_norm": 0.11388547718524933,
      "learning_rate": 9.060752142218258e-06,
      "loss": 0.0059,
      "step": 255
    },
    {
      "epoch": 0.5601750547045952,
      "grad_norm": 2.0945894718170166,
      "learning_rate": 9.049573143085525e-06,
      "loss": 0.1283,
      "step": 256
    },
    {
      "epoch": 0.562363238512035,
      "grad_norm": 0.2612181603908539,
      "learning_rate": 9.038334992579863e-06,
      "loss": 0.0124,
      "step": 257
    },
    {
      "epoch": 0.5645514223194749,
      "grad_norm": 1.0106643438339233,
      "learning_rate": 9.02703785485488e-06,
      "loss": 0.0546,
      "step": 258
    },
    {
      "epoch": 0.5667396061269147,
      "grad_norm": 0.13043871521949768,
      "learning_rate": 9.015681894925795e-06,
      "loss": 0.0065,
      "step": 259
    },
    {
      "epoch": 0.5689277899343544,
      "grad_norm": 0.07114037126302719,
      "learning_rate": 9.004267278667032e-06,
      "loss": 0.0039,
      "step": 260
    },
    {
      "epoch": 0.5711159737417943,
      "grad_norm": 0.020852230489253998,
      "learning_rate": 8.992794172809805e-06,
      "loss": 0.0011,
      "step": 261
    },
    {
      "epoch": 0.5733041575492341,
      "grad_norm": 0.9453116655349731,
      "learning_rate": 8.981262744939662e-06,
      "loss": 0.0319,
      "step": 262
    },
    {
      "epoch": 0.5754923413566739,
      "grad_norm": 1.027701735496521,
      "learning_rate": 8.969673163494063e-06,
      "loss": 0.0277,
      "step": 263
    },
    {
      "epoch": 0.5776805251641138,
      "grad_norm": 0.3598249852657318,
      "learning_rate": 8.958025597759899e-06,
      "loss": 0.0198,
      "step": 264
    },
    {
      "epoch": 0.5798687089715536,
      "grad_norm": 1.162278175354004,
      "learning_rate": 8.946320217871027e-06,
      "loss": 0.0553,
      "step": 265
    },
    {
      "epoch": 0.5820568927789934,
      "grad_norm": 0.028101589530706406,
      "learning_rate": 8.934557194805787e-06,
      "loss": 0.0014,
      "step": 266
    },
    {
      "epoch": 0.5842450765864332,
      "grad_norm": 1.288244366645813,
      "learning_rate": 8.922736700384502e-06,
      "loss": 0.1108,
      "step": 267
    },
    {
      "epoch": 0.5864332603938731,
      "grad_norm": 0.22579151391983032,
      "learning_rate": 8.910858907266971e-06,
      "loss": 0.0122,
      "step": 268
    },
    {
      "epoch": 0.5886214442013129,
      "grad_norm": 0.11301720142364502,
      "learning_rate": 8.898923988949936e-06,
      "loss": 0.0047,
      "step": 269
    },
    {
      "epoch": 0.5908096280087527,
      "grad_norm": 1.2319167852401733,
      "learning_rate": 8.886932119764566e-06,
      "loss": 0.141,
      "step": 270
    },
    {
      "epoch": 0.5929978118161926,
      "grad_norm": 0.21767501533031464,
      "learning_rate": 8.874883474873896e-06,
      "loss": 0.0099,
      "step": 271
    },
    {
      "epoch": 0.5951859956236324,
      "grad_norm": 0.0744757354259491,
      "learning_rate": 8.862778230270276e-06,
      "loss": 0.0041,
      "step": 272
    },
    {
      "epoch": 0.5973741794310722,
      "grad_norm": 1.5500028133392334,
      "learning_rate": 8.850616562772793e-06,
      "loss": 0.0617,
      "step": 273
    },
    {
      "epoch": 0.5995623632385121,
      "grad_norm": 0.1198822483420372,
      "learning_rate": 8.838398650024698e-06,
      "loss": 0.0065,
      "step": 274
    },
    {
      "epoch": 0.6017505470459519,
      "grad_norm": 1.5486798286437988,
      "learning_rate": 8.826124670490804e-06,
      "loss": 0.1253,
      "step": 275
    },
    {
      "epoch": 0.6039387308533917,
      "grad_norm": 1.0104879140853882,
      "learning_rate": 8.813794803454878e-06,
      "loss": 0.1402,
      "step": 276
    },
    {
      "epoch": 0.6061269146608315,
      "grad_norm": 0.5707199573516846,
      "learning_rate": 8.801409229017033e-06,
      "loss": 0.0154,
      "step": 277
    },
    {
      "epoch": 0.6083150984682714,
      "grad_norm": 1.0895487070083618,
      "learning_rate": 8.788968128091084e-06,
      "loss": 0.0372,
      "step": 278
    },
    {
      "epoch": 0.6105032822757112,
      "grad_norm": 0.1390787661075592,
      "learning_rate": 8.776471682401913e-06,
      "loss": 0.0079,
      "step": 279
    },
    {
      "epoch": 0.612691466083151,
      "grad_norm": 0.2145838588476181,
      "learning_rate": 8.76392007448281e-06,
      "loss": 0.0074,
      "step": 280
    },
    {
      "epoch": 0.6148796498905909,
      "grad_norm": 0.019506720826029778,
      "learning_rate": 8.751313487672815e-06,
      "loss": 0.001,
      "step": 281
    },
    {
      "epoch": 0.6170678336980306,
      "grad_norm": 0.028038959950208664,
      "learning_rate": 8.73865210611403e-06,
      "loss": 0.0014,
      "step": 282
    },
    {
      "epoch": 0.6192560175054704,
      "grad_norm": 1.9147146940231323,
      "learning_rate": 8.725936114748936e-06,
      "loss": 0.1165,
      "step": 283
    },
    {
      "epoch": 0.6214442013129103,
      "grad_norm": 1.0854792594909668,
      "learning_rate": 8.71316569931769e-06,
      "loss": 0.0194,
      "step": 284
    },
    {
      "epoch": 0.6236323851203501,
      "grad_norm": 0.13671043515205383,
      "learning_rate": 8.700341046355412e-06,
      "loss": 0.0069,
      "step": 285
    },
    {
      "epoch": 0.6258205689277899,
      "grad_norm": 0.6969447731971741,
      "learning_rate": 8.687462343189453e-06,
      "loss": 0.015,
      "step": 286
    },
    {
      "epoch": 0.6280087527352297,
      "grad_norm": 0.03514693304896355,
      "learning_rate": 8.674529777936674e-06,
      "loss": 0.0018,
      "step": 287
    },
    {
      "epoch": 0.6301969365426696,
      "grad_norm": 0.03582927957177162,
      "learning_rate": 8.661543539500686e-06,
      "loss": 0.0019,
      "step": 288
    },
    {
      "epoch": 0.6323851203501094,
      "grad_norm": 1.2372585535049438,
      "learning_rate": 8.648503817569091e-06,
      "loss": 0.2112,
      "step": 289
    },
    {
      "epoch": 0.6345733041575492,
      "grad_norm": 1.5037264823913574,
      "learning_rate": 8.635410802610724e-06,
      "loss": 0.0806,
      "step": 290
    },
    {
      "epoch": 0.6367614879649891,
      "grad_norm": 0.9110689759254456,
      "learning_rate": 8.622264685872852e-06,
      "loss": 0.0231,
      "step": 291
    },
    {
      "epoch": 0.6389496717724289,
      "grad_norm": 1.0753402709960938,
      "learning_rate": 8.609065659378395e-06,
      "loss": 0.035,
      "step": 292
    },
    {
      "epoch": 0.6411378555798687,
      "grad_norm": 1.1467188596725464,
      "learning_rate": 8.595813915923113e-06,
      "loss": 0.1548,
      "step": 293
    },
    {
      "epoch": 0.6433260393873085,
      "grad_norm": 0.4238477349281311,
      "learning_rate": 8.582509649072793e-06,
      "loss": 0.0508,
      "step": 294
    },
    {
      "epoch": 0.6455142231947484,
      "grad_norm": 0.9996163845062256,
      "learning_rate": 8.569153053160429e-06,
      "loss": 0.0558,
      "step": 295
    },
    {
      "epoch": 0.6477024070021882,
      "grad_norm": 0.14075565338134766,
      "learning_rate": 8.555744323283364e-06,
      "loss": 0.005,
      "step": 296
    },
    {
      "epoch": 0.649890590809628,
      "grad_norm": 0.13494573533535004,
      "learning_rate": 8.542283655300463e-06,
      "loss": 0.0071,
      "step": 297
    },
    {
      "epoch": 0.6520787746170679,
      "grad_norm": 0.8124021887779236,
      "learning_rate": 8.528771245829234e-06,
      "loss": 0.0491,
      "step": 298
    },
    {
      "epoch": 0.6542669584245077,
      "grad_norm": 1.9401800632476807,
      "learning_rate": 8.515207292242969e-06,
      "loss": 0.1574,
      "step": 299
    },
    {
      "epoch": 0.6564551422319475,
      "grad_norm": 0.14024792611598969,
      "learning_rate": 8.50159199266785e-06,
      "loss": 0.0069,
      "step": 300
    },
    {
      "epoch": 0.6586433260393874,
      "grad_norm": 0.10672183334827423,
      "learning_rate": 8.487925545980066e-06,
      "loss": 0.0057,
      "step": 301
    },
    {
      "epoch": 0.6608315098468271,
      "grad_norm": 0.9897513389587402,
      "learning_rate": 8.474208151802898e-06,
      "loss": 0.047,
      "step": 302
    },
    {
      "epoch": 0.6630196936542669,
      "grad_norm": 0.6200073957443237,
      "learning_rate": 8.46044001050381e-06,
      "loss": 0.0297,
      "step": 303
    },
    {
      "epoch": 0.6652078774617067,
      "grad_norm": 0.024536404758691788,
      "learning_rate": 8.44662132319152e-06,
      "loss": 0.0012,
      "step": 304
    },
    {
      "epoch": 0.6673960612691466,
      "grad_norm": 0.14198735356330872,
      "learning_rate": 8.432752291713058e-06,
      "loss": 0.0062,
      "step": 305
    },
    {
      "epoch": 0.6695842450765864,
      "grad_norm": 0.07026015967130661,
      "learning_rate": 8.41883311865083e-06,
      "loss": 0.0034,
      "step": 306
    },
    {
      "epoch": 0.6717724288840262,
      "grad_norm": 1.0680263042449951,
      "learning_rate": 8.404864007319647e-06,
      "loss": 0.0307,
      "step": 307
    },
    {
      "epoch": 0.6739606126914661,
      "grad_norm": 1.4978212118148804,
      "learning_rate": 8.390845161763756e-06,
      "loss": 0.2641,
      "step": 308
    },
    {
      "epoch": 0.6761487964989059,
      "grad_norm": 1.0577466487884521,
      "learning_rate": 8.376776786753866e-06,
      "loss": 0.1819,
      "step": 309
    },
    {
      "epoch": 0.6783369803063457,
      "grad_norm": 0.3804509937763214,
      "learning_rate": 8.362659087784153e-06,
      "loss": 0.0091,
      "step": 310
    },
    {
      "epoch": 0.6805251641137856,
      "grad_norm": 0.7549909949302673,
      "learning_rate": 8.34849227106926e-06,
      "loss": 0.0708,
      "step": 311
    },
    {
      "epoch": 0.6827133479212254,
      "grad_norm": 0.32280242443084717,
      "learning_rate": 8.334276543541285e-06,
      "loss": 0.0128,
      "step": 312
    },
    {
      "epoch": 0.6849015317286652,
      "grad_norm": 2.1272921562194824,
      "learning_rate": 8.32001211284675e-06,
      "loss": 0.1297,
      "step": 313
    },
    {
      "epoch": 0.687089715536105,
      "grad_norm": 0.5462586283683777,
      "learning_rate": 8.305699187343586e-06,
      "loss": 0.0493,
      "step": 314
    },
    {
      "epoch": 0.6892778993435449,
      "grad_norm": 0.6436428427696228,
      "learning_rate": 8.291337976098069e-06,
      "loss": 0.0698,
      "step": 315
    },
    {
      "epoch": 0.6914660831509847,
      "grad_norm": 0.29550355672836304,
      "learning_rate": 8.276928688881783e-06,
      "loss": 0.0159,
      "step": 316
    },
    {
      "epoch": 0.6936542669584245,
      "grad_norm": 0.43613460659980774,
      "learning_rate": 8.262471536168547e-06,
      "loss": 0.0197,
      "step": 317
    },
    {
      "epoch": 0.6958424507658644,
      "grad_norm": 0.6355897188186646,
      "learning_rate": 8.24796672913134e-06,
      "loss": 0.0248,
      "step": 318
    },
    {
      "epoch": 0.6980306345733042,
      "grad_norm": 0.0752108171582222,
      "learning_rate": 8.233414479639221e-06,
      "loss": 0.0038,
      "step": 319
    },
    {
      "epoch": 0.700218818380744,
      "grad_norm": 0.6476627588272095,
      "learning_rate": 8.218815000254233e-06,
      "loss": 0.0533,
      "step": 320
    },
    {
      "epoch": 0.7024070021881839,
      "grad_norm": 1.1945717334747314,
      "learning_rate": 8.204168504228294e-06,
      "loss": 0.136,
      "step": 321
    },
    {
      "epoch": 0.7045951859956237,
      "grad_norm": 0.9046114087104797,
      "learning_rate": 8.189475205500091e-06,
      "loss": 0.1492,
      "step": 322
    },
    {
      "epoch": 0.7067833698030634,
      "grad_norm": 1.157285451889038,
      "learning_rate": 8.174735318691946e-06,
      "loss": 0.119,
      "step": 323
    },
    {
      "epoch": 0.7089715536105032,
      "grad_norm": 0.16111408174037933,
      "learning_rate": 8.159949059106683e-06,
      "loss": 0.0122,
      "step": 324
    },
    {
      "epoch": 0.7111597374179431,
      "grad_norm": 0.08390490710735321,
      "learning_rate": 8.145116642724487e-06,
      "loss": 0.0036,
      "step": 325
    },
    {
      "epoch": 0.7133479212253829,
      "grad_norm": 0.566569447517395,
      "learning_rate": 8.130238286199747e-06,
      "loss": 0.0225,
      "step": 326
    },
    {
      "epoch": 0.7155361050328227,
      "grad_norm": 0.2947120666503906,
      "learning_rate": 8.115314206857892e-06,
      "loss": 0.0141,
      "step": 327
    },
    {
      "epoch": 0.7177242888402626,
      "grad_norm": 0.08075882494449615,
      "learning_rate": 8.100344622692212e-06,
      "loss": 0.0035,
      "step": 328
    },
    {
      "epoch": 0.7199124726477024,
      "grad_norm": 0.25940456986427307,
      "learning_rate": 8.085329752360683e-06,
      "loss": 0.0172,
      "step": 329
    },
    {
      "epoch": 0.7221006564551422,
      "grad_norm": 0.040982283651828766,
      "learning_rate": 8.07026981518276e-06,
      "loss": 0.002,
      "step": 330
    },
    {
      "epoch": 0.7242888402625821,
      "grad_norm": 1.8780430555343628,
      "learning_rate": 8.055165031136192e-06,
      "loss": 0.0607,
      "step": 331
    },
    {
      "epoch": 0.7264770240700219,
      "grad_norm": 0.19531835615634918,
      "learning_rate": 8.04001562085379e-06,
      "loss": 0.0056,
      "step": 332
    },
    {
      "epoch": 0.7286652078774617,
      "grad_norm": 0.37448355555534363,
      "learning_rate": 8.024821805620211e-06,
      "loss": 0.0224,
      "step": 333
    },
    {
      "epoch": 0.7308533916849015,
      "grad_norm": 0.9661240577697754,
      "learning_rate": 8.009583807368734e-06,
      "loss": 0.0497,
      "step": 334
    },
    {
      "epoch": 0.7330415754923414,
      "grad_norm": 0.29396697878837585,
      "learning_rate": 7.994301848678006e-06,
      "loss": 0.0108,
      "step": 335
    },
    {
      "epoch": 0.7352297592997812,
      "grad_norm": 0.802142322063446,
      "learning_rate": 7.9789761527688e-06,
      "loss": 0.0475,
      "step": 336
    },
    {
      "epoch": 0.737417943107221,
      "grad_norm": 0.012710807844996452,
      "learning_rate": 7.963606943500743e-06,
      "loss": 0.0006,
      "step": 337
    },
    {
      "epoch": 0.7396061269146609,
      "grad_norm": 0.9818058013916016,
      "learning_rate": 7.948194445369065e-06,
      "loss": 0.1001,
      "step": 338
    },
    {
      "epoch": 0.7417943107221007,
      "grad_norm": 0.7887936234474182,
      "learning_rate": 7.932738883501297e-06,
      "loss": 0.1189,
      "step": 339
    },
    {
      "epoch": 0.7439824945295405,
      "grad_norm": 0.32194259762763977,
      "learning_rate": 7.917240483654002e-06,
      "loss": 0.0163,
      "step": 340
    },
    {
      "epoch": 0.7461706783369803,
      "grad_norm": 0.020926276221871376,
      "learning_rate": 7.901699472209467e-06,
      "loss": 0.001,
      "step": 341
    },
    {
      "epoch": 0.7483588621444202,
      "grad_norm": 0.008344520814716816,
      "learning_rate": 7.886116076172398e-06,
      "loss": 0.0005,
      "step": 342
    },
    {
      "epoch": 0.75054704595186,
      "grad_norm": 0.05014216527342796,
      "learning_rate": 7.870490523166606e-06,
      "loss": 0.002,
      "step": 343
    },
    {
      "epoch": 0.7527352297592997,
      "grad_norm": 1.2644366025924683,
      "learning_rate": 7.85482304143168e-06,
      "loss": 0.1516,
      "step": 344
    },
    {
      "epoch": 0.7549234135667396,
      "grad_norm": 0.8187833428382874,
      "learning_rate": 7.839113859819656e-06,
      "loss": 0.0955,
      "step": 345
    },
    {
      "epoch": 0.7571115973741794,
      "grad_norm": 0.15154631435871124,
      "learning_rate": 7.823363207791672e-06,
      "loss": 0.0062,
      "step": 346
    },
    {
      "epoch": 0.7592997811816192,
      "grad_norm": 0.06436019390821457,
      "learning_rate": 7.807571315414616e-06,
      "loss": 0.0036,
      "step": 347
    },
    {
      "epoch": 0.7614879649890591,
      "grad_norm": 0.10148206353187561,
      "learning_rate": 7.791738413357766e-06,
      "loss": 0.0055,
      "step": 348
    },
    {
      "epoch": 0.7636761487964989,
      "grad_norm": 0.12627200782299042,
      "learning_rate": 7.77586473288942e-06,
      "loss": 0.0061,
      "step": 349
    },
    {
      "epoch": 0.7658643326039387,
      "grad_norm": 0.1854252815246582,
      "learning_rate": 7.759950505873523e-06,
      "loss": 0.0097,
      "step": 350
    },
    {
      "epoch": 0.7680525164113785,
      "grad_norm": 0.06402240693569183,
      "learning_rate": 7.743995964766272e-06,
      "loss": 0.0031,
      "step": 351
    },
    {
      "epoch": 0.7702407002188184,
      "grad_norm": 0.09641123563051224,
      "learning_rate": 7.728001342612724e-06,
      "loss": 0.0045,
      "step": 352
    },
    {
      "epoch": 0.7724288840262582,
      "grad_norm": 0.11409725248813629,
      "learning_rate": 7.711966873043396e-06,
      "loss": 0.0044,
      "step": 353
    },
    {
      "epoch": 0.774617067833698,
      "grad_norm": 0.1201825812458992,
      "learning_rate": 7.695892790270849e-06,
      "loss": 0.0063,
      "step": 354
    },
    {
      "epoch": 0.7768052516411379,
      "grad_norm": 0.7409016489982605,
      "learning_rate": 7.67977932908626e-06,
      "loss": 0.0488,
      "step": 355
    },
    {
      "epoch": 0.7789934354485777,
      "grad_norm": 0.03380429744720459,
      "learning_rate": 7.66362672485601e-06,
      "loss": 0.0014,
      "step": 356
    },
    {
      "epoch": 0.7811816192560175,
      "grad_norm": 1.4608606100082397,
      "learning_rate": 7.647435213518225e-06,
      "loss": 0.033,
      "step": 357
    },
    {
      "epoch": 0.7833698030634574,
      "grad_norm": 0.04000420868396759,
      "learning_rate": 7.631205031579344e-06,
      "loss": 0.0021,
      "step": 358
    },
    {
      "epoch": 0.7855579868708972,
      "grad_norm": 0.8002092242240906,
      "learning_rate": 7.614936416110668e-06,
      "loss": 0.0429,
      "step": 359
    },
    {
      "epoch": 0.787746170678337,
      "grad_norm": 0.3164515197277069,
      "learning_rate": 7.598629604744874e-06,
      "loss": 0.0102,
      "step": 360
    },
    {
      "epoch": 0.7899343544857768,
      "grad_norm": 0.7687844038009644,
      "learning_rate": 7.582284835672571e-06,
      "loss": 0.0415,
      "step": 361
    },
    {
      "epoch": 0.7921225382932167,
      "grad_norm": 1.3168476819992065,
      "learning_rate": 7.565902347638806e-06,
      "loss": 0.1378,
      "step": 362
    },
    {
      "epoch": 0.7943107221006565,
      "grad_norm": 1.8663101196289062,
      "learning_rate": 7.54948237993958e-06,
      "loss": 0.1989,
      "step": 363
    },
    {
      "epoch": 0.7964989059080962,
      "grad_norm": 1.4458974599838257,
      "learning_rate": 7.533025172418354e-06,
      "loss": 0.081,
      "step": 364
    },
    {
      "epoch": 0.7986870897155361,
      "grad_norm": 0.5505244135856628,
      "learning_rate": 7.5165309654625405e-06,
      "loss": 0.0797,
      "step": 365
    },
    {
      "epoch": 0.8008752735229759,
      "grad_norm": 0.3456757962703705,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0195,
      "step": 366
    },
    {
      "epoch": 0.8030634573304157,
      "grad_norm": 3.3879971504211426,
      "learning_rate": 7.483432517495517e-06,
      "loss": 0.095,
      "step": 367
    },
    {
      "epoch": 0.8052516411378556,
      "grad_norm": 1.559531569480896,
      "learning_rate": 7.466828759947271e-06,
      "loss": 0.1316,
      "step": 368
    },
    {
      "epoch": 0.8074398249452954,
      "grad_norm": 0.3079027533531189,
      "learning_rate": 7.4501889698833075e-06,
      "loss": 0.0126,
      "step": 369
    },
    {
      "epoch": 0.8096280087527352,
      "grad_norm": 0.6226935386657715,
      "learning_rate": 7.4335133903579906e-06,
      "loss": 0.0147,
      "step": 370
    },
    {
      "epoch": 0.811816192560175,
      "grad_norm": 0.8870019912719727,
      "learning_rate": 7.416802264948455e-06,
      "loss": 0.0845,
      "step": 371
    },
    {
      "epoch": 0.8140043763676149,
      "grad_norm": 0.10124438256025314,
      "learning_rate": 7.4000558377510475e-06,
      "loss": 0.004,
      "step": 372
    },
    {
      "epoch": 0.8161925601750547,
      "grad_norm": 0.8693515658378601,
      "learning_rate": 7.383274353377763e-06,
      "loss": 0.1084,
      "step": 373
    },
    {
      "epoch": 0.8183807439824945,
      "grad_norm": 0.10191979259252548,
      "learning_rate": 7.366458056952668e-06,
      "loss": 0.0053,
      "step": 374
    },
    {
      "epoch": 0.8205689277899344,
      "grad_norm": 0.38809481263160706,
      "learning_rate": 7.349607194108323e-06,
      "loss": 0.0718,
      "step": 375
    },
    {
      "epoch": 0.8227571115973742,
      "grad_norm": 0.88350510597229,
      "learning_rate": 7.332722010982196e-06,
      "loss": 0.0551,
      "step": 376
    },
    {
      "epoch": 0.824945295404814,
      "grad_norm": 0.029542172327637672,
      "learning_rate": 7.315802754213062e-06,
      "loss": 0.0016,
      "step": 377
    },
    {
      "epoch": 0.8271334792122538,
      "grad_norm": 1.2076451778411865,
      "learning_rate": 7.298849670937403e-06,
      "loss": 0.0566,
      "step": 378
    },
    {
      "epoch": 0.8293216630196937,
      "grad_norm": 1.3621599674224854,
      "learning_rate": 7.281863008785804e-06,
      "loss": 0.0719,
      "step": 379
    },
    {
      "epoch": 0.8315098468271335,
      "grad_norm": 1.1126539707183838,
      "learning_rate": 7.264843015879321e-06,
      "loss": 0.0612,
      "step": 380
    },
    {
      "epoch": 0.8336980306345733,
      "grad_norm": 0.18467804789543152,
      "learning_rate": 7.247789940825879e-06,
      "loss": 0.0089,
      "step": 381
    },
    {
      "epoch": 0.8358862144420132,
      "grad_norm": 2.1479151248931885,
      "learning_rate": 7.230704032716615e-06,
      "loss": 0.1087,
      "step": 382
    },
    {
      "epoch": 0.838074398249453,
      "grad_norm": 0.7182452082633972,
      "learning_rate": 7.213585541122261e-06,
      "loss": 0.0228,
      "step": 383
    },
    {
      "epoch": 0.8402625820568927,
      "grad_norm": 0.8182430267333984,
      "learning_rate": 7.196434716089487e-06,
      "loss": 0.0609,
      "step": 384
    },
    {
      "epoch": 0.8424507658643327,
      "grad_norm": 0.526904284954071,
      "learning_rate": 7.179251808137251e-06,
      "loss": 0.0462,
      "step": 385
    },
    {
      "epoch": 0.8446389496717724,
      "grad_norm": 0.015587856061756611,
      "learning_rate": 7.162037068253141e-06,
      "loss": 0.0008,
      "step": 386
    },
    {
      "epoch": 0.8468271334792122,
      "grad_norm": 0.07957712560892105,
      "learning_rate": 7.144790747889709e-06,
      "loss": 0.003,
      "step": 387
    },
    {
      "epoch": 0.849015317286652,
      "grad_norm": 0.8318254351615906,
      "learning_rate": 7.127513098960798e-06,
      "loss": 0.0275,
      "step": 388
    },
    {
      "epoch": 0.8512035010940919,
      "grad_norm": 1.2338038682937622,
      "learning_rate": 7.110204373837857e-06,
      "loss": 0.0271,
      "step": 389
    },
    {
      "epoch": 0.8533916849015317,
      "grad_norm": 0.030947206541895866,
      "learning_rate": 7.092864825346266e-06,
      "loss": 0.0015,
      "step": 390
    },
    {
      "epoch": 0.8555798687089715,
      "grad_norm": 1.2888344526290894,
      "learning_rate": 7.0754947067616295e-06,
      "loss": 0.1546,
      "step": 391
    },
    {
      "epoch": 0.8577680525164114,
      "grad_norm": 0.04152311384677887,
      "learning_rate": 7.058094271806091e-06,
      "loss": 0.0021,
      "step": 392
    },
    {
      "epoch": 0.8599562363238512,
      "grad_norm": 0.3723498284816742,
      "learning_rate": 7.040663774644613e-06,
      "loss": 0.0103,
      "step": 393
    },
    {
      "epoch": 0.862144420131291,
      "grad_norm": 1.201735258102417,
      "learning_rate": 7.023203469881272e-06,
      "loss": 0.0526,
      "step": 394
    },
    {
      "epoch": 0.8643326039387309,
      "grad_norm": 1.5413269996643066,
      "learning_rate": 7.0057136125555456e-06,
      "loss": 0.0487,
      "step": 395
    },
    {
      "epoch": 0.8665207877461707,
      "grad_norm": 0.5987399816513062,
      "learning_rate": 6.988194458138571e-06,
      "loss": 0.0762,
      "step": 396
    },
    {
      "epoch": 0.8687089715536105,
      "grad_norm": 0.07985575497150421,
      "learning_rate": 6.970646262529429e-06,
      "loss": 0.0035,
      "step": 397
    },
    {
      "epoch": 0.8708971553610503,
      "grad_norm": 0.06889932602643967,
      "learning_rate": 6.953069282051397e-06,
      "loss": 0.0032,
      "step": 398
    },
    {
      "epoch": 0.8730853391684902,
      "grad_norm": 0.20964494347572327,
      "learning_rate": 6.935463773448209e-06,
      "loss": 0.0092,
      "step": 399
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 0.35817739367485046,
      "learning_rate": 6.917829993880303e-06,
      "loss": 0.0114,
      "step": 400
    },
    {
      "epoch": 0.8774617067833698,
      "grad_norm": 0.8175051212310791,
      "learning_rate": 6.900168200921065e-06,
      "loss": 0.0482,
      "step": 401
    },
    {
      "epoch": 0.8796498905908097,
      "grad_norm": 0.11672089993953705,
      "learning_rate": 6.882478652553071e-06,
      "loss": 0.005,
      "step": 402
    },
    {
      "epoch": 0.8818380743982495,
      "grad_norm": 1.2245155572891235,
      "learning_rate": 6.86476160716431e-06,
      "loss": 0.0272,
      "step": 403
    },
    {
      "epoch": 0.8840262582056893,
      "grad_norm": 0.3168404996395111,
      "learning_rate": 6.84701732354442e-06,
      "loss": 0.014,
      "step": 404
    },
    {
      "epoch": 0.8862144420131292,
      "grad_norm": 2.0572447776794434,
      "learning_rate": 6.829246060880901e-06,
      "loss": 0.1512,
      "step": 405
    },
    {
      "epoch": 0.888402625820569,
      "grad_norm": 0.3258683383464813,
      "learning_rate": 6.81144807875533e-06,
      "loss": 0.0232,
      "step": 406
    },
    {
      "epoch": 0.8905908096280087,
      "grad_norm": 0.09117390215396881,
      "learning_rate": 6.79362363713957e-06,
      "loss": 0.0048,
      "step": 407
    },
    {
      "epoch": 0.8927789934354485,
      "grad_norm": 1.9741424322128296,
      "learning_rate": 6.775772996391974e-06,
      "loss": 0.1183,
      "step": 408
    },
    {
      "epoch": 0.8949671772428884,
      "grad_norm": 1.2525601387023926,
      "learning_rate": 6.757896417253583e-06,
      "loss": 0.0885,
      "step": 409
    },
    {
      "epoch": 0.8971553610503282,
      "grad_norm": 6.890747547149658,
      "learning_rate": 6.7399941608443096e-06,
      "loss": 0.1326,
      "step": 410
    },
    {
      "epoch": 0.899343544857768,
      "grad_norm": 1.3648271560668945,
      "learning_rate": 6.722066488659136e-06,
      "loss": 0.0787,
      "step": 411
    },
    {
      "epoch": 0.9015317286652079,
      "grad_norm": 1.0042791366577148,
      "learning_rate": 6.7041136625642846e-06,
      "loss": 0.0348,
      "step": 412
    },
    {
      "epoch": 0.9037199124726477,
      "grad_norm": 0.1421915739774704,
      "learning_rate": 6.686135944793395e-06,
      "loss": 0.0042,
      "step": 413
    },
    {
      "epoch": 0.9059080962800875,
      "grad_norm": 1.6911065578460693,
      "learning_rate": 6.668133597943699e-06,
      "loss": 0.1625,
      "step": 414
    },
    {
      "epoch": 0.9080962800875274,
      "grad_norm": 0.15455475449562073,
      "learning_rate": 6.650106884972176e-06,
      "loss": 0.0067,
      "step": 415
    },
    {
      "epoch": 0.9102844638949672,
      "grad_norm": 0.023024767637252808,
      "learning_rate": 6.632056069191723e-06,
      "loss": 0.001,
      "step": 416
    },
    {
      "epoch": 0.912472647702407,
      "grad_norm": 0.10904466360807419,
      "learning_rate": 6.613981414267294e-06,
      "loss": 0.0047,
      "step": 417
    },
    {
      "epoch": 0.9146608315098468,
      "grad_norm": 0.8190321326255798,
      "learning_rate": 6.595883184212067e-06,
      "loss": 0.102,
      "step": 418
    },
    {
      "epoch": 0.9168490153172867,
      "grad_norm": 0.11427313089370728,
      "learning_rate": 6.57776164338357e-06,
      "loss": 0.0058,
      "step": 419
    },
    {
      "epoch": 0.9190371991247265,
      "grad_norm": 0.37133875489234924,
      "learning_rate": 6.559617056479828e-06,
      "loss": 0.0112,
      "step": 420
    },
    {
      "epoch": 0.9212253829321663,
      "grad_norm": 1.2474514245986938,
      "learning_rate": 6.5414496885355006e-06,
      "loss": 0.0717,
      "step": 421
    },
    {
      "epoch": 0.9234135667396062,
      "grad_norm": 0.6900101900100708,
      "learning_rate": 6.523259804918001e-06,
      "loss": 0.0217,
      "step": 422
    },
    {
      "epoch": 0.925601750547046,
      "grad_norm": 1.682441234588623,
      "learning_rate": 6.505047671323625e-06,
      "loss": 0.051,
      "step": 423
    },
    {
      "epoch": 0.9277899343544858,
      "grad_norm": 0.6159668564796448,
      "learning_rate": 6.486813553773673e-06,
      "loss": 0.035,
      "step": 424
    },
    {
      "epoch": 0.9299781181619255,
      "grad_norm": 0.7444408535957336,
      "learning_rate": 6.4685577186105595e-06,
      "loss": 0.0459,
      "step": 425
    },
    {
      "epoch": 0.9321663019693655,
      "grad_norm": 0.1586015373468399,
      "learning_rate": 6.450280432493925e-06,
      "loss": 0.0076,
      "step": 426
    },
    {
      "epoch": 0.9343544857768052,
      "grad_norm": 0.004871482495218515,
      "learning_rate": 6.431981962396734e-06,
      "loss": 0.0003,
      "step": 427
    },
    {
      "epoch": 0.936542669584245,
      "grad_norm": 0.1906866878271103,
      "learning_rate": 6.413662575601391e-06,
      "loss": 0.0063,
      "step": 428
    },
    {
      "epoch": 0.9387308533916849,
      "grad_norm": 1.163019061088562,
      "learning_rate": 6.395322539695821e-06,
      "loss": 0.077,
      "step": 429
    },
    {
      "epoch": 0.9409190371991247,
      "grad_norm": 1.1039557456970215,
      "learning_rate": 6.3769621225695675e-06,
      "loss": 0.1017,
      "step": 430
    },
    {
      "epoch": 0.9431072210065645,
      "grad_norm": 0.32126927375793457,
      "learning_rate": 6.358581592409881e-06,
      "loss": 0.0115,
      "step": 431
    },
    {
      "epoch": 0.9452954048140044,
      "grad_norm": 1.6674760580062866,
      "learning_rate": 6.340181217697797e-06,
      "loss": 0.1128,
      "step": 432
    },
    {
      "epoch": 0.9474835886214442,
      "grad_norm": 0.021152038127183914,
      "learning_rate": 6.3217612672042175e-06,
      "loss": 0.0008,
      "step": 433
    },
    {
      "epoch": 0.949671772428884,
      "grad_norm": 0.16989880800247192,
      "learning_rate": 6.303322009985984e-06,
      "loss": 0.0048,
      "step": 434
    },
    {
      "epoch": 0.9518599562363238,
      "grad_norm": 1.8037865161895752,
      "learning_rate": 6.2848637153819495e-06,
      "loss": 0.1038,
      "step": 435
    },
    {
      "epoch": 0.9540481400437637,
      "grad_norm": 1.5411584377288818,
      "learning_rate": 6.2663866530090374e-06,
      "loss": 0.0689,
      "step": 436
    },
    {
      "epoch": 0.9562363238512035,
      "grad_norm": 0.933207631111145,
      "learning_rate": 6.247891092758319e-06,
      "loss": 0.0475,
      "step": 437
    },
    {
      "epoch": 0.9584245076586433,
      "grad_norm": 1.4413621425628662,
      "learning_rate": 6.229377304791049e-06,
      "loss": 0.1751,
      "step": 438
    },
    {
      "epoch": 0.9606126914660832,
      "grad_norm": 0.5506259799003601,
      "learning_rate": 6.2108455595347375e-06,
      "loss": 0.0578,
      "step": 439
    },
    {
      "epoch": 0.962800875273523,
      "grad_norm": 1.3057429790496826,
      "learning_rate": 6.1922961276791925e-06,
      "loss": 0.1422,
      "step": 440
    },
    {
      "epoch": 0.9649890590809628,
      "grad_norm": 0.21492163836956024,
      "learning_rate": 6.173729280172565e-06,
      "loss": 0.0106,
      "step": 441
    },
    {
      "epoch": 0.9671772428884027,
      "grad_norm": 0.1733931601047516,
      "learning_rate": 6.1551452882173975e-06,
      "loss": 0.008,
      "step": 442
    },
    {
      "epoch": 0.9693654266958425,
      "grad_norm": 0.3639136552810669,
      "learning_rate": 6.136544423266651e-06,
      "loss": 0.006,
      "step": 443
    },
    {
      "epoch": 0.9715536105032823,
      "grad_norm": 0.5210350751876831,
      "learning_rate": 6.117926957019758e-06,
      "loss": 0.0327,
      "step": 444
    },
    {
      "epoch": 0.973741794310722,
      "grad_norm": 0.22870194911956787,
      "learning_rate": 6.09929316141863e-06,
      "loss": 0.0097,
      "step": 445
    },
    {
      "epoch": 0.975929978118162,
      "grad_norm": 0.08032616227865219,
      "learning_rate": 6.08064330864371e-06,
      "loss": 0.003,
      "step": 446
    },
    {
      "epoch": 0.9781181619256017,
      "grad_norm": 0.5016306638717651,
      "learning_rate": 6.0619776711099785e-06,
      "loss": 0.0825,
      "step": 447
    },
    {
      "epoch": 0.9803063457330415,
      "grad_norm": 1.0331315994262695,
      "learning_rate": 6.043296521462982e-06,
      "loss": 0.0777,
      "step": 448
    },
    {
      "epoch": 0.9824945295404814,
      "grad_norm": 0.4221677780151367,
      "learning_rate": 6.024600132574855e-06,
      "loss": 0.0158,
      "step": 449
    },
    {
      "epoch": 0.9846827133479212,
      "grad_norm": 0.08498886972665787,
      "learning_rate": 6.0058887775403196e-06,
      "loss": 0.0036,
      "step": 450
    },
    {
      "epoch": 0.986870897155361,
      "grad_norm": 1.7985659837722778,
      "learning_rate": 5.987162729672712e-06,
      "loss": 0.0885,
      "step": 451
    },
    {
      "epoch": 0.9890590809628009,
      "grad_norm": 1.0317997932434082,
      "learning_rate": 5.968422262499983e-06,
      "loss": 0.038,
      "step": 452
    },
    {
      "epoch": 0.9912472647702407,
      "grad_norm": 0.007754984311759472,
      "learning_rate": 5.949667649760702e-06,
      "loss": 0.0003,
      "step": 453
    },
    {
      "epoch": 0.9934354485776805,
      "grad_norm": 0.06187564507126808,
      "learning_rate": 5.930899165400063e-06,
      "loss": 0.0025,
      "step": 454
    },
    {
      "epoch": 0.9956236323851203,
      "grad_norm": 0.1540619134902954,
      "learning_rate": 5.912117083565874e-06,
      "loss": 0.008,
      "step": 455
    },
    {
      "epoch": 0.9978118161925602,
      "grad_norm": 0.21946822106838226,
      "learning_rate": 5.893321678604568e-06,
      "loss": 0.0099,
      "step": 456
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.48518040776252747,
      "learning_rate": 5.874513225057179e-06,
      "loss": 0.0292,
      "step": 457
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.14705882352941177,
      "eval_loss": 0.027475552633404732,
      "eval_runtime": 1068.4028,
      "eval_samples_per_second": 0.191,
      "eval_steps_per_second": 0.191,
      "step": 457
    },
    {
      "epoch": 1.0021881838074398,
      "grad_norm": 0.5310498476028442,
      "learning_rate": 5.85569199765534e-06,
      "loss": 0.0449,
      "step": 458
    },
    {
      "epoch": 1.0043763676148796,
      "grad_norm": 0.17475664615631104,
      "learning_rate": 5.836858271317276e-06,
      "loss": 0.0041,
      "step": 459
    },
    {
      "epoch": 1.0065645514223194,
      "grad_norm": 0.1306382268667221,
      "learning_rate": 5.818012321143773e-06,
      "loss": 0.0038,
      "step": 460
    },
    {
      "epoch": 1.0087527352297594,
      "grad_norm": 0.208683043718338,
      "learning_rate": 5.799154422414174e-06,
      "loss": 0.0032,
      "step": 461
    },
    {
      "epoch": 1.0109409190371992,
      "grad_norm": 0.0048950607888400555,
      "learning_rate": 5.780284850582348e-06,
      "loss": 0.0001,
      "step": 462
    },
    {
      "epoch": 1.013129102844639,
      "grad_norm": 0.921466052532196,
      "learning_rate": 5.761403881272678e-06,
      "loss": 0.0222,
      "step": 463
    },
    {
      "epoch": 1.0153172866520788,
      "grad_norm": 0.1313224583864212,
      "learning_rate": 5.7425117902760195e-06,
      "loss": 0.0044,
      "step": 464
    },
    {
      "epoch": 1.0175054704595186,
      "grad_norm": 0.0262486282736063,
      "learning_rate": 5.723608853545684e-06,
      "loss": 0.001,
      "step": 465
    },
    {
      "epoch": 1.0196936542669583,
      "grad_norm": 0.09037816524505615,
      "learning_rate": 5.704695347193409e-06,
      "loss": 0.0035,
      "step": 466
    },
    {
      "epoch": 1.0218818380743981,
      "grad_norm": 0.11030714958906174,
      "learning_rate": 5.685771547485312e-06,
      "loss": 0.0042,
      "step": 467
    },
    {
      "epoch": 1.0240700218818382,
      "grad_norm": 0.33506152033805847,
      "learning_rate": 5.66683773083787e-06,
      "loss": 0.0107,
      "step": 468
    },
    {
      "epoch": 1.026258205689278,
      "grad_norm": 0.06302671879529953,
      "learning_rate": 5.647894173813871e-06,
      "loss": 0.0026,
      "step": 469
    },
    {
      "epoch": 1.0284463894967177,
      "grad_norm": 0.09121965616941452,
      "learning_rate": 5.628941153118388e-06,
      "loss": 0.0029,
      "step": 470
    },
    {
      "epoch": 1.0306345733041575,
      "grad_norm": 1.6314589977264404,
      "learning_rate": 5.609978945594715e-06,
      "loss": 0.1544,
      "step": 471
    },
    {
      "epoch": 1.0328227571115973,
      "grad_norm": 0.012015029788017273,
      "learning_rate": 5.591007828220346e-06,
      "loss": 0.0004,
      "step": 472
    },
    {
      "epoch": 1.0350109409190371,
      "grad_norm": 0.334236741065979,
      "learning_rate": 5.572028078102917e-06,
      "loss": 0.0043,
      "step": 473
    },
    {
      "epoch": 1.0371991247264771,
      "grad_norm": 0.09103519469499588,
      "learning_rate": 5.5530399724761585e-06,
      "loss": 0.0033,
      "step": 474
    },
    {
      "epoch": 1.039387308533917,
      "grad_norm": 0.34914252161979675,
      "learning_rate": 5.534043788695852e-06,
      "loss": 0.0401,
      "step": 475
    },
    {
      "epoch": 1.0415754923413567,
      "grad_norm": 0.422763854265213,
      "learning_rate": 5.515039804235772e-06,
      "loss": 0.0176,
      "step": 476
    },
    {
      "epoch": 1.0437636761487965,
      "grad_norm": 0.4805803596973419,
      "learning_rate": 5.49602829668364e-06,
      "loss": 0.0157,
      "step": 477
    },
    {
      "epoch": 1.0459518599562363,
      "grad_norm": 0.2981390655040741,
      "learning_rate": 5.477009543737062e-06,
      "loss": 0.0094,
      "step": 478
    },
    {
      "epoch": 1.048140043763676,
      "grad_norm": 1.857564091682434,
      "learning_rate": 5.457983823199475e-06,
      "loss": 0.0249,
      "step": 479
    },
    {
      "epoch": 1.0503282275711159,
      "grad_norm": 0.20245487987995148,
      "learning_rate": 5.438951412976099e-06,
      "loss": 0.0114,
      "step": 480
    },
    {
      "epoch": 1.052516411378556,
      "grad_norm": 0.03184625506401062,
      "learning_rate": 5.4199125910698565e-06,
      "loss": 0.0007,
      "step": 481
    },
    {
      "epoch": 1.0547045951859957,
      "grad_norm": 0.2559829354286194,
      "learning_rate": 5.400867635577335e-06,
      "loss": 0.0079,
      "step": 482
    },
    {
      "epoch": 1.0568927789934355,
      "grad_norm": 0.08915668725967407,
      "learning_rate": 5.381816824684708e-06,
      "loss": 0.0019,
      "step": 483
    },
    {
      "epoch": 1.0590809628008753,
      "grad_norm": 0.643324613571167,
      "learning_rate": 5.3627604366636806e-06,
      "loss": 0.0098,
      "step": 484
    },
    {
      "epoch": 1.061269146608315,
      "grad_norm": 0.02167551778256893,
      "learning_rate": 5.343698749867421e-06,
      "loss": 0.0006,
      "step": 485
    },
    {
      "epoch": 1.0634573304157549,
      "grad_norm": 0.057922013103961945,
      "learning_rate": 5.324632042726494e-06,
      "loss": 0.0012,
      "step": 486
    },
    {
      "epoch": 1.0656455142231946,
      "grad_norm": 0.19980160892009735,
      "learning_rate": 5.3055605937448005e-06,
      "loss": 0.0067,
      "step": 487
    },
    {
      "epoch": 1.0678336980306347,
      "grad_norm": 0.04264837130904198,
      "learning_rate": 5.2864846814955e-06,
      "loss": 0.0012,
      "step": 488
    },
    {
      "epoch": 1.0700218818380745,
      "grad_norm": 0.004501139745116234,
      "learning_rate": 5.267404584616946e-06,
      "loss": 0.0002,
      "step": 489
    },
    {
      "epoch": 1.0722100656455142,
      "grad_norm": 0.15481777489185333,
      "learning_rate": 5.24832058180862e-06,
      "loss": 0.0033,
      "step": 490
    },
    {
      "epoch": 1.074398249452954,
      "grad_norm": 0.004892715252935886,
      "learning_rate": 5.229232951827054e-06,
      "loss": 0.0002,
      "step": 491
    },
    {
      "epoch": 1.0765864332603938,
      "grad_norm": 0.013197368010878563,
      "learning_rate": 5.21014197348176e-06,
      "loss": 0.0004,
      "step": 492
    },
    {
      "epoch": 1.0787746170678336,
      "grad_norm": 1.1321593523025513,
      "learning_rate": 5.1910479256311616e-06,
      "loss": 0.0313,
      "step": 493
    },
    {
      "epoch": 1.0809628008752736,
      "grad_norm": 1.945275068283081,
      "learning_rate": 5.17195108717852e-06,
      "loss": 0.2634,
      "step": 494
    },
    {
      "epoch": 1.0831509846827134,
      "grad_norm": 1.052162766456604,
      "learning_rate": 5.152851737067851e-06,
      "loss": 0.0206,
      "step": 495
    },
    {
      "epoch": 1.0853391684901532,
      "grad_norm": 0.010176599957048893,
      "learning_rate": 5.1337501542798666e-06,
      "loss": 0.0003,
      "step": 496
    },
    {
      "epoch": 1.087527352297593,
      "grad_norm": 0.028431052342057228,
      "learning_rate": 5.114646617827884e-06,
      "loss": 0.0007,
      "step": 497
    },
    {
      "epoch": 1.0897155361050328,
      "grad_norm": 0.23608814179897308,
      "learning_rate": 5.0955414067537605e-06,
      "loss": 0.0069,
      "step": 498
    },
    {
      "epoch": 1.0919037199124726,
      "grad_norm": 0.023809678852558136,
      "learning_rate": 5.076434800123814e-06,
      "loss": 0.001,
      "step": 499
    },
    {
      "epoch": 1.0940919037199124,
      "grad_norm": 0.02997029572725296,
      "learning_rate": 5.057327077024745e-06,
      "loss": 0.0011,
      "step": 500
    },
    {
      "epoch": 1.0962800875273524,
      "grad_norm": 0.004118496086448431,
      "learning_rate": 5.038218516559568e-06,
      "loss": 0.0002,
      "step": 501
    },
    {
      "epoch": 1.0984682713347922,
      "grad_norm": 0.013137035071849823,
      "learning_rate": 5.01910939784352e-06,
      "loss": 0.0004,
      "step": 502
    },
    {
      "epoch": 1.100656455142232,
      "grad_norm": 2.365600347518921,
      "learning_rate": 5e-06,
      "loss": 0.0828,
      "step": 503
    },
    {
      "epoch": 1.1028446389496718,
      "grad_norm": 0.24550624191761017,
      "learning_rate": 4.9808906021564805e-06,
      "loss": 0.0038,
      "step": 504
    },
    {
      "epoch": 1.1050328227571116,
      "grad_norm": 0.018627066165208817,
      "learning_rate": 4.961781483440434e-06,
      "loss": 0.0008,
      "step": 505
    },
    {
      "epoch": 1.1072210065645514,
      "grad_norm": 0.018091848120093346,
      "learning_rate": 4.942672922975255e-06,
      "loss": 0.0006,
      "step": 506
    },
    {
      "epoch": 1.1094091903719911,
      "grad_norm": 0.7504751682281494,
      "learning_rate": 4.923565199876188e-06,
      "loss": 0.0495,
      "step": 507
    },
    {
      "epoch": 1.1115973741794312,
      "grad_norm": 0.46081089973449707,
      "learning_rate": 4.90445859324624e-06,
      "loss": 0.0069,
      "step": 508
    },
    {
      "epoch": 1.113785557986871,
      "grad_norm": 1.4669749736785889,
      "learning_rate": 4.8853533821721175e-06,
      "loss": 0.1037,
      "step": 509
    },
    {
      "epoch": 1.1159737417943107,
      "grad_norm": 0.3610871434211731,
      "learning_rate": 4.866249845720133e-06,
      "loss": 0.0677,
      "step": 510
    },
    {
      "epoch": 1.1181619256017505,
      "grad_norm": 0.009631766006350517,
      "learning_rate": 4.84714826293215e-06,
      "loss": 0.0004,
      "step": 511
    },
    {
      "epoch": 1.1203501094091903,
      "grad_norm": 2.7481284141540527,
      "learning_rate": 4.82804891282148e-06,
      "loss": 0.0421,
      "step": 512
    },
    {
      "epoch": 1.1225382932166301,
      "grad_norm": 0.04408092424273491,
      "learning_rate": 4.808952074368839e-06,
      "loss": 0.0013,
      "step": 513
    },
    {
      "epoch": 1.12472647702407,
      "grad_norm": 0.0022691551130264997,
      "learning_rate": 4.78985802651824e-06,
      "loss": 0.0001,
      "step": 514
    },
    {
      "epoch": 1.12691466083151,
      "grad_norm": 2.919671058654785,
      "learning_rate": 4.770767048172948e-06,
      "loss": 0.11,
      "step": 515
    },
    {
      "epoch": 1.1291028446389497,
      "grad_norm": 0.0024850398767739534,
      "learning_rate": 4.751679418191381e-06,
      "loss": 0.0001,
      "step": 516
    },
    {
      "epoch": 1.1312910284463895,
      "grad_norm": 0.02499239705502987,
      "learning_rate": 4.732595415383055e-06,
      "loss": 0.0008,
      "step": 517
    },
    {
      "epoch": 1.1334792122538293,
      "grad_norm": 0.4511857032775879,
      "learning_rate": 4.713515318504501e-06,
      "loss": 0.0236,
      "step": 518
    },
    {
      "epoch": 1.135667396061269,
      "grad_norm": 0.03140801563858986,
      "learning_rate": 4.6944394062552e-06,
      "loss": 0.0011,
      "step": 519
    },
    {
      "epoch": 1.1378555798687089,
      "grad_norm": 0.2181788682937622,
      "learning_rate": 4.675367957273506e-06,
      "loss": 0.0098,
      "step": 520
    },
    {
      "epoch": 1.140043763676149,
      "grad_norm": 0.05910841003060341,
      "learning_rate": 4.656301250132581e-06,
      "loss": 0.002,
      "step": 521
    },
    {
      "epoch": 1.1422319474835887,
      "grad_norm": 0.8741039037704468,
      "learning_rate": 4.63723956333632e-06,
      "loss": 0.0715,
      "step": 522
    },
    {
      "epoch": 1.1444201312910285,
      "grad_norm": 1.6047146320343018,
      "learning_rate": 4.618183175315293e-06,
      "loss": 0.0291,
      "step": 523
    },
    {
      "epoch": 1.1466083150984683,
      "grad_norm": 0.0016190058086067438,
      "learning_rate": 4.599132364422666e-06,
      "loss": 0.0001,
      "step": 524
    },
    {
      "epoch": 1.148796498905908,
      "grad_norm": 0.058913808315992355,
      "learning_rate": 4.580087408930146e-06,
      "loss": 0.0019,
      "step": 525
    },
    {
      "epoch": 1.1509846827133479,
      "grad_norm": 3.930675506591797,
      "learning_rate": 4.561048587023903e-06,
      "loss": 0.1421,
      "step": 526
    },
    {
      "epoch": 1.1531728665207877,
      "grad_norm": 0.1830427497625351,
      "learning_rate": 4.542016176800527e-06,
      "loss": 0.0052,
      "step": 527
    },
    {
      "epoch": 1.1553610503282277,
      "grad_norm": 0.3432266116142273,
      "learning_rate": 4.522990456262939e-06,
      "loss": 0.0191,
      "step": 528
    },
    {
      "epoch": 1.1575492341356675,
      "grad_norm": 0.012457638047635555,
      "learning_rate": 4.5039717033163625e-06,
      "loss": 0.0005,
      "step": 529
    },
    {
      "epoch": 1.1597374179431073,
      "grad_norm": 0.9039366245269775,
      "learning_rate": 4.4849601957642295e-06,
      "loss": 0.0306,
      "step": 530
    },
    {
      "epoch": 1.161925601750547,
      "grad_norm": 0.002989020198583603,
      "learning_rate": 4.465956211304151e-06,
      "loss": 0.0001,
      "step": 531
    },
    {
      "epoch": 1.1641137855579868,
      "grad_norm": 0.14291715621948242,
      "learning_rate": 4.446960027523843e-06,
      "loss": 0.0029,
      "step": 532
    },
    {
      "epoch": 1.1663019693654266,
      "grad_norm": 1.0184720754623413,
      "learning_rate": 4.427971921897086e-06,
      "loss": 0.046,
      "step": 533
    },
    {
      "epoch": 1.1684901531728666,
      "grad_norm": 0.03841979801654816,
      "learning_rate": 4.408992171779655e-06,
      "loss": 0.0007,
      "step": 534
    },
    {
      "epoch": 1.1706783369803064,
      "grad_norm": 0.001415195525623858,
      "learning_rate": 4.3900210544052865e-06,
      "loss": 0.0001,
      "step": 535
    },
    {
      "epoch": 1.1728665207877462,
      "grad_norm": 0.9374512434005737,
      "learning_rate": 4.371058846881614e-06,
      "loss": 0.0282,
      "step": 536
    },
    {
      "epoch": 1.175054704595186,
      "grad_norm": 0.12369339913129807,
      "learning_rate": 4.3521058261861295e-06,
      "loss": 0.0028,
      "step": 537
    },
    {
      "epoch": 1.1772428884026258,
      "grad_norm": 2.4910271167755127,
      "learning_rate": 4.333162269162132e-06,
      "loss": 0.1538,
      "step": 538
    },
    {
      "epoch": 1.1794310722100656,
      "grad_norm": 0.10901852697134018,
      "learning_rate": 4.3142284525146915e-06,
      "loss": 0.0034,
      "step": 539
    },
    {
      "epoch": 1.1816192560175054,
      "grad_norm": 0.011469028890132904,
      "learning_rate": 4.295304652806592e-06,
      "loss": 0.0004,
      "step": 540
    },
    {
      "epoch": 1.1838074398249452,
      "grad_norm": 3.7362425327301025,
      "learning_rate": 4.276391146454315e-06,
      "loss": 0.1151,
      "step": 541
    },
    {
      "epoch": 1.1859956236323852,
      "grad_norm": 0.06888163834810257,
      "learning_rate": 4.257488209723981e-06,
      "loss": 0.0024,
      "step": 542
    },
    {
      "epoch": 1.188183807439825,
      "grad_norm": 0.012961096130311489,
      "learning_rate": 4.238596118727322e-06,
      "loss": 0.0004,
      "step": 543
    },
    {
      "epoch": 1.1903719912472648,
      "grad_norm": 0.08756019920110703,
      "learning_rate": 4.219715149417653e-06,
      "loss": 0.0017,
      "step": 544
    },
    {
      "epoch": 1.1925601750547046,
      "grad_norm": 0.0005425404524430633,
      "learning_rate": 4.200845577585827e-06,
      "loss": 0.0001,
      "step": 545
    },
    {
      "epoch": 1.1947483588621444,
      "grad_norm": 0.03380338102579117,
      "learning_rate": 4.181987678856229e-06,
      "loss": 0.0011,
      "step": 546
    },
    {
      "epoch": 1.1969365426695842,
      "grad_norm": 0.23451749980449677,
      "learning_rate": 4.163141728682725e-06,
      "loss": 0.0035,
      "step": 547
    },
    {
      "epoch": 1.1991247264770242,
      "grad_norm": 0.1442723274230957,
      "learning_rate": 4.1443080023446605e-06,
      "loss": 0.004,
      "step": 548
    },
    {
      "epoch": 1.201312910284464,
      "grad_norm": 0.0354524627327919,
      "learning_rate": 4.125486774942823e-06,
      "loss": 0.001,
      "step": 549
    },
    {
      "epoch": 1.2035010940919038,
      "grad_norm": 0.01750141941010952,
      "learning_rate": 4.1066783213954335e-06,
      "loss": 0.0004,
      "step": 550
    },
    {
      "epoch": 1.2056892778993435,
      "grad_norm": 0.001331291743554175,
      "learning_rate": 4.087882916434126e-06,
      "loss": 0.0001,
      "step": 551
    },
    {
      "epoch": 1.2078774617067833,
      "grad_norm": 0.005633682943880558,
      "learning_rate": 4.069100834599939e-06,
      "loss": 0.0002,
      "step": 552
    },
    {
      "epoch": 1.2100656455142231,
      "grad_norm": 0.0022530988790094852,
      "learning_rate": 4.0503323502392985e-06,
      "loss": 0.0001,
      "step": 553
    },
    {
      "epoch": 1.212253829321663,
      "grad_norm": 0.031950172036886215,
      "learning_rate": 4.0315777375000185e-06,
      "loss": 0.0009,
      "step": 554
    },
    {
      "epoch": 1.214442013129103,
      "grad_norm": 0.014766816049814224,
      "learning_rate": 4.012837270327288e-06,
      "loss": 0.0005,
      "step": 555
    },
    {
      "epoch": 1.2166301969365427,
      "grad_norm": 0.15900494158267975,
      "learning_rate": 3.994111222459682e-06,
      "loss": 0.0027,
      "step": 556
    },
    {
      "epoch": 1.2188183807439825,
      "grad_norm": 1.1887288093566895,
      "learning_rate": 3.975399867425146e-06,
      "loss": 0.0214,
      "step": 557
    },
    {
      "epoch": 1.2210065645514223,
      "grad_norm": 0.24474723637104034,
      "learning_rate": 3.956703478537019e-06,
      "loss": 0.0056,
      "step": 558
    },
    {
      "epoch": 1.223194748358862,
      "grad_norm": 1.1684974431991577,
      "learning_rate": 3.938022328890022e-06,
      "loss": 0.0771,
      "step": 559
    },
    {
      "epoch": 1.225382932166302,
      "grad_norm": 0.29513147473335266,
      "learning_rate": 3.9193566913562915e-06,
      "loss": 0.0082,
      "step": 560
    },
    {
      "epoch": 1.227571115973742,
      "grad_norm": 0.02613409049808979,
      "learning_rate": 3.9007068385813715e-06,
      "loss": 0.0008,
      "step": 561
    },
    {
      "epoch": 1.2297592997811817,
      "grad_norm": 1.5882216691970825,
      "learning_rate": 3.882073042980245e-06,
      "loss": 0.0908,
      "step": 562
    },
    {
      "epoch": 1.2319474835886215,
      "grad_norm": 0.02386835217475891,
      "learning_rate": 3.863455576733349e-06,
      "loss": 0.0007,
      "step": 563
    },
    {
      "epoch": 1.2341356673960613,
      "grad_norm": 0.051303692162036896,
      "learning_rate": 3.844854711782605e-06,
      "loss": 0.0016,
      "step": 564
    },
    {
      "epoch": 1.236323851203501,
      "grad_norm": 0.7062582969665527,
      "learning_rate": 3.8262707198274354e-06,
      "loss": 0.0661,
      "step": 565
    },
    {
      "epoch": 1.2385120350109409,
      "grad_norm": 0.0021141234319657087,
      "learning_rate": 3.807703872320809e-06,
      "loss": 0.0001,
      "step": 566
    },
    {
      "epoch": 1.2407002188183807,
      "grad_norm": 0.21506376564502716,
      "learning_rate": 3.7891544404652637e-06,
      "loss": 0.0043,
      "step": 567
    },
    {
      "epoch": 1.2428884026258205,
      "grad_norm": 0.3977079689502716,
      "learning_rate": 3.770622695208953e-06,
      "loss": 0.0152,
      "step": 568
    },
    {
      "epoch": 1.2450765864332605,
      "grad_norm": 0.035054102540016174,
      "learning_rate": 3.752108907241682e-06,
      "loss": 0.0012,
      "step": 569
    },
    {
      "epoch": 1.2472647702407003,
      "grad_norm": 0.557714581489563,
      "learning_rate": 3.733613346990963e-06,
      "loss": 0.0098,
      "step": 570
    },
    {
      "epoch": 1.24945295404814,
      "grad_norm": 0.15600137412548065,
      "learning_rate": 3.715136284618053e-06,
      "loss": 0.004,
      "step": 571
    },
    {
      "epoch": 1.2516411378555798,
      "grad_norm": 0.04984314739704132,
      "learning_rate": 3.6966779900140193e-06,
      "loss": 0.0013,
      "step": 572
    },
    {
      "epoch": 1.2538293216630196,
      "grad_norm": 0.01401008665561676,
      "learning_rate": 3.6782387327957837e-06,
      "loss": 0.0004,
      "step": 573
    },
    {
      "epoch": 1.2560175054704596,
      "grad_norm": 0.002173016080632806,
      "learning_rate": 3.659818782302206e-06,
      "loss": 0.0001,
      "step": 574
    },
    {
      "epoch": 1.2582056892778994,
      "grad_norm": 0.012276025488972664,
      "learning_rate": 3.6414184075901206e-06,
      "loss": 0.0004,
      "step": 575
    },
    {
      "epoch": 1.2603938730853392,
      "grad_norm": 0.01969842240214348,
      "learning_rate": 3.623037877430434e-06,
      "loss": 0.0003,
      "step": 576
    },
    {
      "epoch": 1.262582056892779,
      "grad_norm": 0.2928439974784851,
      "learning_rate": 3.6046774603041813e-06,
      "loss": 0.0094,
      "step": 577
    },
    {
      "epoch": 1.2647702407002188,
      "grad_norm": 1.886967658996582,
      "learning_rate": 3.586337424398609e-06,
      "loss": 0.1071,
      "step": 578
    },
    {
      "epoch": 1.2669584245076586,
      "grad_norm": 0.03929109871387482,
      "learning_rate": 3.5680180376032675e-06,
      "loss": 0.0011,
      "step": 579
    },
    {
      "epoch": 1.2691466083150984,
      "grad_norm": 0.9152197241783142,
      "learning_rate": 3.549719567506077e-06,
      "loss": 0.0325,
      "step": 580
    },
    {
      "epoch": 1.2713347921225382,
      "grad_norm": 1.3402562141418457,
      "learning_rate": 3.5314422813894413e-06,
      "loss": 0.1224,
      "step": 581
    },
    {
      "epoch": 1.273522975929978,
      "grad_norm": 0.0029079008381813765,
      "learning_rate": 3.5131864462263266e-06,
      "loss": 0.0001,
      "step": 582
    },
    {
      "epoch": 1.275711159737418,
      "grad_norm": 0.10281231254339218,
      "learning_rate": 3.494952328676376e-06,
      "loss": 0.0029,
      "step": 583
    },
    {
      "epoch": 1.2778993435448578,
      "grad_norm": 0.0021679517813026905,
      "learning_rate": 3.4767401950820003e-06,
      "loss": 0.0001,
      "step": 584
    },
    {
      "epoch": 1.2800875273522976,
      "grad_norm": 0.0018890213686972857,
      "learning_rate": 3.4585503114645002e-06,
      "loss": 0.0001,
      "step": 585
    },
    {
      "epoch": 1.2822757111597374,
      "grad_norm": 0.006605660077184439,
      "learning_rate": 3.440382943520172e-06,
      "loss": 0.0002,
      "step": 586
    },
    {
      "epoch": 1.2844638949671772,
      "grad_norm": 0.739928662776947,
      "learning_rate": 3.4222383566164314e-06,
      "loss": 0.0789,
      "step": 587
    },
    {
      "epoch": 1.2866520787746172,
      "grad_norm": 0.3476693332195282,
      "learning_rate": 3.4041168157879336e-06,
      "loss": 0.0614,
      "step": 588
    },
    {
      "epoch": 1.288840262582057,
      "grad_norm": 0.216409832239151,
      "learning_rate": 3.3860185857327066e-06,
      "loss": 0.0061,
      "step": 589
    },
    {
      "epoch": 1.2910284463894968,
      "grad_norm": 0.026452746242284775,
      "learning_rate": 3.3679439308082777e-06,
      "loss": 0.0007,
      "step": 590
    },
    {
      "epoch": 1.2932166301969366,
      "grad_norm": 0.5615349411964417,
      "learning_rate": 3.349893115027826e-06,
      "loss": 0.0114,
      "step": 591
    },
    {
      "epoch": 1.2954048140043763,
      "grad_norm": 2.103811502456665,
      "learning_rate": 3.331866402056302e-06,
      "loss": 0.1559,
      "step": 592
    },
    {
      "epoch": 1.2975929978118161,
      "grad_norm": 0.10288205742835999,
      "learning_rate": 3.313864055206607e-06,
      "loss": 0.0028,
      "step": 593
    },
    {
      "epoch": 1.299781181619256,
      "grad_norm": 0.31864133477211,
      "learning_rate": 3.295886337435717e-06,
      "loss": 0.0082,
      "step": 594
    },
    {
      "epoch": 1.3019693654266957,
      "grad_norm": 0.09068716317415237,
      "learning_rate": 3.2779335113408652e-06,
      "loss": 0.0026,
      "step": 595
    },
    {
      "epoch": 1.3041575492341357,
      "grad_norm": 0.06961800158023834,
      "learning_rate": 3.260005839155691e-06,
      "loss": 0.0023,
      "step": 596
    },
    {
      "epoch": 1.3063457330415755,
      "grad_norm": 1.121882438659668,
      "learning_rate": 3.2421035827464193e-06,
      "loss": 0.044,
      "step": 597
    },
    {
      "epoch": 1.3085339168490153,
      "grad_norm": 1.1684411764144897,
      "learning_rate": 3.224227003608027e-06,
      "loss": 0.0982,
      "step": 598
    },
    {
      "epoch": 1.3107221006564551,
      "grad_norm": 0.21572674810886383,
      "learning_rate": 3.206376362860432e-06,
      "loss": 0.0071,
      "step": 599
    },
    {
      "epoch": 1.312910284463895,
      "grad_norm": 2.36982798576355,
      "learning_rate": 3.188551921244672e-06,
      "loss": 0.1609,
      "step": 600
    },
    {
      "epoch": 1.315098468271335,
      "grad_norm": 0.36822307109832764,
      "learning_rate": 3.170753939119101e-06,
      "loss": 0.0439,
      "step": 601
    },
    {
      "epoch": 1.3172866520787747,
      "grad_norm": 0.2330097258090973,
      "learning_rate": 3.152982676455581e-06,
      "loss": 0.0068,
      "step": 602
    },
    {
      "epoch": 1.3194748358862145,
      "grad_norm": 1.5132533311843872,
      "learning_rate": 3.135238392835693e-06,
      "loss": 0.0593,
      "step": 603
    },
    {
      "epoch": 1.3216630196936543,
      "grad_norm": 0.007696868386119604,
      "learning_rate": 3.1175213474469313e-06,
      "loss": 0.0003,
      "step": 604
    },
    {
      "epoch": 1.323851203501094,
      "grad_norm": 0.04123544692993164,
      "learning_rate": 3.0998317990789378e-06,
      "loss": 0.0011,
      "step": 605
    },
    {
      "epoch": 1.3260393873085339,
      "grad_norm": 0.08583663403987885,
      "learning_rate": 3.0821700061196986e-06,
      "loss": 0.0031,
      "step": 606
    },
    {
      "epoch": 1.3282275711159737,
      "grad_norm": 0.012993955984711647,
      "learning_rate": 3.0645362265517932e-06,
      "loss": 0.0005,
      "step": 607
    },
    {
      "epoch": 1.3304157549234135,
      "grad_norm": 1.812183141708374,
      "learning_rate": 3.046930717948604e-06,
      "loss": 0.1283,
      "step": 608
    },
    {
      "epoch": 1.3326039387308533,
      "grad_norm": 0.0637216717004776,
      "learning_rate": 3.029353737470573e-06,
      "loss": 0.0018,
      "step": 609
    },
    {
      "epoch": 1.3347921225382933,
      "grad_norm": 0.011659380048513412,
      "learning_rate": 3.01180554186143e-06,
      "loss": 0.0004,
      "step": 610
    },
    {
      "epoch": 1.336980306345733,
      "grad_norm": 0.08092790096998215,
      "learning_rate": 2.9942863874444565e-06,
      "loss": 0.002,
      "step": 611
    },
    {
      "epoch": 1.3391684901531729,
      "grad_norm": 0.0022978426422923803,
      "learning_rate": 2.9767965301187285e-06,
      "loss": 0.0001,
      "step": 612
    },
    {
      "epoch": 1.3413566739606126,
      "grad_norm": 0.0019286281894892454,
      "learning_rate": 2.9593362253553902e-06,
      "loss": 0.0001,
      "step": 613
    },
    {
      "epoch": 1.3435448577680524,
      "grad_norm": 0.33591538667678833,
      "learning_rate": 2.9419057281939106e-06,
      "loss": 0.0173,
      "step": 614
    },
    {
      "epoch": 1.3457330415754925,
      "grad_norm": 0.05268513411283493,
      "learning_rate": 2.924505293238371e-06,
      "loss": 0.0016,
      "step": 615
    },
    {
      "epoch": 1.3479212253829322,
      "grad_norm": 0.11633987724781036,
      "learning_rate": 2.9071351746537358e-06,
      "loss": 0.0039,
      "step": 616
    },
    {
      "epoch": 1.350109409190372,
      "grad_norm": 0.1542436182498932,
      "learning_rate": 2.889795626162143e-06,
      "loss": 0.0048,
      "step": 617
    },
    {
      "epoch": 1.3522975929978118,
      "grad_norm": 0.03783348575234413,
      "learning_rate": 2.8724869010392043e-06,
      "loss": 0.001,
      "step": 618
    },
    {
      "epoch": 1.3544857768052516,
      "grad_norm": 0.03007405437529087,
      "learning_rate": 2.8552092521102925e-06,
      "loss": 0.0008,
      "step": 619
    },
    {
      "epoch": 1.3566739606126914,
      "grad_norm": 1.1710456609725952,
      "learning_rate": 2.8379629317468604e-06,
      "loss": 0.0728,
      "step": 620
    },
    {
      "epoch": 1.3588621444201312,
      "grad_norm": 0.09784366935491562,
      "learning_rate": 2.82074819186275e-06,
      "loss": 0.0031,
      "step": 621
    },
    {
      "epoch": 1.361050328227571,
      "grad_norm": 0.27069535851478577,
      "learning_rate": 2.803565283910515e-06,
      "loss": 0.0083,
      "step": 622
    },
    {
      "epoch": 1.363238512035011,
      "grad_norm": 0.00993876438587904,
      "learning_rate": 2.7864144588777403e-06,
      "loss": 0.0003,
      "step": 623
    },
    {
      "epoch": 1.3654266958424508,
      "grad_norm": 0.14202679693698883,
      "learning_rate": 2.7692959672833857e-06,
      "loss": 0.0037,
      "step": 624
    },
    {
      "epoch": 1.3676148796498906,
      "grad_norm": 0.048412080854177475,
      "learning_rate": 2.752210059174122e-06,
      "loss": 0.0013,
      "step": 625
    },
    {
      "epoch": 1.3698030634573304,
      "grad_norm": 0.8313731551170349,
      "learning_rate": 2.7351569841206792e-06,
      "loss": 0.0639,
      "step": 626
    },
    {
      "epoch": 1.3719912472647702,
      "grad_norm": 0.026850279420614243,
      "learning_rate": 2.7181369912141976e-06,
      "loss": 0.0007,
      "step": 627
    },
    {
      "epoch": 1.3741794310722102,
      "grad_norm": 0.6351528763771057,
      "learning_rate": 2.7011503290625985e-06,
      "loss": 0.0242,
      "step": 628
    },
    {
      "epoch": 1.37636761487965,
      "grad_norm": 0.44622549414634705,
      "learning_rate": 2.684197245786938e-06,
      "loss": 0.0219,
      "step": 629
    },
    {
      "epoch": 1.3785557986870898,
      "grad_norm": 0.04326602816581726,
      "learning_rate": 2.6672779890178046e-06,
      "loss": 0.0015,
      "step": 630
    },
    {
      "epoch": 1.3807439824945296,
      "grad_norm": 0.000598371378146112,
      "learning_rate": 2.6503928058916768e-06,
      "loss": 0.0001,
      "step": 631
    },
    {
      "epoch": 1.3829321663019694,
      "grad_norm": 0.9040973782539368,
      "learning_rate": 2.633541943047334e-06,
      "loss": 0.0315,
      "step": 632
    },
    {
      "epoch": 1.3851203501094091,
      "grad_norm": 0.008894543163478374,
      "learning_rate": 2.6167256466222384e-06,
      "loss": 0.0004,
      "step": 633
    },
    {
      "epoch": 1.387308533916849,
      "grad_norm": 0.029044488444924355,
      "learning_rate": 2.5999441622489533e-06,
      "loss": 0.0008,
      "step": 634
    },
    {
      "epoch": 1.3894967177242887,
      "grad_norm": 2.2400875091552734,
      "learning_rate": 2.583197735051546e-06,
      "loss": 0.0799,
      "step": 635
    },
    {
      "epoch": 1.3916849015317287,
      "grad_norm": 0.008299247361719608,
      "learning_rate": 2.5664866096420115e-06,
      "loss": 0.0002,
      "step": 636
    },
    {
      "epoch": 1.3938730853391685,
      "grad_norm": 0.15219300985336304,
      "learning_rate": 2.5498110301166946e-06,
      "loss": 0.0047,
      "step": 637
    },
    {
      "epoch": 1.3960612691466083,
      "grad_norm": 0.16640599071979523,
      "learning_rate": 2.53317124005273e-06,
      "loss": 0.0071,
      "step": 638
    },
    {
      "epoch": 1.3982494529540481,
      "grad_norm": 0.01229644101113081,
      "learning_rate": 2.516567482504484e-06,
      "loss": 0.0004,
      "step": 639
    },
    {
      "epoch": 1.400437636761488,
      "grad_norm": 0.03489181399345398,
      "learning_rate": 2.5000000000000015e-06,
      "loss": 0.001,
      "step": 640
    },
    {
      "epoch": 1.402625820568928,
      "grad_norm": 1.7849284410476685,
      "learning_rate": 2.4834690345374608e-06,
      "loss": 0.1383,
      "step": 641
    },
    {
      "epoch": 1.4048140043763677,
      "grad_norm": 0.005193118471652269,
      "learning_rate": 2.4669748275816475e-06,
      "loss": 0.0002,
      "step": 642
    },
    {
      "epoch": 1.4070021881838075,
      "grad_norm": 0.003676342312246561,
      "learning_rate": 2.45051762006042e-06,
      "loss": 0.0002,
      "step": 643
    },
    {
      "epoch": 1.4091903719912473,
      "grad_norm": 1.155608057975769,
      "learning_rate": 2.4340976523611957e-06,
      "loss": 0.0772,
      "step": 644
    },
    {
      "epoch": 1.411378555798687,
      "grad_norm": 0.10889638215303421,
      "learning_rate": 2.417715164327431e-06,
      "loss": 0.0043,
      "step": 645
    },
    {
      "epoch": 1.4135667396061269,
      "grad_norm": 0.8476166129112244,
      "learning_rate": 2.401370395255129e-06,
      "loss": 0.0228,
      "step": 646
    },
    {
      "epoch": 1.4157549234135667,
      "grad_norm": 0.40473034977912903,
      "learning_rate": 2.385063583889335e-06,
      "loss": 0.0048,
      "step": 647
    },
    {
      "epoch": 1.4179431072210065,
      "grad_norm": 0.036547787487506866,
      "learning_rate": 2.3687949684206552e-06,
      "loss": 0.0008,
      "step": 648
    },
    {
      "epoch": 1.4201312910284463,
      "grad_norm": 0.37558192014694214,
      "learning_rate": 2.352564786481776e-06,
      "loss": 0.0118,
      "step": 649
    },
    {
      "epoch": 1.4223194748358863,
      "grad_norm": 0.43886759877204895,
      "learning_rate": 2.3363732751439926e-06,
      "loss": 0.0357,
      "step": 650
    },
    {
      "epoch": 1.424507658643326,
      "grad_norm": 0.24887454509735107,
      "learning_rate": 2.320220670913741e-06,
      "loss": 0.0075,
      "step": 651
    },
    {
      "epoch": 1.4266958424507659,
      "grad_norm": 0.15765932202339172,
      "learning_rate": 2.304107209729153e-06,
      "loss": 0.0048,
      "step": 652
    },
    {
      "epoch": 1.4288840262582057,
      "grad_norm": 0.8568727970123291,
      "learning_rate": 2.2880331269566043e-06,
      "loss": 0.0123,
      "step": 653
    },
    {
      "epoch": 1.4310722100656454,
      "grad_norm": 0.09646005183458328,
      "learning_rate": 2.2719986573872767e-06,
      "loss": 0.0034,
      "step": 654
    },
    {
      "epoch": 1.4332603938730855,
      "grad_norm": 0.03073297068476677,
      "learning_rate": 2.2560040352337307e-06,
      "loss": 0.0008,
      "step": 655
    },
    {
      "epoch": 1.4354485776805253,
      "grad_norm": 0.021772321313619614,
      "learning_rate": 2.240049494126479e-06,
      "loss": 0.0006,
      "step": 656
    },
    {
      "epoch": 1.437636761487965,
      "grad_norm": 0.01642421819269657,
      "learning_rate": 2.2241352671105807e-06,
      "loss": 0.0005,
      "step": 657
    },
    {
      "epoch": 1.4398249452954048,
      "grad_norm": 0.31598740816116333,
      "learning_rate": 2.208261586642235e-06,
      "loss": 0.0066,
      "step": 658
    },
    {
      "epoch": 1.4420131291028446,
      "grad_norm": 1.0064377784729004,
      "learning_rate": 2.192428684585386e-06,
      "loss": 0.029,
      "step": 659
    },
    {
      "epoch": 1.4442013129102844,
      "grad_norm": 0.11065936833620071,
      "learning_rate": 2.1766367922083287e-06,
      "loss": 0.0035,
      "step": 660
    },
    {
      "epoch": 1.4463894967177242,
      "grad_norm": 0.28866052627563477,
      "learning_rate": 2.1608861401803456e-06,
      "loss": 0.0088,
      "step": 661
    },
    {
      "epoch": 1.448577680525164,
      "grad_norm": 0.22968675196170807,
      "learning_rate": 2.1451769585683196e-06,
      "loss": 0.0034,
      "step": 662
    },
    {
      "epoch": 1.450765864332604,
      "grad_norm": 1.3195995092391968,
      "learning_rate": 2.129509476833395e-06,
      "loss": 0.022,
      "step": 663
    },
    {
      "epoch": 1.4529540481400438,
      "grad_norm": 0.19656965136528015,
      "learning_rate": 2.1138839238276025e-06,
      "loss": 0.0068,
      "step": 664
    },
    {
      "epoch": 1.4551422319474836,
      "grad_norm": 0.11362072825431824,
      "learning_rate": 2.0983005277905348e-06,
      "loss": 0.0037,
      "step": 665
    },
    {
      "epoch": 1.4573304157549234,
      "grad_norm": 0.2922845482826233,
      "learning_rate": 2.082759516345999e-06,
      "loss": 0.0048,
      "step": 666
    },
    {
      "epoch": 1.4595185995623632,
      "grad_norm": 2.0079362392425537,
      "learning_rate": 2.067261116498704e-06,
      "loss": 0.1552,
      "step": 667
    },
    {
      "epoch": 1.4617067833698032,
      "grad_norm": 0.7521425485610962,
      "learning_rate": 2.0518055546309362e-06,
      "loss": 0.0394,
      "step": 668
    },
    {
      "epoch": 1.463894967177243,
      "grad_norm": 0.11959002166986465,
      "learning_rate": 2.036393056499258e-06,
      "loss": 0.0032,
      "step": 669
    },
    {
      "epoch": 1.4660831509846828,
      "grad_norm": 6.240545749664307,
      "learning_rate": 2.0210238472312023e-06,
      "loss": 0.0486,
      "step": 670
    },
    {
      "epoch": 1.4682713347921226,
      "grad_norm": 0.452983558177948,
      "learning_rate": 2.0056981513219944e-06,
      "loss": 0.0141,
      "step": 671
    },
    {
      "epoch": 1.4704595185995624,
      "grad_norm": 0.0009690610459074378,
      "learning_rate": 1.990416192631266e-06,
      "loss": 0.0001,
      "step": 672
    },
    {
      "epoch": 1.4726477024070022,
      "grad_norm": 0.24518121778964996,
      "learning_rate": 1.9751781943797906e-06,
      "loss": 0.0102,
      "step": 673
    },
    {
      "epoch": 1.474835886214442,
      "grad_norm": 2.2997660636901855,
      "learning_rate": 1.9599843791462123e-06,
      "loss": 0.4266,
      "step": 674
    },
    {
      "epoch": 1.4770240700218817,
      "grad_norm": 0.038095731288194656,
      "learning_rate": 1.9448349688638103e-06,
      "loss": 0.0004,
      "step": 675
    },
    {
      "epoch": 1.4792122538293215,
      "grad_norm": 0.23311495780944824,
      "learning_rate": 1.9297301848172396e-06,
      "loss": 0.0076,
      "step": 676
    },
    {
      "epoch": 1.4814004376367615,
      "grad_norm": 0.2264358252286911,
      "learning_rate": 1.91467024763932e-06,
      "loss": 0.0037,
      "step": 677
    },
    {
      "epoch": 1.4835886214442013,
      "grad_norm": 0.10607028752565384,
      "learning_rate": 1.8996553773077891e-06,
      "loss": 0.003,
      "step": 678
    },
    {
      "epoch": 1.4857768052516411,
      "grad_norm": 0.0009975522989407182,
      "learning_rate": 1.884685793142111e-06,
      "loss": 0.0001,
      "step": 679
    },
    {
      "epoch": 1.487964989059081,
      "grad_norm": 0.013961478136479855,
      "learning_rate": 1.8697617138002545e-06,
      "loss": 0.0003,
      "step": 680
    },
    {
      "epoch": 1.4901531728665207,
      "grad_norm": 0.06260855495929718,
      "learning_rate": 1.8548833572755143e-06,
      "loss": 0.0014,
      "step": 681
    },
    {
      "epoch": 1.4923413566739607,
      "grad_norm": 0.5903983116149902,
      "learning_rate": 1.8400509408933187e-06,
      "loss": 0.0621,
      "step": 682
    },
    {
      "epoch": 1.4945295404814005,
      "grad_norm": 0.03434540703892708,
      "learning_rate": 1.8252646813080566e-06,
      "loss": 0.0009,
      "step": 683
    },
    {
      "epoch": 1.4967177242888403,
      "grad_norm": 0.012868384830653667,
      "learning_rate": 1.81052479449991e-06,
      "loss": 0.0004,
      "step": 684
    },
    {
      "epoch": 1.49890590809628,
      "grad_norm": 0.7868210077285767,
      "learning_rate": 1.7958314957717065e-06,
      "loss": 0.0138,
      "step": 685
    },
    {
      "epoch": 1.50109409190372,
      "grad_norm": 0.3173501193523407,
      "learning_rate": 1.7811849997457681e-06,
      "loss": 0.0064,
      "step": 686
    },
    {
      "epoch": 1.5032822757111597,
      "grad_norm": 0.0006584413349628448,
      "learning_rate": 1.7665855203607813e-06,
      "loss": 0.0001,
      "step": 687
    },
    {
      "epoch": 1.5054704595185995,
      "grad_norm": 0.10924903303384781,
      "learning_rate": 1.7520332708686616e-06,
      "loss": 0.0024,
      "step": 688
    },
    {
      "epoch": 1.5076586433260393,
      "grad_norm": 3.0835776329040527,
      "learning_rate": 1.737528463831456e-06,
      "loss": 0.0246,
      "step": 689
    },
    {
      "epoch": 1.509846827133479,
      "grad_norm": 0.0030261334031820297,
      "learning_rate": 1.7230713111182169e-06,
      "loss": 0.0001,
      "step": 690
    },
    {
      "epoch": 1.512035010940919,
      "grad_norm": 0.0876956656575203,
      "learning_rate": 1.7086620239019309e-06,
      "loss": 0.0014,
      "step": 691
    },
    {
      "epoch": 1.5142231947483589,
      "grad_norm": 0.060410115867853165,
      "learning_rate": 1.6943008126564164e-06,
      "loss": 0.0014,
      "step": 692
    },
    {
      "epoch": 1.5164113785557987,
      "grad_norm": 0.029315883293747902,
      "learning_rate": 1.679987887153251e-06,
      "loss": 0.001,
      "step": 693
    },
    {
      "epoch": 1.5185995623632387,
      "grad_norm": 0.29006391763687134,
      "learning_rate": 1.6657234564587183e-06,
      "loss": 0.0083,
      "step": 694
    },
    {
      "epoch": 1.5207877461706785,
      "grad_norm": 0.016972312703728676,
      "learning_rate": 1.6515077289307391e-06,
      "loss": 0.0005,
      "step": 695
    },
    {
      "epoch": 1.5229759299781183,
      "grad_norm": 0.022300250828266144,
      "learning_rate": 1.6373409122158479e-06,
      "loss": 0.0006,
      "step": 696
    },
    {
      "epoch": 1.525164113785558,
      "grad_norm": 0.1572045087814331,
      "learning_rate": 1.623223213246135e-06,
      "loss": 0.0044,
      "step": 697
    },
    {
      "epoch": 1.5273522975929978,
      "grad_norm": 1.9676828384399414,
      "learning_rate": 1.609154838236246e-06,
      "loss": 0.0919,
      "step": 698
    },
    {
      "epoch": 1.5295404814004376,
      "grad_norm": 0.011577079072594643,
      "learning_rate": 1.5951359926803545e-06,
      "loss": 0.0002,
      "step": 699
    },
    {
      "epoch": 1.5317286652078774,
      "grad_norm": 0.06624346226453781,
      "learning_rate": 1.5811668813491699e-06,
      "loss": 0.0005,
      "step": 700
    },
    {
      "epoch": 1.5339168490153172,
      "grad_norm": 0.09473414719104767,
      "learning_rate": 1.567247708286942e-06,
      "loss": 0.003,
      "step": 701
    },
    {
      "epoch": 1.536105032822757,
      "grad_norm": 0.035041503608226776,
      "learning_rate": 1.553378676808483e-06,
      "loss": 0.0015,
      "step": 702
    },
    {
      "epoch": 1.5382932166301968,
      "grad_norm": 0.8378700017929077,
      "learning_rate": 1.5395599894961915e-06,
      "loss": 0.109,
      "step": 703
    },
    {
      "epoch": 1.5404814004376368,
      "grad_norm": 0.04064025729894638,
      "learning_rate": 1.5257918481971028e-06,
      "loss": 0.0011,
      "step": 704
    },
    {
      "epoch": 1.5426695842450766,
      "grad_norm": 0.03278093785047531,
      "learning_rate": 1.5120744540199345e-06,
      "loss": 0.0008,
      "step": 705
    },
    {
      "epoch": 1.5448577680525164,
      "grad_norm": 0.9477670788764954,
      "learning_rate": 1.4984080073321511e-06,
      "loss": 0.0301,
      "step": 706
    },
    {
      "epoch": 1.5470459518599562,
      "grad_norm": 1.8095351457595825,
      "learning_rate": 1.4847927077570324e-06,
      "loss": 0.2492,
      "step": 707
    },
    {
      "epoch": 1.5492341356673962,
      "grad_norm": 0.014169937931001186,
      "learning_rate": 1.471228754170768e-06,
      "loss": 0.0005,
      "step": 708
    },
    {
      "epoch": 1.551422319474836,
      "grad_norm": 0.0730094388127327,
      "learning_rate": 1.4577163446995379e-06,
      "loss": 0.002,
      "step": 709
    },
    {
      "epoch": 1.5536105032822758,
      "grad_norm": 1.8921842575073242,
      "learning_rate": 1.4442556767166371e-06,
      "loss": 0.0816,
      "step": 710
    },
    {
      "epoch": 1.5557986870897156,
      "grad_norm": 0.42485129833221436,
      "learning_rate": 1.430846946839573e-06,
      "loss": 0.0057,
      "step": 711
    },
    {
      "epoch": 1.5579868708971554,
      "grad_norm": 0.0228114053606987,
      "learning_rate": 1.4174903509272086e-06,
      "loss": 0.0007,
      "step": 712
    },
    {
      "epoch": 1.5601750547045952,
      "grad_norm": 1.901898741722107,
      "learning_rate": 1.40418608407689e-06,
      "loss": 0.2173,
      "step": 713
    },
    {
      "epoch": 1.562363238512035,
      "grad_norm": 0.21490731835365295,
      "learning_rate": 1.390934340621607e-06,
      "loss": 0.0066,
      "step": 714
    },
    {
      "epoch": 1.5645514223194747,
      "grad_norm": 0.3141424059867859,
      "learning_rate": 1.3777353141271483e-06,
      "loss": 0.0121,
      "step": 715
    },
    {
      "epoch": 1.5667396061269145,
      "grad_norm": 0.014852986671030521,
      "learning_rate": 1.3645891973892772e-06,
      "loss": 0.0005,
      "step": 716
    },
    {
      "epoch": 1.5689277899343543,
      "grad_norm": 1.2209969758987427,
      "learning_rate": 1.3514961824309092e-06,
      "loss": 0.0802,
      "step": 717
    },
    {
      "epoch": 1.5711159737417943,
      "grad_norm": 0.0009178351028822362,
      "learning_rate": 1.3384564604993162e-06,
      "loss": 0.0001,
      "step": 718
    },
    {
      "epoch": 1.5733041575492341,
      "grad_norm": 0.7528076171875,
      "learning_rate": 1.325470222063327e-06,
      "loss": 0.0179,
      "step": 719
    },
    {
      "epoch": 1.575492341356674,
      "grad_norm": 0.004233565181493759,
      "learning_rate": 1.312537656810549e-06,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 1.577680525164114,
      "grad_norm": 0.09072928130626678,
      "learning_rate": 1.2996589536445903e-06,
      "loss": 0.0028,
      "step": 721
    },
    {
      "epoch": 1.5798687089715537,
      "grad_norm": 0.12157439440488815,
      "learning_rate": 1.2868343006823113e-06,
      "loss": 0.0036,
      "step": 722
    },
    {
      "epoch": 1.5820568927789935,
      "grad_norm": 0.8156973719596863,
      "learning_rate": 1.274063885251064e-06,
      "loss": 0.0942,
      "step": 723
    },
    {
      "epoch": 1.5842450765864333,
      "grad_norm": 0.6141564249992371,
      "learning_rate": 1.261347893885972e-06,
      "loss": 0.0401,
      "step": 724
    },
    {
      "epoch": 1.5864332603938731,
      "grad_norm": 0.0009289398440159857,
      "learning_rate": 1.2486865123271868e-06,
      "loss": 0.0001,
      "step": 725
    },
    {
      "epoch": 1.588621444201313,
      "grad_norm": 0.0012978751910850406,
      "learning_rate": 1.2360799255171928e-06,
      "loss": 0.0001,
      "step": 726
    },
    {
      "epoch": 1.5908096280087527,
      "grad_norm": 0.17954304814338684,
      "learning_rate": 1.2235283175980899e-06,
      "loss": 0.004,
      "step": 727
    },
    {
      "epoch": 1.5929978118161925,
      "grad_norm": 0.11040466278791428,
      "learning_rate": 1.211031871908916e-06,
      "loss": 0.004,
      "step": 728
    },
    {
      "epoch": 1.5951859956236323,
      "grad_norm": 0.15174813568592072,
      "learning_rate": 1.1985907709829676e-06,
      "loss": 0.0061,
      "step": 729
    },
    {
      "epoch": 1.597374179431072,
      "grad_norm": 0.0516105517745018,
      "learning_rate": 1.1862051965451216e-06,
      "loss": 0.0014,
      "step": 730
    },
    {
      "epoch": 1.599562363238512,
      "grad_norm": 1.2314176559448242,
      "learning_rate": 1.1738753295091986e-06,
      "loss": 0.1332,
      "step": 731
    },
    {
      "epoch": 1.6017505470459519,
      "grad_norm": 0.06924615800380707,
      "learning_rate": 1.1616013499753031e-06,
      "loss": 0.0016,
      "step": 732
    },
    {
      "epoch": 1.6039387308533917,
      "grad_norm": 0.002100519835948944,
      "learning_rate": 1.1493834372272078e-06,
      "loss": 0.0001,
      "step": 733
    },
    {
      "epoch": 1.6061269146608315,
      "grad_norm": 0.6603570580482483,
      "learning_rate": 1.137221769729725e-06,
      "loss": 0.0178,
      "step": 734
    },
    {
      "epoch": 1.6083150984682715,
      "grad_norm": 0.012676444835960865,
      "learning_rate": 1.1251165251261047e-06,
      "loss": 0.0004,
      "step": 735
    },
    {
      "epoch": 1.6105032822757113,
      "grad_norm": 0.021102530881762505,
      "learning_rate": 1.113067880235435e-06,
      "loss": 0.0005,
      "step": 736
    },
    {
      "epoch": 1.612691466083151,
      "grad_norm": 0.22115112841129303,
      "learning_rate": 1.1010760110500652e-06,
      "loss": 0.0058,
      "step": 737
    },
    {
      "epoch": 1.6148796498905909,
      "grad_norm": 0.7068840861320496,
      "learning_rate": 1.0891410927330304e-06,
      "loss": 0.0441,
      "step": 738
    },
    {
      "epoch": 1.6170678336980306,
      "grad_norm": 0.21490873396396637,
      "learning_rate": 1.0772632996154986e-06,
      "loss": 0.0072,
      "step": 739
    },
    {
      "epoch": 1.6192560175054704,
      "grad_norm": 0.14172743260860443,
      "learning_rate": 1.065442805194214e-06,
      "loss": 0.0058,
      "step": 740
    },
    {
      "epoch": 1.6214442013129102,
      "grad_norm": 0.2876474857330322,
      "learning_rate": 1.053679782128975e-06,
      "loss": 0.0101,
      "step": 741
    },
    {
      "epoch": 1.62363238512035,
      "grad_norm": 1.1511520147323608,
      "learning_rate": 1.041974402240102e-06,
      "loss": 0.0147,
      "step": 742
    },
    {
      "epoch": 1.6258205689277898,
      "grad_norm": 0.3189811408519745,
      "learning_rate": 1.0303268365059383e-06,
      "loss": 0.0094,
      "step": 743
    },
    {
      "epoch": 1.6280087527352296,
      "grad_norm": 0.054670125246047974,
      "learning_rate": 1.018737255060338e-06,
      "loss": 0.001,
      "step": 744
    },
    {
      "epoch": 1.6301969365426696,
      "grad_norm": 0.029057547450065613,
      "learning_rate": 1.007205827190198e-06,
      "loss": 0.0007,
      "step": 745
    },
    {
      "epoch": 1.6323851203501094,
      "grad_norm": 1.9532259702682495,
      "learning_rate": 9.957327213329687e-07,
      "loss": 0.3706,
      "step": 746
    },
    {
      "epoch": 1.6345733041575492,
      "grad_norm": 0.7015135884284973,
      "learning_rate": 9.843181050742073e-07,
      "loss": 0.0553,
      "step": 747
    },
    {
      "epoch": 1.6367614879649892,
      "grad_norm": 0.07236248254776001,
      "learning_rate": 9.72962145145121e-07,
      "loss": 0.002,
      "step": 748
    },
    {
      "epoch": 1.638949671772429,
      "grad_norm": 0.3472079038619995,
      "learning_rate": 9.616650074201383e-07,
      "loss": 0.0095,
      "step": 749
    },
    {
      "epoch": 1.6411378555798688,
      "grad_norm": 1.2855106592178345,
      "learning_rate": 9.504268569144764e-07,
      "loss": 0.0716,
      "step": 750
    },
    {
      "epoch": 1.6433260393873086,
      "grad_norm": 2.7743263244628906,
      "learning_rate": 9.392478577817427e-07,
      "loss": 0.2873,
      "step": 751
    },
    {
      "epoch": 1.6455142231947484,
      "grad_norm": 1.8526084423065186,
      "learning_rate": 9.281281733115288e-07,
      "loss": 0.1514,
      "step": 752
    },
    {
      "epoch": 1.6477024070021882,
      "grad_norm": 0.023441778495907784,
      "learning_rate": 9.170679659270304e-07,
      "loss": 0.0005,
      "step": 753
    },
    {
      "epoch": 1.649890590809628,
      "grad_norm": 0.01396870706230402,
      "learning_rate": 9.060673971826667e-07,
      "loss": 0.0004,
      "step": 754
    },
    {
      "epoch": 1.6520787746170678,
      "grad_norm": 0.08717226982116699,
      "learning_rate": 8.951266277617326e-07,
      "loss": 0.0028,
      "step": 755
    },
    {
      "epoch": 1.6542669584245075,
      "grad_norm": 0.13525256514549255,
      "learning_rate": 8.842458174740398e-07,
      "loss": 0.0038,
      "step": 756
    },
    {
      "epoch": 1.6564551422319473,
      "grad_norm": 0.3662928640842438,
      "learning_rate": 8.734251252535941e-07,
      "loss": 0.0222,
      "step": 757
    },
    {
      "epoch": 1.6586433260393874,
      "grad_norm": 0.07748280465602875,
      "learning_rate": 8.626647091562612e-07,
      "loss": 0.0019,
      "step": 758
    },
    {
      "epoch": 1.6608315098468271,
      "grad_norm": 0.30638018250465393,
      "learning_rate": 8.519647263574693e-07,
      "loss": 0.0077,
      "step": 759
    },
    {
      "epoch": 1.663019693654267,
      "grad_norm": 0.0511644072830677,
      "learning_rate": 8.413253331499049e-07,
      "loss": 0.0015,
      "step": 760
    },
    {
      "epoch": 1.6652078774617067,
      "grad_norm": 1.844050407409668,
      "learning_rate": 8.307466849412365e-07,
      "loss": 0.0631,
      "step": 761
    },
    {
      "epoch": 1.6673960612691467,
      "grad_norm": 0.14332866668701172,
      "learning_rate": 8.202289362518401e-07,
      "loss": 0.0041,
      "step": 762
    },
    {
      "epoch": 1.6695842450765865,
      "grad_norm": 1.5434389114379883,
      "learning_rate": 8.097722407125441e-07,
      "loss": 0.1694,
      "step": 763
    },
    {
      "epoch": 1.6717724288840263,
      "grad_norm": 0.05239703133702278,
      "learning_rate": 7.993767510623834e-07,
      "loss": 0.001,
      "step": 764
    },
    {
      "epoch": 1.6739606126914661,
      "grad_norm": 0.19048620760440826,
      "learning_rate": 7.890426191463702e-07,
      "loss": 0.0043,
      "step": 765
    },
    {
      "epoch": 1.676148796498906,
      "grad_norm": 1.969069242477417,
      "learning_rate": 7.787699959132771e-07,
      "loss": 0.0252,
      "step": 766
    },
    {
      "epoch": 1.6783369803063457,
      "grad_norm": 1.3766324520111084,
      "learning_rate": 7.685590314134294e-07,
      "loss": 0.1341,
      "step": 767
    },
    {
      "epoch": 1.6805251641137855,
      "grad_norm": 0.0021511646918952465,
      "learning_rate": 7.584098747965157e-07,
      "loss": 0.0001,
      "step": 768
    },
    {
      "epoch": 1.6827133479212253,
      "grad_norm": 0.00473853200674057,
      "learning_rate": 7.483226743094046e-07,
      "loss": 0.0002,
      "step": 769
    },
    {
      "epoch": 1.684901531728665,
      "grad_norm": 0.011444216594099998,
      "learning_rate": 7.382975772939866e-07,
      "loss": 0.0003,
      "step": 770
    },
    {
      "epoch": 1.6870897155361049,
      "grad_norm": 0.01812845468521118,
      "learning_rate": 7.283347301850168e-07,
      "loss": 0.0005,
      "step": 771
    },
    {
      "epoch": 1.6892778993435449,
      "grad_norm": 0.0029117621015757322,
      "learning_rate": 7.184342785079795e-07,
      "loss": 0.0002,
      "step": 772
    },
    {
      "epoch": 1.6914660831509847,
      "grad_norm": 0.2734316289424896,
      "learning_rate": 7.085963668769552e-07,
      "loss": 0.0078,
      "step": 773
    },
    {
      "epoch": 1.6936542669584245,
      "grad_norm": 0.0034352410584688187,
      "learning_rate": 6.988211389925192e-07,
      "loss": 0.0002,
      "step": 774
    },
    {
      "epoch": 1.6958424507658645,
      "grad_norm": 0.03957577794790268,
      "learning_rate": 6.891087376396316e-07,
      "loss": 0.0014,
      "step": 775
    },
    {
      "epoch": 1.6980306345733043,
      "grad_norm": 0.46236544847488403,
      "learning_rate": 6.794593046855613e-07,
      "loss": 0.0405,
      "step": 776
    },
    {
      "epoch": 1.700218818380744,
      "grad_norm": 0.3816705644130707,
      "learning_rate": 6.698729810778065e-07,
      "loss": 0.0096,
      "step": 777
    },
    {
      "epoch": 1.7024070021881839,
      "grad_norm": 2.480559825897217,
      "learning_rate": 6.603499068420416e-07,
      "loss": 0.1771,
      "step": 778
    },
    {
      "epoch": 1.7045951859956237,
      "grad_norm": 0.003073749365285039,
      "learning_rate": 6.508902210800649e-07,
      "loss": 0.0001,
      "step": 779
    },
    {
      "epoch": 1.7067833698030634,
      "grad_norm": 0.7383581399917603,
      "learning_rate": 6.414940619677734e-07,
      "loss": 0.0398,
      "step": 780
    },
    {
      "epoch": 1.7089715536105032,
      "grad_norm": 0.1223168820142746,
      "learning_rate": 6.321615667531422e-07,
      "loss": 0.0028,
      "step": 781
    },
    {
      "epoch": 1.711159737417943,
      "grad_norm": 0.18541023135185242,
      "learning_rate": 6.228928717542205e-07,
      "loss": 0.0046,
      "step": 782
    },
    {
      "epoch": 1.7133479212253828,
      "grad_norm": 0.058501143008470535,
      "learning_rate": 6.136881123571347e-07,
      "loss": 0.0014,
      "step": 783
    },
    {
      "epoch": 1.7155361050328226,
      "grad_norm": 0.5152701735496521,
      "learning_rate": 6.045474230141207e-07,
      "loss": 0.0045,
      "step": 784
    },
    {
      "epoch": 1.7177242888402626,
      "grad_norm": 0.02368590235710144,
      "learning_rate": 5.954709372415524e-07,
      "loss": 0.0006,
      "step": 785
    },
    {
      "epoch": 1.7199124726477024,
      "grad_norm": 0.45659810304641724,
      "learning_rate": 5.864587876179961e-07,
      "loss": 0.0608,
      "step": 786
    },
    {
      "epoch": 1.7221006564551422,
      "grad_norm": 0.12452812492847443,
      "learning_rate": 5.77511105782268e-07,
      "loss": 0.004,
      "step": 787
    },
    {
      "epoch": 1.7242888402625822,
      "grad_norm": 1.7843443155288696,
      "learning_rate": 5.686280224315189e-07,
      "loss": 0.0862,
      "step": 788
    },
    {
      "epoch": 1.726477024070022,
      "grad_norm": 0.023931505158543587,
      "learning_rate": 5.598096673193165e-07,
      "loss": 0.0007,
      "step": 789
    },
    {
      "epoch": 1.7286652078774618,
      "grad_norm": 0.159272238612175,
      "learning_rate": 5.510561692537631e-07,
      "loss": 0.0047,
      "step": 790
    },
    {
      "epoch": 1.7308533916849016,
      "grad_norm": 0.2321232110261917,
      "learning_rate": 5.423676560955976e-07,
      "loss": 0.0076,
      "step": 791
    },
    {
      "epoch": 1.7330415754923414,
      "grad_norm": 1.4536305665969849,
      "learning_rate": 5.337442547563415e-07,
      "loss": 0.2267,
      "step": 792
    },
    {
      "epoch": 1.7352297592997812,
      "grad_norm": 0.09386990964412689,
      "learning_rate": 5.251860911964363e-07,
      "loss": 0.0027,
      "step": 793
    },
    {
      "epoch": 1.737417943107221,
      "grad_norm": 0.30238571763038635,
      "learning_rate": 5.166932904234101e-07,
      "loss": 0.0061,
      "step": 794
    },
    {
      "epoch": 1.7396061269146608,
      "grad_norm": 0.01277187094092369,
      "learning_rate": 5.082659764900483e-07,
      "loss": 0.0004,
      "step": 795
    },
    {
      "epoch": 1.7417943107221006,
      "grad_norm": 0.021533818915486336,
      "learning_rate": 4.999042724925817e-07,
      "loss": 0.0008,
      "step": 796
    },
    {
      "epoch": 1.7439824945295404,
      "grad_norm": 0.014185507781803608,
      "learning_rate": 4.916083005688865e-07,
      "loss": 0.0004,
      "step": 797
    },
    {
      "epoch": 1.7461706783369801,
      "grad_norm": 0.05232890322804451,
      "learning_rate": 4.833781818967065e-07,
      "loss": 0.0013,
      "step": 798
    },
    {
      "epoch": 1.7483588621444202,
      "grad_norm": 0.014418050646781921,
      "learning_rate": 4.7521403669187616e-07,
      "loss": 0.0005,
      "step": 799
    },
    {
      "epoch": 1.75054704595186,
      "grad_norm": 0.025384172797203064,
      "learning_rate": 4.671159842065698e-07,
      "loss": 0.0006,
      "step": 800
    },
    {
      "epoch": 1.7527352297592997,
      "grad_norm": 0.17780742049217224,
      "learning_rate": 4.59084142727555e-07,
      "loss": 0.0031,
      "step": 801
    },
    {
      "epoch": 1.7549234135667398,
      "grad_norm": 0.488741397857666,
      "learning_rate": 4.5111862957446906e-07,
      "loss": 0.0287,
      "step": 802
    },
    {
      "epoch": 1.7571115973741795,
      "grad_norm": 0.4053252339363098,
      "learning_rate": 4.4321956109810327e-07,
      "loss": 0.0103,
      "step": 803
    },
    {
      "epoch": 1.7592997811816193,
      "grad_norm": 0.11723696440458298,
      "learning_rate": 4.353870526787035e-07,
      "loss": 0.0036,
      "step": 804
    },
    {
      "epoch": 1.7614879649890591,
      "grad_norm": 0.1657276451587677,
      "learning_rate": 4.276212187242862e-07,
      "loss": 0.0032,
      "step": 805
    },
    {
      "epoch": 1.763676148796499,
      "grad_norm": 0.27367472648620605,
      "learning_rate": 4.199221726689634e-07,
      "loss": 0.0044,
      "step": 806
    },
    {
      "epoch": 1.7658643326039387,
      "grad_norm": 2.013779878616333,
      "learning_rate": 4.122900269712921e-07,
      "loss": 0.1074,
      "step": 807
    },
    {
      "epoch": 1.7680525164113785,
      "grad_norm": 0.16585513949394226,
      "learning_rate": 4.047248931126235e-07,
      "loss": 0.006,
      "step": 808
    },
    {
      "epoch": 1.7702407002188183,
      "grad_norm": 0.8647623658180237,
      "learning_rate": 3.972268815954833e-07,
      "loss": 0.0178,
      "step": 809
    },
    {
      "epoch": 1.772428884026258,
      "grad_norm": 0.8092809915542603,
      "learning_rate": 3.897961019419516e-07,
      "loss": 0.0377,
      "step": 810
    },
    {
      "epoch": 1.7746170678336979,
      "grad_norm": 1.8210997581481934,
      "learning_rate": 3.8243266269206656e-07,
      "loss": 0.1617,
      "step": 811
    },
    {
      "epoch": 1.776805251641138,
      "grad_norm": 0.09302343428134918,
      "learning_rate": 3.751366714022342e-07,
      "loss": 0.0023,
      "step": 812
    },
    {
      "epoch": 1.7789934354485777,
      "grad_norm": 0.08373969048261642,
      "learning_rate": 3.6790823464366353e-07,
      "loss": 0.0024,
      "step": 813
    },
    {
      "epoch": 1.7811816192560175,
      "grad_norm": 0.45632651448249817,
      "learning_rate": 3.607474580008058e-07,
      "loss": 0.0376,
      "step": 814
    },
    {
      "epoch": 1.7833698030634575,
      "grad_norm": 1.9131004810333252,
      "learning_rate": 3.5365444606981434e-07,
      "loss": 0.2021,
      "step": 815
    },
    {
      "epoch": 1.7855579868708973,
      "grad_norm": 1.6640894412994385,
      "learning_rate": 3.4662930245701275e-07,
      "loss": 0.0444,
      "step": 816
    },
    {
      "epoch": 1.787746170678337,
      "grad_norm": 1.7472724914550781,
      "learning_rate": 3.396721297773875e-07,
      "loss": 0.081,
      "step": 817
    },
    {
      "epoch": 1.7899343544857769,
      "grad_norm": 0.6302002668380737,
      "learning_rate": 3.3278302965308593e-07,
      "loss": 0.0169,
      "step": 818
    },
    {
      "epoch": 1.7921225382932167,
      "grad_norm": 0.6260852813720703,
      "learning_rate": 3.259621027119314e-07,
      "loss": 0.0285,
      "step": 819
    },
    {
      "epoch": 1.7943107221006565,
      "grad_norm": 0.9730297327041626,
      "learning_rate": 3.192094485859526e-07,
      "loss": 0.0387,
      "step": 820
    },
    {
      "epoch": 1.7964989059080962,
      "grad_norm": 0.3350815773010254,
      "learning_rate": 3.125251659099332e-07,
      "loss": 0.0108,
      "step": 821
    },
    {
      "epoch": 1.798687089715536,
      "grad_norm": 1.2379604578018188,
      "learning_rate": 3.05909352319963e-07,
      "loss": 0.1156,
      "step": 822
    },
    {
      "epoch": 1.8008752735229758,
      "grad_norm": 0.028147513046860695,
      "learning_rate": 2.993621044520201e-07,
      "loss": 0.0009,
      "step": 823
    },
    {
      "epoch": 1.8030634573304156,
      "grad_norm": 0.014236316084861755,
      "learning_rate": 2.928835179405548e-07,
      "loss": 0.0005,
      "step": 824
    },
    {
      "epoch": 1.8052516411378556,
      "grad_norm": 0.003752516582608223,
      "learning_rate": 2.864736874170937e-07,
      "loss": 0.0002,
      "step": 825
    },
    {
      "epoch": 1.8074398249452954,
      "grad_norm": 1.2536908388137817,
      "learning_rate": 2.801327065088555e-07,
      "loss": 0.0937,
      "step": 826
    },
    {
      "epoch": 1.8096280087527352,
      "grad_norm": 0.0265931598842144,
      "learning_rate": 2.738606678373873e-07,
      "loss": 0.001,
      "step": 827
    },
    {
      "epoch": 1.811816192560175,
      "grad_norm": 0.055476270616054535,
      "learning_rate": 2.6765766301720895e-07,
      "loss": 0.0017,
      "step": 828
    },
    {
      "epoch": 1.814004376367615,
      "grad_norm": 0.13167816400527954,
      "learning_rate": 2.615237826544753e-07,
      "loss": 0.0031,
      "step": 829
    },
    {
      "epoch": 1.8161925601750548,
      "grad_norm": 0.06496191769838333,
      "learning_rate": 2.5545911634565266e-07,
      "loss": 0.0024,
      "step": 830
    },
    {
      "epoch": 1.8183807439824946,
      "grad_norm": 0.5648279190063477,
      "learning_rate": 2.4946375267621003e-07,
      "loss": 0.0183,
      "step": 831
    },
    {
      "epoch": 1.8205689277899344,
      "grad_norm": 1.992726445198059,
      "learning_rate": 2.435377792193272e-07,
      "loss": 0.2154,
      "step": 832
    },
    {
      "epoch": 1.8227571115973742,
      "grad_norm": 1.604443907737732,
      "learning_rate": 2.3768128253461253e-07,
      "loss": 0.0509,
      "step": 833
    },
    {
      "epoch": 1.824945295404814,
      "grad_norm": 0.06471147388219833,
      "learning_rate": 2.3189434816683898e-07,
      "loss": 0.0019,
      "step": 834
    },
    {
      "epoch": 1.8271334792122538,
      "grad_norm": 0.017018793150782585,
      "learning_rate": 2.2617706064469836e-07,
      "loss": 0.0006,
      "step": 835
    },
    {
      "epoch": 1.8293216630196936,
      "grad_norm": 0.43441241979599,
      "learning_rate": 2.205295034795596e-07,
      "loss": 0.0163,
      "step": 836
    },
    {
      "epoch": 1.8315098468271334,
      "grad_norm": 0.06636183708906174,
      "learning_rate": 2.1495175916425748e-07,
      "loss": 0.0014,
      "step": 837
    },
    {
      "epoch": 1.8336980306345732,
      "grad_norm": 0.0293126218020916,
      "learning_rate": 2.0944390917187973e-07,
      "loss": 0.0006,
      "step": 838
    },
    {
      "epoch": 1.8358862144420132,
      "grad_norm": 0.15126244723796844,
      "learning_rate": 2.0400603395458408e-07,
      "loss": 0.0029,
      "step": 839
    },
    {
      "epoch": 1.838074398249453,
      "grad_norm": 0.006273407954722643,
      "learning_rate": 1.9863821294241525e-07,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 1.8402625820568927,
      "grad_norm": 0.008480806834995747,
      "learning_rate": 1.9334052454215268e-07,
      "loss": 0.0003,
      "step": 841
    },
    {
      "epoch": 1.8424507658643328,
      "grad_norm": 0.19460920989513397,
      "learning_rate": 1.881130461361591e-07,
      "loss": 0.004,
      "step": 842
    },
    {
      "epoch": 1.8446389496717726,
      "grad_norm": 0.015226159244775772,
      "learning_rate": 1.8295585408125483e-07,
      "loss": 0.0004,
      "step": 843
    },
    {
      "epoch": 1.8468271334792123,
      "grad_norm": 0.05425191670656204,
      "learning_rate": 1.7786902370759917e-07,
      "loss": 0.0008,
      "step": 844
    },
    {
      "epoch": 1.8490153172866521,
      "grad_norm": 1.566624402999878,
      "learning_rate": 1.7285262931759084e-07,
      "loss": 0.0364,
      "step": 845
    },
    {
      "epoch": 1.851203501094092,
      "grad_norm": 3.5231070518493652,
      "learning_rate": 1.679067441847837e-07,
      "loss": 0.0883,
      "step": 846
    },
    {
      "epoch": 1.8533916849015317,
      "grad_norm": 0.23432058095932007,
      "learning_rate": 1.630314405528155e-07,
      "loss": 0.008,
      "step": 847
    },
    {
      "epoch": 1.8555798687089715,
      "grad_norm": 1.4371765851974487,
      "learning_rate": 1.5822678963435479e-07,
      "loss": 0.1002,
      "step": 848
    },
    {
      "epoch": 1.8577680525164113,
      "grad_norm": 0.10913222283124924,
      "learning_rate": 1.534928616100545e-07,
      "loss": 0.0028,
      "step": 849
    },
    {
      "epoch": 1.859956236323851,
      "grad_norm": 0.004234219901263714,
      "learning_rate": 1.4882972562753616e-07,
      "loss": 0.0002,
      "step": 850
    },
    {
      "epoch": 1.862144420131291,
      "grad_norm": 0.0530223548412323,
      "learning_rate": 1.4423744980037068e-07,
      "loss": 0.0012,
      "step": 851
    },
    {
      "epoch": 1.864332603938731,
      "grad_norm": 0.019003016874194145,
      "learning_rate": 1.3971610120709188e-07,
      "loss": 0.0006,
      "step": 852
    },
    {
      "epoch": 1.8665207877461707,
      "grad_norm": 4.058999538421631,
      "learning_rate": 1.3526574589020846e-07,
      "loss": 0.0797,
      "step": 853
    },
    {
      "epoch": 1.8687089715536105,
      "grad_norm": 0.014640678651630878,
      "learning_rate": 1.3088644885524637e-07,
      "loss": 0.0004,
      "step": 854
    },
    {
      "epoch": 1.8708971553610503,
      "grad_norm": 0.1101708859205246,
      "learning_rate": 1.2657827406979406e-07,
      "loss": 0.0038,
      "step": 855
    },
    {
      "epoch": 1.8730853391684903,
      "grad_norm": 0.009372244589030743,
      "learning_rate": 1.223412844625721e-07,
      "loss": 0.0003,
      "step": 856
    },
    {
      "epoch": 1.87527352297593,
      "grad_norm": 0.30947744846343994,
      "learning_rate": 1.1817554192251002e-07,
      "loss": 0.0054,
      "step": 857
    },
    {
      "epoch": 1.8774617067833699,
      "grad_norm": 0.07947759330272675,
      "learning_rate": 1.140811072978476e-07,
      "loss": 0.0018,
      "step": 858
    },
    {
      "epoch": 1.8796498905908097,
      "grad_norm": 0.013006282970309258,
      "learning_rate": 1.1005804039524004e-07,
      "loss": 0.0005,
      "step": 859
    },
    {
      "epoch": 1.8818380743982495,
      "grad_norm": 0.5537364482879639,
      "learning_rate": 1.0610639997888917e-07,
      "loss": 0.0184,
      "step": 860
    },
    {
      "epoch": 1.8840262582056893,
      "grad_norm": 0.1599721908569336,
      "learning_rate": 1.0222624376968138e-07,
      "loss": 0.0049,
      "step": 861
    },
    {
      "epoch": 1.886214442013129,
      "grad_norm": 0.04315546900033951,
      "learning_rate": 9.841762844434888e-08,
      "loss": 0.0016,
      "step": 862
    },
    {
      "epoch": 1.8884026258205688,
      "grad_norm": 0.025963036343455315,
      "learning_rate": 9.468060963463754e-08,
      "loss": 0.0008,
      "step": 863
    },
    {
      "epoch": 1.8905908096280086,
      "grad_norm": 0.4203302562236786,
      "learning_rate": 9.101524192649591e-08,
      "loss": 0.0098,
      "step": 864
    },
    {
      "epoch": 1.8927789934354484,
      "grad_norm": 0.0030147216748446226,
      "learning_rate": 8.742157885927804e-08,
      "loss": 0.0001,
      "step": 865
    },
    {
      "epoch": 1.8949671772428884,
      "grad_norm": 0.1269770711660385,
      "learning_rate": 8.38996729249636e-08,
      "loss": 0.0019,
      "step": 866
    },
    {
      "epoch": 1.8971553610503282,
      "grad_norm": 0.09668894112110138,
      "learning_rate": 8.044957556738564e-08,
      "loss": 0.0021,
      "step": 867
    },
    {
      "epoch": 1.899343544857768,
      "grad_norm": 0.13443610072135925,
      "learning_rate": 7.707133718148518e-08,
      "loss": 0.0021,
      "step": 868
    },
    {
      "epoch": 1.901531728665208,
      "grad_norm": 0.4592706859111786,
      "learning_rate": 7.376500711257062e-08,
      "loss": 0.007,
      "step": 869
    },
    {
      "epoch": 1.9037199124726478,
      "grad_norm": 0.14081399142742157,
      "learning_rate": 7.053063365559998e-08,
      "loss": 0.0044,
      "step": 870
    },
    {
      "epoch": 1.9059080962800876,
      "grad_norm": 0.1359003484249115,
      "learning_rate": 6.736826405447372e-08,
      "loss": 0.0025,
      "step": 871
    },
    {
      "epoch": 1.9080962800875274,
      "grad_norm": 1.352532982826233,
      "learning_rate": 6.427794450134529e-08,
      "loss": 0.0188,
      "step": 872
    },
    {
      "epoch": 1.9102844638949672,
      "grad_norm": 0.016400057822465897,
      "learning_rate": 6.12597201359455e-08,
      "loss": 0.0005,
      "step": 873
    },
    {
      "epoch": 1.912472647702407,
      "grad_norm": 0.5066189169883728,
      "learning_rate": 5.831363504492482e-08,
      "loss": 0.0502,
      "step": 874
    },
    {
      "epoch": 1.9146608315098468,
      "grad_norm": 0.13459424674510956,
      "learning_rate": 5.5439732261209356e-08,
      "loss": 0.0043,
      "step": 875
    },
    {
      "epoch": 1.9168490153172866,
      "grad_norm": 0.041299011558294296,
      "learning_rate": 5.263805376336972e-08,
      "loss": 0.0011,
      "step": 876
    },
    {
      "epoch": 1.9190371991247264,
      "grad_norm": 0.007942994125187397,
      "learning_rate": 4.990864047501043e-08,
      "loss": 0.0003,
      "step": 877
    },
    {
      "epoch": 1.9212253829321662,
      "grad_norm": 0.062156520783901215,
      "learning_rate": 4.72515322641709e-08,
      "loss": 0.0017,
      "step": 878
    },
    {
      "epoch": 1.9234135667396062,
      "grad_norm": 0.057360630482435226,
      "learning_rate": 4.4666767942744826e-08,
      "loss": 0.0019,
      "step": 879
    },
    {
      "epoch": 1.925601750547046,
      "grad_norm": 0.09139911830425262,
      "learning_rate": 4.215438526591065e-08,
      "loss": 0.0027,
      "step": 880
    },
    {
      "epoch": 1.9277899343544858,
      "grad_norm": 0.09283995628356934,
      "learning_rate": 3.971442093158195e-08,
      "loss": 0.0026,
      "step": 881
    },
    {
      "epoch": 1.9299781181619255,
      "grad_norm": 0.3421863317489624,
      "learning_rate": 3.734691057987017e-08,
      "loss": 0.014,
      "step": 882
    },
    {
      "epoch": 1.9321663019693656,
      "grad_norm": 0.6168217062950134,
      "learning_rate": 3.505188879256605e-08,
      "loss": 0.0331,
      "step": 883
    },
    {
      "epoch": 1.9343544857768054,
      "grad_norm": 0.0434543639421463,
      "learning_rate": 3.282938909263122e-08,
      "loss": 0.001,
      "step": 884
    },
    {
      "epoch": 1.9365426695842451,
      "grad_norm": 0.3580015003681183,
      "learning_rate": 3.067944394371247e-08,
      "loss": 0.0067,
      "step": 885
    },
    {
      "epoch": 1.938730853391685,
      "grad_norm": 0.044558536261320114,
      "learning_rate": 2.8602084749664304e-08,
      "loss": 0.0012,
      "step": 886
    },
    {
      "epoch": 1.9409190371991247,
      "grad_norm": 0.7366052269935608,
      "learning_rate": 2.6597341854092685e-08,
      "loss": 0.022,
      "step": 887
    },
    {
      "epoch": 1.9431072210065645,
      "grad_norm": 1.9341036081314087,
      "learning_rate": 2.4665244539908705e-08,
      "loss": 0.0573,
      "step": 888
    },
    {
      "epoch": 1.9452954048140043,
      "grad_norm": 1.0034959316253662,
      "learning_rate": 2.280582102890394e-08,
      "loss": 0.0192,
      "step": 889
    },
    {
      "epoch": 1.947483588621444,
      "grad_norm": 2.5425610542297363,
      "learning_rate": 2.101909848133743e-08,
      "loss": 0.1176,
      "step": 890
    },
    {
      "epoch": 1.949671772428884,
      "grad_norm": 0.07972175627946854,
      "learning_rate": 1.9305102995538227e-08,
      "loss": 0.0022,
      "step": 891
    },
    {
      "epoch": 1.9518599562363237,
      "grad_norm": 2.179767608642578,
      "learning_rate": 1.7663859607523482e-08,
      "loss": 0.1973,
      "step": 892
    },
    {
      "epoch": 1.9540481400437637,
      "grad_norm": 0.08548961579799652,
      "learning_rate": 1.6095392290635393e-08,
      "loss": 0.0021,
      "step": 893
    },
    {
      "epoch": 1.9562363238512035,
      "grad_norm": 0.14631815254688263,
      "learning_rate": 1.459972395518816e-08,
      "loss": 0.0048,
      "step": 894
    },
    {
      "epoch": 1.9584245076586433,
      "grad_norm": 0.09053874760866165,
      "learning_rate": 1.3176876448135478e-08,
      "loss": 0.0028,
      "step": 895
    },
    {
      "epoch": 1.9606126914660833,
      "grad_norm": 0.16066117584705353,
      "learning_rate": 1.1826870552749669e-08,
      "loss": 0.0041,
      "step": 896
    },
    {
      "epoch": 1.962800875273523,
      "grad_norm": 0.013493821024894714,
      "learning_rate": 1.0549725988320824e-08,
      "loss": 0.0005,
      "step": 897
    },
    {
      "epoch": 1.9649890590809629,
      "grad_norm": 0.06404412537813187,
      "learning_rate": 9.345461409863699e-09,
      "loss": 0.0016,
      "step": 898
    },
    {
      "epoch": 1.9671772428884027,
      "grad_norm": 3.1160848140716553,
      "learning_rate": 8.214094407851814e-09,
      "loss": 0.1623,
      "step": 899
    },
    {
      "epoch": 1.9693654266958425,
      "grad_norm": 0.020342692732810974,
      "learning_rate": 7.155641507955446e-09,
      "loss": 0.0006,
      "step": 900
    },
    {
      "epoch": 1.9715536105032823,
      "grad_norm": 0.2951260507106781,
      "learning_rate": 6.170118170801265e-09,
      "loss": 0.0077,
      "step": 901
    },
    {
      "epoch": 1.973741794310722,
      "grad_norm": 0.03414329141378403,
      "learning_rate": 5.257538791749173e-09,
      "loss": 0.001,
      "step": 902
    },
    {
      "epoch": 1.9759299781181618,
      "grad_norm": 0.5379432439804077,
      "learning_rate": 4.417916700678038e-09,
      "loss": 0.0512,
      "step": 903
    },
    {
      "epoch": 1.9781181619256016,
      "grad_norm": 1.0437076091766357,
      "learning_rate": 3.651264161794732e-09,
      "loss": 0.0249,
      "step": 904
    },
    {
      "epoch": 1.9803063457330414,
      "grad_norm": 0.12735095620155334,
      "learning_rate": 2.9575923734520562e-09,
      "loss": 0.0023,
      "step": 905
    },
    {
      "epoch": 1.9824945295404814,
      "grad_norm": 0.05052657052874565,
      "learning_rate": 2.3369114679866466e-09,
      "loss": 0.0012,
      "step": 906
    },
    {
      "epoch": 1.9846827133479212,
      "grad_norm": 0.25778692960739136,
      "learning_rate": 1.789230511571316e-09,
      "loss": 0.0042,
      "step": 907
    },
    {
      "epoch": 1.986870897155361,
      "grad_norm": 0.9778810143470764,
      "learning_rate": 1.3145575040801605e-09,
      "loss": 0.0509,
      "step": 908
    },
    {
      "epoch": 1.989059080962801,
      "grad_norm": 0.05492652580142021,
      "learning_rate": 9.128993789764285e-10,
      "loss": 0.0012,
      "step": 909
    },
    {
      "epoch": 1.9912472647702408,
      "grad_norm": 0.16521714627742767,
      "learning_rate": 5.842620032053825e-10,
      "loss": 0.0037,
      "step": 910
    },
    {
      "epoch": 1.9934354485776806,
      "grad_norm": 0.40144672989845276,
      "learning_rate": 3.2865017711380955e-10,
      "loss": 0.028,
      "step": 911
    },
    {
      "epoch": 1.9956236323851204,
      "grad_norm": 2.2515177726745605,
      "learning_rate": 1.4606763437674531e-10,
      "loss": 0.0847,
      "step": 912
    },
    {
      "epoch": 1.9978118161925602,
      "grad_norm": 0.33488330245018005,
      "learning_rate": 3.6517041943628926e-11,
      "loss": 0.0646,
      "step": 913
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2825501561164856,
      "learning_rate": 0.0,
      "loss": 0.0082,
      "step": 914
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.0784313725490196,
      "eval_loss": 0.03183260187506676,
      "eval_runtime": 1068.4041,
      "eval_samples_per_second": 0.191,
      "eval_steps_per_second": 0.191,
      "step": 914
    }
  ],
  "logging_steps": 1,
  "max_steps": 914,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.597840050180772e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
