{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1511,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006618133686300463,
      "grad_norm": 12.702408790588379,
      "learning_rate": 9.999989192862703e-06,
      "loss": 4.5671,
      "step": 1
    },
    {
      "epoch": 0.0013236267372600927,
      "grad_norm": 10.202866554260254,
      "learning_rate": 9.999956771497528e-06,
      "loss": 4.6015,
      "step": 2
    },
    {
      "epoch": 0.001985440105890139,
      "grad_norm": 9.410564422607422,
      "learning_rate": 9.999902736044627e-06,
      "loss": 4.8458,
      "step": 3
    },
    {
      "epoch": 0.0026472534745201853,
      "grad_norm": 12.243234634399414,
      "learning_rate": 9.999827086737591e-06,
      "loss": 4.5523,
      "step": 4
    },
    {
      "epoch": 0.0033090668431502318,
      "grad_norm": 16.78719711303711,
      "learning_rate": 9.999729823903436e-06,
      "loss": 4.7511,
      "step": 5
    },
    {
      "epoch": 0.003970880211780278,
      "grad_norm": 15.444831848144531,
      "learning_rate": 9.999610947962619e-06,
      "loss": 3.8207,
      "step": 6
    },
    {
      "epoch": 0.004632693580410324,
      "grad_norm": 13.97058391571045,
      "learning_rate": 9.999470459429022e-06,
      "loss": 4.1396,
      "step": 7
    },
    {
      "epoch": 0.005294506949040371,
      "grad_norm": 15.050515174865723,
      "learning_rate": 9.999308358909957e-06,
      "loss": 3.5416,
      "step": 8
    },
    {
      "epoch": 0.005956320317670417,
      "grad_norm": 13.693121910095215,
      "learning_rate": 9.99912464710616e-06,
      "loss": 4.0445,
      "step": 9
    },
    {
      "epoch": 0.0066181336863004635,
      "grad_norm": 13.688529014587402,
      "learning_rate": 9.99891932481179e-06,
      "loss": 3.974,
      "step": 10
    },
    {
      "epoch": 0.00727994705493051,
      "grad_norm": 14.00117015838623,
      "learning_rate": 9.99869239291443e-06,
      "loss": 3.5738,
      "step": 11
    },
    {
      "epoch": 0.007941760423560556,
      "grad_norm": 26.93108367919922,
      "learning_rate": 9.998443852395067e-06,
      "loss": 2.5008,
      "step": 12
    },
    {
      "epoch": 0.008603573792190603,
      "grad_norm": 10.355000495910645,
      "learning_rate": 9.998173704328112e-06,
      "loss": 3.6427,
      "step": 13
    },
    {
      "epoch": 0.009265387160820648,
      "grad_norm": 23.770973205566406,
      "learning_rate": 9.997881949881371e-06,
      "loss": 3.2097,
      "step": 14
    },
    {
      "epoch": 0.009927200529450696,
      "grad_norm": 15.335297584533691,
      "learning_rate": 9.99756859031606e-06,
      "loss": 3.76,
      "step": 15
    },
    {
      "epoch": 0.010589013898080741,
      "grad_norm": 17.00546646118164,
      "learning_rate": 9.997233626986783e-06,
      "loss": 3.2921,
      "step": 16
    },
    {
      "epoch": 0.011250827266710787,
      "grad_norm": 19.754650115966797,
      "learning_rate": 9.99687706134154e-06,
      "loss": 2.1921,
      "step": 17
    },
    {
      "epoch": 0.011912640635340834,
      "grad_norm": 19.12725830078125,
      "learning_rate": 9.996498894921713e-06,
      "loss": 3.2664,
      "step": 18
    },
    {
      "epoch": 0.01257445400397088,
      "grad_norm": 16.11306381225586,
      "learning_rate": 9.99609912936206e-06,
      "loss": 3.4879,
      "step": 19
    },
    {
      "epoch": 0.013236267372600927,
      "grad_norm": 22.390907287597656,
      "learning_rate": 9.995677766390708e-06,
      "loss": 2.2773,
      "step": 20
    },
    {
      "epoch": 0.013898080741230973,
      "grad_norm": 22.355791091918945,
      "learning_rate": 9.99523480782915e-06,
      "loss": 2.7712,
      "step": 21
    },
    {
      "epoch": 0.01455989410986102,
      "grad_norm": 17.002254486083984,
      "learning_rate": 9.994770255592233e-06,
      "loss": 1.7366,
      "step": 22
    },
    {
      "epoch": 0.015221707478491065,
      "grad_norm": 7.977649211883545,
      "learning_rate": 9.994284111688146e-06,
      "loss": 2.8272,
      "step": 23
    },
    {
      "epoch": 0.01588352084712111,
      "grad_norm": 9.463177680969238,
      "learning_rate": 9.993776378218419e-06,
      "loss": 2.2847,
      "step": 24
    },
    {
      "epoch": 0.01654533421575116,
      "grad_norm": 10.246834754943848,
      "learning_rate": 9.99324705737791e-06,
      "loss": 2.6368,
      "step": 25
    },
    {
      "epoch": 0.017207147584381206,
      "grad_norm": 9.773560523986816,
      "learning_rate": 9.9926961514548e-06,
      "loss": 1.392,
      "step": 26
    },
    {
      "epoch": 0.01786896095301125,
      "grad_norm": 13.511144638061523,
      "learning_rate": 9.99212366283057e-06,
      "loss": 1.9292,
      "step": 27
    },
    {
      "epoch": 0.018530774321641297,
      "grad_norm": 11.103730201721191,
      "learning_rate": 9.991529593980006e-06,
      "loss": 0.7298,
      "step": 28
    },
    {
      "epoch": 0.019192587690271344,
      "grad_norm": 14.959622383117676,
      "learning_rate": 9.990913947471185e-06,
      "loss": 2.9416,
      "step": 29
    },
    {
      "epoch": 0.01985440105890139,
      "grad_norm": 14.61452865600586,
      "learning_rate": 9.990276725965455e-06,
      "loss": 2.3062,
      "step": 30
    },
    {
      "epoch": 0.020516214427531435,
      "grad_norm": 13.439095497131348,
      "learning_rate": 9.989617932217433e-06,
      "loss": 1.6128,
      "step": 31
    },
    {
      "epoch": 0.021178027796161483,
      "grad_norm": 12.293511390686035,
      "learning_rate": 9.988937569074987e-06,
      "loss": 1.8292,
      "step": 32
    },
    {
      "epoch": 0.02183984116479153,
      "grad_norm": 14.23809814453125,
      "learning_rate": 9.98823563947923e-06,
      "loss": 1.2107,
      "step": 33
    },
    {
      "epoch": 0.022501654533421574,
      "grad_norm": 14.632577896118164,
      "learning_rate": 9.987512146464504e-06,
      "loss": 2.1066,
      "step": 34
    },
    {
      "epoch": 0.02316346790205162,
      "grad_norm": 14.42038345336914,
      "learning_rate": 9.98676709315836e-06,
      "loss": 1.2374,
      "step": 35
    },
    {
      "epoch": 0.02382528127068167,
      "grad_norm": 13.799739837646484,
      "learning_rate": 9.986000482781557e-06,
      "loss": 1.1672,
      "step": 36
    },
    {
      "epoch": 0.024487094639311716,
      "grad_norm": 38.41227722167969,
      "learning_rate": 9.98521231864804e-06,
      "loss": 1.3702,
      "step": 37
    },
    {
      "epoch": 0.02514890800794176,
      "grad_norm": 14.431031227111816,
      "learning_rate": 9.98440260416493e-06,
      "loss": 1.0794,
      "step": 38
    },
    {
      "epoch": 0.025810721376571807,
      "grad_norm": 21.970928192138672,
      "learning_rate": 9.983571342832502e-06,
      "loss": 2.2298,
      "step": 39
    },
    {
      "epoch": 0.026472534745201854,
      "grad_norm": 18.85930633544922,
      "learning_rate": 9.982718538244182e-06,
      "loss": 1.6762,
      "step": 40
    },
    {
      "epoch": 0.027134348113831898,
      "grad_norm": 12.482803344726562,
      "learning_rate": 9.981844194086518e-06,
      "loss": 1.2154,
      "step": 41
    },
    {
      "epoch": 0.027796161482461945,
      "grad_norm": 9.75306510925293,
      "learning_rate": 9.980948314139173e-06,
      "loss": 0.6735,
      "step": 42
    },
    {
      "epoch": 0.028457974851091992,
      "grad_norm": 13.822609901428223,
      "learning_rate": 9.980030902274906e-06,
      "loss": 1.2986,
      "step": 43
    },
    {
      "epoch": 0.02911978821972204,
      "grad_norm": 16.998517990112305,
      "learning_rate": 9.979091962459558e-06,
      "loss": 1.1459,
      "step": 44
    },
    {
      "epoch": 0.029781601588352084,
      "grad_norm": 9.538378715515137,
      "learning_rate": 9.978131498752025e-06,
      "loss": 0.6193,
      "step": 45
    },
    {
      "epoch": 0.03044341495698213,
      "grad_norm": 7.03523063659668,
      "learning_rate": 9.977149515304258e-06,
      "loss": 0.3751,
      "step": 46
    },
    {
      "epoch": 0.031105228325612178,
      "grad_norm": 11.545844078063965,
      "learning_rate": 9.976146016361224e-06,
      "loss": 1.0295,
      "step": 47
    },
    {
      "epoch": 0.03176704169424222,
      "grad_norm": 8.175880432128906,
      "learning_rate": 9.975121006260905e-06,
      "loss": 0.5122,
      "step": 48
    },
    {
      "epoch": 0.03242885506287227,
      "grad_norm": 9.898730278015137,
      "learning_rate": 9.97407448943427e-06,
      "loss": 0.7722,
      "step": 49
    },
    {
      "epoch": 0.03309066843150232,
      "grad_norm": 3.102250814437866,
      "learning_rate": 9.973006470405264e-06,
      "loss": 0.1319,
      "step": 50
    },
    {
      "epoch": 0.033752481800132364,
      "grad_norm": 19.052038192749023,
      "learning_rate": 9.971916953790771e-06,
      "loss": 2.4333,
      "step": 51
    },
    {
      "epoch": 0.03441429516876241,
      "grad_norm": 14.48635196685791,
      "learning_rate": 9.97080594430062e-06,
      "loss": 2.2104,
      "step": 52
    },
    {
      "epoch": 0.03507610853739246,
      "grad_norm": 2.3451225757598877,
      "learning_rate": 9.96967344673754e-06,
      "loss": 0.0635,
      "step": 53
    },
    {
      "epoch": 0.0357379219060225,
      "grad_norm": 3.2122244834899902,
      "learning_rate": 9.968519465997154e-06,
      "loss": 0.1439,
      "step": 54
    },
    {
      "epoch": 0.036399735274652546,
      "grad_norm": 14.617103576660156,
      "learning_rate": 9.967344007067955e-06,
      "loss": 1.1612,
      "step": 55
    },
    {
      "epoch": 0.037061548643282594,
      "grad_norm": 2.101700782775879,
      "learning_rate": 9.966147075031281e-06,
      "loss": 0.0636,
      "step": 56
    },
    {
      "epoch": 0.03772336201191264,
      "grad_norm": 1.9107098579406738,
      "learning_rate": 9.964928675061291e-06,
      "loss": 0.052,
      "step": 57
    },
    {
      "epoch": 0.03838517538054269,
      "grad_norm": 3.5075864791870117,
      "learning_rate": 9.96368881242496e-06,
      "loss": 0.1104,
      "step": 58
    },
    {
      "epoch": 0.039046988749172735,
      "grad_norm": 4.706087589263916,
      "learning_rate": 9.962427492482027e-06,
      "loss": 0.2434,
      "step": 59
    },
    {
      "epoch": 0.03970880211780278,
      "grad_norm": 5.945282459259033,
      "learning_rate": 9.961144720684997e-06,
      "loss": 0.2076,
      "step": 60
    },
    {
      "epoch": 0.04037061548643282,
      "grad_norm": 1.6805880069732666,
      "learning_rate": 9.959840502579108e-06,
      "loss": 0.0557,
      "step": 61
    },
    {
      "epoch": 0.04103242885506287,
      "grad_norm": 6.735721111297607,
      "learning_rate": 9.958514843802306e-06,
      "loss": 0.5033,
      "step": 62
    },
    {
      "epoch": 0.04169424222369292,
      "grad_norm": 12.583837509155273,
      "learning_rate": 9.957167750085217e-06,
      "loss": 1.0005,
      "step": 63
    },
    {
      "epoch": 0.042356055592322965,
      "grad_norm": 7.527141094207764,
      "learning_rate": 9.955799227251138e-06,
      "loss": 0.4169,
      "step": 64
    },
    {
      "epoch": 0.04301786896095301,
      "grad_norm": 0.3404648005962372,
      "learning_rate": 9.95440928121599e-06,
      "loss": 0.0045,
      "step": 65
    },
    {
      "epoch": 0.04367968232958306,
      "grad_norm": 0.44282516837120056,
      "learning_rate": 9.952997917988309e-06,
      "loss": 0.0137,
      "step": 66
    },
    {
      "epoch": 0.04434149569821311,
      "grad_norm": 0.4753982424736023,
      "learning_rate": 9.951565143669214e-06,
      "loss": 0.0145,
      "step": 67
    },
    {
      "epoch": 0.04500330906684315,
      "grad_norm": 2.20815372467041,
      "learning_rate": 9.950110964452382e-06,
      "loss": 0.0604,
      "step": 68
    },
    {
      "epoch": 0.045665122435473195,
      "grad_norm": 15.683317184448242,
      "learning_rate": 9.948635386624015e-06,
      "loss": 0.5328,
      "step": 69
    },
    {
      "epoch": 0.04632693580410324,
      "grad_norm": 0.7317635416984558,
      "learning_rate": 9.947138416562827e-06,
      "loss": 0.0209,
      "step": 70
    },
    {
      "epoch": 0.04698874917273329,
      "grad_norm": 0.05920504406094551,
      "learning_rate": 9.945620060739999e-06,
      "loss": 0.0014,
      "step": 71
    },
    {
      "epoch": 0.04765056254136334,
      "grad_norm": 0.27585917711257935,
      "learning_rate": 9.944080325719163e-06,
      "loss": 0.0079,
      "step": 72
    },
    {
      "epoch": 0.048312375909993384,
      "grad_norm": 9.72624683380127,
      "learning_rate": 9.94251921815637e-06,
      "loss": 0.9697,
      "step": 73
    },
    {
      "epoch": 0.04897418927862343,
      "grad_norm": 0.09650340676307678,
      "learning_rate": 9.940936744800064e-06,
      "loss": 0.0022,
      "step": 74
    },
    {
      "epoch": 0.04963600264725347,
      "grad_norm": 0.30965936183929443,
      "learning_rate": 9.939332912491044e-06,
      "loss": 0.0098,
      "step": 75
    },
    {
      "epoch": 0.05029781601588352,
      "grad_norm": 4.1255292892456055,
      "learning_rate": 9.937707728162448e-06,
      "loss": 0.3269,
      "step": 76
    },
    {
      "epoch": 0.050959629384513566,
      "grad_norm": 0.5042117238044739,
      "learning_rate": 9.93606119883971e-06,
      "loss": 0.0167,
      "step": 77
    },
    {
      "epoch": 0.05162144275314361,
      "grad_norm": 0.20744289457798004,
      "learning_rate": 9.934393331640538e-06,
      "loss": 0.0062,
      "step": 78
    },
    {
      "epoch": 0.05228325612177366,
      "grad_norm": 0.5316863656044006,
      "learning_rate": 9.932704133774878e-06,
      "loss": 0.0109,
      "step": 79
    },
    {
      "epoch": 0.05294506949040371,
      "grad_norm": 0.28387606143951416,
      "learning_rate": 9.93099361254489e-06,
      "loss": 0.0084,
      "step": 80
    },
    {
      "epoch": 0.053606882859033755,
      "grad_norm": 0.28238987922668457,
      "learning_rate": 9.929261775344908e-06,
      "loss": 0.0075,
      "step": 81
    },
    {
      "epoch": 0.054268696227663796,
      "grad_norm": 4.395970821380615,
      "learning_rate": 9.927508629661413e-06,
      "loss": 0.0411,
      "step": 82
    },
    {
      "epoch": 0.05493050959629384,
      "grad_norm": 0.056481391191482544,
      "learning_rate": 9.925734183073002e-06,
      "loss": 0.0013,
      "step": 83
    },
    {
      "epoch": 0.05559232296492389,
      "grad_norm": 11.243390083312988,
      "learning_rate": 9.923938443250345e-06,
      "loss": 0.7101,
      "step": 84
    },
    {
      "epoch": 0.05625413633355394,
      "grad_norm": 0.07741834223270416,
      "learning_rate": 9.922121417956168e-06,
      "loss": 0.0019,
      "step": 85
    },
    {
      "epoch": 0.056915949702183985,
      "grad_norm": 0.09915710240602493,
      "learning_rate": 9.920283115045207e-06,
      "loss": 0.0009,
      "step": 86
    },
    {
      "epoch": 0.05757776307081403,
      "grad_norm": 0.032593753188848495,
      "learning_rate": 9.918423542464176e-06,
      "loss": 0.0009,
      "step": 87
    },
    {
      "epoch": 0.05823957643944408,
      "grad_norm": 0.2722351551055908,
      "learning_rate": 9.916542708251744e-06,
      "loss": 0.0046,
      "step": 88
    },
    {
      "epoch": 0.05890138980807412,
      "grad_norm": 0.20680291950702667,
      "learning_rate": 9.914640620538481e-06,
      "loss": 0.0047,
      "step": 89
    },
    {
      "epoch": 0.05956320317670417,
      "grad_norm": 10.009082794189453,
      "learning_rate": 9.912717287546836e-06,
      "loss": 0.7968,
      "step": 90
    },
    {
      "epoch": 0.060225016545334215,
      "grad_norm": 0.013227792456746101,
      "learning_rate": 9.910772717591097e-06,
      "loss": 0.0003,
      "step": 91
    },
    {
      "epoch": 0.06088682991396426,
      "grad_norm": 0.11264683306217194,
      "learning_rate": 9.90880691907736e-06,
      "loss": 0.0022,
      "step": 92
    },
    {
      "epoch": 0.06154864328259431,
      "grad_norm": 0.37462490797042847,
      "learning_rate": 9.906819900503486e-06,
      "loss": 0.0129,
      "step": 93
    },
    {
      "epoch": 0.062210456651224356,
      "grad_norm": 0.027642056345939636,
      "learning_rate": 9.904811670459069e-06,
      "loss": 0.0006,
      "step": 94
    },
    {
      "epoch": 0.0628722700198544,
      "grad_norm": 0.057691752910614014,
      "learning_rate": 9.902782237625393e-06,
      "loss": 0.0013,
      "step": 95
    },
    {
      "epoch": 0.06353408338848444,
      "grad_norm": 0.06168411299586296,
      "learning_rate": 9.900731610775405e-06,
      "loss": 0.0013,
      "step": 96
    },
    {
      "epoch": 0.0641958967571145,
      "grad_norm": 0.07643508911132812,
      "learning_rate": 9.898659798773667e-06,
      "loss": 0.0016,
      "step": 97
    },
    {
      "epoch": 0.06485771012574454,
      "grad_norm": 0.027750706300139427,
      "learning_rate": 9.896566810576322e-06,
      "loss": 0.0006,
      "step": 98
    },
    {
      "epoch": 0.06551952349437459,
      "grad_norm": 0.019366003572940826,
      "learning_rate": 9.894452655231051e-06,
      "loss": 0.0005,
      "step": 99
    },
    {
      "epoch": 0.06618133686300463,
      "grad_norm": 0.02390342578291893,
      "learning_rate": 9.892317341877044e-06,
      "loss": 0.0006,
      "step": 100
    },
    {
      "epoch": 0.06684315023163467,
      "grad_norm": 0.004575557541102171,
      "learning_rate": 9.890160879744951e-06,
      "loss": 0.0001,
      "step": 101
    },
    {
      "epoch": 0.06750496360026473,
      "grad_norm": 8.049050331115723,
      "learning_rate": 9.887983278156842e-06,
      "loss": 0.2829,
      "step": 102
    },
    {
      "epoch": 0.06816677696889477,
      "grad_norm": 0.05327683314681053,
      "learning_rate": 9.885784546526177e-06,
      "loss": 0.0013,
      "step": 103
    },
    {
      "epoch": 0.06882859033752482,
      "grad_norm": 0.14202432334423065,
      "learning_rate": 9.88356469435775e-06,
      "loss": 0.003,
      "step": 104
    },
    {
      "epoch": 0.06949040370615486,
      "grad_norm": 0.013176503591239452,
      "learning_rate": 9.881323731247663e-06,
      "loss": 0.0003,
      "step": 105
    },
    {
      "epoch": 0.07015221707478492,
      "grad_norm": 10.981724739074707,
      "learning_rate": 9.879061666883271e-06,
      "loss": 0.5687,
      "step": 106
    },
    {
      "epoch": 0.07081403044341496,
      "grad_norm": 7.871335983276367,
      "learning_rate": 9.876778511043153e-06,
      "loss": 1.6408,
      "step": 107
    },
    {
      "epoch": 0.071475843812045,
      "grad_norm": 0.02018853649497032,
      "learning_rate": 9.874474273597059e-06,
      "loss": 0.0005,
      "step": 108
    },
    {
      "epoch": 0.07213765718067505,
      "grad_norm": 0.011175991035997868,
      "learning_rate": 9.872148964505873e-06,
      "loss": 0.0002,
      "step": 109
    },
    {
      "epoch": 0.07279947054930509,
      "grad_norm": 0.11050838977098465,
      "learning_rate": 9.869802593821569e-06,
      "loss": 0.0015,
      "step": 110
    },
    {
      "epoch": 0.07346128391793515,
      "grad_norm": 0.014282272197306156,
      "learning_rate": 9.867435171687167e-06,
      "loss": 0.0003,
      "step": 111
    },
    {
      "epoch": 0.07412309728656519,
      "grad_norm": 0.02633051760494709,
      "learning_rate": 9.865046708336691e-06,
      "loss": 0.0006,
      "step": 112
    },
    {
      "epoch": 0.07478491065519524,
      "grad_norm": 0.013923028483986855,
      "learning_rate": 9.862637214095122e-06,
      "loss": 0.0003,
      "step": 113
    },
    {
      "epoch": 0.07544672402382528,
      "grad_norm": 0.015939243137836456,
      "learning_rate": 9.86020669937835e-06,
      "loss": 0.0003,
      "step": 114
    },
    {
      "epoch": 0.07610853739245532,
      "grad_norm": 6.466063022613525,
      "learning_rate": 9.85775517469314e-06,
      "loss": 0.1811,
      "step": 115
    },
    {
      "epoch": 0.07677035076108538,
      "grad_norm": 0.021227607503533363,
      "learning_rate": 9.855282650637079e-06,
      "loss": 0.0005,
      "step": 116
    },
    {
      "epoch": 0.07743216412971542,
      "grad_norm": 0.06853535026311874,
      "learning_rate": 9.852789137898526e-06,
      "loss": 0.0018,
      "step": 117
    },
    {
      "epoch": 0.07809397749834547,
      "grad_norm": 0.37198764085769653,
      "learning_rate": 9.85027464725658e-06,
      "loss": 0.0043,
      "step": 118
    },
    {
      "epoch": 0.07875579086697551,
      "grad_norm": 0.020656954497098923,
      "learning_rate": 9.847739189581014e-06,
      "loss": 0.0005,
      "step": 119
    },
    {
      "epoch": 0.07941760423560557,
      "grad_norm": 0.015985004603862762,
      "learning_rate": 9.845182775832245e-06,
      "loss": 0.0003,
      "step": 120
    },
    {
      "epoch": 0.0800794176042356,
      "grad_norm": 0.1765742003917694,
      "learning_rate": 9.842605417061281e-06,
      "loss": 0.0027,
      "step": 121
    },
    {
      "epoch": 0.08074123097286565,
      "grad_norm": 8.60898494720459,
      "learning_rate": 9.84000712440967e-06,
      "loss": 0.4325,
      "step": 122
    },
    {
      "epoch": 0.0814030443414957,
      "grad_norm": 0.015582654625177383,
      "learning_rate": 9.837387909109452e-06,
      "loss": 0.0004,
      "step": 123
    },
    {
      "epoch": 0.08206485771012574,
      "grad_norm": 0.01546182855963707,
      "learning_rate": 9.834747782483114e-06,
      "loss": 0.0003,
      "step": 124
    },
    {
      "epoch": 0.0827266710787558,
      "grad_norm": 0.24888913333415985,
      "learning_rate": 9.832086755943544e-06,
      "loss": 0.0059,
      "step": 125
    },
    {
      "epoch": 0.08338848444738584,
      "grad_norm": 0.27481338381767273,
      "learning_rate": 9.829404840993972e-06,
      "loss": 0.0082,
      "step": 126
    },
    {
      "epoch": 0.08405029781601589,
      "grad_norm": 0.030947653576731682,
      "learning_rate": 9.826702049227926e-06,
      "loss": 0.0007,
      "step": 127
    },
    {
      "epoch": 0.08471211118464593,
      "grad_norm": 0.013938414864242077,
      "learning_rate": 9.823978392329184e-06,
      "loss": 0.0003,
      "step": 128
    },
    {
      "epoch": 0.08537392455327597,
      "grad_norm": 14.987802505493164,
      "learning_rate": 9.821233882071717e-06,
      "loss": 0.5125,
      "step": 129
    },
    {
      "epoch": 0.08603573792190602,
      "grad_norm": 0.014653434045612812,
      "learning_rate": 9.818468530319649e-06,
      "loss": 0.0004,
      "step": 130
    },
    {
      "epoch": 0.08669755129053607,
      "grad_norm": 0.021724849939346313,
      "learning_rate": 9.815682349027194e-06,
      "loss": 0.0006,
      "step": 131
    },
    {
      "epoch": 0.08735936465916612,
      "grad_norm": 0.01215692050755024,
      "learning_rate": 9.812875350238604e-06,
      "loss": 0.0002,
      "step": 132
    },
    {
      "epoch": 0.08802117802779616,
      "grad_norm": 0.025985926389694214,
      "learning_rate": 9.810047546088134e-06,
      "loss": 0.0006,
      "step": 133
    },
    {
      "epoch": 0.08868299139642621,
      "grad_norm": 0.03671732172369957,
      "learning_rate": 9.807198948799967e-06,
      "loss": 0.0007,
      "step": 134
    },
    {
      "epoch": 0.08934480476505625,
      "grad_norm": 0.015732750296592712,
      "learning_rate": 9.804329570688178e-06,
      "loss": 0.0003,
      "step": 135
    },
    {
      "epoch": 0.0900066181336863,
      "grad_norm": 0.0448613315820694,
      "learning_rate": 9.801439424156672e-06,
      "loss": 0.001,
      "step": 136
    },
    {
      "epoch": 0.09066843150231635,
      "grad_norm": 6.1399126052856445,
      "learning_rate": 9.798528521699132e-06,
      "loss": 0.4683,
      "step": 137
    },
    {
      "epoch": 0.09133024487094639,
      "grad_norm": 10.975337028503418,
      "learning_rate": 9.795596875898967e-06,
      "loss": 0.7406,
      "step": 138
    },
    {
      "epoch": 0.09199205823957644,
      "grad_norm": 3.1927411556243896,
      "learning_rate": 9.79264449942926e-06,
      "loss": 0.0541,
      "step": 139
    },
    {
      "epoch": 0.09265387160820648,
      "grad_norm": 9.304032325744629,
      "learning_rate": 9.789671405052702e-06,
      "loss": 0.6726,
      "step": 140
    },
    {
      "epoch": 0.09331568497683654,
      "grad_norm": 0.008994114585220814,
      "learning_rate": 9.786677605621547e-06,
      "loss": 0.0002,
      "step": 141
    },
    {
      "epoch": 0.09397749834546658,
      "grad_norm": 0.01871991902589798,
      "learning_rate": 9.783663114077562e-06,
      "loss": 0.0005,
      "step": 142
    },
    {
      "epoch": 0.09463931171409662,
      "grad_norm": 0.008942333981394768,
      "learning_rate": 9.78062794345195e-06,
      "loss": 0.0002,
      "step": 143
    },
    {
      "epoch": 0.09530112508272667,
      "grad_norm": 0.33071860671043396,
      "learning_rate": 9.777572106865318e-06,
      "loss": 0.0078,
      "step": 144
    },
    {
      "epoch": 0.09596293845135671,
      "grad_norm": 0.014054413884878159,
      "learning_rate": 9.774495617527604e-06,
      "loss": 0.0003,
      "step": 145
    },
    {
      "epoch": 0.09662475181998677,
      "grad_norm": 1.5404880046844482,
      "learning_rate": 9.771398488738021e-06,
      "loss": 0.0238,
      "step": 146
    },
    {
      "epoch": 0.09728656518861681,
      "grad_norm": 5.131400108337402,
      "learning_rate": 9.768280733885014e-06,
      "loss": 0.1141,
      "step": 147
    },
    {
      "epoch": 0.09794837855724686,
      "grad_norm": 0.01793001778423786,
      "learning_rate": 9.76514236644618e-06,
      "loss": 0.0004,
      "step": 148
    },
    {
      "epoch": 0.0986101919258769,
      "grad_norm": 0.5032421946525574,
      "learning_rate": 9.761983399988224e-06,
      "loss": 0.0101,
      "step": 149
    },
    {
      "epoch": 0.09927200529450694,
      "grad_norm": 0.07522916793823242,
      "learning_rate": 9.758803848166904e-06,
      "loss": 0.0019,
      "step": 150
    },
    {
      "epoch": 0.099933818663137,
      "grad_norm": 0.022765319794416428,
      "learning_rate": 9.755603724726962e-06,
      "loss": 0.0004,
      "step": 151
    },
    {
      "epoch": 0.10059563203176704,
      "grad_norm": 0.08426638692617416,
      "learning_rate": 9.752383043502062e-06,
      "loss": 0.0019,
      "step": 152
    },
    {
      "epoch": 0.10125744540039709,
      "grad_norm": 0.03738687187433243,
      "learning_rate": 9.749141818414748e-06,
      "loss": 0.0007,
      "step": 153
    },
    {
      "epoch": 0.10191925876902713,
      "grad_norm": 0.008398162201046944,
      "learning_rate": 9.745880063476362e-06,
      "loss": 0.0002,
      "step": 154
    },
    {
      "epoch": 0.10258107213765719,
      "grad_norm": 0.03714712709188461,
      "learning_rate": 9.742597792786998e-06,
      "loss": 0.001,
      "step": 155
    },
    {
      "epoch": 0.10324288550628723,
      "grad_norm": 0.008566112257540226,
      "learning_rate": 9.739295020535438e-06,
      "loss": 0.0002,
      "step": 156
    },
    {
      "epoch": 0.10390469887491727,
      "grad_norm": 0.011636445298790932,
      "learning_rate": 9.735971760999083e-06,
      "loss": 0.0002,
      "step": 157
    },
    {
      "epoch": 0.10456651224354732,
      "grad_norm": 0.0034887532237917185,
      "learning_rate": 9.732628028543906e-06,
      "loss": 0.0001,
      "step": 158
    },
    {
      "epoch": 0.10522832561217736,
      "grad_norm": 0.013350085355341434,
      "learning_rate": 9.729263837624377e-06,
      "loss": 0.0003,
      "step": 159
    },
    {
      "epoch": 0.10589013898080742,
      "grad_norm": 8.994584083557129,
      "learning_rate": 9.725879202783401e-06,
      "loss": 0.0972,
      "step": 160
    },
    {
      "epoch": 0.10655195234943746,
      "grad_norm": 0.028237445279955864,
      "learning_rate": 9.722474138652268e-06,
      "loss": 0.0007,
      "step": 161
    },
    {
      "epoch": 0.10721376571806751,
      "grad_norm": 0.003959504887461662,
      "learning_rate": 9.719048659950573e-06,
      "loss": 0.0001,
      "step": 162
    },
    {
      "epoch": 0.10787557908669755,
      "grad_norm": 6.386683464050293,
      "learning_rate": 9.715602781486166e-06,
      "loss": 0.2864,
      "step": 163
    },
    {
      "epoch": 0.10853739245532759,
      "grad_norm": 0.006018211133778095,
      "learning_rate": 9.71213651815508e-06,
      "loss": 0.0002,
      "step": 164
    },
    {
      "epoch": 0.10919920582395765,
      "grad_norm": 0.013746660202741623,
      "learning_rate": 9.708649884941466e-06,
      "loss": 0.0003,
      "step": 165
    },
    {
      "epoch": 0.10986101919258769,
      "grad_norm": 0.10888394713401794,
      "learning_rate": 9.705142896917534e-06,
      "loss": 0.0019,
      "step": 166
    },
    {
      "epoch": 0.11052283256121774,
      "grad_norm": 0.037445180118083954,
      "learning_rate": 9.701615569243486e-06,
      "loss": 0.0007,
      "step": 167
    },
    {
      "epoch": 0.11118464592984778,
      "grad_norm": 2.6366066932678223,
      "learning_rate": 9.698067917167446e-06,
      "loss": 0.1351,
      "step": 168
    },
    {
      "epoch": 0.11184645929847783,
      "grad_norm": 0.1196252852678299,
      "learning_rate": 9.6944999560254e-06,
      "loss": 0.0022,
      "step": 169
    },
    {
      "epoch": 0.11250827266710788,
      "grad_norm": 14.642577171325684,
      "learning_rate": 9.690911701241127e-06,
      "loss": 0.7017,
      "step": 170
    },
    {
      "epoch": 0.11317008603573792,
      "grad_norm": 0.00859841424971819,
      "learning_rate": 9.687303168326134e-06,
      "loss": 0.0002,
      "step": 171
    },
    {
      "epoch": 0.11383189940436797,
      "grad_norm": 0.013485078699886799,
      "learning_rate": 9.68367437287958e-06,
      "loss": 0.0003,
      "step": 172
    },
    {
      "epoch": 0.11449371277299801,
      "grad_norm": 0.008059673011302948,
      "learning_rate": 9.680025330588224e-06,
      "loss": 0.0002,
      "step": 173
    },
    {
      "epoch": 0.11515552614162806,
      "grad_norm": 0.008157184347510338,
      "learning_rate": 9.676356057226346e-06,
      "loss": 0.0002,
      "step": 174
    },
    {
      "epoch": 0.1158173395102581,
      "grad_norm": 0.004666222725063562,
      "learning_rate": 9.672666568655684e-06,
      "loss": 0.0001,
      "step": 175
    },
    {
      "epoch": 0.11647915287888816,
      "grad_norm": 0.04435385763645172,
      "learning_rate": 9.66895688082536e-06,
      "loss": 0.0011,
      "step": 176
    },
    {
      "epoch": 0.1171409662475182,
      "grad_norm": 0.07435335963964462,
      "learning_rate": 9.665227009771817e-06,
      "loss": 0.002,
      "step": 177
    },
    {
      "epoch": 0.11780277961614824,
      "grad_norm": 14.886228561401367,
      "learning_rate": 9.661476971618744e-06,
      "loss": 0.3082,
      "step": 178
    },
    {
      "epoch": 0.1184645929847783,
      "grad_norm": 0.11044255644083023,
      "learning_rate": 9.657706782577017e-06,
      "loss": 0.0027,
      "step": 179
    },
    {
      "epoch": 0.11912640635340833,
      "grad_norm": 0.16498887538909912,
      "learning_rate": 9.653916458944612e-06,
      "loss": 0.0043,
      "step": 180
    },
    {
      "epoch": 0.11978821972203839,
      "grad_norm": 0.016469046473503113,
      "learning_rate": 9.65010601710655e-06,
      "loss": 0.0003,
      "step": 181
    },
    {
      "epoch": 0.12045003309066843,
      "grad_norm": 3.52942156791687,
      "learning_rate": 9.646275473534815e-06,
      "loss": 0.0865,
      "step": 182
    },
    {
      "epoch": 0.12111184645929848,
      "grad_norm": 0.003670677775517106,
      "learning_rate": 9.642424844788298e-06,
      "loss": 0.0001,
      "step": 183
    },
    {
      "epoch": 0.12177365982792852,
      "grad_norm": 0.009158329106867313,
      "learning_rate": 9.638554147512702e-06,
      "loss": 0.0002,
      "step": 184
    },
    {
      "epoch": 0.12243547319655856,
      "grad_norm": 0.020303288474678993,
      "learning_rate": 9.634663398440493e-06,
      "loss": 0.0003,
      "step": 185
    },
    {
      "epoch": 0.12309728656518862,
      "grad_norm": 0.030566103756427765,
      "learning_rate": 9.630752614390813e-06,
      "loss": 0.0007,
      "step": 186
    },
    {
      "epoch": 0.12375909993381866,
      "grad_norm": 0.22714512050151825,
      "learning_rate": 9.626821812269416e-06,
      "loss": 0.0035,
      "step": 187
    },
    {
      "epoch": 0.12442091330244871,
      "grad_norm": 0.04456240311264992,
      "learning_rate": 9.622871009068588e-06,
      "loss": 0.0005,
      "step": 188
    },
    {
      "epoch": 0.12508272667107875,
      "grad_norm": 0.0038577704690396786,
      "learning_rate": 9.618900221867077e-06,
      "loss": 0.0001,
      "step": 189
    },
    {
      "epoch": 0.1257445400397088,
      "grad_norm": 0.11047317087650299,
      "learning_rate": 9.614909467830022e-06,
      "loss": 0.002,
      "step": 190
    },
    {
      "epoch": 0.12640635340833886,
      "grad_norm": 5.387887477874756,
      "learning_rate": 9.610898764208874e-06,
      "loss": 0.239,
      "step": 191
    },
    {
      "epoch": 0.1270681667769689,
      "grad_norm": 0.020179107785224915,
      "learning_rate": 9.60686812834132e-06,
      "loss": 0.0004,
      "step": 192
    },
    {
      "epoch": 0.12772998014559894,
      "grad_norm": 17.003149032592773,
      "learning_rate": 9.602817577651217e-06,
      "loss": 0.6161,
      "step": 193
    },
    {
      "epoch": 0.128391793514229,
      "grad_norm": 0.09582424908876419,
      "learning_rate": 9.598747129648506e-06,
      "loss": 0.0018,
      "step": 194
    },
    {
      "epoch": 0.12905360688285902,
      "grad_norm": 15.050335884094238,
      "learning_rate": 9.594656801929145e-06,
      "loss": 0.7098,
      "step": 195
    },
    {
      "epoch": 0.12971542025148908,
      "grad_norm": 0.010253192856907845,
      "learning_rate": 9.590546612175024e-06,
      "loss": 0.0002,
      "step": 196
    },
    {
      "epoch": 0.13037723362011913,
      "grad_norm": 0.008404994383454323,
      "learning_rate": 9.586416578153903e-06,
      "loss": 0.0002,
      "step": 197
    },
    {
      "epoch": 0.13103904698874919,
      "grad_norm": 0.003834919538348913,
      "learning_rate": 9.582266717719314e-06,
      "loss": 0.0001,
      "step": 198
    },
    {
      "epoch": 0.1317008603573792,
      "grad_norm": 0.012880566529929638,
      "learning_rate": 9.578097048810505e-06,
      "loss": 0.0002,
      "step": 199
    },
    {
      "epoch": 0.13236267372600927,
      "grad_norm": 1.4910163879394531,
      "learning_rate": 9.573907589452346e-06,
      "loss": 0.0237,
      "step": 200
    },
    {
      "epoch": 0.13302448709463932,
      "grad_norm": 0.014228668995201588,
      "learning_rate": 9.569698357755267e-06,
      "loss": 0.0003,
      "step": 201
    },
    {
      "epoch": 0.13368630046326935,
      "grad_norm": 0.018719496205449104,
      "learning_rate": 9.565469371915164e-06,
      "loss": 0.0003,
      "step": 202
    },
    {
      "epoch": 0.1343481138318994,
      "grad_norm": 0.006605672184377909,
      "learning_rate": 9.561220650213326e-06,
      "loss": 0.0002,
      "step": 203
    },
    {
      "epoch": 0.13500992720052946,
      "grad_norm": 0.14238017797470093,
      "learning_rate": 9.556952211016365e-06,
      "loss": 0.002,
      "step": 204
    },
    {
      "epoch": 0.1356717405691595,
      "grad_norm": 13.306337356567383,
      "learning_rate": 9.552664072776123e-06,
      "loss": 0.7121,
      "step": 205
    },
    {
      "epoch": 0.13633355393778954,
      "grad_norm": 0.0058511169627308846,
      "learning_rate": 9.548356254029599e-06,
      "loss": 0.0001,
      "step": 206
    },
    {
      "epoch": 0.1369953673064196,
      "grad_norm": 0.006341413129121065,
      "learning_rate": 9.544028773398867e-06,
      "loss": 0.0001,
      "step": 207
    },
    {
      "epoch": 0.13765718067504965,
      "grad_norm": 8.831740379333496,
      "learning_rate": 9.539681649591001e-06,
      "loss": 0.1731,
      "step": 208
    },
    {
      "epoch": 0.13831899404367967,
      "grad_norm": 4.872690200805664,
      "learning_rate": 9.535314901397985e-06,
      "loss": 0.022,
      "step": 209
    },
    {
      "epoch": 0.13898080741230973,
      "grad_norm": 0.023554548621177673,
      "learning_rate": 9.530928547696639e-06,
      "loss": 0.0006,
      "step": 210
    },
    {
      "epoch": 0.13964262078093978,
      "grad_norm": 0.05656176060438156,
      "learning_rate": 9.526522607448529e-06,
      "loss": 0.0016,
      "step": 211
    },
    {
      "epoch": 0.14030443414956983,
      "grad_norm": 0.007255470380187035,
      "learning_rate": 9.522097099699903e-06,
      "loss": 0.0001,
      "step": 212
    },
    {
      "epoch": 0.14096624751819986,
      "grad_norm": 0.010481910780072212,
      "learning_rate": 9.517652043581584e-06,
      "loss": 0.0002,
      "step": 213
    },
    {
      "epoch": 0.14162806088682992,
      "grad_norm": 0.018452182412147522,
      "learning_rate": 9.513187458308904e-06,
      "loss": 0.0004,
      "step": 214
    },
    {
      "epoch": 0.14228987425545997,
      "grad_norm": 0.04405271261930466,
      "learning_rate": 9.508703363181621e-06,
      "loss": 0.0008,
      "step": 215
    },
    {
      "epoch": 0.14295168762409,
      "grad_norm": 0.004534670151770115,
      "learning_rate": 9.504199777583825e-06,
      "loss": 0.0001,
      "step": 216
    },
    {
      "epoch": 0.14361350099272005,
      "grad_norm": 0.002652534283697605,
      "learning_rate": 9.499676720983864e-06,
      "loss": 0.0001,
      "step": 217
    },
    {
      "epoch": 0.1442753143613501,
      "grad_norm": 0.030258139595389366,
      "learning_rate": 9.495134212934255e-06,
      "loss": 0.0003,
      "step": 218
    },
    {
      "epoch": 0.14493712772998016,
      "grad_norm": 0.06366835534572601,
      "learning_rate": 9.490572273071603e-06,
      "loss": 0.0019,
      "step": 219
    },
    {
      "epoch": 0.14559894109861019,
      "grad_norm": 0.0024956774432212114,
      "learning_rate": 9.485990921116512e-06,
      "loss": 0.0001,
      "step": 220
    },
    {
      "epoch": 0.14626075446724024,
      "grad_norm": 3.844120979309082,
      "learning_rate": 9.481390176873498e-06,
      "loss": 0.3461,
      "step": 221
    },
    {
      "epoch": 0.1469225678358703,
      "grad_norm": 0.012416724115610123,
      "learning_rate": 9.476770060230915e-06,
      "loss": 0.0003,
      "step": 222
    },
    {
      "epoch": 0.14758438120450032,
      "grad_norm": 0.0022739777341485023,
      "learning_rate": 9.472130591160856e-06,
      "loss": 0.0001,
      "step": 223
    },
    {
      "epoch": 0.14824619457313037,
      "grad_norm": 7.372269153594971,
      "learning_rate": 9.467471789719072e-06,
      "loss": 0.0898,
      "step": 224
    },
    {
      "epoch": 0.14890800794176043,
      "grad_norm": 3.0895683765411377,
      "learning_rate": 9.462793676044884e-06,
      "loss": 0.0457,
      "step": 225
    },
    {
      "epoch": 0.14956982131039048,
      "grad_norm": 0.002353460993617773,
      "learning_rate": 9.458096270361103e-06,
      "loss": 0.0001,
      "step": 226
    },
    {
      "epoch": 0.1502316346790205,
      "grad_norm": 6.9346089363098145,
      "learning_rate": 9.45337959297393e-06,
      "loss": 0.1503,
      "step": 227
    },
    {
      "epoch": 0.15089344804765056,
      "grad_norm": 0.19870655238628387,
      "learning_rate": 9.448643664272876e-06,
      "loss": 0.0032,
      "step": 228
    },
    {
      "epoch": 0.15155526141628062,
      "grad_norm": 0.0038989372551441193,
      "learning_rate": 9.443888504730674e-06,
      "loss": 0.0001,
      "step": 229
    },
    {
      "epoch": 0.15221707478491064,
      "grad_norm": 0.002223425079137087,
      "learning_rate": 9.439114134903191e-06,
      "loss": 0.0001,
      "step": 230
    },
    {
      "epoch": 0.1528788881535407,
      "grad_norm": 0.0031174798496067524,
      "learning_rate": 9.434320575429334e-06,
      "loss": 0.0001,
      "step": 231
    },
    {
      "epoch": 0.15354070152217075,
      "grad_norm": 0.004120126366615295,
      "learning_rate": 9.429507847030963e-06,
      "loss": 0.0001,
      "step": 232
    },
    {
      "epoch": 0.1542025148908008,
      "grad_norm": 0.006279831752181053,
      "learning_rate": 9.424675970512807e-06,
      "loss": 0.0001,
      "step": 233
    },
    {
      "epoch": 0.15486432825943083,
      "grad_norm": 6.480002403259277,
      "learning_rate": 9.419824966762367e-06,
      "loss": 0.1218,
      "step": 234
    },
    {
      "epoch": 0.1555261416280609,
      "grad_norm": 8.691030502319336,
      "learning_rate": 9.414954856749828e-06,
      "loss": 0.247,
      "step": 235
    },
    {
      "epoch": 0.15618795499669094,
      "grad_norm": 0.008601989597082138,
      "learning_rate": 9.410065661527969e-06,
      "loss": 0.0002,
      "step": 236
    },
    {
      "epoch": 0.15684976836532097,
      "grad_norm": 0.04323222488164902,
      "learning_rate": 9.405157402232072e-06,
      "loss": 0.0009,
      "step": 237
    },
    {
      "epoch": 0.15751158173395102,
      "grad_norm": 0.022523649036884308,
      "learning_rate": 9.400230100079828e-06,
      "loss": 0.0005,
      "step": 238
    },
    {
      "epoch": 0.15817339510258108,
      "grad_norm": 0.18763773143291473,
      "learning_rate": 9.395283776371253e-06,
      "loss": 0.0036,
      "step": 239
    },
    {
      "epoch": 0.15883520847121113,
      "grad_norm": 0.02005503512918949,
      "learning_rate": 9.390318452488583e-06,
      "loss": 0.0004,
      "step": 240
    },
    {
      "epoch": 0.15949702183984116,
      "grad_norm": 0.004495618399232626,
      "learning_rate": 9.385334149896195e-06,
      "loss": 0.0001,
      "step": 241
    },
    {
      "epoch": 0.1601588352084712,
      "grad_norm": 0.008538298308849335,
      "learning_rate": 9.380330890140505e-06,
      "loss": 0.0002,
      "step": 242
    },
    {
      "epoch": 0.16082064857710127,
      "grad_norm": 0.017994269728660583,
      "learning_rate": 9.37530869484988e-06,
      "loss": 0.0004,
      "step": 243
    },
    {
      "epoch": 0.1614824619457313,
      "grad_norm": 6.880463123321533,
      "learning_rate": 9.37026758573454e-06,
      "loss": 0.3067,
      "step": 244
    },
    {
      "epoch": 0.16214427531436135,
      "grad_norm": 0.4659038782119751,
      "learning_rate": 9.36520758458647e-06,
      "loss": 0.0055,
      "step": 245
    },
    {
      "epoch": 0.1628060886829914,
      "grad_norm": 0.03354083374142647,
      "learning_rate": 9.360128713279322e-06,
      "loss": 0.0005,
      "step": 246
    },
    {
      "epoch": 0.16346790205162146,
      "grad_norm": 10.858159065246582,
      "learning_rate": 9.355030993768315e-06,
      "loss": 0.7576,
      "step": 247
    },
    {
      "epoch": 0.16412971542025148,
      "grad_norm": 0.00587659515440464,
      "learning_rate": 9.349914448090156e-06,
      "loss": 0.0002,
      "step": 248
    },
    {
      "epoch": 0.16479152878888154,
      "grad_norm": 0.030036309733986855,
      "learning_rate": 9.344779098362926e-06,
      "loss": 0.0007,
      "step": 249
    },
    {
      "epoch": 0.1654533421575116,
      "grad_norm": 10.323126792907715,
      "learning_rate": 9.339624966786e-06,
      "loss": 1.2062,
      "step": 250
    },
    {
      "epoch": 0.16611515552614162,
      "grad_norm": 0.4141397774219513,
      "learning_rate": 9.334452075639938e-06,
      "loss": 0.0075,
      "step": 251
    },
    {
      "epoch": 0.16677696889477167,
      "grad_norm": 0.04923465475440025,
      "learning_rate": 9.3292604472864e-06,
      "loss": 0.0012,
      "step": 252
    },
    {
      "epoch": 0.16743878226340173,
      "grad_norm": 0.045019179582595825,
      "learning_rate": 9.324050104168042e-06,
      "loss": 0.0008,
      "step": 253
    },
    {
      "epoch": 0.16810059563203178,
      "grad_norm": 14.506521224975586,
      "learning_rate": 9.318821068808419e-06,
      "loss": 0.1995,
      "step": 254
    },
    {
      "epoch": 0.1687624090006618,
      "grad_norm": 0.010898548178374767,
      "learning_rate": 9.313573363811896e-06,
      "loss": 0.0001,
      "step": 255
    },
    {
      "epoch": 0.16942422236929186,
      "grad_norm": 0.8626495599746704,
      "learning_rate": 9.308307011863538e-06,
      "loss": 0.014,
      "step": 256
    },
    {
      "epoch": 0.17008603573792191,
      "grad_norm": 0.001339753856882453,
      "learning_rate": 9.30302203572902e-06,
      "loss": 0.0001,
      "step": 257
    },
    {
      "epoch": 0.17074784910655194,
      "grad_norm": 0.01026949193328619,
      "learning_rate": 9.297718458254528e-06,
      "loss": 0.0003,
      "step": 258
    },
    {
      "epoch": 0.171409662475182,
      "grad_norm": 0.015307229943573475,
      "learning_rate": 9.292396302366659e-06,
      "loss": 0.0004,
      "step": 259
    },
    {
      "epoch": 0.17207147584381205,
      "grad_norm": 0.0020273509435355663,
      "learning_rate": 9.28705559107232e-06,
      "loss": 0.0001,
      "step": 260
    },
    {
      "epoch": 0.1727332892124421,
      "grad_norm": 0.011101659387350082,
      "learning_rate": 9.28169634745863e-06,
      "loss": 0.0002,
      "step": 261
    },
    {
      "epoch": 0.17339510258107213,
      "grad_norm": 0.0022645641583949327,
      "learning_rate": 9.276318594692822e-06,
      "loss": 0.0001,
      "step": 262
    },
    {
      "epoch": 0.17405691594970218,
      "grad_norm": 0.00999987218528986,
      "learning_rate": 9.270922356022142e-06,
      "loss": 0.0003,
      "step": 263
    },
    {
      "epoch": 0.17471872931833224,
      "grad_norm": 0.004029101692140102,
      "learning_rate": 9.265507654773746e-06,
      "loss": 0.0001,
      "step": 264
    },
    {
      "epoch": 0.17538054268696227,
      "grad_norm": 0.004445677623152733,
      "learning_rate": 9.260074514354603e-06,
      "loss": 0.0001,
      "step": 265
    },
    {
      "epoch": 0.17604235605559232,
      "grad_norm": 4.11250638961792,
      "learning_rate": 9.254622958251388e-06,
      "loss": 0.1351,
      "step": 266
    },
    {
      "epoch": 0.17670416942422237,
      "grad_norm": 0.007354626432061195,
      "learning_rate": 9.249153010030392e-06,
      "loss": 0.0001,
      "step": 267
    },
    {
      "epoch": 0.17736598279285243,
      "grad_norm": 0.0018633527215570211,
      "learning_rate": 9.243664693337404e-06,
      "loss": 0.0001,
      "step": 268
    },
    {
      "epoch": 0.17802779616148245,
      "grad_norm": 0.026719748973846436,
      "learning_rate": 9.23815803189762e-06,
      "loss": 0.0003,
      "step": 269
    },
    {
      "epoch": 0.1786896095301125,
      "grad_norm": 0.008337884210050106,
      "learning_rate": 9.232633049515541e-06,
      "loss": 0.0003,
      "step": 270
    },
    {
      "epoch": 0.17935142289874256,
      "grad_norm": 0.20925121009349823,
      "learning_rate": 9.227089770074864e-06,
      "loss": 0.0019,
      "step": 271
    },
    {
      "epoch": 0.1800132362673726,
      "grad_norm": 0.04245558753609657,
      "learning_rate": 9.22152821753838e-06,
      "loss": 0.0005,
      "step": 272
    },
    {
      "epoch": 0.18067504963600264,
      "grad_norm": 0.05600237101316452,
      "learning_rate": 9.215948415947876e-06,
      "loss": 0.0011,
      "step": 273
    },
    {
      "epoch": 0.1813368630046327,
      "grad_norm": 0.002952760783955455,
      "learning_rate": 9.210350389424022e-06,
      "loss": 0.0001,
      "step": 274
    },
    {
      "epoch": 0.18199867637326275,
      "grad_norm": 16.630136489868164,
      "learning_rate": 9.204734162166275e-06,
      "loss": 0.7914,
      "step": 275
    },
    {
      "epoch": 0.18266048974189278,
      "grad_norm": 24.141212463378906,
      "learning_rate": 9.199099758452775e-06,
      "loss": 0.104,
      "step": 276
    },
    {
      "epoch": 0.18332230311052283,
      "grad_norm": 0.010453170165419579,
      "learning_rate": 9.193447202640226e-06,
      "loss": 0.0001,
      "step": 277
    },
    {
      "epoch": 0.1839841164791529,
      "grad_norm": 0.017108038067817688,
      "learning_rate": 9.187776519163812e-06,
      "loss": 0.0001,
      "step": 278
    },
    {
      "epoch": 0.1846459298477829,
      "grad_norm": 1.6841553449630737,
      "learning_rate": 9.182087732537069e-06,
      "loss": 0.0307,
      "step": 279
    },
    {
      "epoch": 0.18530774321641297,
      "grad_norm": 14.158442497253418,
      "learning_rate": 9.1763808673518e-06,
      "loss": 0.5155,
      "step": 280
    },
    {
      "epoch": 0.18596955658504302,
      "grad_norm": 0.0076323216781020164,
      "learning_rate": 9.170655948277956e-06,
      "loss": 0.0002,
      "step": 281
    },
    {
      "epoch": 0.18663136995367308,
      "grad_norm": 0.00880163349211216,
      "learning_rate": 9.164913000063529e-06,
      "loss": 0.0001,
      "step": 282
    },
    {
      "epoch": 0.1872931833223031,
      "grad_norm": 0.001298536197282374,
      "learning_rate": 9.159152047534455e-06,
      "loss": 0.0,
      "step": 283
    },
    {
      "epoch": 0.18795499669093316,
      "grad_norm": 10.986468315124512,
      "learning_rate": 9.153373115594489e-06,
      "loss": 0.3806,
      "step": 284
    },
    {
      "epoch": 0.1886168100595632,
      "grad_norm": 1.0561898946762085,
      "learning_rate": 9.147576229225121e-06,
      "loss": 0.0158,
      "step": 285
    },
    {
      "epoch": 0.18927862342819324,
      "grad_norm": 0.0022243817802518606,
      "learning_rate": 9.14176141348545e-06,
      "loss": 0.0001,
      "step": 286
    },
    {
      "epoch": 0.1899404367968233,
      "grad_norm": 0.23524625599384308,
      "learning_rate": 9.135928693512078e-06,
      "loss": 0.0041,
      "step": 287
    },
    {
      "epoch": 0.19060225016545335,
      "grad_norm": 3.147054433822632,
      "learning_rate": 9.130078094519008e-06,
      "loss": 0.1472,
      "step": 288
    },
    {
      "epoch": 0.1912640635340834,
      "grad_norm": 0.040578629821538925,
      "learning_rate": 9.12420964179753e-06,
      "loss": 0.0008,
      "step": 289
    },
    {
      "epoch": 0.19192587690271343,
      "grad_norm": 0.15212689340114594,
      "learning_rate": 9.118323360716118e-06,
      "loss": 0.0026,
      "step": 290
    },
    {
      "epoch": 0.19258769027134348,
      "grad_norm": 0.008098914287984371,
      "learning_rate": 9.112419276720304e-06,
      "loss": 0.0001,
      "step": 291
    },
    {
      "epoch": 0.19324950363997354,
      "grad_norm": 0.14141745865345,
      "learning_rate": 9.106497415332592e-06,
      "loss": 0.0027,
      "step": 292
    },
    {
      "epoch": 0.19391131700860356,
      "grad_norm": 0.012711106799542904,
      "learning_rate": 9.100557802152328e-06,
      "loss": 0.0003,
      "step": 293
    },
    {
      "epoch": 0.19457313037723362,
      "grad_norm": 0.0036683399230241776,
      "learning_rate": 9.094600462855598e-06,
      "loss": 0.0001,
      "step": 294
    },
    {
      "epoch": 0.19523494374586367,
      "grad_norm": 0.004800326190888882,
      "learning_rate": 9.088625423195116e-06,
      "loss": 0.0001,
      "step": 295
    },
    {
      "epoch": 0.19589675711449372,
      "grad_norm": 0.0032867349218577147,
      "learning_rate": 9.08263270900011e-06,
      "loss": 0.0001,
      "step": 296
    },
    {
      "epoch": 0.19655857048312375,
      "grad_norm": 0.0012794238282367587,
      "learning_rate": 9.076622346176217e-06,
      "loss": 0.0,
      "step": 297
    },
    {
      "epoch": 0.1972203838517538,
      "grad_norm": 0.012936216779053211,
      "learning_rate": 9.070594360705358e-06,
      "loss": 0.0004,
      "step": 298
    },
    {
      "epoch": 0.19788219722038386,
      "grad_norm": 0.001970892772078514,
      "learning_rate": 9.064548778645646e-06,
      "loss": 0.0001,
      "step": 299
    },
    {
      "epoch": 0.1985440105890139,
      "grad_norm": 0.0034661865793168545,
      "learning_rate": 9.058485626131253e-06,
      "loss": 0.0001,
      "step": 300
    },
    {
      "epoch": 0.19920582395764394,
      "grad_norm": 11.34197998046875,
      "learning_rate": 9.052404929372306e-06,
      "loss": 0.239,
      "step": 301
    },
    {
      "epoch": 0.199867637326274,
      "grad_norm": 0.036410268396139145,
      "learning_rate": 9.046306714654776e-06,
      "loss": 0.0006,
      "step": 302
    },
    {
      "epoch": 0.20052945069490405,
      "grad_norm": 0.012464147061109543,
      "learning_rate": 9.04019100834036e-06,
      "loss": 0.0003,
      "step": 303
    },
    {
      "epoch": 0.20119126406353408,
      "grad_norm": 0.008226446807384491,
      "learning_rate": 9.034057836866371e-06,
      "loss": 0.0002,
      "step": 304
    },
    {
      "epoch": 0.20185307743216413,
      "grad_norm": 0.031379323452711105,
      "learning_rate": 9.027907226745617e-06,
      "loss": 0.0007,
      "step": 305
    },
    {
      "epoch": 0.20251489080079418,
      "grad_norm": 7.96045446395874,
      "learning_rate": 9.021739204566296e-06,
      "loss": 0.4251,
      "step": 306
    },
    {
      "epoch": 0.2031767041694242,
      "grad_norm": 0.002709178486838937,
      "learning_rate": 9.015553796991869e-06,
      "loss": 0.0001,
      "step": 307
    },
    {
      "epoch": 0.20383851753805426,
      "grad_norm": 0.0095724081620574,
      "learning_rate": 9.009351030760958e-06,
      "loss": 0.0002,
      "step": 308
    },
    {
      "epoch": 0.20450033090668432,
      "grad_norm": 8.735855102539062,
      "learning_rate": 9.003130932687223e-06,
      "loss": 0.3486,
      "step": 309
    },
    {
      "epoch": 0.20516214427531437,
      "grad_norm": 0.08536536991596222,
      "learning_rate": 8.996893529659242e-06,
      "loss": 0.0016,
      "step": 310
    },
    {
      "epoch": 0.2058239576439444,
      "grad_norm": 0.004371879622340202,
      "learning_rate": 8.990638848640408e-06,
      "loss": 0.0001,
      "step": 311
    },
    {
      "epoch": 0.20648577101257445,
      "grad_norm": 0.0016238546231761575,
      "learning_rate": 8.984366916668795e-06,
      "loss": 0.0,
      "step": 312
    },
    {
      "epoch": 0.2071475843812045,
      "grad_norm": 0.03441173583269119,
      "learning_rate": 8.978077760857059e-06,
      "loss": 0.0004,
      "step": 313
    },
    {
      "epoch": 0.20780939774983453,
      "grad_norm": 0.0019966079853475094,
      "learning_rate": 8.971771408392302e-06,
      "loss": 0.0001,
      "step": 314
    },
    {
      "epoch": 0.2084712111184646,
      "grad_norm": 0.012993223033845425,
      "learning_rate": 8.965447886535978e-06,
      "loss": 0.0002,
      "step": 315
    },
    {
      "epoch": 0.20913302448709464,
      "grad_norm": 0.34125202894210815,
      "learning_rate": 8.959107222623751e-06,
      "loss": 0.0033,
      "step": 316
    },
    {
      "epoch": 0.2097948378557247,
      "grad_norm": 1.5591168403625488,
      "learning_rate": 8.95274944406539e-06,
      "loss": 0.0271,
      "step": 317
    },
    {
      "epoch": 0.21045665122435472,
      "grad_norm": 0.0022641245741397142,
      "learning_rate": 8.946374578344654e-06,
      "loss": 0.0001,
      "step": 318
    },
    {
      "epoch": 0.21111846459298478,
      "grad_norm": 0.42649295926094055,
      "learning_rate": 8.939982653019156e-06,
      "loss": 0.008,
      "step": 319
    },
    {
      "epoch": 0.21178027796161483,
      "grad_norm": 0.0019670515321195126,
      "learning_rate": 8.933573695720267e-06,
      "loss": 0.0,
      "step": 320
    },
    {
      "epoch": 0.21244209133024486,
      "grad_norm": 0.000803611648734659,
      "learning_rate": 8.927147734152978e-06,
      "loss": 0.0,
      "step": 321
    },
    {
      "epoch": 0.2131039046988749,
      "grad_norm": 6.769001007080078,
      "learning_rate": 8.920704796095788e-06,
      "loss": 0.228,
      "step": 322
    },
    {
      "epoch": 0.21376571806750497,
      "grad_norm": 0.003231974318623543,
      "learning_rate": 8.914244909400585e-06,
      "loss": 0.0001,
      "step": 323
    },
    {
      "epoch": 0.21442753143613502,
      "grad_norm": 0.0010444174986332655,
      "learning_rate": 8.90776810199252e-06,
      "loss": 0.0,
      "step": 324
    },
    {
      "epoch": 0.21508934480476505,
      "grad_norm": 0.031084593385457993,
      "learning_rate": 8.901274401869892e-06,
      "loss": 0.0005,
      "step": 325
    },
    {
      "epoch": 0.2157511581733951,
      "grad_norm": 0.00034515754668973386,
      "learning_rate": 8.894763837104027e-06,
      "loss": 0.0,
      "step": 326
    },
    {
      "epoch": 0.21641297154202516,
      "grad_norm": 0.1386328637599945,
      "learning_rate": 8.888236435839149e-06,
      "loss": 0.0009,
      "step": 327
    },
    {
      "epoch": 0.21707478491065518,
      "grad_norm": 0.003849721746519208,
      "learning_rate": 8.881692226292268e-06,
      "loss": 0.0001,
      "step": 328
    },
    {
      "epoch": 0.21773659827928524,
      "grad_norm": 0.003161732107400894,
      "learning_rate": 8.875131236753051e-06,
      "loss": 0.0001,
      "step": 329
    },
    {
      "epoch": 0.2183984116479153,
      "grad_norm": 0.002131391316652298,
      "learning_rate": 8.868553495583707e-06,
      "loss": 0.0001,
      "step": 330
    },
    {
      "epoch": 0.21906022501654535,
      "grad_norm": 0.0010027873795479536,
      "learning_rate": 8.861959031218855e-06,
      "loss": 0.0,
      "step": 331
    },
    {
      "epoch": 0.21972203838517537,
      "grad_norm": 0.0007887206156738102,
      "learning_rate": 8.855347872165407e-06,
      "loss": 0.0,
      "step": 332
    },
    {
      "epoch": 0.22038385175380543,
      "grad_norm": 0.0037612563464790583,
      "learning_rate": 8.848720047002446e-06,
      "loss": 0.0001,
      "step": 333
    },
    {
      "epoch": 0.22104566512243548,
      "grad_norm": 0.01890166662633419,
      "learning_rate": 8.842075584381096e-06,
      "loss": 0.0005,
      "step": 334
    },
    {
      "epoch": 0.2217074784910655,
      "grad_norm": 0.015825435519218445,
      "learning_rate": 8.835414513024409e-06,
      "loss": 0.0002,
      "step": 335
    },
    {
      "epoch": 0.22236929185969556,
      "grad_norm": 0.007124636322259903,
      "learning_rate": 8.828736861727225e-06,
      "loss": 0.0002,
      "step": 336
    },
    {
      "epoch": 0.22303110522832562,
      "grad_norm": 0.0007126188720576465,
      "learning_rate": 8.822042659356067e-06,
      "loss": 0.0,
      "step": 337
    },
    {
      "epoch": 0.22369291859695567,
      "grad_norm": 0.0020319947507232428,
      "learning_rate": 8.815331934848996e-06,
      "loss": 0.0001,
      "step": 338
    },
    {
      "epoch": 0.2243547319655857,
      "grad_norm": 0.03865731135010719,
      "learning_rate": 8.808604717215504e-06,
      "loss": 0.0006,
      "step": 339
    },
    {
      "epoch": 0.22501654533421575,
      "grad_norm": 0.0018244133098050952,
      "learning_rate": 8.801861035536374e-06,
      "loss": 0.0001,
      "step": 340
    },
    {
      "epoch": 0.2256783587028458,
      "grad_norm": 0.0021540289744734764,
      "learning_rate": 8.795100918963566e-06,
      "loss": 0.0,
      "step": 341
    },
    {
      "epoch": 0.22634017207147583,
      "grad_norm": 0.0015553906559944153,
      "learning_rate": 8.78832439672008e-06,
      "loss": 0.0,
      "step": 342
    },
    {
      "epoch": 0.22700198544010589,
      "grad_norm": 0.0011904246639460325,
      "learning_rate": 8.781531498099843e-06,
      "loss": 0.0,
      "step": 343
    },
    {
      "epoch": 0.22766379880873594,
      "grad_norm": 7.902155876159668,
      "learning_rate": 8.774722252467566e-06,
      "loss": 0.3615,
      "step": 344
    },
    {
      "epoch": 0.228325612177366,
      "grad_norm": 0.06529983878135681,
      "learning_rate": 8.767896689258634e-06,
      "loss": 0.0006,
      "step": 345
    },
    {
      "epoch": 0.22898742554599602,
      "grad_norm": 0.39700302481651306,
      "learning_rate": 8.761054837978964e-06,
      "loss": 0.0083,
      "step": 346
    },
    {
      "epoch": 0.22964923891462607,
      "grad_norm": 0.004034294746816158,
      "learning_rate": 8.754196728204886e-06,
      "loss": 0.0001,
      "step": 347
    },
    {
      "epoch": 0.23031105228325613,
      "grad_norm": 0.018252940848469734,
      "learning_rate": 8.747322389583014e-06,
      "loss": 0.0002,
      "step": 348
    },
    {
      "epoch": 0.23097286565188616,
      "grad_norm": 0.004282145295292139,
      "learning_rate": 8.740431851830118e-06,
      "loss": 0.0001,
      "step": 349
    },
    {
      "epoch": 0.2316346790205162,
      "grad_norm": 0.003589906729757786,
      "learning_rate": 8.733525144732991e-06,
      "loss": 0.0001,
      "step": 350
    },
    {
      "epoch": 0.23229649238914626,
      "grad_norm": 0.01322118565440178,
      "learning_rate": 8.726602298148326e-06,
      "loss": 0.0003,
      "step": 351
    },
    {
      "epoch": 0.23295830575777632,
      "grad_norm": 0.00265099061653018,
      "learning_rate": 8.719663342002584e-06,
      "loss": 0.0001,
      "step": 352
    },
    {
      "epoch": 0.23362011912640634,
      "grad_norm": 0.005788602400571108,
      "learning_rate": 8.71270830629187e-06,
      "loss": 0.0001,
      "step": 353
    },
    {
      "epoch": 0.2342819324950364,
      "grad_norm": 0.0012678417842835188,
      "learning_rate": 8.70573722108179e-06,
      "loss": 0.0,
      "step": 354
    },
    {
      "epoch": 0.23494374586366645,
      "grad_norm": 0.003030583495274186,
      "learning_rate": 8.698750116507334e-06,
      "loss": 0.0001,
      "step": 355
    },
    {
      "epoch": 0.23560555923229648,
      "grad_norm": 0.0013012064155191183,
      "learning_rate": 8.691747022772744e-06,
      "loss": 0.0,
      "step": 356
    },
    {
      "epoch": 0.23626737260092653,
      "grad_norm": 0.009197413921356201,
      "learning_rate": 8.684727970151374e-06,
      "loss": 0.0002,
      "step": 357
    },
    {
      "epoch": 0.2369291859695566,
      "grad_norm": 0.00101799878757447,
      "learning_rate": 8.677692988985574e-06,
      "loss": 0.0,
      "step": 358
    },
    {
      "epoch": 0.23759099933818664,
      "grad_norm": 0.004319262690842152,
      "learning_rate": 8.670642109686546e-06,
      "loss": 0.0001,
      "step": 359
    },
    {
      "epoch": 0.23825281270681667,
      "grad_norm": 0.005054401233792305,
      "learning_rate": 8.663575362734219e-06,
      "loss": 0.0001,
      "step": 360
    },
    {
      "epoch": 0.23891462607544672,
      "grad_norm": 0.00029270598315633833,
      "learning_rate": 8.656492778677113e-06,
      "loss": 0.0,
      "step": 361
    },
    {
      "epoch": 0.23957643944407678,
      "grad_norm": 0.001550754182972014,
      "learning_rate": 8.649394388132212e-06,
      "loss": 0.0,
      "step": 362
    },
    {
      "epoch": 0.2402382528127068,
      "grad_norm": 8.21713924407959,
      "learning_rate": 8.642280221784829e-06,
      "loss": 0.113,
      "step": 363
    },
    {
      "epoch": 0.24090006618133686,
      "grad_norm": 0.013091878965497017,
      "learning_rate": 8.63515031038847e-06,
      "loss": 0.0002,
      "step": 364
    },
    {
      "epoch": 0.2415618795499669,
      "grad_norm": 0.005339120514690876,
      "learning_rate": 8.628004684764715e-06,
      "loss": 0.0001,
      "step": 365
    },
    {
      "epoch": 0.24222369291859697,
      "grad_norm": 9.781844139099121,
      "learning_rate": 8.620843375803058e-06,
      "loss": 0.4262,
      "step": 366
    },
    {
      "epoch": 0.242885506287227,
      "grad_norm": 0.008633577264845371,
      "learning_rate": 8.613666414460806e-06,
      "loss": 0.0001,
      "step": 367
    },
    {
      "epoch": 0.24354731965585705,
      "grad_norm": 0.0009490813827142119,
      "learning_rate": 8.606473831762916e-06,
      "loss": 0.0,
      "step": 368
    },
    {
      "epoch": 0.2442091330244871,
      "grad_norm": 0.03834034875035286,
      "learning_rate": 8.599265658801882e-06,
      "loss": 0.0007,
      "step": 369
    },
    {
      "epoch": 0.24487094639311713,
      "grad_norm": 0.011807805858552456,
      "learning_rate": 8.592041926737591e-06,
      "loss": 0.0003,
      "step": 370
    },
    {
      "epoch": 0.24553275976174718,
      "grad_norm": 0.0023180455900728703,
      "learning_rate": 8.584802666797187e-06,
      "loss": 0.0001,
      "step": 371
    },
    {
      "epoch": 0.24619457313037724,
      "grad_norm": 0.0036140454467386007,
      "learning_rate": 8.577547910274942e-06,
      "loss": 0.0001,
      "step": 372
    },
    {
      "epoch": 0.2468563864990073,
      "grad_norm": 0.023831045255064964,
      "learning_rate": 8.570277688532112e-06,
      "loss": 0.0005,
      "step": 373
    },
    {
      "epoch": 0.24751819986763732,
      "grad_norm": 15.017815589904785,
      "learning_rate": 8.562992032996815e-06,
      "loss": 0.6143,
      "step": 374
    },
    {
      "epoch": 0.24818001323626737,
      "grad_norm": 4.38313627243042,
      "learning_rate": 8.555690975163883e-06,
      "loss": 0.0542,
      "step": 375
    },
    {
      "epoch": 0.24884182660489743,
      "grad_norm": 0.0028944246005266905,
      "learning_rate": 8.548374546594726e-06,
      "loss": 0.0001,
      "step": 376
    },
    {
      "epoch": 0.24950363997352745,
      "grad_norm": 0.014875873923301697,
      "learning_rate": 8.541042778917207e-06,
      "loss": 0.0004,
      "step": 377
    },
    {
      "epoch": 0.2501654533421575,
      "grad_norm": 0.001240191631950438,
      "learning_rate": 8.533695703825492e-06,
      "loss": 0.0,
      "step": 378
    },
    {
      "epoch": 0.25082726671078753,
      "grad_norm": 0.0017748215468600392,
      "learning_rate": 8.526333353079923e-06,
      "loss": 0.0,
      "step": 379
    },
    {
      "epoch": 0.2514890800794176,
      "grad_norm": 0.0015970568638294935,
      "learning_rate": 8.51895575850687e-06,
      "loss": 0.0,
      "step": 380
    },
    {
      "epoch": 0.25215089344804764,
      "grad_norm": 11.853694915771484,
      "learning_rate": 8.511562951998608e-06,
      "loss": 0.7,
      "step": 381
    },
    {
      "epoch": 0.2528127068166777,
      "grad_norm": 0.583092451095581,
      "learning_rate": 8.504154965513165e-06,
      "loss": 0.0087,
      "step": 382
    },
    {
      "epoch": 0.25347452018530775,
      "grad_norm": 0.017083190381526947,
      "learning_rate": 8.49673183107419e-06,
      "loss": 0.0003,
      "step": 383
    },
    {
      "epoch": 0.2541363335539378,
      "grad_norm": 0.001260705292224884,
      "learning_rate": 8.489293580770821e-06,
      "loss": 0.0,
      "step": 384
    },
    {
      "epoch": 0.25479814692256786,
      "grad_norm": 5.234918117523193,
      "learning_rate": 8.481840246757532e-06,
      "loss": 0.0576,
      "step": 385
    },
    {
      "epoch": 0.2554599602911979,
      "grad_norm": 0.1211993545293808,
      "learning_rate": 8.474371861254002e-06,
      "loss": 0.0018,
      "step": 386
    },
    {
      "epoch": 0.2561217736598279,
      "grad_norm": 0.0002570315555203706,
      "learning_rate": 8.466888456544984e-06,
      "loss": 0.0,
      "step": 387
    },
    {
      "epoch": 0.256783587028458,
      "grad_norm": 0.046440936625003815,
      "learning_rate": 8.459390064980146e-06,
      "loss": 0.0009,
      "step": 388
    },
    {
      "epoch": 0.257445400397088,
      "grad_norm": 2.352788209915161,
      "learning_rate": 8.45187671897395e-06,
      "loss": 0.0237,
      "step": 389
    },
    {
      "epoch": 0.25810721376571805,
      "grad_norm": 0.027365736663341522,
      "learning_rate": 8.4443484510055e-06,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.25876902713434813,
      "grad_norm": 0.12044770270586014,
      "learning_rate": 8.436805293618403e-06,
      "loss": 0.0013,
      "step": 391
    },
    {
      "epoch": 0.25943084050297816,
      "grad_norm": 0.02676335908472538,
      "learning_rate": 8.429247279420639e-06,
      "loss": 0.0006,
      "step": 392
    },
    {
      "epoch": 0.2600926538716082,
      "grad_norm": 0.4642864167690277,
      "learning_rate": 8.421674441084404e-06,
      "loss": 0.008,
      "step": 393
    },
    {
      "epoch": 0.26075446724023826,
      "grad_norm": 13.209519386291504,
      "learning_rate": 8.414086811345978e-06,
      "loss": 0.8563,
      "step": 394
    },
    {
      "epoch": 0.2614162806088683,
      "grad_norm": 0.01040560007095337,
      "learning_rate": 8.406484423005587e-06,
      "loss": 0.0003,
      "step": 395
    },
    {
      "epoch": 0.26207809397749837,
      "grad_norm": 0.004824437666684389,
      "learning_rate": 8.398867308927253e-06,
      "loss": 0.0001,
      "step": 396
    },
    {
      "epoch": 0.2627399073461284,
      "grad_norm": 0.20690308511257172,
      "learning_rate": 8.39123550203865e-06,
      "loss": 0.0035,
      "step": 397
    },
    {
      "epoch": 0.2634017207147584,
      "grad_norm": 2.897268772125244,
      "learning_rate": 8.383589035330976e-06,
      "loss": 0.0443,
      "step": 398
    },
    {
      "epoch": 0.2640635340833885,
      "grad_norm": 1.3239037990570068,
      "learning_rate": 8.375927941858797e-06,
      "loss": 0.0184,
      "step": 399
    },
    {
      "epoch": 0.26472534745201853,
      "grad_norm": 12.204263687133789,
      "learning_rate": 8.368252254739908e-06,
      "loss": 0.552,
      "step": 400
    },
    {
      "epoch": 0.26538716082064856,
      "grad_norm": 0.017846863716840744,
      "learning_rate": 8.360562007155193e-06,
      "loss": 0.0003,
      "step": 401
    },
    {
      "epoch": 0.26604897418927864,
      "grad_norm": 0.0014348544646054506,
      "learning_rate": 8.352857232348473e-06,
      "loss": 0.0,
      "step": 402
    },
    {
      "epoch": 0.26671078755790867,
      "grad_norm": 0.006744560319930315,
      "learning_rate": 8.345137963626374e-06,
      "loss": 0.0002,
      "step": 403
    },
    {
      "epoch": 0.2673726009265387,
      "grad_norm": 0.028663093224167824,
      "learning_rate": 8.337404234358172e-06,
      "loss": 0.0003,
      "step": 404
    },
    {
      "epoch": 0.2680344142951688,
      "grad_norm": 8.648537635803223,
      "learning_rate": 8.329656077975658e-06,
      "loss": 0.4276,
      "step": 405
    },
    {
      "epoch": 0.2686962276637988,
      "grad_norm": 13.042095184326172,
      "learning_rate": 8.32189352797299e-06,
      "loss": 0.9723,
      "step": 406
    },
    {
      "epoch": 0.26935804103242883,
      "grad_norm": 0.0027928242925554514,
      "learning_rate": 8.314116617906545e-06,
      "loss": 0.0001,
      "step": 407
    },
    {
      "epoch": 0.2700198544010589,
      "grad_norm": 0.0028040511533617973,
      "learning_rate": 8.306325381394774e-06,
      "loss": 0.0001,
      "step": 408
    },
    {
      "epoch": 0.27068166776968894,
      "grad_norm": 0.016252340748906136,
      "learning_rate": 8.298519852118066e-06,
      "loss": 0.0003,
      "step": 409
    },
    {
      "epoch": 0.271343481138319,
      "grad_norm": 9.759669303894043,
      "learning_rate": 8.290700063818588e-06,
      "loss": 0.934,
      "step": 410
    },
    {
      "epoch": 0.27200529450694905,
      "grad_norm": 0.008084303699433804,
      "learning_rate": 8.282866050300152e-06,
      "loss": 0.0001,
      "step": 411
    },
    {
      "epoch": 0.2726671078755791,
      "grad_norm": 0.039455536752939224,
      "learning_rate": 8.275017845428063e-06,
      "loss": 0.0007,
      "step": 412
    },
    {
      "epoch": 0.27332892124420916,
      "grad_norm": 2.6852798461914062,
      "learning_rate": 8.26715548312897e-06,
      "loss": 0.0297,
      "step": 413
    },
    {
      "epoch": 0.2739907346128392,
      "grad_norm": 9.729235649108887,
      "learning_rate": 8.259278997390725e-06,
      "loss": 1.0783,
      "step": 414
    },
    {
      "epoch": 0.2746525479814692,
      "grad_norm": 0.0032264823094010353,
      "learning_rate": 8.251388422262234e-06,
      "loss": 0.0001,
      "step": 415
    },
    {
      "epoch": 0.2753143613500993,
      "grad_norm": 0.0011535041267052293,
      "learning_rate": 8.243483791853308e-06,
      "loss": 0.0,
      "step": 416
    },
    {
      "epoch": 0.2759761747187293,
      "grad_norm": 0.015592599287629128,
      "learning_rate": 8.235565140334518e-06,
      "loss": 0.0003,
      "step": 417
    },
    {
      "epoch": 0.27663798808735934,
      "grad_norm": 8.410562515258789,
      "learning_rate": 8.227632501937045e-06,
      "loss": 0.2887,
      "step": 418
    },
    {
      "epoch": 0.2772998014559894,
      "grad_norm": 2.3191978931427,
      "learning_rate": 8.219685910952533e-06,
      "loss": 0.1608,
      "step": 419
    },
    {
      "epoch": 0.27796161482461945,
      "grad_norm": 0.0017850202275440097,
      "learning_rate": 8.211725401732944e-06,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 0.2786234281932495,
      "grad_norm": 0.0005120128043927252,
      "learning_rate": 8.203751008690404e-06,
      "loss": 0.0,
      "step": 421
    },
    {
      "epoch": 0.27928524156187956,
      "grad_norm": 0.5945883989334106,
      "learning_rate": 8.195762766297055e-06,
      "loss": 0.0097,
      "step": 422
    },
    {
      "epoch": 0.2799470549305096,
      "grad_norm": 0.06153634190559387,
      "learning_rate": 8.187760709084913e-06,
      "loss": 0.0013,
      "step": 423
    },
    {
      "epoch": 0.28060886829913967,
      "grad_norm": 4.528405666351318,
      "learning_rate": 8.179744871645708e-06,
      "loss": 0.241,
      "step": 424
    },
    {
      "epoch": 0.2812706816677697,
      "grad_norm": 0.007553663570433855,
      "learning_rate": 8.171715288630742e-06,
      "loss": 0.0002,
      "step": 425
    },
    {
      "epoch": 0.2819324950363997,
      "grad_norm": 0.0012620444176718593,
      "learning_rate": 8.16367199475074e-06,
      "loss": 0.0,
      "step": 426
    },
    {
      "epoch": 0.2825943084050298,
      "grad_norm": 0.004476945847272873,
      "learning_rate": 8.155615024775693e-06,
      "loss": 0.0001,
      "step": 427
    },
    {
      "epoch": 0.28325612177365983,
      "grad_norm": 0.002578487852588296,
      "learning_rate": 8.147544413534714e-06,
      "loss": 0.0001,
      "step": 428
    },
    {
      "epoch": 0.28391793514228986,
      "grad_norm": 0.0009058390860445797,
      "learning_rate": 8.139460195915884e-06,
      "loss": 0.0,
      "step": 429
    },
    {
      "epoch": 0.28457974851091994,
      "grad_norm": 0.34677839279174805,
      "learning_rate": 8.1313624068661e-06,
      "loss": 0.0032,
      "step": 430
    },
    {
      "epoch": 0.28524156187954997,
      "grad_norm": 0.01180731039494276,
      "learning_rate": 8.123251081390937e-06,
      "loss": 0.0003,
      "step": 431
    },
    {
      "epoch": 0.28590337524818,
      "grad_norm": 2.835728406906128,
      "learning_rate": 8.11512625455447e-06,
      "loss": 0.087,
      "step": 432
    },
    {
      "epoch": 0.2865651886168101,
      "grad_norm": 0.0023061500396579504,
      "learning_rate": 8.106987961479152e-06,
      "loss": 0.0001,
      "step": 433
    },
    {
      "epoch": 0.2872270019854401,
      "grad_norm": 0.0013283140724524856,
      "learning_rate": 8.09883623734564e-06,
      "loss": 0.0001,
      "step": 434
    },
    {
      "epoch": 0.2878888153540701,
      "grad_norm": 0.0012902265880256891,
      "learning_rate": 8.090671117392655e-06,
      "loss": 0.0001,
      "step": 435
    },
    {
      "epoch": 0.2885506287227002,
      "grad_norm": 0.19849538803100586,
      "learning_rate": 8.082492636916829e-06,
      "loss": 0.0025,
      "step": 436
    },
    {
      "epoch": 0.28921244209133024,
      "grad_norm": 0.0006919176666997373,
      "learning_rate": 8.074300831272542e-06,
      "loss": 0.0,
      "step": 437
    },
    {
      "epoch": 0.2898742554599603,
      "grad_norm": 0.0048482040874660015,
      "learning_rate": 8.066095735871786e-06,
      "loss": 0.0001,
      "step": 438
    },
    {
      "epoch": 0.29053606882859034,
      "grad_norm": 0.006883109454065561,
      "learning_rate": 8.057877386183996e-06,
      "loss": 0.0001,
      "step": 439
    },
    {
      "epoch": 0.29119788219722037,
      "grad_norm": 2.4484739303588867,
      "learning_rate": 8.049645817735904e-06,
      "loss": 0.0567,
      "step": 440
    },
    {
      "epoch": 0.29185969556585045,
      "grad_norm": 0.20968246459960938,
      "learning_rate": 8.041401066111387e-06,
      "loss": 0.002,
      "step": 441
    },
    {
      "epoch": 0.2925215089344805,
      "grad_norm": 0.0019517031032592058,
      "learning_rate": 8.033143166951312e-06,
      "loss": 0.0001,
      "step": 442
    },
    {
      "epoch": 0.2931833223031105,
      "grad_norm": 0.011737081222236156,
      "learning_rate": 8.024872155953375e-06,
      "loss": 0.0003,
      "step": 443
    },
    {
      "epoch": 0.2938451356717406,
      "grad_norm": 0.0021395289804786444,
      "learning_rate": 8.016588068871962e-06,
      "loss": 0.0001,
      "step": 444
    },
    {
      "epoch": 0.2945069490403706,
      "grad_norm": 0.0018932681996375322,
      "learning_rate": 8.008290941517975e-06,
      "loss": 0.0,
      "step": 445
    },
    {
      "epoch": 0.29516876240900064,
      "grad_norm": 0.0012047868221998215,
      "learning_rate": 7.999980809758693e-06,
      "loss": 0.0,
      "step": 446
    },
    {
      "epoch": 0.2958305757776307,
      "grad_norm": 0.21834984421730042,
      "learning_rate": 7.991657709517613e-06,
      "loss": 0.0032,
      "step": 447
    },
    {
      "epoch": 0.29649238914626075,
      "grad_norm": 0.995771050453186,
      "learning_rate": 7.983321676774286e-06,
      "loss": 0.0236,
      "step": 448
    },
    {
      "epoch": 0.2971542025148908,
      "grad_norm": 0.13607607781887054,
      "learning_rate": 7.974972747564173e-06,
      "loss": 0.0018,
      "step": 449
    },
    {
      "epoch": 0.29781601588352086,
      "grad_norm": 12.787888526916504,
      "learning_rate": 7.966610957978483e-06,
      "loss": 0.2772,
      "step": 450
    },
    {
      "epoch": 0.2984778292521509,
      "grad_norm": 0.048918746411800385,
      "learning_rate": 7.958236344164023e-06,
      "loss": 0.0008,
      "step": 451
    },
    {
      "epoch": 0.29913964262078097,
      "grad_norm": 0.01424188632518053,
      "learning_rate": 7.949848942323028e-06,
      "loss": 0.0004,
      "step": 452
    },
    {
      "epoch": 0.299801455989411,
      "grad_norm": 9.815145492553711,
      "learning_rate": 7.941448788713024e-06,
      "loss": 0.4519,
      "step": 453
    },
    {
      "epoch": 0.300463269358041,
      "grad_norm": 0.04836011677980423,
      "learning_rate": 7.933035919646655e-06,
      "loss": 0.0009,
      "step": 454
    },
    {
      "epoch": 0.3011250827266711,
      "grad_norm": 0.001417173189111054,
      "learning_rate": 7.92461037149153e-06,
      "loss": 0.0,
      "step": 455
    },
    {
      "epoch": 0.3017868960953011,
      "grad_norm": 0.030300425365567207,
      "learning_rate": 7.916172180670077e-06,
      "loss": 0.0006,
      "step": 456
    },
    {
      "epoch": 0.30244870946393115,
      "grad_norm": 0.22684261202812195,
      "learning_rate": 7.907721383659368e-06,
      "loss": 0.0032,
      "step": 457
    },
    {
      "epoch": 0.30311052283256124,
      "grad_norm": 0.002555587561801076,
      "learning_rate": 7.89925801699097e-06,
      "loss": 0.0,
      "step": 458
    },
    {
      "epoch": 0.30377233620119126,
      "grad_norm": 4.463242053985596,
      "learning_rate": 7.890782117250793e-06,
      "loss": 0.1017,
      "step": 459
    },
    {
      "epoch": 0.3044341495698213,
      "grad_norm": 0.0005713801365345716,
      "learning_rate": 7.882293721078923e-06,
      "loss": 0.0,
      "step": 460
    },
    {
      "epoch": 0.30509596293845137,
      "grad_norm": 16.251258850097656,
      "learning_rate": 7.873792865169458e-06,
      "loss": 0.7227,
      "step": 461
    },
    {
      "epoch": 0.3057577763070814,
      "grad_norm": 11.4706449508667,
      "learning_rate": 7.865279586270371e-06,
      "loss": 0.6789,
      "step": 462
    },
    {
      "epoch": 0.3064195896757114,
      "grad_norm": 0.0009528473019599915,
      "learning_rate": 7.856753921183332e-06,
      "loss": 0.0,
      "step": 463
    },
    {
      "epoch": 0.3070814030443415,
      "grad_norm": 18.940902709960938,
      "learning_rate": 7.84821590676355e-06,
      "loss": 1.5172,
      "step": 464
    },
    {
      "epoch": 0.30774321641297153,
      "grad_norm": 0.03189466893672943,
      "learning_rate": 7.839665579919626e-06,
      "loss": 0.0005,
      "step": 465
    },
    {
      "epoch": 0.3084050297816016,
      "grad_norm": 0.09607511758804321,
      "learning_rate": 7.83110297761338e-06,
      "loss": 0.0018,
      "step": 466
    },
    {
      "epoch": 0.30906684315023164,
      "grad_norm": 0.047992922365665436,
      "learning_rate": 7.822528136859703e-06,
      "loss": 0.0007,
      "step": 467
    },
    {
      "epoch": 0.30972865651886167,
      "grad_norm": 0.027137143537402153,
      "learning_rate": 7.813941094726383e-06,
      "loss": 0.0005,
      "step": 468
    },
    {
      "epoch": 0.31039046988749175,
      "grad_norm": 0.016833946108818054,
      "learning_rate": 7.805341888333962e-06,
      "loss": 0.0003,
      "step": 469
    },
    {
      "epoch": 0.3110522832561218,
      "grad_norm": 0.0007957532070577145,
      "learning_rate": 7.796730554855559e-06,
      "loss": 0.0,
      "step": 470
    },
    {
      "epoch": 0.3117140966247518,
      "grad_norm": 0.1547325700521469,
      "learning_rate": 7.788107131516719e-06,
      "loss": 0.0032,
      "step": 471
    },
    {
      "epoch": 0.3123759099933819,
      "grad_norm": 0.0024795515928417444,
      "learning_rate": 7.779471655595249e-06,
      "loss": 0.0001,
      "step": 472
    },
    {
      "epoch": 0.3130377233620119,
      "grad_norm": 0.0025746868923306465,
      "learning_rate": 7.770824164421063e-06,
      "loss": 0.0001,
      "step": 473
    },
    {
      "epoch": 0.31369953673064194,
      "grad_norm": 0.017638660967350006,
      "learning_rate": 7.762164695376006e-06,
      "loss": 0.0002,
      "step": 474
    },
    {
      "epoch": 0.314361350099272,
      "grad_norm": 0.00033955625258386135,
      "learning_rate": 7.753493285893707e-06,
      "loss": 0.0,
      "step": 475
    },
    {
      "epoch": 0.31502316346790205,
      "grad_norm": 5.123021125793457,
      "learning_rate": 7.744809973459415e-06,
      "loss": 0.13,
      "step": 476
    },
    {
      "epoch": 0.31568497683653207,
      "grad_norm": 0.001962340669706464,
      "learning_rate": 7.736114795609828e-06,
      "loss": 0.0,
      "step": 477
    },
    {
      "epoch": 0.31634679020516215,
      "grad_norm": 4.061677932739258,
      "learning_rate": 7.727407789932936e-06,
      "loss": 0.1246,
      "step": 478
    },
    {
      "epoch": 0.3170086035737922,
      "grad_norm": 0.0019376848358660936,
      "learning_rate": 7.718688994067863e-06,
      "loss": 0.0,
      "step": 479
    },
    {
      "epoch": 0.31767041694242226,
      "grad_norm": 0.0010297740809619427,
      "learning_rate": 7.709958445704699e-06,
      "loss": 0.0,
      "step": 480
    },
    {
      "epoch": 0.3183322303110523,
      "grad_norm": 0.0020116136875003576,
      "learning_rate": 7.701216182584337e-06,
      "loss": 0.0001,
      "step": 481
    },
    {
      "epoch": 0.3189940436796823,
      "grad_norm": 3.371367931365967,
      "learning_rate": 7.692462242498313e-06,
      "loss": 0.1219,
      "step": 482
    },
    {
      "epoch": 0.3196558570483124,
      "grad_norm": 0.0017753505380824208,
      "learning_rate": 7.68369666328864e-06,
      "loss": 0.0001,
      "step": 483
    },
    {
      "epoch": 0.3203176704169424,
      "grad_norm": 0.00043392638326622546,
      "learning_rate": 7.674919482847645e-06,
      "loss": 0.0,
      "step": 484
    },
    {
      "epoch": 0.32097948378557245,
      "grad_norm": 0.013988545164465904,
      "learning_rate": 7.666130739117805e-06,
      "loss": 0.0002,
      "step": 485
    },
    {
      "epoch": 0.32164129715420253,
      "grad_norm": 0.0008679106831550598,
      "learning_rate": 7.657330470091584e-06,
      "loss": 0.0,
      "step": 486
    },
    {
      "epoch": 0.32230311052283256,
      "grad_norm": 0.0042084320448338985,
      "learning_rate": 7.648518713811269e-06,
      "loss": 0.0001,
      "step": 487
    },
    {
      "epoch": 0.3229649238914626,
      "grad_norm": 0.0036477805115282536,
      "learning_rate": 7.639695508368804e-06,
      "loss": 0.0001,
      "step": 488
    },
    {
      "epoch": 0.32362673726009267,
      "grad_norm": 10.950356483459473,
      "learning_rate": 7.630860891905625e-06,
      "loss": 0.4393,
      "step": 489
    },
    {
      "epoch": 0.3242885506287227,
      "grad_norm": 4.261658668518066,
      "learning_rate": 7.6220149026125e-06,
      "loss": 0.0839,
      "step": 490
    },
    {
      "epoch": 0.3249503639973527,
      "grad_norm": 15.459757804870605,
      "learning_rate": 7.613157578729353e-06,
      "loss": 0.2031,
      "step": 491
    },
    {
      "epoch": 0.3256121773659828,
      "grad_norm": 0.10484819859266281,
      "learning_rate": 7.604288958545114e-06,
      "loss": 0.0016,
      "step": 492
    },
    {
      "epoch": 0.32627399073461283,
      "grad_norm": 0.009529219940304756,
      "learning_rate": 7.59540908039754e-06,
      "loss": 0.0002,
      "step": 493
    },
    {
      "epoch": 0.3269358041032429,
      "grad_norm": 0.09233663231134415,
      "learning_rate": 7.5865179826730536e-06,
      "loss": 0.0006,
      "step": 494
    },
    {
      "epoch": 0.32759761747187294,
      "grad_norm": 0.0016656636726111174,
      "learning_rate": 7.577615703806587e-06,
      "loss": 0.0,
      "step": 495
    },
    {
      "epoch": 0.32825943084050296,
      "grad_norm": 0.0010902245994657278,
      "learning_rate": 7.568702282281392e-06,
      "loss": 0.0,
      "step": 496
    },
    {
      "epoch": 0.32892124420913305,
      "grad_norm": 0.3536032438278198,
      "learning_rate": 7.559777756628901e-06,
      "loss": 0.0088,
      "step": 497
    },
    {
      "epoch": 0.32958305757776307,
      "grad_norm": 0.0002933685318566859,
      "learning_rate": 7.550842165428544e-06,
      "loss": 0.0,
      "step": 498
    },
    {
      "epoch": 0.3302448709463931,
      "grad_norm": 0.002310945885255933,
      "learning_rate": 7.541895547307584e-06,
      "loss": 0.0001,
      "step": 499
    },
    {
      "epoch": 0.3309066843150232,
      "grad_norm": 0.0007953271269798279,
      "learning_rate": 7.532937940940953e-06,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 0.3315684976836532,
      "grad_norm": 9.275840759277344,
      "learning_rate": 7.523969385051084e-06,
      "loss": 0.1953,
      "step": 501
    },
    {
      "epoch": 0.33223031105228323,
      "grad_norm": 0.006906786002218723,
      "learning_rate": 7.514989918407745e-06,
      "loss": 0.0002,
      "step": 502
    },
    {
      "epoch": 0.3328921244209133,
      "grad_norm": 1.0012484788894653,
      "learning_rate": 7.505999579827864e-06,
      "loss": 0.0111,
      "step": 503
    },
    {
      "epoch": 0.33355393778954334,
      "grad_norm": 0.020608006045222282,
      "learning_rate": 7.496998408175374e-06,
      "loss": 0.0005,
      "step": 504
    },
    {
      "epoch": 0.33421575115817337,
      "grad_norm": 0.10909194499254227,
      "learning_rate": 7.487986442361031e-06,
      "loss": 0.0017,
      "step": 505
    },
    {
      "epoch": 0.33487756452680345,
      "grad_norm": 0.3079602122306824,
      "learning_rate": 7.478963721342256e-06,
      "loss": 0.0047,
      "step": 506
    },
    {
      "epoch": 0.3355393778954335,
      "grad_norm": 0.9342598915100098,
      "learning_rate": 7.469930284122966e-06,
      "loss": 0.0122,
      "step": 507
    },
    {
      "epoch": 0.33620119126406356,
      "grad_norm": 0.02893955633044243,
      "learning_rate": 7.460886169753396e-06,
      "loss": 0.0005,
      "step": 508
    },
    {
      "epoch": 0.3368630046326936,
      "grad_norm": 0.001919832662679255,
      "learning_rate": 7.451831417329943e-06,
      "loss": 0.0001,
      "step": 509
    },
    {
      "epoch": 0.3375248180013236,
      "grad_norm": 0.000970635621342808,
      "learning_rate": 7.442766065994986e-06,
      "loss": 0.0,
      "step": 510
    },
    {
      "epoch": 0.3381866313699537,
      "grad_norm": 7.880006790161133,
      "learning_rate": 7.4336901549367246e-06,
      "loss": 0.3363,
      "step": 511
    },
    {
      "epoch": 0.3388484447385837,
      "grad_norm": 0.16047237813472748,
      "learning_rate": 7.424603723389007e-06,
      "loss": 0.0034,
      "step": 512
    },
    {
      "epoch": 0.33951025810721375,
      "grad_norm": 0.0021919249556958675,
      "learning_rate": 7.415506810631156e-06,
      "loss": 0.0001,
      "step": 513
    },
    {
      "epoch": 0.34017207147584383,
      "grad_norm": 0.0018050564685836434,
      "learning_rate": 7.406399455987805e-06,
      "loss": 0.0,
      "step": 514
    },
    {
      "epoch": 0.34083388484447386,
      "grad_norm": 0.0036596835125237703,
      "learning_rate": 7.39728169882873e-06,
      "loss": 0.0001,
      "step": 515
    },
    {
      "epoch": 0.3414956982131039,
      "grad_norm": 0.0005833376199007034,
      "learning_rate": 7.388153578568671e-06,
      "loss": 0.0,
      "step": 516
    },
    {
      "epoch": 0.34215751158173396,
      "grad_norm": 11.394954681396484,
      "learning_rate": 7.379015134667166e-06,
      "loss": 0.5466,
      "step": 517
    },
    {
      "epoch": 0.342819324950364,
      "grad_norm": 12.098597526550293,
      "learning_rate": 7.369866406628386e-06,
      "loss": 1.127,
      "step": 518
    },
    {
      "epoch": 0.343481138318994,
      "grad_norm": 0.001302888966165483,
      "learning_rate": 7.360707434000951e-06,
      "loss": 0.0,
      "step": 519
    },
    {
      "epoch": 0.3441429516876241,
      "grad_norm": 0.0014723344938829541,
      "learning_rate": 7.351538256377771e-06,
      "loss": 0.0,
      "step": 520
    },
    {
      "epoch": 0.3448047650562541,
      "grad_norm": 0.015465370379388332,
      "learning_rate": 7.342358913395875e-06,
      "loss": 0.0003,
      "step": 521
    },
    {
      "epoch": 0.3454665784248842,
      "grad_norm": 0.0010148261208087206,
      "learning_rate": 7.333169444736226e-06,
      "loss": 0.0001,
      "step": 522
    },
    {
      "epoch": 0.34612839179351423,
      "grad_norm": 0.001110928482376039,
      "learning_rate": 7.3239698901235655e-06,
      "loss": 0.0,
      "step": 523
    },
    {
      "epoch": 0.34679020516214426,
      "grad_norm": 0.07743499428033829,
      "learning_rate": 7.314760289326236e-06,
      "loss": 0.0011,
      "step": 524
    },
    {
      "epoch": 0.34745201853077434,
      "grad_norm": 6.882952690124512,
      "learning_rate": 7.305540682156e-06,
      "loss": 0.2722,
      "step": 525
    },
    {
      "epoch": 0.34811383189940437,
      "grad_norm": 0.0799650326371193,
      "learning_rate": 7.296311108467888e-06,
      "loss": 0.0012,
      "step": 526
    },
    {
      "epoch": 0.3487756452680344,
      "grad_norm": 0.00036045568413101137,
      "learning_rate": 7.287071608160003e-06,
      "loss": 0.0,
      "step": 527
    },
    {
      "epoch": 0.3494374586366645,
      "grad_norm": 5.0289835929870605,
      "learning_rate": 7.277822221173367e-06,
      "loss": 0.0691,
      "step": 528
    },
    {
      "epoch": 0.3500992720052945,
      "grad_norm": 0.6676562428474426,
      "learning_rate": 7.26856298749174e-06,
      "loss": 0.0087,
      "step": 529
    },
    {
      "epoch": 0.35076108537392453,
      "grad_norm": 4.627135276794434,
      "learning_rate": 7.259293947141441e-06,
      "loss": 0.0825,
      "step": 530
    },
    {
      "epoch": 0.3514228987425546,
      "grad_norm": 0.002544860588386655,
      "learning_rate": 7.250015140191189e-06,
      "loss": 0.0001,
      "step": 531
    },
    {
      "epoch": 0.35208471211118464,
      "grad_norm": 0.0038822076749056578,
      "learning_rate": 7.24072660675192e-06,
      "loss": 0.0001,
      "step": 532
    },
    {
      "epoch": 0.35274652547981467,
      "grad_norm": 0.033802490681409836,
      "learning_rate": 7.231428386976618e-06,
      "loss": 0.0005,
      "step": 533
    },
    {
      "epoch": 0.35340833884844475,
      "grad_norm": 0.7209934592247009,
      "learning_rate": 7.222120521060134e-06,
      "loss": 0.0126,
      "step": 534
    },
    {
      "epoch": 0.3540701522170748,
      "grad_norm": 0.0022266136948019266,
      "learning_rate": 7.212803049239028e-06,
      "loss": 0.0,
      "step": 535
    },
    {
      "epoch": 0.35473196558570486,
      "grad_norm": 0.0028181744273751974,
      "learning_rate": 7.203476011791374e-06,
      "loss": 0.0001,
      "step": 536
    },
    {
      "epoch": 0.3553937789543349,
      "grad_norm": 9.190023422241211,
      "learning_rate": 7.1941394490366025e-06,
      "loss": 0.7871,
      "step": 537
    },
    {
      "epoch": 0.3560555923229649,
      "grad_norm": 0.003859851276502013,
      "learning_rate": 7.184793401335323e-06,
      "loss": 0.0001,
      "step": 538
    },
    {
      "epoch": 0.356717405691595,
      "grad_norm": 0.025696666911244392,
      "learning_rate": 7.175437909089139e-06,
      "loss": 0.0006,
      "step": 539
    },
    {
      "epoch": 0.357379219060225,
      "grad_norm": 0.0013631428591907024,
      "learning_rate": 7.166073012740491e-06,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 0.35804103242885504,
      "grad_norm": 0.027923060581088066,
      "learning_rate": 7.156698752772463e-06,
      "loss": 0.0005,
      "step": 541
    },
    {
      "epoch": 0.3587028457974851,
      "grad_norm": 0.002461038762703538,
      "learning_rate": 7.1473151697086214e-06,
      "loss": 0.0001,
      "step": 542
    },
    {
      "epoch": 0.35936465916611515,
      "grad_norm": 13.198086738586426,
      "learning_rate": 7.137922304112839e-06,
      "loss": 0.6532,
      "step": 543
    },
    {
      "epoch": 0.3600264725347452,
      "grad_norm": 0.03010646253824234,
      "learning_rate": 7.128520196589106e-06,
      "loss": 0.0007,
      "step": 544
    },
    {
      "epoch": 0.36068828590337526,
      "grad_norm": 7.84566593170166,
      "learning_rate": 7.119108887781371e-06,
      "loss": 0.5661,
      "step": 545
    },
    {
      "epoch": 0.3613500992720053,
      "grad_norm": 0.017717160284519196,
      "learning_rate": 7.109688418373355e-06,
      "loss": 0.0002,
      "step": 546
    },
    {
      "epoch": 0.3620119126406353,
      "grad_norm": 0.006595097482204437,
      "learning_rate": 7.1002588290883846e-06,
      "loss": 0.0001,
      "step": 547
    },
    {
      "epoch": 0.3626737260092654,
      "grad_norm": 0.07212088257074356,
      "learning_rate": 7.090820160689201e-06,
      "loss": 0.0018,
      "step": 548
    },
    {
      "epoch": 0.3633355393778954,
      "grad_norm": 0.0051404754631221294,
      "learning_rate": 7.0813724539778026e-06,
      "loss": 0.0001,
      "step": 549
    },
    {
      "epoch": 0.3639973527465255,
      "grad_norm": 0.23884007334709167,
      "learning_rate": 7.071915749795253e-06,
      "loss": 0.0035,
      "step": 550
    },
    {
      "epoch": 0.36465916611515553,
      "grad_norm": 0.0005567713524214923,
      "learning_rate": 7.062450089021511e-06,
      "loss": 0.0,
      "step": 551
    },
    {
      "epoch": 0.36532097948378556,
      "grad_norm": 0.0016806282801553607,
      "learning_rate": 7.052975512575258e-06,
      "loss": 0.0001,
      "step": 552
    },
    {
      "epoch": 0.36598279285241564,
      "grad_norm": 0.006392742972820997,
      "learning_rate": 7.043492061413711e-06,
      "loss": 0.0001,
      "step": 553
    },
    {
      "epoch": 0.36664460622104567,
      "grad_norm": 1.3300024271011353,
      "learning_rate": 7.033999776532454e-06,
      "loss": 0.0078,
      "step": 554
    },
    {
      "epoch": 0.3673064195896757,
      "grad_norm": 8.248723983764648,
      "learning_rate": 7.024498698965259e-06,
      "loss": 0.461,
      "step": 555
    },
    {
      "epoch": 0.3679682329583058,
      "grad_norm": 0.003004679922014475,
      "learning_rate": 7.014988869783902e-06,
      "loss": 0.0001,
      "step": 556
    },
    {
      "epoch": 0.3686300463269358,
      "grad_norm": 0.24357996881008148,
      "learning_rate": 7.005470330098e-06,
      "loss": 0.0031,
      "step": 557
    },
    {
      "epoch": 0.3692918596955658,
      "grad_norm": 0.024388613179326057,
      "learning_rate": 6.995943121054816e-06,
      "loss": 0.0005,
      "step": 558
    },
    {
      "epoch": 0.3699536730641959,
      "grad_norm": 0.26782146096229553,
      "learning_rate": 6.986407283839092e-06,
      "loss": 0.0039,
      "step": 559
    },
    {
      "epoch": 0.37061548643282594,
      "grad_norm": 0.010012274608016014,
      "learning_rate": 6.9768628596728695e-06,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 0.37127729980145596,
      "grad_norm": 0.028257446363568306,
      "learning_rate": 6.96730988981531e-06,
      "loss": 0.0003,
      "step": 561
    },
    {
      "epoch": 0.37193911317008604,
      "grad_norm": 1.820068120956421,
      "learning_rate": 6.9577484155625166e-06,
      "loss": 0.0203,
      "step": 562
    },
    {
      "epoch": 0.37260092653871607,
      "grad_norm": 7.74701452255249,
      "learning_rate": 6.948178478247355e-06,
      "loss": 0.5764,
      "step": 563
    },
    {
      "epoch": 0.37326273990734615,
      "grad_norm": 6.81617546081543,
      "learning_rate": 6.938600119239274e-06,
      "loss": 0.229,
      "step": 564
    },
    {
      "epoch": 0.3739245532759762,
      "grad_norm": 10.149151802062988,
      "learning_rate": 6.929013379944131e-06,
      "loss": 0.2947,
      "step": 565
    },
    {
      "epoch": 0.3745863666446062,
      "grad_norm": 0.001739501254633069,
      "learning_rate": 6.9194183018040125e-06,
      "loss": 0.0001,
      "step": 566
    },
    {
      "epoch": 0.3752481800132363,
      "grad_norm": 3.872678518295288,
      "learning_rate": 6.909814926297045e-06,
      "loss": 0.0962,
      "step": 567
    },
    {
      "epoch": 0.3759099933818663,
      "grad_norm": 0.07380955666303635,
      "learning_rate": 6.900203294937229e-06,
      "loss": 0.0011,
      "step": 568
    },
    {
      "epoch": 0.37657180675049634,
      "grad_norm": 4.6524128913879395,
      "learning_rate": 6.890583449274251e-06,
      "loss": 0.2793,
      "step": 569
    },
    {
      "epoch": 0.3772336201191264,
      "grad_norm": 0.0025157995987683535,
      "learning_rate": 6.88095543089331e-06,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 0.37789543348775645,
      "grad_norm": 3.848388433456421,
      "learning_rate": 6.871319281414932e-06,
      "loss": 0.1148,
      "step": 571
    },
    {
      "epoch": 0.3785572468563865,
      "grad_norm": 0.16411516070365906,
      "learning_rate": 6.861675042494794e-06,
      "loss": 0.0021,
      "step": 572
    },
    {
      "epoch": 0.37921906022501656,
      "grad_norm": 0.008927292190492153,
      "learning_rate": 6.85202275582354e-06,
      "loss": 0.0001,
      "step": 573
    },
    {
      "epoch": 0.3798808735936466,
      "grad_norm": 0.039828430861234665,
      "learning_rate": 6.842362463126605e-06,
      "loss": 0.0008,
      "step": 574
    },
    {
      "epoch": 0.3805426869622766,
      "grad_norm": 0.006794107146561146,
      "learning_rate": 6.832694206164036e-06,
      "loss": 0.0001,
      "step": 575
    },
    {
      "epoch": 0.3812045003309067,
      "grad_norm": 0.0047652036882936954,
      "learning_rate": 6.8230180267303005e-06,
      "loss": 0.0001,
      "step": 576
    },
    {
      "epoch": 0.3818663136995367,
      "grad_norm": 0.00027206024969927967,
      "learning_rate": 6.813333966654122e-06,
      "loss": 0.0,
      "step": 577
    },
    {
      "epoch": 0.3825281270681668,
      "grad_norm": 0.012833035551011562,
      "learning_rate": 6.803642067798284e-06,
      "loss": 0.0002,
      "step": 578
    },
    {
      "epoch": 0.3831899404367968,
      "grad_norm": 0.006980798207223415,
      "learning_rate": 6.793942372059462e-06,
      "loss": 0.0001,
      "step": 579
    },
    {
      "epoch": 0.38385175380542685,
      "grad_norm": 0.021508241072297096,
      "learning_rate": 6.784234921368033e-06,
      "loss": 0.0003,
      "step": 580
    },
    {
      "epoch": 0.38451356717405694,
      "grad_norm": 0.14140675961971283,
      "learning_rate": 6.774519757687896e-06,
      "loss": 0.0018,
      "step": 581
    },
    {
      "epoch": 0.38517538054268696,
      "grad_norm": 0.12068768590688705,
      "learning_rate": 6.764796923016298e-06,
      "loss": 0.0019,
      "step": 582
    },
    {
      "epoch": 0.385837193911317,
      "grad_norm": 6.461127758026123,
      "learning_rate": 6.755066459383638e-06,
      "loss": 0.1259,
      "step": 583
    },
    {
      "epoch": 0.38649900727994707,
      "grad_norm": 0.008589996956288815,
      "learning_rate": 6.745328408853301e-06,
      "loss": 0.0001,
      "step": 584
    },
    {
      "epoch": 0.3871608206485771,
      "grad_norm": 14.433432579040527,
      "learning_rate": 6.735582813521467e-06,
      "loss": 1.4486,
      "step": 585
    },
    {
      "epoch": 0.3878226340172071,
      "grad_norm": 0.13856104016304016,
      "learning_rate": 6.72582971551693e-06,
      "loss": 0.0021,
      "step": 586
    },
    {
      "epoch": 0.3884844473858372,
      "grad_norm": 0.005023828707635403,
      "learning_rate": 6.716069157000917e-06,
      "loss": 0.0001,
      "step": 587
    },
    {
      "epoch": 0.38914626075446723,
      "grad_norm": 8.016767501831055,
      "learning_rate": 6.706301180166909e-06,
      "loss": 0.5306,
      "step": 588
    },
    {
      "epoch": 0.38980807412309726,
      "grad_norm": 0.004869080614298582,
      "learning_rate": 6.69652582724045e-06,
      "loss": 0.0001,
      "step": 589
    },
    {
      "epoch": 0.39046988749172734,
      "grad_norm": 0.0012261229567229748,
      "learning_rate": 6.686743140478973e-06,
      "loss": 0.0,
      "step": 590
    },
    {
      "epoch": 0.39113170086035737,
      "grad_norm": 0.14756180346012115,
      "learning_rate": 6.676953162171613e-06,
      "loss": 0.0025,
      "step": 591
    },
    {
      "epoch": 0.39179351422898745,
      "grad_norm": 0.006184602156281471,
      "learning_rate": 6.667155934639027e-06,
      "loss": 0.0001,
      "step": 592
    },
    {
      "epoch": 0.3924553275976175,
      "grad_norm": 0.0023215629626065493,
      "learning_rate": 6.65735150023321e-06,
      "loss": 0.0001,
      "step": 593
    },
    {
      "epoch": 0.3931171409662475,
      "grad_norm": 0.0022020689211785793,
      "learning_rate": 6.647539901337307e-06,
      "loss": 0.0001,
      "step": 594
    },
    {
      "epoch": 0.3937789543348776,
      "grad_norm": 0.0028067894745618105,
      "learning_rate": 6.637721180365437e-06,
      "loss": 0.0001,
      "step": 595
    },
    {
      "epoch": 0.3944407677035076,
      "grad_norm": 2.386430263519287,
      "learning_rate": 6.627895379762506e-06,
      "loss": 0.0177,
      "step": 596
    },
    {
      "epoch": 0.39510258107213764,
      "grad_norm": 0.38635650277137756,
      "learning_rate": 6.618062542004024e-06,
      "loss": 0.0049,
      "step": 597
    },
    {
      "epoch": 0.3957643944407677,
      "grad_norm": 3.453902244567871,
      "learning_rate": 6.608222709595925e-06,
      "loss": 0.0891,
      "step": 598
    },
    {
      "epoch": 0.39642620780939775,
      "grad_norm": 0.006435407791286707,
      "learning_rate": 6.598375925074374e-06,
      "loss": 0.0001,
      "step": 599
    },
    {
      "epoch": 0.3970880211780278,
      "grad_norm": 25.11819076538086,
      "learning_rate": 6.588522231005592e-06,
      "loss": 0.5234,
      "step": 600
    },
    {
      "epoch": 0.39774983454665785,
      "grad_norm": 0.006630051881074905,
      "learning_rate": 6.57866166998567e-06,
      "loss": 0.0001,
      "step": 601
    },
    {
      "epoch": 0.3984116479152879,
      "grad_norm": 0.006169511936604977,
      "learning_rate": 6.568794284640383e-06,
      "loss": 0.0001,
      "step": 602
    },
    {
      "epoch": 0.3990734612839179,
      "grad_norm": 3.9224424362182617,
      "learning_rate": 6.558920117625006e-06,
      "loss": 0.0516,
      "step": 603
    },
    {
      "epoch": 0.399735274652548,
      "grad_norm": 0.07918693870306015,
      "learning_rate": 6.549039211624129e-06,
      "loss": 0.0009,
      "step": 604
    },
    {
      "epoch": 0.400397088021178,
      "grad_norm": 9.948626518249512,
      "learning_rate": 6.5391516093514764e-06,
      "loss": 0.2865,
      "step": 605
    },
    {
      "epoch": 0.4010589013898081,
      "grad_norm": 6.387362480163574,
      "learning_rate": 6.529257353549717e-06,
      "loss": 0.2516,
      "step": 606
    },
    {
      "epoch": 0.4017207147584381,
      "grad_norm": 5.9186577796936035,
      "learning_rate": 6.519356486990287e-06,
      "loss": 0.2992,
      "step": 607
    },
    {
      "epoch": 0.40238252812706815,
      "grad_norm": 9.519051551818848,
      "learning_rate": 6.509449052473193e-06,
      "loss": 0.5749,
      "step": 608
    },
    {
      "epoch": 0.40304434149569823,
      "grad_norm": 2.560375690460205,
      "learning_rate": 6.4995350928268355e-06,
      "loss": 0.2422,
      "step": 609
    },
    {
      "epoch": 0.40370615486432826,
      "grad_norm": 0.05290709435939789,
      "learning_rate": 6.4896146509078254e-06,
      "loss": 0.0008,
      "step": 610
    },
    {
      "epoch": 0.4043679682329583,
      "grad_norm": 6.534412860870361,
      "learning_rate": 6.479687769600795e-06,
      "loss": 0.3115,
      "step": 611
    },
    {
      "epoch": 0.40502978160158837,
      "grad_norm": 0.008540326729416847,
      "learning_rate": 6.469754491818212e-06,
      "loss": 0.0002,
      "step": 612
    },
    {
      "epoch": 0.4056915949702184,
      "grad_norm": 0.2617141604423523,
      "learning_rate": 6.459814860500195e-06,
      "loss": 0.0058,
      "step": 613
    },
    {
      "epoch": 0.4063534083388484,
      "grad_norm": 0.00816107913851738,
      "learning_rate": 6.449868918614325e-06,
      "loss": 0.0001,
      "step": 614
    },
    {
      "epoch": 0.4070152217074785,
      "grad_norm": 0.008469700813293457,
      "learning_rate": 6.439916709155468e-06,
      "loss": 0.0001,
      "step": 615
    },
    {
      "epoch": 0.40767703507610853,
      "grad_norm": 2.9653313159942627,
      "learning_rate": 6.429958275145584e-06,
      "loss": 0.0671,
      "step": 616
    },
    {
      "epoch": 0.4083388484447386,
      "grad_norm": 0.144500732421875,
      "learning_rate": 6.419993659633534e-06,
      "loss": 0.0016,
      "step": 617
    },
    {
      "epoch": 0.40900066181336864,
      "grad_norm": 2.891960859298706,
      "learning_rate": 6.410022905694909e-06,
      "loss": 0.2026,
      "step": 618
    },
    {
      "epoch": 0.40966247518199866,
      "grad_norm": 4.398860931396484,
      "learning_rate": 6.400046056431829e-06,
      "loss": 0.1068,
      "step": 619
    },
    {
      "epoch": 0.41032428855062875,
      "grad_norm": 0.001962291309610009,
      "learning_rate": 6.390063154972767e-06,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 0.4109861019192588,
      "grad_norm": 0.5489677786827087,
      "learning_rate": 6.380074244472359e-06,
      "loss": 0.009,
      "step": 621
    },
    {
      "epoch": 0.4116479152878888,
      "grad_norm": 10.092537879943848,
      "learning_rate": 6.370079368111215e-06,
      "loss": 0.7235,
      "step": 622
    },
    {
      "epoch": 0.4123097286565189,
      "grad_norm": 10.950965881347656,
      "learning_rate": 6.360078569095733e-06,
      "loss": 0.2504,
      "step": 623
    },
    {
      "epoch": 0.4129715420251489,
      "grad_norm": 0.007832425646483898,
      "learning_rate": 6.350071890657918e-06,
      "loss": 0.0002,
      "step": 624
    },
    {
      "epoch": 0.41363335539377893,
      "grad_norm": 0.008806816302239895,
      "learning_rate": 6.340059376055192e-06,
      "loss": 0.0001,
      "step": 625
    },
    {
      "epoch": 0.414295168762409,
      "grad_norm": 0.5755372643470764,
      "learning_rate": 6.330041068570199e-06,
      "loss": 0.008,
      "step": 626
    },
    {
      "epoch": 0.41495698213103904,
      "grad_norm": 10.57274055480957,
      "learning_rate": 6.320017011510631e-06,
      "loss": 0.8267,
      "step": 627
    },
    {
      "epoch": 0.41561879549966907,
      "grad_norm": 0.0016512202564626932,
      "learning_rate": 6.30998724820903e-06,
      "loss": 0.0001,
      "step": 628
    },
    {
      "epoch": 0.41628060886829915,
      "grad_norm": 0.25214630365371704,
      "learning_rate": 6.299951822022609e-06,
      "loss": 0.0035,
      "step": 629
    },
    {
      "epoch": 0.4169424222369292,
      "grad_norm": 0.002957382705062628,
      "learning_rate": 6.289910776333062e-06,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.41760423560555926,
      "grad_norm": 0.1297789067029953,
      "learning_rate": 6.279864154546367e-06,
      "loss": 0.0021,
      "step": 631
    },
    {
      "epoch": 0.4182660489741893,
      "grad_norm": 0.23820075392723083,
      "learning_rate": 6.269812000092619e-06,
      "loss": 0.0036,
      "step": 632
    },
    {
      "epoch": 0.4189278623428193,
      "grad_norm": 0.4792306423187256,
      "learning_rate": 6.259754356425818e-06,
      "loss": 0.0048,
      "step": 633
    },
    {
      "epoch": 0.4195896757114494,
      "grad_norm": 3.1057889461517334,
      "learning_rate": 6.249691267023701e-06,
      "loss": 0.105,
      "step": 634
    },
    {
      "epoch": 0.4202514890800794,
      "grad_norm": 4.154674530029297,
      "learning_rate": 6.239622775387543e-06,
      "loss": 0.2771,
      "step": 635
    },
    {
      "epoch": 0.42091330244870945,
      "grad_norm": 0.28396177291870117,
      "learning_rate": 6.229548925041974e-06,
      "loss": 0.0064,
      "step": 636
    },
    {
      "epoch": 0.42157511581733953,
      "grad_norm": 0.4481322467327118,
      "learning_rate": 6.219469759534784e-06,
      "loss": 0.0067,
      "step": 637
    },
    {
      "epoch": 0.42223692918596956,
      "grad_norm": 0.004676694981753826,
      "learning_rate": 6.209385322436746e-06,
      "loss": 0.0001,
      "step": 638
    },
    {
      "epoch": 0.4228987425545996,
      "grad_norm": 0.0037919788155704737,
      "learning_rate": 6.1992956573414186e-06,
      "loss": 0.0001,
      "step": 639
    },
    {
      "epoch": 0.42356055592322966,
      "grad_norm": 0.0006597053725272417,
      "learning_rate": 6.189200807864959e-06,
      "loss": 0.0,
      "step": 640
    },
    {
      "epoch": 0.4242223692918597,
      "grad_norm": 6.384133338928223,
      "learning_rate": 6.179100817645938e-06,
      "loss": 0.4309,
      "step": 641
    },
    {
      "epoch": 0.4248841826604897,
      "grad_norm": 0.607567548751831,
      "learning_rate": 6.168995730345146e-06,
      "loss": 0.0143,
      "step": 642
    },
    {
      "epoch": 0.4255459960291198,
      "grad_norm": 0.038454506546258926,
      "learning_rate": 6.15888558964541e-06,
      "loss": 0.0011,
      "step": 643
    },
    {
      "epoch": 0.4262078093977498,
      "grad_norm": 0.05050959810614586,
      "learning_rate": 6.148770439251405e-06,
      "loss": 0.0005,
      "step": 644
    },
    {
      "epoch": 0.4268696227663799,
      "grad_norm": 4.2235846519470215,
      "learning_rate": 6.138650322889453e-06,
      "loss": 0.2081,
      "step": 645
    },
    {
      "epoch": 0.42753143613500993,
      "grad_norm": 0.015136443078517914,
      "learning_rate": 6.128525284307354e-06,
      "loss": 0.0002,
      "step": 646
    },
    {
      "epoch": 0.42819324950363996,
      "grad_norm": 0.3785651624202728,
      "learning_rate": 6.118395367274177e-06,
      "loss": 0.0069,
      "step": 647
    },
    {
      "epoch": 0.42885506287227004,
      "grad_norm": 0.022114461287856102,
      "learning_rate": 6.108260615580086e-06,
      "loss": 0.0005,
      "step": 648
    },
    {
      "epoch": 0.42951687624090007,
      "grad_norm": 0.11007736623287201,
      "learning_rate": 6.098121073036141e-06,
      "loss": 0.0017,
      "step": 649
    },
    {
      "epoch": 0.4301786896095301,
      "grad_norm": 0.0011614806717261672,
      "learning_rate": 6.087976783474114e-06,
      "loss": 0.0001,
      "step": 650
    },
    {
      "epoch": 0.4308405029781602,
      "grad_norm": 1.1377021074295044,
      "learning_rate": 6.077827790746294e-06,
      "loss": 0.0223,
      "step": 651
    },
    {
      "epoch": 0.4315023163467902,
      "grad_norm": 6.564091682434082,
      "learning_rate": 6.0676741387253104e-06,
      "loss": 0.4002,
      "step": 652
    },
    {
      "epoch": 0.43216412971542023,
      "grad_norm": 0.012335025705397129,
      "learning_rate": 6.0575158713039236e-06,
      "loss": 0.0002,
      "step": 653
    },
    {
      "epoch": 0.4328259430840503,
      "grad_norm": 3.6428825855255127,
      "learning_rate": 6.047353032394849e-06,
      "loss": 0.2069,
      "step": 654
    },
    {
      "epoch": 0.43348775645268034,
      "grad_norm": 0.03220533952116966,
      "learning_rate": 6.037185665930567e-06,
      "loss": 0.0006,
      "step": 655
    },
    {
      "epoch": 0.43414956982131037,
      "grad_norm": 0.0009990185499191284,
      "learning_rate": 6.027013815863129e-06,
      "loss": 0.0001,
      "step": 656
    },
    {
      "epoch": 0.43481138318994045,
      "grad_norm": 0.0050841751508414745,
      "learning_rate": 6.016837526163962e-06,
      "loss": 0.0001,
      "step": 657
    },
    {
      "epoch": 0.4354731965585705,
      "grad_norm": 1.2732837200164795,
      "learning_rate": 6.006656840823696e-06,
      "loss": 0.0418,
      "step": 658
    },
    {
      "epoch": 0.43613500992720056,
      "grad_norm": 0.014676868915557861,
      "learning_rate": 5.996471803851951e-06,
      "loss": 0.0002,
      "step": 659
    },
    {
      "epoch": 0.4367968232958306,
      "grad_norm": 1.2451729774475098,
      "learning_rate": 5.9862824592771684e-06,
      "loss": 0.0159,
      "step": 660
    },
    {
      "epoch": 0.4374586366644606,
      "grad_norm": 0.34740135073661804,
      "learning_rate": 5.976088851146405e-06,
      "loss": 0.0074,
      "step": 661
    },
    {
      "epoch": 0.4381204500330907,
      "grad_norm": 0.12470830231904984,
      "learning_rate": 5.96589102352515e-06,
      "loss": 0.0022,
      "step": 662
    },
    {
      "epoch": 0.4387822634017207,
      "grad_norm": 0.03386622294783592,
      "learning_rate": 5.955689020497133e-06,
      "loss": 0.0005,
      "step": 663
    },
    {
      "epoch": 0.43944407677035074,
      "grad_norm": 16.35873794555664,
      "learning_rate": 5.945482886164132e-06,
      "loss": 0.3977,
      "step": 664
    },
    {
      "epoch": 0.4401058901389808,
      "grad_norm": 2.5485339164733887,
      "learning_rate": 5.935272664645786e-06,
      "loss": 0.1301,
      "step": 665
    },
    {
      "epoch": 0.44076770350761085,
      "grad_norm": 0.21151848137378693,
      "learning_rate": 5.925058400079402e-06,
      "loss": 0.0021,
      "step": 666
    },
    {
      "epoch": 0.4414295168762409,
      "grad_norm": 0.011408445425331593,
      "learning_rate": 5.914840136619762e-06,
      "loss": 0.0002,
      "step": 667
    },
    {
      "epoch": 0.44209133024487096,
      "grad_norm": 14.179211616516113,
      "learning_rate": 5.904617918438936e-06,
      "loss": 0.8793,
      "step": 668
    },
    {
      "epoch": 0.442753143613501,
      "grad_norm": 0.0006565865478478372,
      "learning_rate": 5.894391789726092e-06,
      "loss": 0.0,
      "step": 669
    },
    {
      "epoch": 0.443414956982131,
      "grad_norm": 0.0010837489971891046,
      "learning_rate": 5.884161794687302e-06,
      "loss": 0.0,
      "step": 670
    },
    {
      "epoch": 0.4440767703507611,
      "grad_norm": 0.013546793721616268,
      "learning_rate": 5.873927977545346e-06,
      "loss": 0.0003,
      "step": 671
    },
    {
      "epoch": 0.4447385837193911,
      "grad_norm": 0.01872323453426361,
      "learning_rate": 5.863690382539535e-06,
      "loss": 0.0004,
      "step": 672
    },
    {
      "epoch": 0.4454003970880212,
      "grad_norm": 0.0025546990800648928,
      "learning_rate": 5.853449053925505e-06,
      "loss": 0.0001,
      "step": 673
    },
    {
      "epoch": 0.44606221045665123,
      "grad_norm": 5.693121433258057,
      "learning_rate": 5.843204035975033e-06,
      "loss": 0.3001,
      "step": 674
    },
    {
      "epoch": 0.44672402382528126,
      "grad_norm": 0.019726872444152832,
      "learning_rate": 5.832955372975848e-06,
      "loss": 0.0003,
      "step": 675
    },
    {
      "epoch": 0.44738583719391134,
      "grad_norm": 0.053829312324523926,
      "learning_rate": 5.822703109231431e-06,
      "loss": 0.0014,
      "step": 676
    },
    {
      "epoch": 0.44804765056254137,
      "grad_norm": 0.030956164002418518,
      "learning_rate": 5.812447289060832e-06,
      "loss": 0.0008,
      "step": 677
    },
    {
      "epoch": 0.4487094639311714,
      "grad_norm": 0.04144800454378128,
      "learning_rate": 5.802187956798471e-06,
      "loss": 0.0005,
      "step": 678
    },
    {
      "epoch": 0.4493712772998015,
      "grad_norm": 0.0009258284699171782,
      "learning_rate": 5.791925156793956e-06,
      "loss": 0.0,
      "step": 679
    },
    {
      "epoch": 0.4500330906684315,
      "grad_norm": 0.0029748675879091024,
      "learning_rate": 5.7816589334118825e-06,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 0.45069490403706153,
      "grad_norm": 0.0027442178688943386,
      "learning_rate": 5.7713893310316425e-06,
      "loss": 0.0001,
      "step": 681
    },
    {
      "epoch": 0.4513567174056916,
      "grad_norm": 0.05176916718482971,
      "learning_rate": 5.761116394047238e-06,
      "loss": 0.0012,
      "step": 682
    },
    {
      "epoch": 0.45201853077432164,
      "grad_norm": 0.005133007187396288,
      "learning_rate": 5.750840166867085e-06,
      "loss": 0.0001,
      "step": 683
    },
    {
      "epoch": 0.45268034414295166,
      "grad_norm": 10.8590087890625,
      "learning_rate": 5.740560693913825e-06,
      "loss": 0.5676,
      "step": 684
    },
    {
      "epoch": 0.45334215751158174,
      "grad_norm": 0.01563701406121254,
      "learning_rate": 5.730278019624124e-06,
      "loss": 0.0004,
      "step": 685
    },
    {
      "epoch": 0.45400397088021177,
      "grad_norm": 9.821488380432129,
      "learning_rate": 5.7199921884484975e-06,
      "loss": 0.1952,
      "step": 686
    },
    {
      "epoch": 0.45466578424884185,
      "grad_norm": 0.01245309878140688,
      "learning_rate": 5.7097032448510945e-06,
      "loss": 0.0003,
      "step": 687
    },
    {
      "epoch": 0.4553275976174719,
      "grad_norm": 0.00026909567532129586,
      "learning_rate": 5.699411233309528e-06,
      "loss": 0.0,
      "step": 688
    },
    {
      "epoch": 0.4559894109861019,
      "grad_norm": 0.0024807301815599203,
      "learning_rate": 5.6891161983146736e-06,
      "loss": 0.0001,
      "step": 689
    },
    {
      "epoch": 0.456651224354732,
      "grad_norm": 0.03884740173816681,
      "learning_rate": 5.678818184370469e-06,
      "loss": 0.0007,
      "step": 690
    },
    {
      "epoch": 0.457313037723362,
      "grad_norm": 4.175657749176025,
      "learning_rate": 5.668517235993739e-06,
      "loss": 0.322,
      "step": 691
    },
    {
      "epoch": 0.45797485109199204,
      "grad_norm": 0.003932994790375233,
      "learning_rate": 5.658213397713985e-06,
      "loss": 0.0001,
      "step": 692
    },
    {
      "epoch": 0.4586366644606221,
      "grad_norm": 0.0010040836641564965,
      "learning_rate": 5.647906714073208e-06,
      "loss": 0.0001,
      "step": 693
    },
    {
      "epoch": 0.45929847782925215,
      "grad_norm": 0.08255140483379364,
      "learning_rate": 5.637597229625705e-06,
      "loss": 0.0016,
      "step": 694
    },
    {
      "epoch": 0.4599602911978822,
      "grad_norm": 0.018713291734457016,
      "learning_rate": 5.627284988937882e-06,
      "loss": 0.0002,
      "step": 695
    },
    {
      "epoch": 0.46062210456651226,
      "grad_norm": 0.002249056939035654,
      "learning_rate": 5.6169700365880585e-06,
      "loss": 0.0001,
      "step": 696
    },
    {
      "epoch": 0.4612839179351423,
      "grad_norm": 0.005524014588445425,
      "learning_rate": 5.6066524171662765e-06,
      "loss": 0.0002,
      "step": 697
    },
    {
      "epoch": 0.4619457313037723,
      "grad_norm": 0.00153267418500036,
      "learning_rate": 5.5963321752741105e-06,
      "loss": 0.0001,
      "step": 698
    },
    {
      "epoch": 0.4626075446724024,
      "grad_norm": 6.595988750457764,
      "learning_rate": 5.5860093555244656e-06,
      "loss": 0.1927,
      "step": 699
    },
    {
      "epoch": 0.4632693580410324,
      "grad_norm": 0.012423002161085606,
      "learning_rate": 5.575684002541397e-06,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 0.4639311714096625,
      "grad_norm": 0.07802154123783112,
      "learning_rate": 5.565356160959905e-06,
      "loss": 0.0013,
      "step": 701
    },
    {
      "epoch": 0.46459298477829253,
      "grad_norm": 0.1561034768819809,
      "learning_rate": 5.555025875425751e-06,
      "loss": 0.0019,
      "step": 702
    },
    {
      "epoch": 0.46525479814692255,
      "grad_norm": 0.004090913571417332,
      "learning_rate": 5.544693190595263e-06,
      "loss": 0.0001,
      "step": 703
    },
    {
      "epoch": 0.46591661151555264,
      "grad_norm": 0.003916710615158081,
      "learning_rate": 5.534358151135135e-06,
      "loss": 0.0001,
      "step": 704
    },
    {
      "epoch": 0.46657842488418266,
      "grad_norm": 0.0007131873280741274,
      "learning_rate": 5.524020801722247e-06,
      "loss": 0.0,
      "step": 705
    },
    {
      "epoch": 0.4672402382528127,
      "grad_norm": 0.005720032844692469,
      "learning_rate": 5.513681187043456e-06,
      "loss": 0.0001,
      "step": 706
    },
    {
      "epoch": 0.46790205162144277,
      "grad_norm": 0.09349609166383743,
      "learning_rate": 5.5033393517954194e-06,
      "loss": 0.0016,
      "step": 707
    },
    {
      "epoch": 0.4685638649900728,
      "grad_norm": 0.0784706100821495,
      "learning_rate": 5.49299534068439e-06,
      "loss": 0.0013,
      "step": 708
    },
    {
      "epoch": 0.4692256783587028,
      "grad_norm": 0.0032978153321892023,
      "learning_rate": 5.4826491984260285e-06,
      "loss": 0.0001,
      "step": 709
    },
    {
      "epoch": 0.4698874917273329,
      "grad_norm": 0.020696090534329414,
      "learning_rate": 5.472300969745205e-06,
      "loss": 0.0005,
      "step": 710
    },
    {
      "epoch": 0.47054930509596293,
      "grad_norm": 0.00396889541298151,
      "learning_rate": 5.461950699375809e-06,
      "loss": 0.0001,
      "step": 711
    },
    {
      "epoch": 0.47121111846459296,
      "grad_norm": 11.279080390930176,
      "learning_rate": 5.451598432060563e-06,
      "loss": 0.6143,
      "step": 712
    },
    {
      "epoch": 0.47187293183322304,
      "grad_norm": 0.0014679256128147244,
      "learning_rate": 5.4412442125508115e-06,
      "loss": 0.0001,
      "step": 713
    },
    {
      "epoch": 0.47253474520185307,
      "grad_norm": 4.9178996086120605,
      "learning_rate": 5.430888085606346e-06,
      "loss": 0.4366,
      "step": 714
    },
    {
      "epoch": 0.47319655857048315,
      "grad_norm": 1.6859396696090698,
      "learning_rate": 5.420530095995198e-06,
      "loss": 0.0317,
      "step": 715
    },
    {
      "epoch": 0.4738583719391132,
      "grad_norm": 0.013875379227101803,
      "learning_rate": 5.410170288493458e-06,
      "loss": 0.0002,
      "step": 716
    },
    {
      "epoch": 0.4745201853077432,
      "grad_norm": 0.0024631989654153585,
      "learning_rate": 5.399808707885069e-06,
      "loss": 0.0001,
      "step": 717
    },
    {
      "epoch": 0.4751819986763733,
      "grad_norm": 0.10739407688379288,
      "learning_rate": 5.389445398961639e-06,
      "loss": 0.0021,
      "step": 718
    },
    {
      "epoch": 0.4758438120450033,
      "grad_norm": 0.0008494414505548775,
      "learning_rate": 5.379080406522253e-06,
      "loss": 0.0,
      "step": 719
    },
    {
      "epoch": 0.47650562541363334,
      "grad_norm": 0.20736032724380493,
      "learning_rate": 5.368713775373264e-06,
      "loss": 0.004,
      "step": 720
    },
    {
      "epoch": 0.4771674387822634,
      "grad_norm": 0.0074742934666574,
      "learning_rate": 5.358345550328118e-06,
      "loss": 0.0001,
      "step": 721
    },
    {
      "epoch": 0.47782925215089345,
      "grad_norm": 0.005933358799666166,
      "learning_rate": 5.347975776207148e-06,
      "loss": 0.0001,
      "step": 722
    },
    {
      "epoch": 0.4784910655195235,
      "grad_norm": 0.001804803847335279,
      "learning_rate": 5.337604497837383e-06,
      "loss": 0.0,
      "step": 723
    },
    {
      "epoch": 0.47915287888815355,
      "grad_norm": 0.007865388877689838,
      "learning_rate": 5.3272317600523505e-06,
      "loss": 0.0002,
      "step": 724
    },
    {
      "epoch": 0.4798146922567836,
      "grad_norm": 0.46899986267089844,
      "learning_rate": 5.316857607691896e-06,
      "loss": 0.0107,
      "step": 725
    },
    {
      "epoch": 0.4804765056254136,
      "grad_norm": 7.874037265777588,
      "learning_rate": 5.306482085601975e-06,
      "loss": 0.3635,
      "step": 726
    },
    {
      "epoch": 0.4811383189940437,
      "grad_norm": 0.03337458148598671,
      "learning_rate": 5.296105238634461e-06,
      "loss": 0.0004,
      "step": 727
    },
    {
      "epoch": 0.4818001323626737,
      "grad_norm": 0.22684064507484436,
      "learning_rate": 5.28572711164696e-06,
      "loss": 0.0028,
      "step": 728
    },
    {
      "epoch": 0.4824619457313038,
      "grad_norm": 0.05128590762615204,
      "learning_rate": 5.275347749502609e-06,
      "loss": 0.0013,
      "step": 729
    },
    {
      "epoch": 0.4831237590999338,
      "grad_norm": 0.0030932023655623198,
      "learning_rate": 5.264967197069884e-06,
      "loss": 0.0001,
      "step": 730
    },
    {
      "epoch": 0.48378557246856385,
      "grad_norm": 0.03851217031478882,
      "learning_rate": 5.25458549922241e-06,
      "loss": 0.0007,
      "step": 731
    },
    {
      "epoch": 0.48444738583719393,
      "grad_norm": 7.908039093017578,
      "learning_rate": 5.244202700838756e-06,
      "loss": 0.3893,
      "step": 732
    },
    {
      "epoch": 0.48510919920582396,
      "grad_norm": 9.118852615356445,
      "learning_rate": 5.233818846802255e-06,
      "loss": 0.8102,
      "step": 733
    },
    {
      "epoch": 0.485771012574454,
      "grad_norm": 11.253800392150879,
      "learning_rate": 5.223433982000804e-06,
      "loss": 0.7192,
      "step": 734
    },
    {
      "epoch": 0.48643282594308407,
      "grad_norm": 0.0013900386402383447,
      "learning_rate": 5.213048151326664e-06,
      "loss": 0.0,
      "step": 735
    },
    {
      "epoch": 0.4870946393117141,
      "grad_norm": 0.0011732177808880806,
      "learning_rate": 5.202661399676276e-06,
      "loss": 0.0,
      "step": 736
    },
    {
      "epoch": 0.4877564526803441,
      "grad_norm": 0.3603931963443756,
      "learning_rate": 5.192273771950057e-06,
      "loss": 0.0058,
      "step": 737
    },
    {
      "epoch": 0.4884182660489742,
      "grad_norm": 0.003041299758478999,
      "learning_rate": 5.181885313052219e-06,
      "loss": 0.0001,
      "step": 738
    },
    {
      "epoch": 0.48908007941760423,
      "grad_norm": 4.229525566101074,
      "learning_rate": 5.17149606789056e-06,
      "loss": 0.0943,
      "step": 739
    },
    {
      "epoch": 0.48974189278623426,
      "grad_norm": 0.0025115138851106167,
      "learning_rate": 5.161106081376282e-06,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.49040370615486434,
      "grad_norm": 0.03940216824412346,
      "learning_rate": 5.150715398423786e-06,
      "loss": 0.0009,
      "step": 741
    },
    {
      "epoch": 0.49106551952349436,
      "grad_norm": 0.007454422768205404,
      "learning_rate": 5.140324063950488e-06,
      "loss": 0.0001,
      "step": 742
    },
    {
      "epoch": 0.49172733289212445,
      "grad_norm": 0.06355396658182144,
      "learning_rate": 5.12993212287662e-06,
      "loss": 0.0019,
      "step": 743
    },
    {
      "epoch": 0.4923891462607545,
      "grad_norm": 0.37700074911117554,
      "learning_rate": 5.119539620125037e-06,
      "loss": 0.0061,
      "step": 744
    },
    {
      "epoch": 0.4930509596293845,
      "grad_norm": 0.06519635021686554,
      "learning_rate": 5.109146600621019e-06,
      "loss": 0.0011,
      "step": 745
    },
    {
      "epoch": 0.4937127729980146,
      "grad_norm": 0.005161901004612446,
      "learning_rate": 5.098753109292081e-06,
      "loss": 0.0001,
      "step": 746
    },
    {
      "epoch": 0.4943745863666446,
      "grad_norm": 0.001639832160435617,
      "learning_rate": 5.088359191067778e-06,
      "loss": 0.0,
      "step": 747
    },
    {
      "epoch": 0.49503639973527463,
      "grad_norm": 0.10746078938245773,
      "learning_rate": 5.077964890879512e-06,
      "loss": 0.0018,
      "step": 748
    },
    {
      "epoch": 0.4956982131039047,
      "grad_norm": 0.35989969968795776,
      "learning_rate": 5.067570253660333e-06,
      "loss": 0.0072,
      "step": 749
    },
    {
      "epoch": 0.49636002647253474,
      "grad_norm": 0.035464975982904434,
      "learning_rate": 5.057175324344752e-06,
      "loss": 0.0006,
      "step": 750
    },
    {
      "epoch": 0.49702183984116477,
      "grad_norm": 0.007679045666009188,
      "learning_rate": 5.046780147868537e-06,
      "loss": 0.0002,
      "step": 751
    },
    {
      "epoch": 0.49768365320979485,
      "grad_norm": 1.291237711906433,
      "learning_rate": 5.036384769168531e-06,
      "loss": 0.0336,
      "step": 752
    },
    {
      "epoch": 0.4983454665784249,
      "grad_norm": 6.943925857543945,
      "learning_rate": 5.0259892331824476e-06,
      "loss": 0.2695,
      "step": 753
    },
    {
      "epoch": 0.4990072799470549,
      "grad_norm": 3.3652398586273193,
      "learning_rate": 5.015593584848679e-06,
      "loss": 0.0408,
      "step": 754
    },
    {
      "epoch": 0.499669093315685,
      "grad_norm": 3.4602203369140625,
      "learning_rate": 5.005197869106105e-06,
      "loss": 0.2264,
      "step": 755
    },
    {
      "epoch": 0.500330906684315,
      "grad_norm": 0.016787618398666382,
      "learning_rate": 4.994802130893897e-06,
      "loss": 0.0002,
      "step": 756
    },
    {
      "epoch": 0.500992720052945,
      "grad_norm": 0.0001271326473215595,
      "learning_rate": 4.9844064151513234e-06,
      "loss": 0.0,
      "step": 757
    },
    {
      "epoch": 0.5016545334215751,
      "grad_norm": 0.0266489889472723,
      "learning_rate": 4.974010766817555e-06,
      "loss": 0.0004,
      "step": 758
    },
    {
      "epoch": 0.5023163467902052,
      "grad_norm": 0.00809770729392767,
      "learning_rate": 4.9636152308314685e-06,
      "loss": 0.0001,
      "step": 759
    },
    {
      "epoch": 0.5029781601588352,
      "grad_norm": 0.10261885076761246,
      "learning_rate": 4.953219852131464e-06,
      "loss": 0.0016,
      "step": 760
    },
    {
      "epoch": 0.5036399735274653,
      "grad_norm": 0.0018846929306164384,
      "learning_rate": 4.94282467565525e-06,
      "loss": 0.0001,
      "step": 761
    },
    {
      "epoch": 0.5043017868960953,
      "grad_norm": 0.06556399911642075,
      "learning_rate": 4.932429746339668e-06,
      "loss": 0.0013,
      "step": 762
    },
    {
      "epoch": 0.5049636002647253,
      "grad_norm": 0.7782140374183655,
      "learning_rate": 4.922035109120491e-06,
      "loss": 0.0156,
      "step": 763
    },
    {
      "epoch": 0.5056254136333554,
      "grad_norm": 7.84725284576416,
      "learning_rate": 4.911640808932223e-06,
      "loss": 0.6489,
      "step": 764
    },
    {
      "epoch": 0.5062872270019855,
      "grad_norm": 0.007887299172580242,
      "learning_rate": 4.9012468907079216e-06,
      "loss": 0.0002,
      "step": 765
    },
    {
      "epoch": 0.5069490403706155,
      "grad_norm": 0.001295779598876834,
      "learning_rate": 4.890853399378983e-06,
      "loss": 0.0001,
      "step": 766
    },
    {
      "epoch": 0.5076108537392455,
      "grad_norm": 0.03443460166454315,
      "learning_rate": 4.880460379874965e-06,
      "loss": 0.0006,
      "step": 767
    },
    {
      "epoch": 0.5082726671078756,
      "grad_norm": 2.5311923027038574,
      "learning_rate": 4.870067877123382e-06,
      "loss": 0.049,
      "step": 768
    },
    {
      "epoch": 0.5089344804765056,
      "grad_norm": 0.10131332278251648,
      "learning_rate": 4.8596759360495135e-06,
      "loss": 0.002,
      "step": 769
    },
    {
      "epoch": 0.5095962938451357,
      "grad_norm": 0.0007360694580711424,
      "learning_rate": 4.849284601576215e-06,
      "loss": 0.0,
      "step": 770
    },
    {
      "epoch": 0.5102581072137657,
      "grad_norm": 5.028912544250488,
      "learning_rate": 4.83889391862372e-06,
      "loss": 0.4575,
      "step": 771
    },
    {
      "epoch": 0.5109199205823958,
      "grad_norm": 0.9152045249938965,
      "learning_rate": 4.828503932109442e-06,
      "loss": 0.0187,
      "step": 772
    },
    {
      "epoch": 0.5115817339510258,
      "grad_norm": 0.0037701858673244715,
      "learning_rate": 4.818114686947783e-06,
      "loss": 0.0001,
      "step": 773
    },
    {
      "epoch": 0.5122435473196558,
      "grad_norm": 0.06403883546590805,
      "learning_rate": 4.807726228049944e-06,
      "loss": 0.0009,
      "step": 774
    },
    {
      "epoch": 0.5129053606882858,
      "grad_norm": 0.07327501475811005,
      "learning_rate": 4.797338600323727e-06,
      "loss": 0.0009,
      "step": 775
    },
    {
      "epoch": 0.513567174056916,
      "grad_norm": 0.003804423613473773,
      "learning_rate": 4.786951848673337e-06,
      "loss": 0.0001,
      "step": 776
    },
    {
      "epoch": 0.514228987425546,
      "grad_norm": 13.4599027633667,
      "learning_rate": 4.7765660179991965e-06,
      "loss": 0.7234,
      "step": 777
    },
    {
      "epoch": 0.514890800794176,
      "grad_norm": 3.39192533493042,
      "learning_rate": 4.766181153197746e-06,
      "loss": 0.0725,
      "step": 778
    },
    {
      "epoch": 0.5155526141628061,
      "grad_norm": 0.2930142283439636,
      "learning_rate": 4.755797299161245e-06,
      "loss": 0.0064,
      "step": 779
    },
    {
      "epoch": 0.5162144275314361,
      "grad_norm": 0.003506129141896963,
      "learning_rate": 4.745414500777592e-06,
      "loss": 0.0001,
      "step": 780
    },
    {
      "epoch": 0.5168762409000662,
      "grad_norm": 0.00048141489969566464,
      "learning_rate": 4.735032802930116e-06,
      "loss": 0.0,
      "step": 781
    },
    {
      "epoch": 0.5175380542686963,
      "grad_norm": 0.06508062034845352,
      "learning_rate": 4.724652250497392e-06,
      "loss": 0.0011,
      "step": 782
    },
    {
      "epoch": 0.5181998676373263,
      "grad_norm": 0.0032655030954629183,
      "learning_rate": 4.7142728883530415e-06,
      "loss": 0.0001,
      "step": 783
    },
    {
      "epoch": 0.5188616810059563,
      "grad_norm": 0.0006524981581605971,
      "learning_rate": 4.70389476136554e-06,
      "loss": 0.0,
      "step": 784
    },
    {
      "epoch": 0.5195234943745863,
      "grad_norm": 0.2484452724456787,
      "learning_rate": 4.693517914398027e-06,
      "loss": 0.0037,
      "step": 785
    },
    {
      "epoch": 0.5201853077432164,
      "grad_norm": 0.0052129607647657394,
      "learning_rate": 4.683142392308105e-06,
      "loss": 0.0002,
      "step": 786
    },
    {
      "epoch": 0.5208471211118465,
      "grad_norm": 0.09848477691411972,
      "learning_rate": 4.6727682399476495e-06,
      "loss": 0.0018,
      "step": 787
    },
    {
      "epoch": 0.5215089344804765,
      "grad_norm": 0.0009606341482140124,
      "learning_rate": 4.662395502162619e-06,
      "loss": 0.0,
      "step": 788
    },
    {
      "epoch": 0.5221707478491066,
      "grad_norm": 0.04674139618873596,
      "learning_rate": 4.652024223792853e-06,
      "loss": 0.001,
      "step": 789
    },
    {
      "epoch": 0.5228325612177366,
      "grad_norm": 7.162926197052002,
      "learning_rate": 4.641654449671884e-06,
      "loss": 0.4175,
      "step": 790
    },
    {
      "epoch": 0.5234943745863666,
      "grad_norm": 9.761975288391113,
      "learning_rate": 4.631286224626738e-06,
      "loss": 0.7296,
      "step": 791
    },
    {
      "epoch": 0.5241561879549967,
      "grad_norm": 0.5241225361824036,
      "learning_rate": 4.620919593477749e-06,
      "loss": 0.0075,
      "step": 792
    },
    {
      "epoch": 0.5248180013236268,
      "grad_norm": 5.0483222007751465,
      "learning_rate": 4.610554601038361e-06,
      "loss": 0.1194,
      "step": 793
    },
    {
      "epoch": 0.5254798146922568,
      "grad_norm": 0.005641717929393053,
      "learning_rate": 4.600191292114932e-06,
      "loss": 0.0001,
      "step": 794
    },
    {
      "epoch": 0.5261416280608868,
      "grad_norm": 0.0014177138218656182,
      "learning_rate": 4.589829711506543e-06,
      "loss": 0.0001,
      "step": 795
    },
    {
      "epoch": 0.5268034414295168,
      "grad_norm": 3.176114797592163,
      "learning_rate": 4.5794699040048036e-06,
      "loss": 0.0433,
      "step": 796
    },
    {
      "epoch": 0.5274652547981469,
      "grad_norm": 0.005049627739936113,
      "learning_rate": 4.569111914393657e-06,
      "loss": 0.0001,
      "step": 797
    },
    {
      "epoch": 0.528127068166777,
      "grad_norm": 3.891094446182251,
      "learning_rate": 4.558755787449189e-06,
      "loss": 0.0545,
      "step": 798
    },
    {
      "epoch": 0.528788881535407,
      "grad_norm": 13.18693733215332,
      "learning_rate": 4.548401567939439e-06,
      "loss": 0.4445,
      "step": 799
    },
    {
      "epoch": 0.5294506949040371,
      "grad_norm": 0.0061899167485535145,
      "learning_rate": 4.538049300624192e-06,
      "loss": 0.0001,
      "step": 800
    },
    {
      "epoch": 0.5301125082726671,
      "grad_norm": 0.05325816571712494,
      "learning_rate": 4.527699030254797e-06,
      "loss": 0.0011,
      "step": 801
    },
    {
      "epoch": 0.5307743216412971,
      "grad_norm": 4.25078821182251,
      "learning_rate": 4.517350801573974e-06,
      "loss": 0.2464,
      "step": 802
    },
    {
      "epoch": 0.5314361350099271,
      "grad_norm": 0.003979577217251062,
      "learning_rate": 4.5070046593156115e-06,
      "loss": 0.0001,
      "step": 803
    },
    {
      "epoch": 0.5320979483785573,
      "grad_norm": 0.03473566845059395,
      "learning_rate": 4.496660648204581e-06,
      "loss": 0.0007,
      "step": 804
    },
    {
      "epoch": 0.5327597617471873,
      "grad_norm": 0.8906238675117493,
      "learning_rate": 4.486318812956546e-06,
      "loss": 0.0209,
      "step": 805
    },
    {
      "epoch": 0.5334215751158173,
      "grad_norm": 0.14821484684944153,
      "learning_rate": 4.475979198277755e-06,
      "loss": 0.0025,
      "step": 806
    },
    {
      "epoch": 0.5340833884844474,
      "grad_norm": 0.06057769060134888,
      "learning_rate": 4.465641848864867e-06,
      "loss": 0.001,
      "step": 807
    },
    {
      "epoch": 0.5347452018530774,
      "grad_norm": 0.4113360047340393,
      "learning_rate": 4.455306809404739e-06,
      "loss": 0.0059,
      "step": 808
    },
    {
      "epoch": 0.5354070152217075,
      "grad_norm": 14.107372283935547,
      "learning_rate": 4.44497412457425e-06,
      "loss": 0.7844,
      "step": 809
    },
    {
      "epoch": 0.5360688285903376,
      "grad_norm": 0.008469870314002037,
      "learning_rate": 4.434643839040097e-06,
      "loss": 0.0001,
      "step": 810
    },
    {
      "epoch": 0.5367306419589676,
      "grad_norm": 0.07741834223270416,
      "learning_rate": 4.4243159974586044e-06,
      "loss": 0.0011,
      "step": 811
    },
    {
      "epoch": 0.5373924553275976,
      "grad_norm": 0.004074903205037117,
      "learning_rate": 4.413990644475536e-06,
      "loss": 0.0001,
      "step": 812
    },
    {
      "epoch": 0.5380542686962276,
      "grad_norm": 0.0021265575196594,
      "learning_rate": 4.403667824725892e-06,
      "loss": 0.0001,
      "step": 813
    },
    {
      "epoch": 0.5387160820648577,
      "grad_norm": 0.02396826073527336,
      "learning_rate": 4.393347582833724e-06,
      "loss": 0.0007,
      "step": 814
    },
    {
      "epoch": 0.5393778954334878,
      "grad_norm": 6.185585975646973,
      "learning_rate": 4.383029963411943e-06,
      "loss": 0.3598,
      "step": 815
    },
    {
      "epoch": 0.5400397088021178,
      "grad_norm": 1.8775579929351807,
      "learning_rate": 4.372715011062119e-06,
      "loss": 0.0236,
      "step": 816
    },
    {
      "epoch": 0.5407015221707479,
      "grad_norm": 0.0014169907663017511,
      "learning_rate": 4.362402770374296e-06,
      "loss": 0.0001,
      "step": 817
    },
    {
      "epoch": 0.5413633355393779,
      "grad_norm": 6.945932388305664,
      "learning_rate": 4.352093285926793e-06,
      "loss": 0.3378,
      "step": 818
    },
    {
      "epoch": 0.5420251489080079,
      "grad_norm": 1.359619140625,
      "learning_rate": 4.341786602286016e-06,
      "loss": 0.0291,
      "step": 819
    },
    {
      "epoch": 0.542686962276638,
      "grad_norm": 0.01159713789820671,
      "learning_rate": 4.331482764006263e-06,
      "loss": 0.0002,
      "step": 820
    },
    {
      "epoch": 0.5433487756452681,
      "grad_norm": 8.252345085144043,
      "learning_rate": 4.321181815629531e-06,
      "loss": 0.2576,
      "step": 821
    },
    {
      "epoch": 0.5440105890138981,
      "grad_norm": 0.0028152847662568092,
      "learning_rate": 4.310883801685328e-06,
      "loss": 0.0,
      "step": 822
    },
    {
      "epoch": 0.5446724023825281,
      "grad_norm": 0.01484899315983057,
      "learning_rate": 4.3005887666904725e-06,
      "loss": 0.0003,
      "step": 823
    },
    {
      "epoch": 0.5453342157511581,
      "grad_norm": 0.0027581520844250917,
      "learning_rate": 4.290296755148907e-06,
      "loss": 0.0001,
      "step": 824
    },
    {
      "epoch": 0.5459960291197882,
      "grad_norm": 0.002948533045127988,
      "learning_rate": 4.280007811551505e-06,
      "loss": 0.0001,
      "step": 825
    },
    {
      "epoch": 0.5466578424884183,
      "grad_norm": 0.04082091897726059,
      "learning_rate": 4.269721980375875e-06,
      "loss": 0.0007,
      "step": 826
    },
    {
      "epoch": 0.5473196558570483,
      "grad_norm": 3.7325642108917236,
      "learning_rate": 4.259439306086176e-06,
      "loss": 0.1492,
      "step": 827
    },
    {
      "epoch": 0.5479814692256784,
      "grad_norm": 0.0068495976738631725,
      "learning_rate": 4.249159833132916e-06,
      "loss": 0.0001,
      "step": 828
    },
    {
      "epoch": 0.5486432825943084,
      "grad_norm": 0.4554820656776428,
      "learning_rate": 4.238883605952764e-06,
      "loss": 0.01,
      "step": 829
    },
    {
      "epoch": 0.5493050959629384,
      "grad_norm": 9.208914756774902,
      "learning_rate": 4.22861066896836e-06,
      "loss": 0.7013,
      "step": 830
    },
    {
      "epoch": 0.5499669093315684,
      "grad_norm": 0.0006143659120425582,
      "learning_rate": 4.218341066588121e-06,
      "loss": 0.0,
      "step": 831
    },
    {
      "epoch": 0.5506287227001986,
      "grad_norm": 0.02188747562468052,
      "learning_rate": 4.208074843206045e-06,
      "loss": 0.0002,
      "step": 832
    },
    {
      "epoch": 0.5512905360688286,
      "grad_norm": 10.287099838256836,
      "learning_rate": 4.19781204320153e-06,
      "loss": 0.9639,
      "step": 833
    },
    {
      "epoch": 0.5519523494374586,
      "grad_norm": 3.711183786392212,
      "learning_rate": 4.18755271093917e-06,
      "loss": 0.0745,
      "step": 834
    },
    {
      "epoch": 0.5526141628060887,
      "grad_norm": 0.003918972797691822,
      "learning_rate": 4.177296890768571e-06,
      "loss": 0.0001,
      "step": 835
    },
    {
      "epoch": 0.5532759761747187,
      "grad_norm": 9.218042373657227,
      "learning_rate": 4.167044627024154e-06,
      "loss": 0.5519,
      "step": 836
    },
    {
      "epoch": 0.5539377895433488,
      "grad_norm": 0.0007130419835448265,
      "learning_rate": 4.156795964024967e-06,
      "loss": 0.0001,
      "step": 837
    },
    {
      "epoch": 0.5545996029119789,
      "grad_norm": 0.001955335261300206,
      "learning_rate": 4.1465509460744965e-06,
      "loss": 0.0,
      "step": 838
    },
    {
      "epoch": 0.5552614162806089,
      "grad_norm": 0.03545152395963669,
      "learning_rate": 4.136309617460466e-06,
      "loss": 0.0005,
      "step": 839
    },
    {
      "epoch": 0.5559232296492389,
      "grad_norm": 0.0024081943556666374,
      "learning_rate": 4.126072022454655e-06,
      "loss": 0.0001,
      "step": 840
    },
    {
      "epoch": 0.5565850430178689,
      "grad_norm": 0.02132485806941986,
      "learning_rate": 4.115838205312701e-06,
      "loss": 0.0002,
      "step": 841
    },
    {
      "epoch": 0.557246856386499,
      "grad_norm": 0.0027767629362642765,
      "learning_rate": 4.105608210273909e-06,
      "loss": 0.0001,
      "step": 842
    },
    {
      "epoch": 0.5579086697551291,
      "grad_norm": 0.005220923572778702,
      "learning_rate": 4.095382081561064e-06,
      "loss": 0.0001,
      "step": 843
    },
    {
      "epoch": 0.5585704831237591,
      "grad_norm": 0.00437278114259243,
      "learning_rate": 4.085159863380239e-06,
      "loss": 0.0001,
      "step": 844
    },
    {
      "epoch": 0.5592322964923891,
      "grad_norm": 0.050807420164346695,
      "learning_rate": 4.0749415999206e-06,
      "loss": 0.0011,
      "step": 845
    },
    {
      "epoch": 0.5598941098610192,
      "grad_norm": 0.20697660744190216,
      "learning_rate": 4.064727335354216e-06,
      "loss": 0.0044,
      "step": 846
    },
    {
      "epoch": 0.5605559232296492,
      "grad_norm": 0.007427067495882511,
      "learning_rate": 4.0545171138358695e-06,
      "loss": 0.0001,
      "step": 847
    },
    {
      "epoch": 0.5612177365982793,
      "grad_norm": 0.002908355090767145,
      "learning_rate": 4.044310979502867e-06,
      "loss": 0.0,
      "step": 848
    },
    {
      "epoch": 0.5618795499669094,
      "grad_norm": 0.004598580300807953,
      "learning_rate": 4.0341089764748505e-06,
      "loss": 0.0001,
      "step": 849
    },
    {
      "epoch": 0.5625413633355394,
      "grad_norm": 0.005185294430702925,
      "learning_rate": 4.023911148853596e-06,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 0.5632031767041694,
      "grad_norm": 0.011129478923976421,
      "learning_rate": 4.013717540722833e-06,
      "loss": 0.0002,
      "step": 851
    },
    {
      "epoch": 0.5638649900727994,
      "grad_norm": 0.10426144301891327,
      "learning_rate": 4.00352819614805e-06,
      "loss": 0.0025,
      "step": 852
    },
    {
      "epoch": 0.5645268034414295,
      "grad_norm": 12.723078727722168,
      "learning_rate": 3.993343159176307e-06,
      "loss": 0.9585,
      "step": 853
    },
    {
      "epoch": 0.5651886168100596,
      "grad_norm": 0.006486586295068264,
      "learning_rate": 3.9831624738360384e-06,
      "loss": 0.0001,
      "step": 854
    },
    {
      "epoch": 0.5658504301786896,
      "grad_norm": 13.279292106628418,
      "learning_rate": 3.9729861841368735e-06,
      "loss": 0.2525,
      "step": 855
    },
    {
      "epoch": 0.5665122435473197,
      "grad_norm": 7.1231818199157715,
      "learning_rate": 3.962814334069434e-06,
      "loss": 0.2869,
      "step": 856
    },
    {
      "epoch": 0.5671740569159497,
      "grad_norm": 8.849084854125977,
      "learning_rate": 3.9526469676051515e-06,
      "loss": 0.2396,
      "step": 857
    },
    {
      "epoch": 0.5678358702845797,
      "grad_norm": 2.0526628494262695,
      "learning_rate": 3.942484128696079e-06,
      "loss": 0.1093,
      "step": 858
    },
    {
      "epoch": 0.5684976836532097,
      "grad_norm": 0.005353350192308426,
      "learning_rate": 3.932325861274692e-06,
      "loss": 0.0001,
      "step": 859
    },
    {
      "epoch": 0.5691594970218399,
      "grad_norm": 0.017858725041151047,
      "learning_rate": 3.922172209253706e-06,
      "loss": 0.0002,
      "step": 860
    },
    {
      "epoch": 0.5698213103904699,
      "grad_norm": 0.0012761256657540798,
      "learning_rate": 3.9120232165258875e-06,
      "loss": 0.0001,
      "step": 861
    },
    {
      "epoch": 0.5704831237590999,
      "grad_norm": 0.7094792127609253,
      "learning_rate": 3.90187892696386e-06,
      "loss": 0.0129,
      "step": 862
    },
    {
      "epoch": 0.57114493712773,
      "grad_norm": 0.010673231445252895,
      "learning_rate": 3.891739384419916e-06,
      "loss": 0.0002,
      "step": 863
    },
    {
      "epoch": 0.57180675049636,
      "grad_norm": 1.2760872840881348,
      "learning_rate": 3.881604632725825e-06,
      "loss": 0.027,
      "step": 864
    },
    {
      "epoch": 0.5724685638649901,
      "grad_norm": 0.08456950634717941,
      "learning_rate": 3.871474715692647e-06,
      "loss": 0.0012,
      "step": 865
    },
    {
      "epoch": 0.5731303772336201,
      "grad_norm": 1.3026578426361084,
      "learning_rate": 3.8613496771105466e-06,
      "loss": 0.1642,
      "step": 866
    },
    {
      "epoch": 0.5737921906022502,
      "grad_norm": 0.004804557655006647,
      "learning_rate": 3.851229560748597e-06,
      "loss": 0.0001,
      "step": 867
    },
    {
      "epoch": 0.5744540039708802,
      "grad_norm": 0.012767055071890354,
      "learning_rate": 3.841114410354591e-06,
      "loss": 0.0002,
      "step": 868
    },
    {
      "epoch": 0.5751158173395102,
      "grad_norm": 0.021565794944763184,
      "learning_rate": 3.831004269654857e-06,
      "loss": 0.0004,
      "step": 869
    },
    {
      "epoch": 0.5757776307081403,
      "grad_norm": 0.008545857854187489,
      "learning_rate": 3.820899182354065e-06,
      "loss": 0.0002,
      "step": 870
    },
    {
      "epoch": 0.5764394440767704,
      "grad_norm": 16.437145233154297,
      "learning_rate": 3.8107991921350417e-06,
      "loss": 1.3087,
      "step": 871
    },
    {
      "epoch": 0.5771012574454004,
      "grad_norm": 0.012025895528495312,
      "learning_rate": 3.8007043426585827e-06,
      "loss": 0.0002,
      "step": 872
    },
    {
      "epoch": 0.5777630708140304,
      "grad_norm": 0.012876860797405243,
      "learning_rate": 3.7906146775632557e-06,
      "loss": 0.0003,
      "step": 873
    },
    {
      "epoch": 0.5784248841826605,
      "grad_norm": 0.02148408815264702,
      "learning_rate": 3.7805302404652172e-06,
      "loss": 0.0004,
      "step": 874
    },
    {
      "epoch": 0.5790866975512905,
      "grad_norm": 0.005774569232016802,
      "learning_rate": 3.7704510749580293e-06,
      "loss": 0.0001,
      "step": 875
    },
    {
      "epoch": 0.5797485109199206,
      "grad_norm": 0.003955663647502661,
      "learning_rate": 3.760377224612457e-06,
      "loss": 0.0001,
      "step": 876
    },
    {
      "epoch": 0.5804103242885507,
      "grad_norm": 0.011713430285453796,
      "learning_rate": 3.7503087329762997e-06,
      "loss": 0.0001,
      "step": 877
    },
    {
      "epoch": 0.5810721376571807,
      "grad_norm": 14.68677806854248,
      "learning_rate": 3.740245643574184e-06,
      "loss": 1.7821,
      "step": 878
    },
    {
      "epoch": 0.5817339510258107,
      "grad_norm": 0.01256653480231762,
      "learning_rate": 3.7301879999073833e-06,
      "loss": 0.0002,
      "step": 879
    },
    {
      "epoch": 0.5823957643944407,
      "grad_norm": 0.011333790607750416,
      "learning_rate": 3.720135845453634e-06,
      "loss": 0.0002,
      "step": 880
    },
    {
      "epoch": 0.5830575777630708,
      "grad_norm": 0.18699771165847778,
      "learning_rate": 3.7100892236669417e-06,
      "loss": 0.0038,
      "step": 881
    },
    {
      "epoch": 0.5837193911317009,
      "grad_norm": 7.832843780517578,
      "learning_rate": 3.700048177977391e-06,
      "loss": 0.3681,
      "step": 882
    },
    {
      "epoch": 0.5843812045003309,
      "grad_norm": 0.11446569859981537,
      "learning_rate": 3.690012751790972e-06,
      "loss": 0.0022,
      "step": 883
    },
    {
      "epoch": 0.585043017868961,
      "grad_norm": 0.2119974046945572,
      "learning_rate": 3.679982988489371e-06,
      "loss": 0.0041,
      "step": 884
    },
    {
      "epoch": 0.585704831237591,
      "grad_norm": 0.0024179425090551376,
      "learning_rate": 3.669958931429803e-06,
      "loss": 0.0001,
      "step": 885
    },
    {
      "epoch": 0.586366644606221,
      "grad_norm": 0.008741015568375587,
      "learning_rate": 3.6599406239448106e-06,
      "loss": 0.0001,
      "step": 886
    },
    {
      "epoch": 0.587028457974851,
      "grad_norm": 6.393293380737305,
      "learning_rate": 3.6499281093420825e-06,
      "loss": 0.3529,
      "step": 887
    },
    {
      "epoch": 0.5876902713434812,
      "grad_norm": 10.740516662597656,
      "learning_rate": 3.6399214309042683e-06,
      "loss": 1.0896,
      "step": 888
    },
    {
      "epoch": 0.5883520847121112,
      "grad_norm": 0.010228240862488747,
      "learning_rate": 3.6299206318887867e-06,
      "loss": 0.0003,
      "step": 889
    },
    {
      "epoch": 0.5890138980807412,
      "grad_norm": 0.0013944843085482717,
      "learning_rate": 3.6199257555276424e-06,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.5896757114493713,
      "grad_norm": 0.1020684763789177,
      "learning_rate": 3.6099368450272343e-06,
      "loss": 0.002,
      "step": 891
    },
    {
      "epoch": 0.5903375248180013,
      "grad_norm": 0.18061460554599762,
      "learning_rate": 3.5999539435681717e-06,
      "loss": 0.0035,
      "step": 892
    },
    {
      "epoch": 0.5909993381866314,
      "grad_norm": 0.10822074860334396,
      "learning_rate": 3.589977094305093e-06,
      "loss": 0.0018,
      "step": 893
    },
    {
      "epoch": 0.5916611515552614,
      "grad_norm": 0.004390880931168795,
      "learning_rate": 3.5800063403664664e-06,
      "loss": 0.0001,
      "step": 894
    },
    {
      "epoch": 0.5923229649238915,
      "grad_norm": 6.211117267608643,
      "learning_rate": 3.5700417248544177e-06,
      "loss": 0.23,
      "step": 895
    },
    {
      "epoch": 0.5929847782925215,
      "grad_norm": 0.010170199908316135,
      "learning_rate": 3.560083290844534e-06,
      "loss": 0.0002,
      "step": 896
    },
    {
      "epoch": 0.5936465916611515,
      "grad_norm": 0.004865639843046665,
      "learning_rate": 3.550131081385677e-06,
      "loss": 0.0001,
      "step": 897
    },
    {
      "epoch": 0.5943084050297816,
      "grad_norm": 0.004315171856433153,
      "learning_rate": 3.5401851394998087e-06,
      "loss": 0.0001,
      "step": 898
    },
    {
      "epoch": 0.5949702183984117,
      "grad_norm": 2.707899332046509,
      "learning_rate": 3.530245508181789e-06,
      "loss": 0.1044,
      "step": 899
    },
    {
      "epoch": 0.5956320317670417,
      "grad_norm": 2.3197805881500244,
      "learning_rate": 3.5203122303992055e-06,
      "loss": 0.1952,
      "step": 900
    },
    {
      "epoch": 0.5962938451356717,
      "grad_norm": 0.016778530552983284,
      "learning_rate": 3.510385349092176e-06,
      "loss": 0.0004,
      "step": 901
    },
    {
      "epoch": 0.5969556585043018,
      "grad_norm": 0.023354168981313705,
      "learning_rate": 3.5004649071731666e-06,
      "loss": 0.0004,
      "step": 902
    },
    {
      "epoch": 0.5976174718729318,
      "grad_norm": 11.12568187713623,
      "learning_rate": 3.4905509475268106e-06,
      "loss": 0.279,
      "step": 903
    },
    {
      "epoch": 0.5982792852415619,
      "grad_norm": 0.0047485604882240295,
      "learning_rate": 3.4806435130097137e-06,
      "loss": 0.0001,
      "step": 904
    },
    {
      "epoch": 0.598941098610192,
      "grad_norm": 1.631593942642212,
      "learning_rate": 3.4707426464502823e-06,
      "loss": 0.0223,
      "step": 905
    },
    {
      "epoch": 0.599602911978822,
      "grad_norm": 1.5610390901565552,
      "learning_rate": 3.4608483906485252e-06,
      "loss": 0.0179,
      "step": 906
    },
    {
      "epoch": 0.600264725347452,
      "grad_norm": 0.011014805175364017,
      "learning_rate": 3.4509607883758723e-06,
      "loss": 0.0003,
      "step": 907
    },
    {
      "epoch": 0.600926538716082,
      "grad_norm": 0.041479676961898804,
      "learning_rate": 3.4410798823749964e-06,
      "loss": 0.0008,
      "step": 908
    },
    {
      "epoch": 0.6015883520847121,
      "grad_norm": 8.445569038391113,
      "learning_rate": 3.431205715359619e-06,
      "loss": 0.6672,
      "step": 909
    },
    {
      "epoch": 0.6022501654533422,
      "grad_norm": 0.7011697888374329,
      "learning_rate": 3.4213383300143298e-06,
      "loss": 0.013,
      "step": 910
    },
    {
      "epoch": 0.6029119788219722,
      "grad_norm": 8.564976692199707,
      "learning_rate": 3.411477768994409e-06,
      "loss": 0.7181,
      "step": 911
    },
    {
      "epoch": 0.6035737921906023,
      "grad_norm": 0.005822253413498402,
      "learning_rate": 3.4016240749256266e-06,
      "loss": 0.0001,
      "step": 912
    },
    {
      "epoch": 0.6042356055592323,
      "grad_norm": 0.06255117058753967,
      "learning_rate": 3.391777290404077e-06,
      "loss": 0.0011,
      "step": 913
    },
    {
      "epoch": 0.6048974189278623,
      "grad_norm": 2.8590590953826904,
      "learning_rate": 3.3819374579959773e-06,
      "loss": 0.0563,
      "step": 914
    },
    {
      "epoch": 0.6055592322964924,
      "grad_norm": 0.2778255343437195,
      "learning_rate": 3.372104620237495e-06,
      "loss": 0.0062,
      "step": 915
    },
    {
      "epoch": 0.6062210456651225,
      "grad_norm": 0.031801462173461914,
      "learning_rate": 3.3622788196345635e-06,
      "loss": 0.0005,
      "step": 916
    },
    {
      "epoch": 0.6068828590337525,
      "grad_norm": 0.0012585753574967384,
      "learning_rate": 3.3524600986626944e-06,
      "loss": 0.0,
      "step": 917
    },
    {
      "epoch": 0.6075446724023825,
      "grad_norm": 0.013736027292907238,
      "learning_rate": 3.3426484997667912e-06,
      "loss": 0.0003,
      "step": 918
    },
    {
      "epoch": 0.6082064857710126,
      "grad_norm": 2.9626452922821045,
      "learning_rate": 3.332844065360974e-06,
      "loss": 0.1596,
      "step": 919
    },
    {
      "epoch": 0.6088682991396426,
      "grad_norm": 0.003851751098409295,
      "learning_rate": 3.3230468378283886e-06,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 0.6095301125082727,
      "grad_norm": 2.4016458988189697,
      "learning_rate": 3.3132568595210278e-06,
      "loss": 0.193,
      "step": 921
    },
    {
      "epoch": 0.6101919258769027,
      "grad_norm": 0.0027626873925328255,
      "learning_rate": 3.303474172759552e-06,
      "loss": 0.0,
      "step": 922
    },
    {
      "epoch": 0.6108537392455328,
      "grad_norm": 0.05102232098579407,
      "learning_rate": 3.2936988198330933e-06,
      "loss": 0.0008,
      "step": 923
    },
    {
      "epoch": 0.6115155526141628,
      "grad_norm": 0.017538689076900482,
      "learning_rate": 3.2839308429990846e-06,
      "loss": 0.0005,
      "step": 924
    },
    {
      "epoch": 0.6121773659827928,
      "grad_norm": 9.116748809814453,
      "learning_rate": 3.2741702844830715e-06,
      "loss": 0.8341,
      "step": 925
    },
    {
      "epoch": 0.6128391793514228,
      "grad_norm": 0.08999254554510117,
      "learning_rate": 3.264417186478535e-06,
      "loss": 0.0018,
      "step": 926
    },
    {
      "epoch": 0.613500992720053,
      "grad_norm": 4.371392250061035,
      "learning_rate": 3.2546715911466997e-06,
      "loss": 0.1911,
      "step": 927
    },
    {
      "epoch": 0.614162806088683,
      "grad_norm": 2.157078504562378,
      "learning_rate": 3.2449335406163636e-06,
      "loss": 0.0514,
      "step": 928
    },
    {
      "epoch": 0.614824619457313,
      "grad_norm": 0.00857871025800705,
      "learning_rate": 3.235203076983704e-06,
      "loss": 0.0002,
      "step": 929
    },
    {
      "epoch": 0.6154864328259431,
      "grad_norm": 0.0018743813270702958,
      "learning_rate": 3.2254802423121045e-06,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 0.6161482461945731,
      "grad_norm": 0.0009590155677869916,
      "learning_rate": 3.2157650786319695e-06,
      "loss": 0.0,
      "step": 931
    },
    {
      "epoch": 0.6168100595632032,
      "grad_norm": 0.00730256550014019,
      "learning_rate": 3.206057627940539e-06,
      "loss": 0.0001,
      "step": 932
    },
    {
      "epoch": 0.6174718729318333,
      "grad_norm": 0.013731421902775764,
      "learning_rate": 3.196357932201717e-06,
      "loss": 0.0002,
      "step": 933
    },
    {
      "epoch": 0.6181336863004633,
      "grad_norm": 10.60574722290039,
      "learning_rate": 3.18666603334588e-06,
      "loss": 0.7657,
      "step": 934
    },
    {
      "epoch": 0.6187954996690933,
      "grad_norm": 0.04013669490814209,
      "learning_rate": 3.176981973269701e-06,
      "loss": 0.0007,
      "step": 935
    },
    {
      "epoch": 0.6194573130377233,
      "grad_norm": 0.04564974829554558,
      "learning_rate": 3.1673057938359668e-06,
      "loss": 0.0007,
      "step": 936
    },
    {
      "epoch": 0.6201191264063534,
      "grad_norm": 0.8721848726272583,
      "learning_rate": 3.157637536873397e-06,
      "loss": 0.0207,
      "step": 937
    },
    {
      "epoch": 0.6207809397749835,
      "grad_norm": 0.009782494977116585,
      "learning_rate": 3.147977244176461e-06,
      "loss": 0.0002,
      "step": 938
    },
    {
      "epoch": 0.6214427531436135,
      "grad_norm": 0.006602540612220764,
      "learning_rate": 3.138324957505207e-06,
      "loss": 0.0001,
      "step": 939
    },
    {
      "epoch": 0.6221045665122436,
      "grad_norm": 0.012032791040837765,
      "learning_rate": 3.128680718585069e-06,
      "loss": 0.0002,
      "step": 940
    },
    {
      "epoch": 0.6227663798808736,
      "grad_norm": 5.677693843841553,
      "learning_rate": 3.1190445691066918e-06,
      "loss": 0.1253,
      "step": 941
    },
    {
      "epoch": 0.6234281932495036,
      "grad_norm": 0.006906887982040644,
      "learning_rate": 3.1094165507257513e-06,
      "loss": 0.0001,
      "step": 942
    },
    {
      "epoch": 0.6240900066181337,
      "grad_norm": 0.20734460651874542,
      "learning_rate": 3.099796705062773e-06,
      "loss": 0.0033,
      "step": 943
    },
    {
      "epoch": 0.6247518199867638,
      "grad_norm": 0.2677047848701477,
      "learning_rate": 3.090185073702956e-06,
      "loss": 0.005,
      "step": 944
    },
    {
      "epoch": 0.6254136333553938,
      "grad_norm": 0.09303992241621017,
      "learning_rate": 3.080581698195989e-06,
      "loss": 0.0016,
      "step": 945
    },
    {
      "epoch": 0.6260754467240238,
      "grad_norm": 0.043340083211660385,
      "learning_rate": 3.070986620055869e-06,
      "loss": 0.0009,
      "step": 946
    },
    {
      "epoch": 0.6267372600926538,
      "grad_norm": 5.383605003356934,
      "learning_rate": 3.061399880760727e-06,
      "loss": 0.3885,
      "step": 947
    },
    {
      "epoch": 0.6273990734612839,
      "grad_norm": 0.005880339536815882,
      "learning_rate": 3.0518215217526474e-06,
      "loss": 0.0001,
      "step": 948
    },
    {
      "epoch": 0.628060886829914,
      "grad_norm": 0.002582893008366227,
      "learning_rate": 3.042251584437484e-06,
      "loss": 0.0001,
      "step": 949
    },
    {
      "epoch": 0.628722700198544,
      "grad_norm": 0.904565155506134,
      "learning_rate": 3.0326901101846906e-06,
      "loss": 0.0117,
      "step": 950
    },
    {
      "epoch": 0.6293845135671741,
      "grad_norm": 0.039481308311223984,
      "learning_rate": 3.023137140327132e-06,
      "loss": 0.0005,
      "step": 951
    },
    {
      "epoch": 0.6300463269358041,
      "grad_norm": 0.06124360114336014,
      "learning_rate": 3.0135927161609097e-06,
      "loss": 0.001,
      "step": 952
    },
    {
      "epoch": 0.6307081403044341,
      "grad_norm": 0.019802799448370934,
      "learning_rate": 3.004056878945186e-06,
      "loss": 0.0004,
      "step": 953
    },
    {
      "epoch": 0.6313699536730641,
      "grad_norm": 0.37755170464515686,
      "learning_rate": 2.9945296699020027e-06,
      "loss": 0.0075,
      "step": 954
    },
    {
      "epoch": 0.6320317670416943,
      "grad_norm": 0.6604249477386475,
      "learning_rate": 2.9850111302160977e-06,
      "loss": 0.013,
      "step": 955
    },
    {
      "epoch": 0.6326935804103243,
      "grad_norm": 0.946819543838501,
      "learning_rate": 2.9755013010347433e-06,
      "loss": 0.0171,
      "step": 956
    },
    {
      "epoch": 0.6333553937789543,
      "grad_norm": 2.7960941791534424,
      "learning_rate": 2.9660002234675466e-06,
      "loss": 0.098,
      "step": 957
    },
    {
      "epoch": 0.6340172071475844,
      "grad_norm": 0.019501667469739914,
      "learning_rate": 2.9565079385862906e-06,
      "loss": 0.0003,
      "step": 958
    },
    {
      "epoch": 0.6346790205162144,
      "grad_norm": 7.055060386657715,
      "learning_rate": 2.9470244874247446e-06,
      "loss": 0.5622,
      "step": 959
    },
    {
      "epoch": 0.6353408338848445,
      "grad_norm": 0.0076131136156618595,
      "learning_rate": 2.937549910978489e-06,
      "loss": 0.0002,
      "step": 960
    },
    {
      "epoch": 0.6360026472534746,
      "grad_norm": 0.0038548640441149473,
      "learning_rate": 2.9280842502047493e-06,
      "loss": 0.0001,
      "step": 961
    },
    {
      "epoch": 0.6366644606221046,
      "grad_norm": 5.560781002044678,
      "learning_rate": 2.918627546022199e-06,
      "loss": 0.0911,
      "step": 962
    },
    {
      "epoch": 0.6373262739907346,
      "grad_norm": 11.25663948059082,
      "learning_rate": 2.9091798393107995e-06,
      "loss": 0.6612,
      "step": 963
    },
    {
      "epoch": 0.6379880873593646,
      "grad_norm": 0.06461676210165024,
      "learning_rate": 2.899741170911617e-06,
      "loss": 0.0013,
      "step": 964
    },
    {
      "epoch": 0.6386499007279947,
      "grad_norm": 0.04322569817304611,
      "learning_rate": 2.890311581626647e-06,
      "loss": 0.0006,
      "step": 965
    },
    {
      "epoch": 0.6393117140966248,
      "grad_norm": 0.028216592967510223,
      "learning_rate": 2.8808911122186295e-06,
      "loss": 0.0005,
      "step": 966
    },
    {
      "epoch": 0.6399735274652548,
      "grad_norm": 0.0017626741901040077,
      "learning_rate": 2.8714798034108957e-06,
      "loss": 0.0001,
      "step": 967
    },
    {
      "epoch": 0.6406353408338848,
      "grad_norm": 0.033477891236543655,
      "learning_rate": 2.8620776958871626e-06,
      "loss": 0.0008,
      "step": 968
    },
    {
      "epoch": 0.6412971542025149,
      "grad_norm": 0.06202325597405434,
      "learning_rate": 2.8526848302913777e-06,
      "loss": 0.0008,
      "step": 969
    },
    {
      "epoch": 0.6419589675711449,
      "grad_norm": 0.006032679229974747,
      "learning_rate": 2.84330124722754e-06,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 0.642620780939775,
      "grad_norm": 0.10284701734781265,
      "learning_rate": 2.83392698725951e-06,
      "loss": 0.0017,
      "step": 971
    },
    {
      "epoch": 0.6432825943084051,
      "grad_norm": 0.2404119372367859,
      "learning_rate": 2.824562090910862e-06,
      "loss": 0.004,
      "step": 972
    },
    {
      "epoch": 0.6439444076770351,
      "grad_norm": 7.4230055809021,
      "learning_rate": 2.8152065986646788e-06,
      "loss": 0.1428,
      "step": 973
    },
    {
      "epoch": 0.6446062210456651,
      "grad_norm": 0.18022744357585907,
      "learning_rate": 2.8058605509633974e-06,
      "loss": 0.0038,
      "step": 974
    },
    {
      "epoch": 0.6452680344142951,
      "grad_norm": 0.1635054647922516,
      "learning_rate": 2.7965239882086293e-06,
      "loss": 0.004,
      "step": 975
    },
    {
      "epoch": 0.6459298477829252,
      "grad_norm": 10.649120330810547,
      "learning_rate": 2.7871969507609747e-06,
      "loss": 0.7965,
      "step": 976
    },
    {
      "epoch": 0.6465916611515553,
      "grad_norm": 0.025342248380184174,
      "learning_rate": 2.7778794789398665e-06,
      "loss": 0.0006,
      "step": 977
    },
    {
      "epoch": 0.6472534745201853,
      "grad_norm": 9.821378707885742,
      "learning_rate": 2.7685716130233844e-06,
      "loss": 0.5877,
      "step": 978
    },
    {
      "epoch": 0.6479152878888154,
      "grad_norm": 0.012867345474660397,
      "learning_rate": 2.759273393248081e-06,
      "loss": 0.0003,
      "step": 979
    },
    {
      "epoch": 0.6485771012574454,
      "grad_norm": 0.09106610715389252,
      "learning_rate": 2.7499848598088137e-06,
      "loss": 0.001,
      "step": 980
    },
    {
      "epoch": 0.6492389146260754,
      "grad_norm": 0.007839185185730457,
      "learning_rate": 2.7407060528585617e-06,
      "loss": 0.0001,
      "step": 981
    },
    {
      "epoch": 0.6499007279947054,
      "grad_norm": 0.0019332760712131858,
      "learning_rate": 2.7314370125082624e-06,
      "loss": 0.0001,
      "step": 982
    },
    {
      "epoch": 0.6505625413633356,
      "grad_norm": 0.092667356133461,
      "learning_rate": 2.722177778826632e-06,
      "loss": 0.0014,
      "step": 983
    },
    {
      "epoch": 0.6512243547319656,
      "grad_norm": 0.01534377969801426,
      "learning_rate": 2.7129283918399963e-06,
      "loss": 0.0002,
      "step": 984
    },
    {
      "epoch": 0.6518861681005956,
      "grad_norm": 0.12090545892715454,
      "learning_rate": 2.7036888915321134e-06,
      "loss": 0.0034,
      "step": 985
    },
    {
      "epoch": 0.6525479814692257,
      "grad_norm": 0.004261474125087261,
      "learning_rate": 2.6944593178440005e-06,
      "loss": 0.0001,
      "step": 986
    },
    {
      "epoch": 0.6532097948378557,
      "grad_norm": 0.047798559069633484,
      "learning_rate": 2.685239710673766e-06,
      "loss": 0.0012,
      "step": 987
    },
    {
      "epoch": 0.6538716082064858,
      "grad_norm": 8.150275230407715,
      "learning_rate": 2.676030109876434e-06,
      "loss": 0.5879,
      "step": 988
    },
    {
      "epoch": 0.6545334215751158,
      "grad_norm": 7.006753444671631,
      "learning_rate": 2.666830555263774e-06,
      "loss": 0.297,
      "step": 989
    },
    {
      "epoch": 0.6551952349437459,
      "grad_norm": 0.03269399330019951,
      "learning_rate": 2.6576410866041276e-06,
      "loss": 0.0006,
      "step": 990
    },
    {
      "epoch": 0.6558570483123759,
      "grad_norm": 0.00492817023769021,
      "learning_rate": 2.648461743622229e-06,
      "loss": 0.0001,
      "step": 991
    },
    {
      "epoch": 0.6565188616810059,
      "grad_norm": 0.0017266548238694668,
      "learning_rate": 2.639292565999051e-06,
      "loss": 0.0001,
      "step": 992
    },
    {
      "epoch": 0.657180675049636,
      "grad_norm": 0.27272358536720276,
      "learning_rate": 2.6301335933716177e-06,
      "loss": 0.0052,
      "step": 993
    },
    {
      "epoch": 0.6578424884182661,
      "grad_norm": 0.0168174859136343,
      "learning_rate": 2.620984865332834e-06,
      "loss": 0.0002,
      "step": 994
    },
    {
      "epoch": 0.6585043017868961,
      "grad_norm": 1.2795045375823975,
      "learning_rate": 2.611846421431331e-06,
      "loss": 0.0225,
      "step": 995
    },
    {
      "epoch": 0.6591661151555261,
      "grad_norm": 1.2371824979782104,
      "learning_rate": 2.6027183011712708e-06,
      "loss": 0.0309,
      "step": 996
    },
    {
      "epoch": 0.6598279285241562,
      "grad_norm": 0.014617246575653553,
      "learning_rate": 2.593600544012196e-06,
      "loss": 0.0003,
      "step": 997
    },
    {
      "epoch": 0.6604897418927862,
      "grad_norm": 0.07454943656921387,
      "learning_rate": 2.5844931893688474e-06,
      "loss": 0.001,
      "step": 998
    },
    {
      "epoch": 0.6611515552614163,
      "grad_norm": 7.544186115264893,
      "learning_rate": 2.575396276610994e-06,
      "loss": 0.1346,
      "step": 999
    },
    {
      "epoch": 0.6618133686300464,
      "grad_norm": 0.002450639149174094,
      "learning_rate": 2.5663098450632762e-06,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 0.6624751819986764,
      "grad_norm": 0.038316838443279266,
      "learning_rate": 2.557233934005015e-06,
      "loss": 0.0007,
      "step": 1001
    },
    {
      "epoch": 0.6631369953673064,
      "grad_norm": 13.57371997833252,
      "learning_rate": 2.548168582670058e-06,
      "loss": 0.6612,
      "step": 1002
    },
    {
      "epoch": 0.6637988087359364,
      "grad_norm": 0.010661558248102665,
      "learning_rate": 2.5391138302466064e-06,
      "loss": 0.0002,
      "step": 1003
    },
    {
      "epoch": 0.6644606221045665,
      "grad_norm": 6.960390090942383,
      "learning_rate": 2.5300697158770366e-06,
      "loss": 0.296,
      "step": 1004
    },
    {
      "epoch": 0.6651224354731966,
      "grad_norm": 1.40421462059021,
      "learning_rate": 2.5210362786577454e-06,
      "loss": 0.0312,
      "step": 1005
    },
    {
      "epoch": 0.6657842488418266,
      "grad_norm": 2.7715156078338623,
      "learning_rate": 2.5120135576389714e-06,
      "loss": 0.0335,
      "step": 1006
    },
    {
      "epoch": 0.6664460622104567,
      "grad_norm": 0.010341096669435501,
      "learning_rate": 2.503001591824628e-06,
      "loss": 0.0002,
      "step": 1007
    },
    {
      "epoch": 0.6671078755790867,
      "grad_norm": 0.007912899367511272,
      "learning_rate": 2.4940004201721387e-06,
      "loss": 0.0001,
      "step": 1008
    },
    {
      "epoch": 0.6677696889477167,
      "grad_norm": 1.1599674224853516,
      "learning_rate": 2.4850100815922577e-06,
      "loss": 0.0155,
      "step": 1009
    },
    {
      "epoch": 0.6684315023163467,
      "grad_norm": 0.01025515515357256,
      "learning_rate": 2.476030614948917e-06,
      "loss": 0.0002,
      "step": 1010
    },
    {
      "epoch": 0.6690933156849769,
      "grad_norm": 0.003972229547798634,
      "learning_rate": 2.467062059059048e-06,
      "loss": 0.0001,
      "step": 1011
    },
    {
      "epoch": 0.6697551290536069,
      "grad_norm": 0.00455864192917943,
      "learning_rate": 2.4581044526924175e-06,
      "loss": 0.0001,
      "step": 1012
    },
    {
      "epoch": 0.6704169424222369,
      "grad_norm": 0.0020815145689994097,
      "learning_rate": 2.4491578345714587e-06,
      "loss": 0.0001,
      "step": 1013
    },
    {
      "epoch": 0.671078755790867,
      "grad_norm": 0.16808362305164337,
      "learning_rate": 2.440222243371101e-06,
      "loss": 0.0033,
      "step": 1014
    },
    {
      "epoch": 0.671740569159497,
      "grad_norm": 0.0027326252311468124,
      "learning_rate": 2.4312977177186096e-06,
      "loss": 0.0001,
      "step": 1015
    },
    {
      "epoch": 0.6724023825281271,
      "grad_norm": 6.281482696533203,
      "learning_rate": 2.4223842961934154e-06,
      "loss": 0.4435,
      "step": 1016
    },
    {
      "epoch": 0.6730641958967571,
      "grad_norm": 0.08257195353507996,
      "learning_rate": 2.4134820173269456e-06,
      "loss": 0.0012,
      "step": 1017
    },
    {
      "epoch": 0.6737260092653872,
      "grad_norm": 0.022418543696403503,
      "learning_rate": 2.4045909196024624e-06,
      "loss": 0.0004,
      "step": 1018
    },
    {
      "epoch": 0.6743878226340172,
      "grad_norm": 0.29147055745124817,
      "learning_rate": 2.395711041454887e-06,
      "loss": 0.005,
      "step": 1019
    },
    {
      "epoch": 0.6750496360026472,
      "grad_norm": 0.013863119296729565,
      "learning_rate": 2.3868424212706476e-06,
      "loss": 0.0004,
      "step": 1020
    },
    {
      "epoch": 0.6757114493712773,
      "grad_norm": 8.67892074584961,
      "learning_rate": 2.3779850973875036e-06,
      "loss": 0.2549,
      "step": 1021
    },
    {
      "epoch": 0.6763732627399074,
      "grad_norm": 0.08353541791439056,
      "learning_rate": 2.369139108094375e-06,
      "loss": 0.0017,
      "step": 1022
    },
    {
      "epoch": 0.6770350761085374,
      "grad_norm": 2.482353925704956,
      "learning_rate": 2.3603044916311962e-06,
      "loss": 0.0407,
      "step": 1023
    },
    {
      "epoch": 0.6776968894771674,
      "grad_norm": 0.0489581897854805,
      "learning_rate": 2.3514812861887324e-06,
      "loss": 0.0007,
      "step": 1024
    },
    {
      "epoch": 0.6783587028457975,
      "grad_norm": 6.406458854675293,
      "learning_rate": 2.3426695299084174e-06,
      "loss": 0.2368,
      "step": 1025
    },
    {
      "epoch": 0.6790205162144275,
      "grad_norm": 0.276782751083374,
      "learning_rate": 2.3338692608821985e-06,
      "loss": 0.0046,
      "step": 1026
    },
    {
      "epoch": 0.6796823295830576,
      "grad_norm": 0.02192450501024723,
      "learning_rate": 2.325080517152356e-06,
      "loss": 0.0003,
      "step": 1027
    },
    {
      "epoch": 0.6803441429516877,
      "grad_norm": 0.05636701360344887,
      "learning_rate": 2.3163033367113603e-06,
      "loss": 0.0009,
      "step": 1028
    },
    {
      "epoch": 0.6810059563203177,
      "grad_norm": 0.004347159061580896,
      "learning_rate": 2.3075377575016883e-06,
      "loss": 0.0001,
      "step": 1029
    },
    {
      "epoch": 0.6816677696889477,
      "grad_norm": 10.082204818725586,
      "learning_rate": 2.298783817415664e-06,
      "loss": 0.7822,
      "step": 1030
    },
    {
      "epoch": 0.6823295830575777,
      "grad_norm": 0.0063577862456440926,
      "learning_rate": 2.2900415542953035e-06,
      "loss": 0.0001,
      "step": 1031
    },
    {
      "epoch": 0.6829913964262078,
      "grad_norm": 0.0005967675824649632,
      "learning_rate": 2.281311005932139e-06,
      "loss": 0.0,
      "step": 1032
    },
    {
      "epoch": 0.6836532097948379,
      "grad_norm": 0.0033522124867886305,
      "learning_rate": 2.2725922100670642e-06,
      "loss": 0.0001,
      "step": 1033
    },
    {
      "epoch": 0.6843150231634679,
      "grad_norm": 0.29553911089897156,
      "learning_rate": 2.2638852043901744e-06,
      "loss": 0.0057,
      "step": 1034
    },
    {
      "epoch": 0.684976836532098,
      "grad_norm": 0.022426605224609375,
      "learning_rate": 2.2551900265405854e-06,
      "loss": 0.0003,
      "step": 1035
    },
    {
      "epoch": 0.685638649900728,
      "grad_norm": 0.01026198547333479,
      "learning_rate": 2.246506714106294e-06,
      "loss": 0.0002,
      "step": 1036
    },
    {
      "epoch": 0.686300463269358,
      "grad_norm": 0.021102584898471832,
      "learning_rate": 2.2378353046239966e-06,
      "loss": 0.0002,
      "step": 1037
    },
    {
      "epoch": 0.686962276637988,
      "grad_norm": 0.009021659381687641,
      "learning_rate": 2.22917583557894e-06,
      "loss": 0.0002,
      "step": 1038
    },
    {
      "epoch": 0.6876240900066182,
      "grad_norm": 0.0501142218708992,
      "learning_rate": 2.2205283444047522e-06,
      "loss": 0.0011,
      "step": 1039
    },
    {
      "epoch": 0.6882859033752482,
      "grad_norm": 0.011561108753085136,
      "learning_rate": 2.211892868483283e-06,
      "loss": 0.0002,
      "step": 1040
    },
    {
      "epoch": 0.6889477167438782,
      "grad_norm": 7.54709529876709,
      "learning_rate": 2.2032694451444426e-06,
      "loss": 0.3341,
      "step": 1041
    },
    {
      "epoch": 0.6896095301125083,
      "grad_norm": 0.043849337846040726,
      "learning_rate": 2.1946581116660403e-06,
      "loss": 0.0007,
      "step": 1042
    },
    {
      "epoch": 0.6902713434811383,
      "grad_norm": 0.011827307753264904,
      "learning_rate": 2.186058905273618e-06,
      "loss": 0.0002,
      "step": 1043
    },
    {
      "epoch": 0.6909331568497684,
      "grad_norm": 0.015221892856061459,
      "learning_rate": 2.1774718631402987e-06,
      "loss": 0.0003,
      "step": 1044
    },
    {
      "epoch": 0.6915949702183984,
      "grad_norm": 0.0026493347249925137,
      "learning_rate": 2.1688970223866202e-06,
      "loss": 0.0001,
      "step": 1045
    },
    {
      "epoch": 0.6922567835870285,
      "grad_norm": 0.017140954732894897,
      "learning_rate": 2.1603344200803743e-06,
      "loss": 0.0003,
      "step": 1046
    },
    {
      "epoch": 0.6929185969556585,
      "grad_norm": 3.1123716831207275,
      "learning_rate": 2.151784093236452e-06,
      "loss": 0.0785,
      "step": 1047
    },
    {
      "epoch": 0.6935804103242885,
      "grad_norm": 0.008034049533307552,
      "learning_rate": 2.1432460788166704e-06,
      "loss": 0.0001,
      "step": 1048
    },
    {
      "epoch": 0.6942422236929185,
      "grad_norm": 0.018204091116786003,
      "learning_rate": 2.134720413729631e-06,
      "loss": 0.0003,
      "step": 1049
    },
    {
      "epoch": 0.6949040370615487,
      "grad_norm": 0.007677720859646797,
      "learning_rate": 2.1262071348305424e-06,
      "loss": 0.0002,
      "step": 1050
    },
    {
      "epoch": 0.6955658504301787,
      "grad_norm": 0.004903412889689207,
      "learning_rate": 2.1177062789210795e-06,
      "loss": 0.0001,
      "step": 1051
    },
    {
      "epoch": 0.6962276637988087,
      "grad_norm": 0.0760616734623909,
      "learning_rate": 2.109217882749208e-06,
      "loss": 0.0014,
      "step": 1052
    },
    {
      "epoch": 0.6968894771674388,
      "grad_norm": 3.3029897212982178,
      "learning_rate": 2.100741983009031e-06,
      "loss": 0.0454,
      "step": 1053
    },
    {
      "epoch": 0.6975512905360688,
      "grad_norm": 0.14020812511444092,
      "learning_rate": 2.092278616340634e-06,
      "loss": 0.0024,
      "step": 1054
    },
    {
      "epoch": 0.6982131039046989,
      "grad_norm": 0.05223222076892853,
      "learning_rate": 2.0838278193299236e-06,
      "loss": 0.0007,
      "step": 1055
    },
    {
      "epoch": 0.698874917273329,
      "grad_norm": 0.290637344121933,
      "learning_rate": 2.0753896285084698e-06,
      "loss": 0.0045,
      "step": 1056
    },
    {
      "epoch": 0.699536730641959,
      "grad_norm": 0.05019794777035713,
      "learning_rate": 2.0669640803533474e-06,
      "loss": 0.0008,
      "step": 1057
    },
    {
      "epoch": 0.700198544010589,
      "grad_norm": 0.006901565473526716,
      "learning_rate": 2.058551211286977e-06,
      "loss": 0.0001,
      "step": 1058
    },
    {
      "epoch": 0.700860357379219,
      "grad_norm": 5.548801422119141,
      "learning_rate": 2.050151057676972e-06,
      "loss": 0.2603,
      "step": 1059
    },
    {
      "epoch": 0.7015221707478491,
      "grad_norm": 0.011410455219447613,
      "learning_rate": 2.04176365583598e-06,
      "loss": 0.0002,
      "step": 1060
    },
    {
      "epoch": 0.7021839841164792,
      "grad_norm": 0.6685484051704407,
      "learning_rate": 2.0333890420215165e-06,
      "loss": 0.0136,
      "step": 1061
    },
    {
      "epoch": 0.7028457974851092,
      "grad_norm": 0.23427551984786987,
      "learning_rate": 2.025027252435829e-06,
      "loss": 0.0055,
      "step": 1062
    },
    {
      "epoch": 0.7035076108537393,
      "grad_norm": 0.004614101257175207,
      "learning_rate": 2.016678323225715e-06,
      "loss": 0.0001,
      "step": 1063
    },
    {
      "epoch": 0.7041694242223693,
      "grad_norm": 0.010801846161484718,
      "learning_rate": 2.008342290482388e-06,
      "loss": 0.0002,
      "step": 1064
    },
    {
      "epoch": 0.7048312375909993,
      "grad_norm": 0.043791428208351135,
      "learning_rate": 2.0000191902413073e-06,
      "loss": 0.0007,
      "step": 1065
    },
    {
      "epoch": 0.7054930509596293,
      "grad_norm": 0.14103753864765167,
      "learning_rate": 1.991709058482026e-06,
      "loss": 0.0026,
      "step": 1066
    },
    {
      "epoch": 0.7061548643282595,
      "grad_norm": 0.001006887760013342,
      "learning_rate": 1.9834119311280393e-06,
      "loss": 0.0001,
      "step": 1067
    },
    {
      "epoch": 0.7068166776968895,
      "grad_norm": 0.16209371387958527,
      "learning_rate": 1.9751278440466247e-06,
      "loss": 0.0023,
      "step": 1068
    },
    {
      "epoch": 0.7074784910655195,
      "grad_norm": 0.007180118467658758,
      "learning_rate": 1.9668568330486893e-06,
      "loss": 0.0001,
      "step": 1069
    },
    {
      "epoch": 0.7081403044341495,
      "grad_norm": 0.007779969833791256,
      "learning_rate": 1.9585989338886147e-06,
      "loss": 0.0001,
      "step": 1070
    },
    {
      "epoch": 0.7088021178027796,
      "grad_norm": 10.15489673614502,
      "learning_rate": 1.950354182264098e-06,
      "loss": 0.7125,
      "step": 1071
    },
    {
      "epoch": 0.7094639311714097,
      "grad_norm": 0.010890055447816849,
      "learning_rate": 1.942122613816006e-06,
      "loss": 0.0002,
      "step": 1072
    },
    {
      "epoch": 0.7101257445400397,
      "grad_norm": 3.1577723026275635,
      "learning_rate": 1.9339042641282146e-06,
      "loss": 0.0646,
      "step": 1073
    },
    {
      "epoch": 0.7107875579086698,
      "grad_norm": 0.0089712580665946,
      "learning_rate": 1.9256991687274577e-06,
      "loss": 0.0001,
      "step": 1074
    },
    {
      "epoch": 0.7114493712772998,
      "grad_norm": 0.013012648560106754,
      "learning_rate": 1.9175073630831735e-06,
      "loss": 0.0002,
      "step": 1075
    },
    {
      "epoch": 0.7121111846459298,
      "grad_norm": 0.01100072544068098,
      "learning_rate": 1.9093288826073464e-06,
      "loss": 0.0002,
      "step": 1076
    },
    {
      "epoch": 0.7127729980145598,
      "grad_norm": 4.717611789703369,
      "learning_rate": 1.9011637626543617e-06,
      "loss": 0.1495,
      "step": 1077
    },
    {
      "epoch": 0.71343481138319,
      "grad_norm": 0.00983597431331873,
      "learning_rate": 1.8930120385208494e-06,
      "loss": 0.0002,
      "step": 1078
    },
    {
      "epoch": 0.71409662475182,
      "grad_norm": 0.10512309521436691,
      "learning_rate": 1.8848737454455301e-06,
      "loss": 0.0018,
      "step": 1079
    },
    {
      "epoch": 0.71475843812045,
      "grad_norm": 4.248065948486328,
      "learning_rate": 1.8767489186090654e-06,
      "loss": 0.1609,
      "step": 1080
    },
    {
      "epoch": 0.7154202514890801,
      "grad_norm": 0.03692542761564255,
      "learning_rate": 1.8686375931338995e-06,
      "loss": 0.0009,
      "step": 1081
    },
    {
      "epoch": 0.7160820648577101,
      "grad_norm": 7.471920013427734,
      "learning_rate": 1.8605398040841171e-06,
      "loss": 0.3804,
      "step": 1082
    },
    {
      "epoch": 0.7167438782263402,
      "grad_norm": 0.008847725577652454,
      "learning_rate": 1.8524555864652865e-06,
      "loss": 0.0002,
      "step": 1083
    },
    {
      "epoch": 0.7174056915949703,
      "grad_norm": 0.03536992147564888,
      "learning_rate": 1.8443849752243071e-06,
      "loss": 0.0006,
      "step": 1084
    },
    {
      "epoch": 0.7180675049636003,
      "grad_norm": 0.019656386226415634,
      "learning_rate": 1.8363280052492616e-06,
      "loss": 0.0002,
      "step": 1085
    },
    {
      "epoch": 0.7187293183322303,
      "grad_norm": 0.00420952495187521,
      "learning_rate": 1.8282847113692592e-06,
      "loss": 0.0001,
      "step": 1086
    },
    {
      "epoch": 0.7193911317008603,
      "grad_norm": 1.352213978767395,
      "learning_rate": 1.820255128354294e-06,
      "loss": 0.0236,
      "step": 1087
    },
    {
      "epoch": 0.7200529450694904,
      "grad_norm": 0.24336464703083038,
      "learning_rate": 1.8122392909150903e-06,
      "loss": 0.0047,
      "step": 1088
    },
    {
      "epoch": 0.7207147584381205,
      "grad_norm": 0.003369787009432912,
      "learning_rate": 1.8042372337029457e-06,
      "loss": 0.0001,
      "step": 1089
    },
    {
      "epoch": 0.7213765718067505,
      "grad_norm": 0.02080732397735119,
      "learning_rate": 1.7962489913095988e-06,
      "loss": 0.0002,
      "step": 1090
    },
    {
      "epoch": 0.7220383851753805,
      "grad_norm": 0.011914098635315895,
      "learning_rate": 1.7882745982670575e-06,
      "loss": 0.0003,
      "step": 1091
    },
    {
      "epoch": 0.7227001985440106,
      "grad_norm": 6.440502643585205,
      "learning_rate": 1.7803140890474674e-06,
      "loss": 0.2237,
      "step": 1092
    },
    {
      "epoch": 0.7233620119126406,
      "grad_norm": 0.019447585567831993,
      "learning_rate": 1.7723674980629574e-06,
      "loss": 0.0004,
      "step": 1093
    },
    {
      "epoch": 0.7240238252812706,
      "grad_norm": 10.382583618164062,
      "learning_rate": 1.7644348596654836e-06,
      "loss": 0.9875,
      "step": 1094
    },
    {
      "epoch": 0.7246856386499008,
      "grad_norm": 0.004129203502088785,
      "learning_rate": 1.756516208146693e-06,
      "loss": 0.0001,
      "step": 1095
    },
    {
      "epoch": 0.7253474520185308,
      "grad_norm": 0.7663268446922302,
      "learning_rate": 1.7486115777377666e-06,
      "loss": 0.0106,
      "step": 1096
    },
    {
      "epoch": 0.7260092653871608,
      "grad_norm": 0.025080576539039612,
      "learning_rate": 1.7407210026092753e-06,
      "loss": 0.0005,
      "step": 1097
    },
    {
      "epoch": 0.7266710787557908,
      "grad_norm": 0.025514867156744003,
      "learning_rate": 1.7328445168710322e-06,
      "loss": 0.0003,
      "step": 1098
    },
    {
      "epoch": 0.7273328921244209,
      "grad_norm": 0.010480261407792568,
      "learning_rate": 1.7249821545719387e-06,
      "loss": 0.0001,
      "step": 1099
    },
    {
      "epoch": 0.727994705493051,
      "grad_norm": 0.08350495249032974,
      "learning_rate": 1.717133949699849e-06,
      "loss": 0.0011,
      "step": 1100
    },
    {
      "epoch": 0.728656518861681,
      "grad_norm": 13.186980247497559,
      "learning_rate": 1.7092999361814127e-06,
      "loss": 1.1209,
      "step": 1101
    },
    {
      "epoch": 0.7293183322303111,
      "grad_norm": 11.871930122375488,
      "learning_rate": 1.7014801478819347e-06,
      "loss": 0.2301,
      "step": 1102
    },
    {
      "epoch": 0.7299801455989411,
      "grad_norm": 0.004955507814884186,
      "learning_rate": 1.6936746186052273e-06,
      "loss": 0.0001,
      "step": 1103
    },
    {
      "epoch": 0.7306419589675711,
      "grad_norm": 2.340907096862793,
      "learning_rate": 1.6858833820934566e-06,
      "loss": 0.0561,
      "step": 1104
    },
    {
      "epoch": 0.7313037723362011,
      "grad_norm": 0.003938297275453806,
      "learning_rate": 1.6781064720270107e-06,
      "loss": 0.0001,
      "step": 1105
    },
    {
      "epoch": 0.7319655857048313,
      "grad_norm": 0.02641037479043007,
      "learning_rate": 1.6703439220243422e-06,
      "loss": 0.0004,
      "step": 1106
    },
    {
      "epoch": 0.7326273990734613,
      "grad_norm": 0.005285212304443121,
      "learning_rate": 1.6625957656418296e-06,
      "loss": 0.0001,
      "step": 1107
    },
    {
      "epoch": 0.7332892124420913,
      "grad_norm": 0.06964019685983658,
      "learning_rate": 1.6548620363736296e-06,
      "loss": 0.0014,
      "step": 1108
    },
    {
      "epoch": 0.7339510258107214,
      "grad_norm": 0.01727357693016529,
      "learning_rate": 1.647142767651529e-06,
      "loss": 0.0003,
      "step": 1109
    },
    {
      "epoch": 0.7346128391793514,
      "grad_norm": 0.11267571151256561,
      "learning_rate": 1.6394379928448085e-06,
      "loss": 0.0016,
      "step": 1110
    },
    {
      "epoch": 0.7352746525479815,
      "grad_norm": 0.002577061066403985,
      "learning_rate": 1.6317477452600917e-06,
      "loss": 0.0001,
      "step": 1111
    },
    {
      "epoch": 0.7359364659166115,
      "grad_norm": 0.9515700340270996,
      "learning_rate": 1.6240720581412022e-06,
      "loss": 0.0116,
      "step": 1112
    },
    {
      "epoch": 0.7365982792852416,
      "grad_norm": 0.0029304991476237774,
      "learning_rate": 1.6164109646690252e-06,
      "loss": 0.0001,
      "step": 1113
    },
    {
      "epoch": 0.7372600926538716,
      "grad_norm": 0.1506270170211792,
      "learning_rate": 1.6087644979613515e-06,
      "loss": 0.0025,
      "step": 1114
    },
    {
      "epoch": 0.7379219060225016,
      "grad_norm": 0.0008745089289732277,
      "learning_rate": 1.6011326910727492e-06,
      "loss": 0.0,
      "step": 1115
    },
    {
      "epoch": 0.7385837193911317,
      "grad_norm": 0.009105048142373562,
      "learning_rate": 1.593515576994415e-06,
      "loss": 0.0002,
      "step": 1116
    },
    {
      "epoch": 0.7392455327597618,
      "grad_norm": 0.01013643853366375,
      "learning_rate": 1.5859131886540214e-06,
      "loss": 0.0002,
      "step": 1117
    },
    {
      "epoch": 0.7399073461283918,
      "grad_norm": 0.15418829023838043,
      "learning_rate": 1.5783255589155983e-06,
      "loss": 0.0029,
      "step": 1118
    },
    {
      "epoch": 0.7405691594970218,
      "grad_norm": 0.002031712792813778,
      "learning_rate": 1.5707527205793621e-06,
      "loss": 0.0001,
      "step": 1119
    },
    {
      "epoch": 0.7412309728656519,
      "grad_norm": 0.0079070208594203,
      "learning_rate": 1.5631947063815972e-06,
      "loss": 0.0002,
      "step": 1120
    },
    {
      "epoch": 0.7418927862342819,
      "grad_norm": 0.004005082417279482,
      "learning_rate": 1.5556515489945029e-06,
      "loss": 0.0001,
      "step": 1121
    },
    {
      "epoch": 0.7425545996029119,
      "grad_norm": 0.0008697159355506301,
      "learning_rate": 1.548123281026051e-06,
      "loss": 0.0001,
      "step": 1122
    },
    {
      "epoch": 0.7432164129715421,
      "grad_norm": 0.0496857650578022,
      "learning_rate": 1.5406099350198545e-06,
      "loss": 0.0008,
      "step": 1123
    },
    {
      "epoch": 0.7438782263401721,
      "grad_norm": 0.5395315885543823,
      "learning_rate": 1.533111543455017e-06,
      "loss": 0.0065,
      "step": 1124
    },
    {
      "epoch": 0.7445400397088021,
      "grad_norm": 0.004007047042250633,
      "learning_rate": 1.5256281387459976e-06,
      "loss": 0.0001,
      "step": 1125
    },
    {
      "epoch": 0.7452018530774321,
      "grad_norm": 0.00959976576268673,
      "learning_rate": 1.5181597532424714e-06,
      "loss": 0.0003,
      "step": 1126
    },
    {
      "epoch": 0.7458636664460622,
      "grad_norm": 0.0063423458486795425,
      "learning_rate": 1.510706419229181e-06,
      "loss": 0.0001,
      "step": 1127
    },
    {
      "epoch": 0.7465254798146923,
      "grad_norm": 0.006494727451354265,
      "learning_rate": 1.5032681689258104e-06,
      "loss": 0.0001,
      "step": 1128
    },
    {
      "epoch": 0.7471872931833223,
      "grad_norm": 10.456424713134766,
      "learning_rate": 1.4958450344868369e-06,
      "loss": 1.0921,
      "step": 1129
    },
    {
      "epoch": 0.7478491065519524,
      "grad_norm": 0.020566221326589584,
      "learning_rate": 1.4884370480013933e-06,
      "loss": 0.0005,
      "step": 1130
    },
    {
      "epoch": 0.7485109199205824,
      "grad_norm": 0.007133281324058771,
      "learning_rate": 1.481044241493132e-06,
      "loss": 0.0001,
      "step": 1131
    },
    {
      "epoch": 0.7491727332892124,
      "grad_norm": 0.03673508018255234,
      "learning_rate": 1.4736666469200795e-06,
      "loss": 0.0008,
      "step": 1132
    },
    {
      "epoch": 0.7498345466578424,
      "grad_norm": 0.026870092377066612,
      "learning_rate": 1.4663042961745082e-06,
      "loss": 0.0005,
      "step": 1133
    },
    {
      "epoch": 0.7504963600264726,
      "grad_norm": 0.0028774261008948088,
      "learning_rate": 1.4589572210827935e-06,
      "loss": 0.0001,
      "step": 1134
    },
    {
      "epoch": 0.7511581733951026,
      "grad_norm": 0.02516506239771843,
      "learning_rate": 1.4516254534052738e-06,
      "loss": 0.0004,
      "step": 1135
    },
    {
      "epoch": 0.7518199867637326,
      "grad_norm": 0.9794548749923706,
      "learning_rate": 1.4443090248361191e-06,
      "loss": 0.0186,
      "step": 1136
    },
    {
      "epoch": 0.7524818001323627,
      "grad_norm": 0.0435870923101902,
      "learning_rate": 1.4370079670031856e-06,
      "loss": 0.0007,
      "step": 1137
    },
    {
      "epoch": 0.7531436135009927,
      "grad_norm": 0.0021601261105388403,
      "learning_rate": 1.4297223114678887e-06,
      "loss": 0.0001,
      "step": 1138
    },
    {
      "epoch": 0.7538054268696228,
      "grad_norm": 0.009127220138907433,
      "learning_rate": 1.4224520897250599e-06,
      "loss": 0.0002,
      "step": 1139
    },
    {
      "epoch": 0.7544672402382528,
      "grad_norm": 1.3363009691238403,
      "learning_rate": 1.4151973332028135e-06,
      "loss": 0.0201,
      "step": 1140
    },
    {
      "epoch": 0.7551290536068829,
      "grad_norm": 0.06644554436206818,
      "learning_rate": 1.4079580732624103e-06,
      "loss": 0.0013,
      "step": 1141
    },
    {
      "epoch": 0.7557908669755129,
      "grad_norm": 0.06748830527067184,
      "learning_rate": 1.4007343411981188e-06,
      "loss": 0.0012,
      "step": 1142
    },
    {
      "epoch": 0.7564526803441429,
      "grad_norm": 0.3338082730770111,
      "learning_rate": 1.3935261682370849e-06,
      "loss": 0.0054,
      "step": 1143
    },
    {
      "epoch": 0.757114493712773,
      "grad_norm": 8.097585678100586,
      "learning_rate": 1.3863335855391968e-06,
      "loss": 0.5488,
      "step": 1144
    },
    {
      "epoch": 0.7577763070814031,
      "grad_norm": 4.539534568786621,
      "learning_rate": 1.3791566241969411e-06,
      "loss": 0.3894,
      "step": 1145
    },
    {
      "epoch": 0.7584381204500331,
      "grad_norm": 0.007175018545240164,
      "learning_rate": 1.3719953152352871e-06,
      "loss": 0.0001,
      "step": 1146
    },
    {
      "epoch": 0.7590999338186631,
      "grad_norm": 0.02598450891673565,
      "learning_rate": 1.3648496896115294e-06,
      "loss": 0.0004,
      "step": 1147
    },
    {
      "epoch": 0.7597617471872932,
      "grad_norm": 0.18461576104164124,
      "learning_rate": 1.3577197782151725e-06,
      "loss": 0.0045,
      "step": 1148
    },
    {
      "epoch": 0.7604235605559232,
      "grad_norm": 1.9068474769592285,
      "learning_rate": 1.35060561186779e-06,
      "loss": 0.0302,
      "step": 1149
    },
    {
      "epoch": 0.7610853739245532,
      "grad_norm": 0.0011192928068339825,
      "learning_rate": 1.343507221322889e-06,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.7617471872931834,
      "grad_norm": 0.08923523873090744,
      "learning_rate": 1.3364246372657824e-06,
      "loss": 0.0015,
      "step": 1151
    },
    {
      "epoch": 0.7624090006618134,
      "grad_norm": 0.036413632333278656,
      "learning_rate": 1.3293578903134546e-06,
      "loss": 0.0006,
      "step": 1152
    },
    {
      "epoch": 0.7630708140304434,
      "grad_norm": 11.10554027557373,
      "learning_rate": 1.3223070110144264e-06,
      "loss": 0.4178,
      "step": 1153
    },
    {
      "epoch": 0.7637326273990734,
      "grad_norm": 0.0007455392624251544,
      "learning_rate": 1.3152720298486277e-06,
      "loss": 0.0,
      "step": 1154
    },
    {
      "epoch": 0.7643944407677035,
      "grad_norm": 0.011709473095834255,
      "learning_rate": 1.308252977227259e-06,
      "loss": 0.0002,
      "step": 1155
    },
    {
      "epoch": 0.7650562541363336,
      "grad_norm": 0.04917864874005318,
      "learning_rate": 1.3012498834926663e-06,
      "loss": 0.0008,
      "step": 1156
    },
    {
      "epoch": 0.7657180675049636,
      "grad_norm": 0.12810681760311127,
      "learning_rate": 1.2942627789182122e-06,
      "loss": 0.0031,
      "step": 1157
    },
    {
      "epoch": 0.7663798808735937,
      "grad_norm": 0.02742988057434559,
      "learning_rate": 1.287291693708131e-06,
      "loss": 0.0005,
      "step": 1158
    },
    {
      "epoch": 0.7670416942422237,
      "grad_norm": 0.0037516711745411158,
      "learning_rate": 1.280336657997417e-06,
      "loss": 0.0001,
      "step": 1159
    },
    {
      "epoch": 0.7677035076108537,
      "grad_norm": 0.7537198662757874,
      "learning_rate": 1.2733977018516757e-06,
      "loss": 0.0097,
      "step": 1160
    },
    {
      "epoch": 0.7683653209794837,
      "grad_norm": 0.10129232704639435,
      "learning_rate": 1.2664748552670115e-06,
      "loss": 0.0024,
      "step": 1161
    },
    {
      "epoch": 0.7690271343481139,
      "grad_norm": 10.147521018981934,
      "learning_rate": 1.259568148169884e-06,
      "loss": 0.8942,
      "step": 1162
    },
    {
      "epoch": 0.7696889477167439,
      "grad_norm": 0.007195962592959404,
      "learning_rate": 1.2526776104169869e-06,
      "loss": 0.0001,
      "step": 1163
    },
    {
      "epoch": 0.7703507610853739,
      "grad_norm": 0.015021092258393764,
      "learning_rate": 1.2458032717951163e-06,
      "loss": 0.0004,
      "step": 1164
    },
    {
      "epoch": 0.771012574454004,
      "grad_norm": 0.0045143794268369675,
      "learning_rate": 1.238945162021038e-06,
      "loss": 0.0001,
      "step": 1165
    },
    {
      "epoch": 0.771674387822634,
      "grad_norm": 0.20183709263801575,
      "learning_rate": 1.2321033107413666e-06,
      "loss": 0.0039,
      "step": 1166
    },
    {
      "epoch": 0.7723362011912641,
      "grad_norm": 0.4562968611717224,
      "learning_rate": 1.2252777475324335e-06,
      "loss": 0.0084,
      "step": 1167
    },
    {
      "epoch": 0.7729980145598941,
      "grad_norm": 12.658150672912598,
      "learning_rate": 1.2184685019001574e-06,
      "loss": 1.1274,
      "step": 1168
    },
    {
      "epoch": 0.7736598279285242,
      "grad_norm": 0.04103823006153107,
      "learning_rate": 1.2116756032799193e-06,
      "loss": 0.0008,
      "step": 1169
    },
    {
      "epoch": 0.7743216412971542,
      "grad_norm": 9.467284202575684,
      "learning_rate": 1.2048990810364364e-06,
      "loss": 0.9986,
      "step": 1170
    },
    {
      "epoch": 0.7749834546657842,
      "grad_norm": 0.003518468700349331,
      "learning_rate": 1.1981389644636276e-06,
      "loss": 0.0001,
      "step": 1171
    },
    {
      "epoch": 0.7756452680344142,
      "grad_norm": 0.005521431099623442,
      "learning_rate": 1.1913952827844994e-06,
      "loss": 0.0001,
      "step": 1172
    },
    {
      "epoch": 0.7763070814030444,
      "grad_norm": 0.007954240776598454,
      "learning_rate": 1.1846680651510052e-06,
      "loss": 0.0001,
      "step": 1173
    },
    {
      "epoch": 0.7769688947716744,
      "grad_norm": 0.006175374146550894,
      "learning_rate": 1.1779573406439344e-06,
      "loss": 0.0001,
      "step": 1174
    },
    {
      "epoch": 0.7776307081403044,
      "grad_norm": 0.06498746573925018,
      "learning_rate": 1.1712631382727762e-06,
      "loss": 0.0012,
      "step": 1175
    },
    {
      "epoch": 0.7782925215089345,
      "grad_norm": 0.025189442560076714,
      "learning_rate": 1.164585486975593e-06,
      "loss": 0.0005,
      "step": 1176
    },
    {
      "epoch": 0.7789543348775645,
      "grad_norm": 7.547616958618164,
      "learning_rate": 1.1579244156189057e-06,
      "loss": 0.5227,
      "step": 1177
    },
    {
      "epoch": 0.7796161482461945,
      "grad_norm": 0.0007454007281921804,
      "learning_rate": 1.151279952997556e-06,
      "loss": 0.0,
      "step": 1178
    },
    {
      "epoch": 0.7802779616148247,
      "grad_norm": 7.681670665740967,
      "learning_rate": 1.144652127834593e-06,
      "loss": 0.577,
      "step": 1179
    },
    {
      "epoch": 0.7809397749834547,
      "grad_norm": 0.055215541273355484,
      "learning_rate": 1.1380409687811462e-06,
      "loss": 0.0008,
      "step": 1180
    },
    {
      "epoch": 0.7816015883520847,
      "grad_norm": 0.0072863479144871235,
      "learning_rate": 1.1314465044162932e-06,
      "loss": 0.0002,
      "step": 1181
    },
    {
      "epoch": 0.7822634017207147,
      "grad_norm": 0.006220443639904261,
      "learning_rate": 1.1248687632469485e-06,
      "loss": 0.0001,
      "step": 1182
    },
    {
      "epoch": 0.7829252150893448,
      "grad_norm": 0.022230137139558792,
      "learning_rate": 1.1183077737077336e-06,
      "loss": 0.0004,
      "step": 1183
    },
    {
      "epoch": 0.7835870284579749,
      "grad_norm": 0.6046655774116516,
      "learning_rate": 1.111763564160851e-06,
      "loss": 0.0066,
      "step": 1184
    },
    {
      "epoch": 0.7842488418266049,
      "grad_norm": 9.743293762207031,
      "learning_rate": 1.1052361628959746e-06,
      "loss": 0.7385,
      "step": 1185
    },
    {
      "epoch": 0.784910655195235,
      "grad_norm": 0.008103675208985806,
      "learning_rate": 1.0987255981301081e-06,
      "loss": 0.0001,
      "step": 1186
    },
    {
      "epoch": 0.785572468563865,
      "grad_norm": 1.512559175491333,
      "learning_rate": 1.0922318980074808e-06,
      "loss": 0.151,
      "step": 1187
    },
    {
      "epoch": 0.786234281932495,
      "grad_norm": 0.006508685648441315,
      "learning_rate": 1.0857550905994175e-06,
      "loss": 0.0001,
      "step": 1188
    },
    {
      "epoch": 0.786896095301125,
      "grad_norm": 8.631138801574707,
      "learning_rate": 1.0792952039042132e-06,
      "loss": 0.6206,
      "step": 1189
    },
    {
      "epoch": 0.7875579086697552,
      "grad_norm": 0.14274312555789948,
      "learning_rate": 1.072852265847023e-06,
      "loss": 0.0024,
      "step": 1190
    },
    {
      "epoch": 0.7882197220383852,
      "grad_norm": 0.014007756486535072,
      "learning_rate": 1.0664263042797335e-06,
      "loss": 0.0002,
      "step": 1191
    },
    {
      "epoch": 0.7888815354070152,
      "grad_norm": 7.561637878417969,
      "learning_rate": 1.0600173469808445e-06,
      "loss": 0.2602,
      "step": 1192
    },
    {
      "epoch": 0.7895433487756452,
      "grad_norm": 0.36059632897377014,
      "learning_rate": 1.0536254216553487e-06,
      "loss": 0.0063,
      "step": 1193
    },
    {
      "epoch": 0.7902051621442753,
      "grad_norm": 0.007463354617357254,
      "learning_rate": 1.0472505559346102e-06,
      "loss": 0.0001,
      "step": 1194
    },
    {
      "epoch": 0.7908669755129054,
      "grad_norm": 0.06314490735530853,
      "learning_rate": 1.0408927773762501e-06,
      "loss": 0.0012,
      "step": 1195
    },
    {
      "epoch": 0.7915287888815354,
      "grad_norm": 6.170405387878418,
      "learning_rate": 1.0345521134640225e-06,
      "loss": 0.4566,
      "step": 1196
    },
    {
      "epoch": 0.7921906022501655,
      "grad_norm": 4.42210578918457,
      "learning_rate": 1.0282285916076972e-06,
      "loss": 0.1044,
      "step": 1197
    },
    {
      "epoch": 0.7928524156187955,
      "grad_norm": 0.006083511281758547,
      "learning_rate": 1.021922239142944e-06,
      "loss": 0.0001,
      "step": 1198
    },
    {
      "epoch": 0.7935142289874255,
      "grad_norm": 13.54372501373291,
      "learning_rate": 1.015633083331206e-06,
      "loss": 1.2194,
      "step": 1199
    },
    {
      "epoch": 0.7941760423560555,
      "grad_norm": 0.003616875968873501,
      "learning_rate": 1.009361151359593e-06,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 0.7948378557246857,
      "grad_norm": 1.7273085117340088,
      "learning_rate": 1.0031064703407573e-06,
      "loss": 0.0362,
      "step": 1201
    },
    {
      "epoch": 0.7954996690933157,
      "grad_norm": 0.015223930589854717,
      "learning_rate": 9.968690673127774e-07,
      "loss": 0.0003,
      "step": 1202
    },
    {
      "epoch": 0.7961614824619457,
      "grad_norm": 0.22944898903369904,
      "learning_rate": 9.906489692390426e-07,
      "loss": 0.0048,
      "step": 1203
    },
    {
      "epoch": 0.7968232958305758,
      "grad_norm": 0.0007624313002452254,
      "learning_rate": 9.84446203008132e-07,
      "loss": 0.0,
      "step": 1204
    },
    {
      "epoch": 0.7974851091992058,
      "grad_norm": 0.0024297297932207584,
      "learning_rate": 9.782607954337059e-07,
      "loss": 0.0001,
      "step": 1205
    },
    {
      "epoch": 0.7981469225678358,
      "grad_norm": 6.73953914642334,
      "learning_rate": 9.720927732543844e-07,
      "loss": 0.131,
      "step": 1206
    },
    {
      "epoch": 0.798808735936466,
      "grad_norm": 10.967161178588867,
      "learning_rate": 9.659421631336297e-07,
      "loss": 0.6852,
      "step": 1207
    },
    {
      "epoch": 0.799470549305096,
      "grad_norm": 0.05199715867638588,
      "learning_rate": 9.598089916596409e-07,
      "loss": 0.0007,
      "step": 1208
    },
    {
      "epoch": 0.800132362673726,
      "grad_norm": 9.915882110595703,
      "learning_rate": 9.536932853452252e-07,
      "loss": 1.0477,
      "step": 1209
    },
    {
      "epoch": 0.800794176042356,
      "grad_norm": 0.0019866644870489836,
      "learning_rate": 9.475950706276949e-07,
      "loss": 0.0001,
      "step": 1210
    },
    {
      "epoch": 0.8014559894109861,
      "grad_norm": 0.1842396855354309,
      "learning_rate": 9.415143738687493e-07,
      "loss": 0.0039,
      "step": 1211
    },
    {
      "epoch": 0.8021178027796162,
      "grad_norm": 0.024633055552840233,
      "learning_rate": 9.354512213543538e-07,
      "loss": 0.0004,
      "step": 1212
    },
    {
      "epoch": 0.8027796161482462,
      "grad_norm": 0.010070154443383217,
      "learning_rate": 9.294056392946427e-07,
      "loss": 0.0002,
      "step": 1213
    },
    {
      "epoch": 0.8034414295168762,
      "grad_norm": 0.18676912784576416,
      "learning_rate": 9.233776538237854e-07,
      "loss": 0.0031,
      "step": 1214
    },
    {
      "epoch": 0.8041032428855063,
      "grad_norm": 6.289721965789795,
      "learning_rate": 9.17367290999891e-07,
      "loss": 0.3535,
      "step": 1215
    },
    {
      "epoch": 0.8047650562541363,
      "grad_norm": 15.165045738220215,
      "learning_rate": 9.113745768048865e-07,
      "loss": 1.1468,
      "step": 1216
    },
    {
      "epoch": 0.8054268696227663,
      "grad_norm": 0.49527397751808167,
      "learning_rate": 9.053995371444035e-07,
      "loss": 0.0049,
      "step": 1217
    },
    {
      "epoch": 0.8060886829913965,
      "grad_norm": 0.010746671818196774,
      "learning_rate": 8.994421978476736e-07,
      "loss": 0.0002,
      "step": 1218
    },
    {
      "epoch": 0.8067504963600265,
      "grad_norm": 0.02496870793402195,
      "learning_rate": 8.935025846674089e-07,
      "loss": 0.0005,
      "step": 1219
    },
    {
      "epoch": 0.8074123097286565,
      "grad_norm": 1.2560837268829346,
      "learning_rate": 8.875807232796968e-07,
      "loss": 0.038,
      "step": 1220
    },
    {
      "epoch": 0.8080741230972865,
      "grad_norm": 2.1045124530792236,
      "learning_rate": 8.816766392838854e-07,
      "loss": 0.0479,
      "step": 1221
    },
    {
      "epoch": 0.8087359364659166,
      "grad_norm": 0.3011969327926636,
      "learning_rate": 8.757903582024707e-07,
      "loss": 0.0053,
      "step": 1222
    },
    {
      "epoch": 0.8093977498345467,
      "grad_norm": 0.004365296568721533,
      "learning_rate": 8.699219054809938e-07,
      "loss": 0.0001,
      "step": 1223
    },
    {
      "epoch": 0.8100595632031767,
      "grad_norm": 9.847142219543457,
      "learning_rate": 8.640713064879236e-07,
      "loss": 0.3313,
      "step": 1224
    },
    {
      "epoch": 0.8107213765718068,
      "grad_norm": 0.014865390956401825,
      "learning_rate": 8.582385865145509e-07,
      "loss": 0.0003,
      "step": 1225
    },
    {
      "epoch": 0.8113831899404368,
      "grad_norm": 0.005668541416525841,
      "learning_rate": 8.524237707748801e-07,
      "loss": 0.0001,
      "step": 1226
    },
    {
      "epoch": 0.8120450033090668,
      "grad_norm": 6.740996837615967,
      "learning_rate": 8.46626884405512e-07,
      "loss": 0.1695,
      "step": 1227
    },
    {
      "epoch": 0.8127068166776968,
      "grad_norm": 0.014238922856748104,
      "learning_rate": 8.408479524655478e-07,
      "loss": 0.0002,
      "step": 1228
    },
    {
      "epoch": 0.813368630046327,
      "grad_norm": 0.051459405571222305,
      "learning_rate": 8.350869999364714e-07,
      "loss": 0.0005,
      "step": 1229
    },
    {
      "epoch": 0.814030443414957,
      "grad_norm": 1.2341413497924805,
      "learning_rate": 8.293440517220447e-07,
      "loss": 0.028,
      "step": 1230
    },
    {
      "epoch": 0.814692256783587,
      "grad_norm": 0.004087765701115131,
      "learning_rate": 8.236191326482007e-07,
      "loss": 0.0001,
      "step": 1231
    },
    {
      "epoch": 0.8153540701522171,
      "grad_norm": 0.9060036540031433,
      "learning_rate": 8.179122674629325e-07,
      "loss": 0.018,
      "step": 1232
    },
    {
      "epoch": 0.8160158835208471,
      "grad_norm": 0.2367936223745346,
      "learning_rate": 8.122234808361906e-07,
      "loss": 0.004,
      "step": 1233
    },
    {
      "epoch": 0.8166776968894772,
      "grad_norm": 6.282594680786133,
      "learning_rate": 8.065527973597742e-07,
      "loss": 0.3087,
      "step": 1234
    },
    {
      "epoch": 0.8173395102581072,
      "grad_norm": 0.013320911675691605,
      "learning_rate": 8.009002415472261e-07,
      "loss": 0.0002,
      "step": 1235
    },
    {
      "epoch": 0.8180013236267373,
      "grad_norm": 5.135796546936035,
      "learning_rate": 7.952658378337252e-07,
      "loss": 0.2903,
      "step": 1236
    },
    {
      "epoch": 0.8186631369953673,
      "grad_norm": 0.0027709314599633217,
      "learning_rate": 7.896496105759799e-07,
      "loss": 0.0001,
      "step": 1237
    },
    {
      "epoch": 0.8193249503639973,
      "grad_norm": 0.004595922771841288,
      "learning_rate": 7.840515840521263e-07,
      "loss": 0.0001,
      "step": 1238
    },
    {
      "epoch": 0.8199867637326274,
      "grad_norm": 0.004015752580016851,
      "learning_rate": 7.784717824616222e-07,
      "loss": 0.0001,
      "step": 1239
    },
    {
      "epoch": 0.8206485771012575,
      "grad_norm": 0.17325134575366974,
      "learning_rate": 7.729102299251368e-07,
      "loss": 0.0033,
      "step": 1240
    },
    {
      "epoch": 0.8213103904698875,
      "grad_norm": 0.061807237565517426,
      "learning_rate": 7.6736695048446e-07,
      "loss": 0.001,
      "step": 1241
    },
    {
      "epoch": 0.8219722038385175,
      "grad_norm": 0.0176446083933115,
      "learning_rate": 7.618419681023809e-07,
      "loss": 0.0002,
      "step": 1242
    },
    {
      "epoch": 0.8226340172071476,
      "grad_norm": 0.008595960214734077,
      "learning_rate": 7.563353066625973e-07,
      "loss": 0.0001,
      "step": 1243
    },
    {
      "epoch": 0.8232958305757776,
      "grad_norm": 0.0027170483954250813,
      "learning_rate": 7.508469899696097e-07,
      "loss": 0.0001,
      "step": 1244
    },
    {
      "epoch": 0.8239576439444076,
      "grad_norm": 0.008835168555378914,
      "learning_rate": 7.453770417486122e-07,
      "loss": 0.0002,
      "step": 1245
    },
    {
      "epoch": 0.8246194573130378,
      "grad_norm": 0.005809182301163673,
      "learning_rate": 7.399254856453986e-07,
      "loss": 0.0001,
      "step": 1246
    },
    {
      "epoch": 0.8252812706816678,
      "grad_norm": 0.007432869169861078,
      "learning_rate": 7.344923452262548e-07,
      "loss": 0.0001,
      "step": 1247
    },
    {
      "epoch": 0.8259430840502978,
      "grad_norm": 0.022182825952768326,
      "learning_rate": 7.290776439778585e-07,
      "loss": 0.0004,
      "step": 1248
    },
    {
      "epoch": 0.8266048974189278,
      "grad_norm": 0.0020373687148094177,
      "learning_rate": 7.236814053071794e-07,
      "loss": 0.0,
      "step": 1249
    },
    {
      "epoch": 0.8272667107875579,
      "grad_norm": 0.017761416733264923,
      "learning_rate": 7.183036525413717e-07,
      "loss": 0.0003,
      "step": 1250
    },
    {
      "epoch": 0.827928524156188,
      "grad_norm": 0.0038262088783085346,
      "learning_rate": 7.129444089276815e-07,
      "loss": 0.0001,
      "step": 1251
    },
    {
      "epoch": 0.828590337524818,
      "grad_norm": 0.026700329035520554,
      "learning_rate": 7.076036976333416e-07,
      "loss": 0.0003,
      "step": 1252
    },
    {
      "epoch": 0.8292521508934481,
      "grad_norm": 0.2606208920478821,
      "learning_rate": 7.02281541745472e-07,
      "loss": 0.0039,
      "step": 1253
    },
    {
      "epoch": 0.8299139642620781,
      "grad_norm": 0.0038980108220130205,
      "learning_rate": 6.969779642709818e-07,
      "loss": 0.0001,
      "step": 1254
    },
    {
      "epoch": 0.8305757776307081,
      "grad_norm": 0.004350155591964722,
      "learning_rate": 6.916929881364643e-07,
      "loss": 0.0001,
      "step": 1255
    },
    {
      "epoch": 0.8312375909993381,
      "grad_norm": 0.0042404187843203545,
      "learning_rate": 6.864266361881055e-07,
      "loss": 0.0001,
      "step": 1256
    },
    {
      "epoch": 0.8318994043679683,
      "grad_norm": 0.1823924034833908,
      "learning_rate": 6.811789311915818e-07,
      "loss": 0.0038,
      "step": 1257
    },
    {
      "epoch": 0.8325612177365983,
      "grad_norm": 0.002551672048866749,
      "learning_rate": 6.759498958319599e-07,
      "loss": 0.0001,
      "step": 1258
    },
    {
      "epoch": 0.8332230311052283,
      "grad_norm": 0.004916212521493435,
      "learning_rate": 6.707395527136018e-07,
      "loss": 0.0001,
      "step": 1259
    },
    {
      "epoch": 0.8338848444738584,
      "grad_norm": 0.3691519796848297,
      "learning_rate": 6.655479243600632e-07,
      "loss": 0.0025,
      "step": 1260
    },
    {
      "epoch": 0.8345466578424884,
      "grad_norm": 5.655209064483643,
      "learning_rate": 6.603750332140018e-07,
      "loss": 0.455,
      "step": 1261
    },
    {
      "epoch": 0.8352084712111185,
      "grad_norm": 0.012863073498010635,
      "learning_rate": 6.552209016370742e-07,
      "loss": 0.0002,
      "step": 1262
    },
    {
      "epoch": 0.8358702845797485,
      "grad_norm": 0.007043861318379641,
      "learning_rate": 6.500855519098448e-07,
      "loss": 0.0002,
      "step": 1263
    },
    {
      "epoch": 0.8365320979483786,
      "grad_norm": 1.3076387643814087,
      "learning_rate": 6.44969006231686e-07,
      "loss": 0.0244,
      "step": 1264
    },
    {
      "epoch": 0.8371939113170086,
      "grad_norm": 0.005365789867937565,
      "learning_rate": 6.398712867206797e-07,
      "loss": 0.0001,
      "step": 1265
    },
    {
      "epoch": 0.8378557246856386,
      "grad_norm": 0.034835085272789,
      "learning_rate": 6.347924154135299e-07,
      "loss": 0.0003,
      "step": 1266
    },
    {
      "epoch": 0.8385175380542687,
      "grad_norm": 15.469818115234375,
      "learning_rate": 6.297324142654609e-07,
      "loss": 0.385,
      "step": 1267
    },
    {
      "epoch": 0.8391793514228988,
      "grad_norm": 0.014904228039085865,
      "learning_rate": 6.246913051501202e-07,
      "loss": 0.0002,
      "step": 1268
    },
    {
      "epoch": 0.8398411647915288,
      "grad_norm": 0.02316873148083687,
      "learning_rate": 6.196691098594954e-07,
      "loss": 0.0004,
      "step": 1269
    },
    {
      "epoch": 0.8405029781601588,
      "grad_norm": 0.012608381919562817,
      "learning_rate": 6.146658501038055e-07,
      "loss": 0.0003,
      "step": 1270
    },
    {
      "epoch": 0.8411647915287889,
      "grad_norm": 0.09381214529275894,
      "learning_rate": 6.09681547511417e-07,
      "loss": 0.0019,
      "step": 1271
    },
    {
      "epoch": 0.8418266048974189,
      "grad_norm": 0.006782451644539833,
      "learning_rate": 6.047162236287485e-07,
      "loss": 0.0001,
      "step": 1272
    },
    {
      "epoch": 0.8424884182660489,
      "grad_norm": 0.02872879058122635,
      "learning_rate": 5.997698999201723e-07,
      "loss": 0.0005,
      "step": 1273
    },
    {
      "epoch": 0.8431502316346791,
      "grad_norm": 1.4543483257293701,
      "learning_rate": 5.94842597767929e-07,
      "loss": 0.0203,
      "step": 1274
    },
    {
      "epoch": 0.8438120450033091,
      "grad_norm": 0.013903080485761166,
      "learning_rate": 5.899343384720313e-07,
      "loss": 0.0002,
      "step": 1275
    },
    {
      "epoch": 0.8444738583719391,
      "grad_norm": 0.006530097220093012,
      "learning_rate": 5.850451432501724e-07,
      "loss": 0.0001,
      "step": 1276
    },
    {
      "epoch": 0.8451356717405691,
      "grad_norm": 0.01057329960167408,
      "learning_rate": 5.801750332376337e-07,
      "loss": 0.0002,
      "step": 1277
    },
    {
      "epoch": 0.8457974851091992,
      "grad_norm": 0.019525345414876938,
      "learning_rate": 5.753240294871937e-07,
      "loss": 0.0002,
      "step": 1278
    },
    {
      "epoch": 0.8464592984778293,
      "grad_norm": 0.0014088135212659836,
      "learning_rate": 5.704921529690377e-07,
      "loss": 0.0001,
      "step": 1279
    },
    {
      "epoch": 0.8471211118464593,
      "grad_norm": 0.08813004195690155,
      "learning_rate": 5.656794245706676e-07,
      "loss": 0.0019,
      "step": 1280
    },
    {
      "epoch": 0.8477829252150894,
      "grad_norm": 0.13957034051418304,
      "learning_rate": 5.608858650968097e-07,
      "loss": 0.0027,
      "step": 1281
    },
    {
      "epoch": 0.8484447385837194,
      "grad_norm": 0.022389570251107216,
      "learning_rate": 5.56111495269327e-07,
      "loss": 0.0004,
      "step": 1282
    },
    {
      "epoch": 0.8491065519523494,
      "grad_norm": 0.6923274993896484,
      "learning_rate": 5.513563357271256e-07,
      "loss": 0.0193,
      "step": 1283
    },
    {
      "epoch": 0.8497683653209794,
      "grad_norm": 0.0009029367938637733,
      "learning_rate": 5.466204070260717e-07,
      "loss": 0.0,
      "step": 1284
    },
    {
      "epoch": 0.8504301786896096,
      "grad_norm": 0.09475121647119522,
      "learning_rate": 5.419037296388979e-07,
      "loss": 0.0018,
      "step": 1285
    },
    {
      "epoch": 0.8510919920582396,
      "grad_norm": 0.0012031474616378546,
      "learning_rate": 5.372063239551161e-07,
      "loss": 0.0001,
      "step": 1286
    },
    {
      "epoch": 0.8517538054268696,
      "grad_norm": 0.013892818242311478,
      "learning_rate": 5.325282102809304e-07,
      "loss": 0.0002,
      "step": 1287
    },
    {
      "epoch": 0.8524156187954997,
      "grad_norm": 0.014627300202846527,
      "learning_rate": 5.278694088391462e-07,
      "loss": 0.0002,
      "step": 1288
    },
    {
      "epoch": 0.8530774321641297,
      "grad_norm": 9.745905876159668,
      "learning_rate": 5.23229939769086e-07,
      "loss": 0.3466,
      "step": 1289
    },
    {
      "epoch": 0.8537392455327598,
      "grad_norm": 0.148905947804451,
      "learning_rate": 5.186098231265024e-07,
      "loss": 0.0031,
      "step": 1290
    },
    {
      "epoch": 0.8544010589013898,
      "grad_norm": 0.00437304237857461,
      "learning_rate": 5.140090788834895e-07,
      "loss": 0.0001,
      "step": 1291
    },
    {
      "epoch": 0.8550628722700199,
      "grad_norm": 0.027703426778316498,
      "learning_rate": 5.094277269283976e-07,
      "loss": 0.0006,
      "step": 1292
    },
    {
      "epoch": 0.8557246856386499,
      "grad_norm": 0.022492658346891403,
      "learning_rate": 5.048657870657447e-07,
      "loss": 0.0004,
      "step": 1293
    },
    {
      "epoch": 0.8563864990072799,
      "grad_norm": 0.0075880009680986404,
      "learning_rate": 5.003232790161367e-07,
      "loss": 0.0001,
      "step": 1294
    },
    {
      "epoch": 0.85704831237591,
      "grad_norm": 0.007990896701812744,
      "learning_rate": 4.958002224161768e-07,
      "loss": 0.0002,
      "step": 1295
    },
    {
      "epoch": 0.8577101257445401,
      "grad_norm": 0.01304942648857832,
      "learning_rate": 4.912966368183797e-07,
      "loss": 0.0002,
      "step": 1296
    },
    {
      "epoch": 0.8583719391131701,
      "grad_norm": 0.0027181755285710096,
      "learning_rate": 4.868125416910957e-07,
      "loss": 0.0001,
      "step": 1297
    },
    {
      "epoch": 0.8590337524818001,
      "grad_norm": 0.5866110324859619,
      "learning_rate": 4.82347956418418e-07,
      "loss": 0.0092,
      "step": 1298
    },
    {
      "epoch": 0.8596955658504302,
      "grad_norm": 0.3189757168292999,
      "learning_rate": 4.779029003000979e-07,
      "loss": 0.0057,
      "step": 1299
    },
    {
      "epoch": 0.8603573792190602,
      "grad_norm": 0.07610678672790527,
      "learning_rate": 4.7347739255147127e-07,
      "loss": 0.0013,
      "step": 1300
    },
    {
      "epoch": 0.8610191925876902,
      "grad_norm": 10.066123962402344,
      "learning_rate": 4.690714523033635e-07,
      "loss": 0.8423,
      "step": 1301
    },
    {
      "epoch": 0.8616810059563204,
      "grad_norm": 0.02696934901177883,
      "learning_rate": 4.646850986020152e-07,
      "loss": 0.0004,
      "step": 1302
    },
    {
      "epoch": 0.8623428193249504,
      "grad_norm": 0.5028492212295532,
      "learning_rate": 4.6031835040899974e-07,
      "loss": 0.0078,
      "step": 1303
    },
    {
      "epoch": 0.8630046326935804,
      "grad_norm": 0.0018864532466977835,
      "learning_rate": 4.559712266011329e-07,
      "loss": 0.0001,
      "step": 1304
    },
    {
      "epoch": 0.8636664460622104,
      "grad_norm": 0.06858209520578384,
      "learning_rate": 4.5164374597040316e-07,
      "loss": 0.0011,
      "step": 1305
    },
    {
      "epoch": 0.8643282594308405,
      "grad_norm": 0.012124006636440754,
      "learning_rate": 4.473359272238786e-07,
      "loss": 0.0003,
      "step": 1306
    },
    {
      "epoch": 0.8649900727994706,
      "grad_norm": 0.07310435175895691,
      "learning_rate": 4.4304778898363486e-07,
      "loss": 0.0016,
      "step": 1307
    },
    {
      "epoch": 0.8656518861681006,
      "grad_norm": 12.953839302062988,
      "learning_rate": 4.3877934978667437e-07,
      "loss": 0.3267,
      "step": 1308
    },
    {
      "epoch": 0.8663136995367307,
      "grad_norm": 6.995963096618652,
      "learning_rate": 4.345306280848377e-07,
      "loss": 0.2699,
      "step": 1309
    },
    {
      "epoch": 0.8669755129053607,
      "grad_norm": 0.022867515683174133,
      "learning_rate": 4.303016422447337e-07,
      "loss": 0.0003,
      "step": 1310
    },
    {
      "epoch": 0.8676373262739907,
      "grad_norm": 0.004528010729700327,
      "learning_rate": 4.2609241054765437e-07,
      "loss": 0.0001,
      "step": 1311
    },
    {
      "epoch": 0.8682991396426207,
      "grad_norm": 0.08306919783353806,
      "learning_rate": 4.219029511894973e-07,
      "loss": 0.0014,
      "step": 1312
    },
    {
      "epoch": 0.8689609530112509,
      "grad_norm": 0.03633609041571617,
      "learning_rate": 4.177332822806873e-07,
      "loss": 0.0006,
      "step": 1313
    },
    {
      "epoch": 0.8696227663798809,
      "grad_norm": 0.001160870073363185,
      "learning_rate": 4.1358342184609824e-07,
      "loss": 0.0001,
      "step": 1314
    },
    {
      "epoch": 0.8702845797485109,
      "grad_norm": 0.025177719071507454,
      "learning_rate": 4.094533878249751e-07,
      "loss": 0.0004,
      "step": 1315
    },
    {
      "epoch": 0.870946393117141,
      "grad_norm": 2.621661901473999,
      "learning_rate": 4.0534319807085664e-07,
      "loss": 0.0586,
      "step": 1316
    },
    {
      "epoch": 0.871608206485771,
      "grad_norm": 0.002487050835043192,
      "learning_rate": 4.0125287035149507e-07,
      "loss": 0.0001,
      "step": 1317
    },
    {
      "epoch": 0.8722700198544011,
      "grad_norm": 0.02687044069170952,
      "learning_rate": 3.9718242234878414e-07,
      "loss": 0.0006,
      "step": 1318
    },
    {
      "epoch": 0.8729318332230311,
      "grad_norm": 0.07694531232118607,
      "learning_rate": 3.931318716586807e-07,
      "loss": 0.0013,
      "step": 1319
    },
    {
      "epoch": 0.8735936465916612,
      "grad_norm": 0.41033506393432617,
      "learning_rate": 3.8910123579112723e-07,
      "loss": 0.0085,
      "step": 1320
    },
    {
      "epoch": 0.8742554599602912,
      "grad_norm": 0.06939544528722763,
      "learning_rate": 3.850905321699788e-07,
      "loss": 0.0012,
      "step": 1321
    },
    {
      "epoch": 0.8749172733289212,
      "grad_norm": 0.005354878026992083,
      "learning_rate": 3.8109977813292343e-07,
      "loss": 0.0001,
      "step": 1322
    },
    {
      "epoch": 0.8755790866975512,
      "grad_norm": 7.3854899406433105,
      "learning_rate": 3.771289909314141e-07,
      "loss": 0.551,
      "step": 1323
    },
    {
      "epoch": 0.8762409000661814,
      "grad_norm": 0.021960042417049408,
      "learning_rate": 3.7317818773058455e-07,
      "loss": 0.0004,
      "step": 1324
    },
    {
      "epoch": 0.8769027134348114,
      "grad_norm": 0.017002660781145096,
      "learning_rate": 3.692473856091866e-07,
      "loss": 0.0004,
      "step": 1325
    },
    {
      "epoch": 0.8775645268034414,
      "grad_norm": 0.007901255041360855,
      "learning_rate": 3.653366015595078e-07,
      "loss": 0.0001,
      "step": 1326
    },
    {
      "epoch": 0.8782263401720715,
      "grad_norm": 8.26220989227295,
      "learning_rate": 3.6144585248729825e-07,
      "loss": 0.7586,
      "step": 1327
    },
    {
      "epoch": 0.8788881535407015,
      "grad_norm": 0.008559017442166805,
      "learning_rate": 3.575751552117029e-07,
      "loss": 0.0002,
      "step": 1328
    },
    {
      "epoch": 0.8795499669093315,
      "grad_norm": 0.16090905666351318,
      "learning_rate": 3.5372452646518454e-07,
      "loss": 0.0031,
      "step": 1329
    },
    {
      "epoch": 0.8802117802779617,
      "grad_norm": 0.00496219377964735,
      "learning_rate": 3.498939828934511e-07,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 0.8808735936465917,
      "grad_norm": 0.0039023547433316708,
      "learning_rate": 3.460835410553898e-07,
      "loss": 0.0001,
      "step": 1331
    },
    {
      "epoch": 0.8815354070152217,
      "grad_norm": 3.008561611175537,
      "learning_rate": 3.4229321742298427e-07,
      "loss": 0.0383,
      "step": 1332
    },
    {
      "epoch": 0.8821972203838517,
      "grad_norm": 0.006431343033909798,
      "learning_rate": 3.3852302838125627e-07,
      "loss": 0.0002,
      "step": 1333
    },
    {
      "epoch": 0.8828590337524818,
      "grad_norm": 5.357556343078613,
      "learning_rate": 3.3477299022818545e-07,
      "loss": 0.3795,
      "step": 1334
    },
    {
      "epoch": 0.8835208471211119,
      "grad_norm": 0.05975182354450226,
      "learning_rate": 3.3104311917464106e-07,
      "loss": 0.0009,
      "step": 1335
    },
    {
      "epoch": 0.8841826604897419,
      "grad_norm": 0.0060006300918757915,
      "learning_rate": 3.2733343134431716e-07,
      "loss": 0.0001,
      "step": 1336
    },
    {
      "epoch": 0.884844473858372,
      "grad_norm": 0.0069830045104026794,
      "learning_rate": 3.236439427736543e-07,
      "loss": 0.0002,
      "step": 1337
    },
    {
      "epoch": 0.885506287227002,
      "grad_norm": 0.04416361823678017,
      "learning_rate": 3.1997466941177667e-07,
      "loss": 0.0008,
      "step": 1338
    },
    {
      "epoch": 0.886168100595632,
      "grad_norm": 0.01335030235350132,
      "learning_rate": 3.163256271204218e-07,
      "loss": 0.0001,
      "step": 1339
    },
    {
      "epoch": 0.886829913964262,
      "grad_norm": 0.003322160802781582,
      "learning_rate": 3.126968316738677e-07,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 0.8874917273328922,
      "grad_norm": 7.851497650146484,
      "learning_rate": 3.0908829875887227e-07,
      "loss": 0.4485,
      "step": 1341
    },
    {
      "epoch": 0.8881535407015222,
      "grad_norm": 0.9609814882278442,
      "learning_rate": 3.0550004397459974e-07,
      "loss": 0.0171,
      "step": 1342
    },
    {
      "epoch": 0.8888153540701522,
      "grad_norm": 0.008399982936680317,
      "learning_rate": 3.019320828325539e-07,
      "loss": 0.0001,
      "step": 1343
    },
    {
      "epoch": 0.8894771674387822,
      "grad_norm": 0.010622677393257618,
      "learning_rate": 2.9838443075651533e-07,
      "loss": 0.0002,
      "step": 1344
    },
    {
      "epoch": 0.8901389808074123,
      "grad_norm": 0.01568569988012314,
      "learning_rate": 2.948571030824671e-07,
      "loss": 0.0003,
      "step": 1345
    },
    {
      "epoch": 0.8908007941760424,
      "grad_norm": 1.1229759454727173,
      "learning_rate": 2.913501150585357e-07,
      "loss": 0.0117,
      "step": 1346
    },
    {
      "epoch": 0.8914626075446724,
      "grad_norm": 6.697653293609619,
      "learning_rate": 2.878634818449211e-07,
      "loss": 0.2829,
      "step": 1347
    },
    {
      "epoch": 0.8921244209133025,
      "grad_norm": 0.863206148147583,
      "learning_rate": 2.8439721851383385e-07,
      "loss": 0.0068,
      "step": 1348
    },
    {
      "epoch": 0.8927862342819325,
      "grad_norm": 0.14902736246585846,
      "learning_rate": 2.8095134004942737e-07,
      "loss": 0.0023,
      "step": 1349
    },
    {
      "epoch": 0.8934480476505625,
      "grad_norm": 0.007536513265222311,
      "learning_rate": 2.775258613477333e-07,
      "loss": 0.0002,
      "step": 1350
    },
    {
      "epoch": 0.8941098610191925,
      "grad_norm": 0.05921022966504097,
      "learning_rate": 2.741207972165999e-07,
      "loss": 0.001,
      "step": 1351
    },
    {
      "epoch": 0.8947716743878227,
      "grad_norm": 0.00048161277663894,
      "learning_rate": 2.7073616237562497e-07,
      "loss": 0.0,
      "step": 1352
    },
    {
      "epoch": 0.8954334877564527,
      "grad_norm": 0.005376145243644714,
      "learning_rate": 2.6737197145609404e-07,
      "loss": 0.0001,
      "step": 1353
    },
    {
      "epoch": 0.8960953011250827,
      "grad_norm": 0.06878270953893661,
      "learning_rate": 2.640282390009175e-07,
      "loss": 0.0009,
      "step": 1354
    },
    {
      "epoch": 0.8967571144937128,
      "grad_norm": 0.057400356978178024,
      "learning_rate": 2.6070497946456333e-07,
      "loss": 0.0009,
      "step": 1355
    },
    {
      "epoch": 0.8974189278623428,
      "grad_norm": 0.031212573871016502,
      "learning_rate": 2.574022072130017e-07,
      "loss": 0.0006,
      "step": 1356
    },
    {
      "epoch": 0.8980807412309728,
      "grad_norm": 0.012502632103860378,
      "learning_rate": 2.541199365236391e-07,
      "loss": 0.0002,
      "step": 1357
    },
    {
      "epoch": 0.898742554599603,
      "grad_norm": 0.08347481489181519,
      "learning_rate": 2.508581815852523e-07,
      "loss": 0.0015,
      "step": 1358
    },
    {
      "epoch": 0.899404367968233,
      "grad_norm": 0.0020376737229526043,
      "learning_rate": 2.47616956497938e-07,
      "loss": 0.0001,
      "step": 1359
    },
    {
      "epoch": 0.900066181336863,
      "grad_norm": 0.018363066017627716,
      "learning_rate": 2.4439627527304e-07,
      "loss": 0.0003,
      "step": 1360
    },
    {
      "epoch": 0.900727994705493,
      "grad_norm": 0.0006732809124514461,
      "learning_rate": 2.411961518330963e-07,
      "loss": 0.0001,
      "step": 1361
    },
    {
      "epoch": 0.9013898080741231,
      "grad_norm": 0.4881412982940674,
      "learning_rate": 2.3801660001177785e-07,
      "loss": 0.0116,
      "step": 1362
    },
    {
      "epoch": 0.9020516214427532,
      "grad_norm": 0.021796559914946556,
      "learning_rate": 2.3485763355382274e-07,
      "loss": 0.0004,
      "step": 1363
    },
    {
      "epoch": 0.9027134348113832,
      "grad_norm": 5.715933322906494,
      "learning_rate": 2.3171926611498808e-07,
      "loss": 0.0274,
      "step": 1364
    },
    {
      "epoch": 0.9033752481800132,
      "grad_norm": 0.0986863523721695,
      "learning_rate": 2.2860151126197826e-07,
      "loss": 0.0023,
      "step": 1365
    },
    {
      "epoch": 0.9040370615486433,
      "grad_norm": 0.012367443181574345,
      "learning_rate": 2.255043824723968e-07,
      "loss": 0.0002,
      "step": 1366
    },
    {
      "epoch": 0.9046988749172733,
      "grad_norm": 14.556102752685547,
      "learning_rate": 2.224278931346824e-07,
      "loss": 1.3545,
      "step": 1367
    },
    {
      "epoch": 0.9053606882859033,
      "grad_norm": 0.056373197585344315,
      "learning_rate": 2.1937205654805004e-07,
      "loss": 0.0011,
      "step": 1368
    },
    {
      "epoch": 0.9060225016545335,
      "grad_norm": 0.02170770987868309,
      "learning_rate": 2.1633688592244018e-07,
      "loss": 0.0003,
      "step": 1369
    },
    {
      "epoch": 0.9066843150231635,
      "grad_norm": 0.0056599960662424564,
      "learning_rate": 2.1332239437845348e-07,
      "loss": 0.0001,
      "step": 1370
    },
    {
      "epoch": 0.9073461283917935,
      "grad_norm": 0.00789080373942852,
      "learning_rate": 2.103285949473005e-07,
      "loss": 0.0001,
      "step": 1371
    },
    {
      "epoch": 0.9080079417604235,
      "grad_norm": 0.004169194959104061,
      "learning_rate": 2.0735550057074227e-07,
      "loss": 0.0001,
      "step": 1372
    },
    {
      "epoch": 0.9086697551290536,
      "grad_norm": 0.015142247080802917,
      "learning_rate": 2.04403124101033e-07,
      "loss": 0.0002,
      "step": 1373
    },
    {
      "epoch": 0.9093315684976837,
      "grad_norm": 3.225818395614624,
      "learning_rate": 2.0147147830086865e-07,
      "loss": 0.246,
      "step": 1374
    },
    {
      "epoch": 0.9099933818663137,
      "grad_norm": 0.011088489554822445,
      "learning_rate": 1.98560575843329e-07,
      "loss": 0.0002,
      "step": 1375
    },
    {
      "epoch": 0.9106551952349438,
      "grad_norm": 0.01221743505448103,
      "learning_rate": 1.9567042931182223e-07,
      "loss": 0.0002,
      "step": 1376
    },
    {
      "epoch": 0.9113170086035738,
      "grad_norm": 9.52663516998291,
      "learning_rate": 1.9280105120003335e-07,
      "loss": 0.2847,
      "step": 1377
    },
    {
      "epoch": 0.9119788219722038,
      "grad_norm": 0.032349396497011185,
      "learning_rate": 1.899524539118669e-07,
      "loss": 0.0004,
      "step": 1378
    },
    {
      "epoch": 0.9126406353408338,
      "grad_norm": 5.329322338104248,
      "learning_rate": 1.8712464976139598e-07,
      "loss": 0.427,
      "step": 1379
    },
    {
      "epoch": 0.913302448709464,
      "grad_norm": 0.014742100611329079,
      "learning_rate": 1.8431765097280786e-07,
      "loss": 0.0003,
      "step": 1380
    },
    {
      "epoch": 0.913964262078094,
      "grad_norm": 1.3531540632247925,
      "learning_rate": 1.8153146968035107e-07,
      "loss": 0.0144,
      "step": 1381
    },
    {
      "epoch": 0.914626075446724,
      "grad_norm": 0.010596445761620998,
      "learning_rate": 1.7876611792828347e-07,
      "loss": 0.0002,
      "step": 1382
    },
    {
      "epoch": 0.9152878888153541,
      "grad_norm": 0.006650054827332497,
      "learning_rate": 1.7602160767081821e-07,
      "loss": 0.0001,
      "step": 1383
    },
    {
      "epoch": 0.9159497021839841,
      "grad_norm": 0.09513669461011887,
      "learning_rate": 1.7329795077207556e-07,
      "loss": 0.0012,
      "step": 1384
    },
    {
      "epoch": 0.9166115155526141,
      "grad_norm": 0.09494132548570633,
      "learning_rate": 1.7059515900603007e-07,
      "loss": 0.0005,
      "step": 1385
    },
    {
      "epoch": 0.9172733289212442,
      "grad_norm": 0.0059389034286141396,
      "learning_rate": 1.6791324405645627e-07,
      "loss": 0.0001,
      "step": 1386
    },
    {
      "epoch": 0.9179351422898743,
      "grad_norm": 0.07936283946037292,
      "learning_rate": 1.6525221751688637e-07,
      "loss": 0.0014,
      "step": 1387
    },
    {
      "epoch": 0.9185969556585043,
      "grad_norm": 0.012780501507222652,
      "learning_rate": 1.6261209089054986e-07,
      "loss": 0.0002,
      "step": 1388
    },
    {
      "epoch": 0.9192587690271343,
      "grad_norm": 15.462848663330078,
      "learning_rate": 1.5999287559033127e-07,
      "loss": 0.754,
      "step": 1389
    },
    {
      "epoch": 0.9199205823957644,
      "grad_norm": 1.8275865316390991,
      "learning_rate": 1.5739458293871966e-07,
      "loss": 0.0348,
      "step": 1390
    },
    {
      "epoch": 0.9205823957643945,
      "grad_norm": 3.034789800643921,
      "learning_rate": 1.548172241677548e-07,
      "loss": 0.1252,
      "step": 1391
    },
    {
      "epoch": 0.9212442091330245,
      "grad_norm": 0.20436300337314606,
      "learning_rate": 1.5226081041898767e-07,
      "loss": 0.0028,
      "step": 1392
    },
    {
      "epoch": 0.9219060225016545,
      "grad_norm": 0.008724095299839973,
      "learning_rate": 1.4972535274342227e-07,
      "loss": 0.0002,
      "step": 1393
    },
    {
      "epoch": 0.9225678358702846,
      "grad_norm": 0.0881618782877922,
      "learning_rate": 1.472108621014745e-07,
      "loss": 0.0017,
      "step": 1394
    },
    {
      "epoch": 0.9232296492389146,
      "grad_norm": 0.13125911355018616,
      "learning_rate": 1.4471734936292281e-07,
      "loss": 0.0026,
      "step": 1395
    },
    {
      "epoch": 0.9238914626075446,
      "grad_norm": 5.344671726226807,
      "learning_rate": 1.4224482530686091e-07,
      "loss": 0.3662,
      "step": 1396
    },
    {
      "epoch": 0.9245532759761748,
      "grad_norm": 2.353485345840454,
      "learning_rate": 1.397933006216512e-07,
      "loss": 0.0481,
      "step": 1397
    },
    {
      "epoch": 0.9252150893448048,
      "grad_norm": 0.006770851090550423,
      "learning_rate": 1.373627859048793e-07,
      "loss": 0.0001,
      "step": 1398
    },
    {
      "epoch": 0.9258769027134348,
      "grad_norm": 0.020141510292887688,
      "learning_rate": 1.349532916633084e-07,
      "loss": 0.0003,
      "step": 1399
    },
    {
      "epoch": 0.9265387160820648,
      "grad_norm": 0.025314712896943092,
      "learning_rate": 1.325648283128328e-07,
      "loss": 0.0007,
      "step": 1400
    },
    {
      "epoch": 0.9272005294506949,
      "grad_norm": 0.1303807646036148,
      "learning_rate": 1.3019740617843167e-07,
      "loss": 0.0021,
      "step": 1401
    },
    {
      "epoch": 0.927862342819325,
      "grad_norm": 0.005807014182209969,
      "learning_rate": 1.2785103549412815e-07,
      "loss": 0.0001,
      "step": 1402
    },
    {
      "epoch": 0.928524156187955,
      "grad_norm": 0.022563837468624115,
      "learning_rate": 1.2552572640294246e-07,
      "loss": 0.0004,
      "step": 1403
    },
    {
      "epoch": 0.9291859695565851,
      "grad_norm": 0.043625254184007645,
      "learning_rate": 1.2322148895684837e-07,
      "loss": 0.0009,
      "step": 1404
    },
    {
      "epoch": 0.9298477829252151,
      "grad_norm": 0.009658453054726124,
      "learning_rate": 1.209383331167302e-07,
      "loss": 0.0002,
      "step": 1405
    },
    {
      "epoch": 0.9305095962938451,
      "grad_norm": 0.05857494845986366,
      "learning_rate": 1.186762687523385e-07,
      "loss": 0.0009,
      "step": 1406
    },
    {
      "epoch": 0.9311714096624751,
      "grad_norm": 0.007266067434102297,
      "learning_rate": 1.1643530564225014e-07,
      "loss": 0.0001,
      "step": 1407
    },
    {
      "epoch": 0.9318332230311053,
      "grad_norm": 4.625545501708984,
      "learning_rate": 1.142154534738238e-07,
      "loss": 0.0659,
      "step": 1408
    },
    {
      "epoch": 0.9324950363997353,
      "grad_norm": 3.714223861694336,
      "learning_rate": 1.1201672184315727e-07,
      "loss": 0.0528,
      "step": 1409
    },
    {
      "epoch": 0.9331568497683653,
      "grad_norm": 0.00625430466607213,
      "learning_rate": 1.0983912025505028e-07,
      "loss": 0.0001,
      "step": 1410
    },
    {
      "epoch": 0.9338186631369954,
      "grad_norm": 0.002378839999437332,
      "learning_rate": 1.0768265812295619e-07,
      "loss": 0.0001,
      "step": 1411
    },
    {
      "epoch": 0.9344804765056254,
      "grad_norm": 0.09405592828989029,
      "learning_rate": 1.0554734476894923e-07,
      "loss": 0.0013,
      "step": 1412
    },
    {
      "epoch": 0.9351422898742554,
      "grad_norm": 0.04580700770020485,
      "learning_rate": 1.0343318942367952e-07,
      "loss": 0.0008,
      "step": 1413
    },
    {
      "epoch": 0.9358041032428855,
      "grad_norm": 0.108210988342762,
      "learning_rate": 1.0134020122633314e-07,
      "loss": 0.0021,
      "step": 1414
    },
    {
      "epoch": 0.9364659166115156,
      "grad_norm": 0.029496582224965096,
      "learning_rate": 9.926838922459492e-08,
      "loss": 0.0006,
      "step": 1415
    },
    {
      "epoch": 0.9371277299801456,
      "grad_norm": 0.052899450063705444,
      "learning_rate": 9.721776237460734e-08,
      "loss": 0.0012,
      "step": 1416
    },
    {
      "epoch": 0.9377895433487756,
      "grad_norm": 5.940402030944824,
      "learning_rate": 9.518832954093282e-08,
      "loss": 0.4391,
      "step": 1417
    },
    {
      "epoch": 0.9384513567174056,
      "grad_norm": 0.03674924746155739,
      "learning_rate": 9.318009949651541e-08,
      "loss": 0.0006,
      "step": 1418
    },
    {
      "epoch": 0.9391131700860358,
      "grad_norm": 0.026622246950864792,
      "learning_rate": 9.119308092264079e-08,
      "loss": 0.0005,
      "step": 1419
    },
    {
      "epoch": 0.9397749834546658,
      "grad_norm": 0.00319274771027267,
      "learning_rate": 8.922728240890411e-08,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 0.9404367968232958,
      "grad_norm": 6.271252155303955,
      "learning_rate": 8.728271245316555e-08,
      "loss": 0.3779,
      "step": 1421
    },
    {
      "epoch": 0.9410986101919259,
      "grad_norm": 0.11428588628768921,
      "learning_rate": 8.535937946151984e-08,
      "loss": 0.0019,
      "step": 1422
    },
    {
      "epoch": 0.9417604235605559,
      "grad_norm": 0.0035695352125912905,
      "learning_rate": 8.345729174825623e-08,
      "loss": 0.0001,
      "step": 1423
    },
    {
      "epoch": 0.9424222369291859,
      "grad_norm": 16.091257095336914,
      "learning_rate": 8.157645753582299e-08,
      "loss": 0.171,
      "step": 1424
    },
    {
      "epoch": 0.9430840502978161,
      "grad_norm": 0.004813089966773987,
      "learning_rate": 7.971688495479468e-08,
      "loss": 0.0001,
      "step": 1425
    },
    {
      "epoch": 0.9437458636664461,
      "grad_norm": 0.02056955359876156,
      "learning_rate": 7.787858204383381e-08,
      "loss": 0.0004,
      "step": 1426
    },
    {
      "epoch": 0.9444076770350761,
      "grad_norm": 0.13830582797527313,
      "learning_rate": 7.606155674965698e-08,
      "loss": 0.0024,
      "step": 1427
    },
    {
      "epoch": 0.9450694904037061,
      "grad_norm": 0.04183465987443924,
      "learning_rate": 7.426581692700053e-08,
      "loss": 0.0007,
      "step": 1428
    },
    {
      "epoch": 0.9457313037723362,
      "grad_norm": 0.0595865473151207,
      "learning_rate": 7.24913703385871e-08,
      "loss": 0.0009,
      "step": 1429
    },
    {
      "epoch": 0.9463931171409663,
      "grad_norm": 21.675155639648438,
      "learning_rate": 7.073822465509195e-08,
      "loss": 0.2903,
      "step": 1430
    },
    {
      "epoch": 0.9470549305095963,
      "grad_norm": 0.012716193683445454,
      "learning_rate": 6.900638745511057e-08,
      "loss": 0.0002,
      "step": 1431
    },
    {
      "epoch": 0.9477167438782264,
      "grad_norm": 0.0047702970914542675,
      "learning_rate": 6.729586622512274e-08,
      "loss": 0.0001,
      "step": 1432
    },
    {
      "epoch": 0.9483785572468564,
      "grad_norm": 0.06294713169336319,
      "learning_rate": 6.560666835946416e-08,
      "loss": 0.0011,
      "step": 1433
    },
    {
      "epoch": 0.9490403706154864,
      "grad_norm": 8.841341018676758,
      "learning_rate": 6.39388011602915e-08,
      "loss": 0.2682,
      "step": 1434
    },
    {
      "epoch": 0.9497021839841164,
      "grad_norm": 0.011792557314038277,
      "learning_rate": 6.229227183755293e-08,
      "loss": 0.0002,
      "step": 1435
    },
    {
      "epoch": 0.9503639973527466,
      "grad_norm": 0.008351918309926987,
      "learning_rate": 6.0667087508956e-08,
      "loss": 0.0002,
      "step": 1436
    },
    {
      "epoch": 0.9510258107213766,
      "grad_norm": 0.00410436512902379,
      "learning_rate": 5.9063255199937054e-08,
      "loss": 0.0001,
      "step": 1437
    },
    {
      "epoch": 0.9516876240900066,
      "grad_norm": 5.533013820648193,
      "learning_rate": 5.7480781843630155e-08,
      "loss": 0.0747,
      "step": 1438
    },
    {
      "epoch": 0.9523494374586366,
      "grad_norm": 0.009129120968282223,
      "learning_rate": 5.591967428083822e-08,
      "loss": 0.0002,
      "step": 1439
    },
    {
      "epoch": 0.9530112508272667,
      "grad_norm": 0.008840820752084255,
      "learning_rate": 5.4379939260001956e-08,
      "loss": 0.0001,
      "step": 1440
    },
    {
      "epoch": 0.9536730641958967,
      "grad_norm": 0.0074727823957800865,
      "learning_rate": 5.2861583437174294e-08,
      "loss": 0.0001,
      "step": 1441
    },
    {
      "epoch": 0.9543348775645268,
      "grad_norm": 0.06442847847938538,
      "learning_rate": 5.1364613375984865e-08,
      "loss": 0.0011,
      "step": 1442
    },
    {
      "epoch": 0.9549966909331569,
      "grad_norm": 0.23543791472911835,
      "learning_rate": 4.988903554761948e-08,
      "loss": 0.005,
      "step": 1443
    },
    {
      "epoch": 0.9556585043017869,
      "grad_norm": 0.35951948165893555,
      "learning_rate": 4.843485633078682e-08,
      "loss": 0.0056,
      "step": 1444
    },
    {
      "epoch": 0.9563203176704169,
      "grad_norm": 0.012605062685906887,
      "learning_rate": 4.7002082011692316e-08,
      "loss": 0.0002,
      "step": 1445
    },
    {
      "epoch": 0.956982131039047,
      "grad_norm": 0.00480964919552207,
      "learning_rate": 4.559071878401211e-08,
      "loss": 0.0001,
      "step": 1446
    },
    {
      "epoch": 0.9576439444076771,
      "grad_norm": 8.73056411743164,
      "learning_rate": 4.420077274886414e-08,
      "loss": 0.7466,
      "step": 1447
    },
    {
      "epoch": 0.9583057577763071,
      "grad_norm": 9.05325984954834,
      "learning_rate": 4.2832249914783744e-08,
      "loss": 0.2593,
      "step": 1448
    },
    {
      "epoch": 0.9589675711449371,
      "grad_norm": 0.14355450868606567,
      "learning_rate": 4.148515619769644e-08,
      "loss": 0.0032,
      "step": 1449
    },
    {
      "epoch": 0.9596293845135672,
      "grad_norm": 2.686523199081421,
      "learning_rate": 4.015949742089298e-08,
      "loss": 0.0723,
      "step": 1450
    },
    {
      "epoch": 0.9602911978821972,
      "grad_norm": 0.004748520907014608,
      "learning_rate": 3.885527931500377e-08,
      "loss": 0.0001,
      "step": 1451
    },
    {
      "epoch": 0.9609530112508272,
      "grad_norm": 0.15606503188610077,
      "learning_rate": 3.757250751797448e-08,
      "loss": 0.0025,
      "step": 1452
    },
    {
      "epoch": 0.9616148246194574,
      "grad_norm": 0.05969049409031868,
      "learning_rate": 3.631118757504159e-08,
      "loss": 0.0009,
      "step": 1453
    },
    {
      "epoch": 0.9622766379880874,
      "grad_norm": 0.03219914063811302,
      "learning_rate": 3.5071324938708575e-08,
      "loss": 0.0005,
      "step": 1454
    },
    {
      "epoch": 0.9629384513567174,
      "grad_norm": 9.470518112182617,
      "learning_rate": 3.385292496872084e-08,
      "loss": 0.8292,
      "step": 1455
    },
    {
      "epoch": 0.9636002647253474,
      "grad_norm": 8.623472213745117,
      "learning_rate": 3.26559929320458e-08,
      "loss": 0.4632,
      "step": 1456
    },
    {
      "epoch": 0.9642620780939775,
      "grad_norm": 0.555470883846283,
      "learning_rate": 3.148053400284623e-08,
      "loss": 0.0119,
      "step": 1457
    },
    {
      "epoch": 0.9649238914626076,
      "grad_norm": 13.420433044433594,
      "learning_rate": 3.0326553262460257e-08,
      "loss": 0.2079,
      "step": 1458
    },
    {
      "epoch": 0.9655857048312376,
      "grad_norm": 4.9259490966796875,
      "learning_rate": 2.9194055699380276e-08,
      "loss": 0.5131,
      "step": 1459
    },
    {
      "epoch": 0.9662475181998676,
      "grad_norm": 0.017521850764751434,
      "learning_rate": 2.8083046209228525e-08,
      "loss": 0.0003,
      "step": 1460
    },
    {
      "epoch": 0.9669093315684977,
      "grad_norm": 2.0733754634857178,
      "learning_rate": 2.6993529594737112e-08,
      "loss": 0.0338,
      "step": 1461
    },
    {
      "epoch": 0.9675711449371277,
      "grad_norm": 0.0015951597597450018,
      "learning_rate": 2.5925510565729116e-08,
      "loss": 0.0001,
      "step": 1462
    },
    {
      "epoch": 0.9682329583057577,
      "grad_norm": 0.14424638450145721,
      "learning_rate": 2.4878993739095858e-08,
      "loss": 0.0022,
      "step": 1463
    },
    {
      "epoch": 0.9688947716743879,
      "grad_norm": 0.05329546332359314,
      "learning_rate": 2.3853983638776888e-08,
      "loss": 0.0008,
      "step": 1464
    },
    {
      "epoch": 0.9695565850430179,
      "grad_norm": 0.006407597567886114,
      "learning_rate": 2.285048469574336e-08,
      "loss": 0.0001,
      "step": 1465
    },
    {
      "epoch": 0.9702183984116479,
      "grad_norm": 0.0057309530675411224,
      "learning_rate": 2.1868501247974684e-08,
      "loss": 0.0001,
      "step": 1466
    },
    {
      "epoch": 0.970880211780278,
      "grad_norm": 5.943024635314941,
      "learning_rate": 2.090803754044357e-08,
      "loss": 0.3394,
      "step": 1467
    },
    {
      "epoch": 0.971542025148908,
      "grad_norm": 0.23002511262893677,
      "learning_rate": 1.9969097725094365e-08,
      "loss": 0.003,
      "step": 1468
    },
    {
      "epoch": 0.972203838517538,
      "grad_norm": 0.01056636217981577,
      "learning_rate": 1.9051685860828063e-08,
      "loss": 0.0002,
      "step": 1469
    },
    {
      "epoch": 0.9728656518861681,
      "grad_norm": 0.22108452022075653,
      "learning_rate": 1.8155805913483428e-08,
      "loss": 0.0021,
      "step": 1470
    },
    {
      "epoch": 0.9735274652547982,
      "grad_norm": 0.006087282672524452,
      "learning_rate": 1.728146175581924e-08,
      "loss": 0.0001,
      "step": 1471
    },
    {
      "epoch": 0.9741892786234282,
      "grad_norm": 0.027363654226064682,
      "learning_rate": 1.642865716749875e-08,
      "loss": 0.0005,
      "step": 1472
    },
    {
      "epoch": 0.9748510919920582,
      "grad_norm": 0.0016057388857007027,
      "learning_rate": 1.5597395835071916e-08,
      "loss": 0.0001,
      "step": 1473
    },
    {
      "epoch": 0.9755129053606882,
      "grad_norm": 1.5408744812011719,
      "learning_rate": 1.4787681351960959e-08,
      "loss": 0.192,
      "step": 1474
    },
    {
      "epoch": 0.9761747187293184,
      "grad_norm": 0.022323260083794594,
      "learning_rate": 1.3999517218444281e-08,
      "loss": 0.0003,
      "step": 1475
    },
    {
      "epoch": 0.9768365320979484,
      "grad_norm": 11.685315132141113,
      "learning_rate": 1.3232906841641468e-08,
      "loss": 0.95,
      "step": 1476
    },
    {
      "epoch": 0.9774983454665784,
      "grad_norm": 0.013027938082814217,
      "learning_rate": 1.2487853535497196e-08,
      "loss": 0.0002,
      "step": 1477
    },
    {
      "epoch": 0.9781601588352085,
      "grad_norm": 0.038612693548202515,
      "learning_rate": 1.1764360520769568e-08,
      "loss": 0.0005,
      "step": 1478
    },
    {
      "epoch": 0.9788219722038385,
      "grad_norm": 0.006238135509192944,
      "learning_rate": 1.1062430925012913e-08,
      "loss": 0.0001,
      "step": 1479
    },
    {
      "epoch": 0.9794837855724685,
      "grad_norm": 0.7115968465805054,
      "learning_rate": 1.038206778256834e-08,
      "loss": 0.0059,
      "step": 1480
    },
    {
      "epoch": 0.9801455989410987,
      "grad_norm": 0.015978608280420303,
      "learning_rate": 9.723274034545982e-09,
      "loss": 0.0002,
      "step": 1481
    },
    {
      "epoch": 0.9808074123097287,
      "grad_norm": 8.302145957946777,
      "learning_rate": 9.086052528816113e-09,
      "loss": 0.3305,
      "step": 1482
    },
    {
      "epoch": 0.9814692256783587,
      "grad_norm": 0.022480882704257965,
      "learning_rate": 8.470406019994715e-09,
      "loss": 0.0005,
      "step": 1483
    },
    {
      "epoch": 0.9821310390469887,
      "grad_norm": 0.027927543967962265,
      "learning_rate": 7.876337169432368e-09,
      "loss": 0.0005,
      "step": 1484
    },
    {
      "epoch": 0.9827928524156188,
      "grad_norm": 0.009122421033680439,
      "learning_rate": 7.303848545202052e-09,
      "loss": 0.0002,
      "step": 1485
    },
    {
      "epoch": 0.9834546657842489,
      "grad_norm": 0.032891009002923965,
      "learning_rate": 6.752942622089698e-09,
      "loss": 0.0006,
      "step": 1486
    },
    {
      "epoch": 0.9841164791528789,
      "grad_norm": 0.11174983531236649,
      "learning_rate": 6.2236217815819785e-09,
      "loss": 0.0021,
      "step": 1487
    },
    {
      "epoch": 0.984778292521509,
      "grad_norm": 0.0963679775595665,
      "learning_rate": 5.715888311855211e-09,
      "loss": 0.0017,
      "step": 1488
    },
    {
      "epoch": 0.985440105890139,
      "grad_norm": 0.0024417827371507883,
      "learning_rate": 5.229744407767578e-09,
      "loss": 0.0001,
      "step": 1489
    },
    {
      "epoch": 0.986101919258769,
      "grad_norm": 1.8377068042755127,
      "learning_rate": 4.765192170849697e-09,
      "loss": 0.039,
      "step": 1490
    },
    {
      "epoch": 0.986763732627399,
      "grad_norm": 0.013855284079909325,
      "learning_rate": 4.322233609292404e-09,
      "loss": 0.0003,
      "step": 1491
    },
    {
      "epoch": 0.9874255459960292,
      "grad_norm": 0.14208608865737915,
      "learning_rate": 3.900870637941201e-09,
      "loss": 0.003,
      "step": 1492
    },
    {
      "epoch": 0.9880873593646592,
      "grad_norm": 0.00932330172508955,
      "learning_rate": 3.5011050782879364e-09,
      "loss": 0.0001,
      "step": 1493
    },
    {
      "epoch": 0.9887491727332892,
      "grad_norm": 7.032313823699951,
      "learning_rate": 3.1229386584608057e-09,
      "loss": 0.5137,
      "step": 1494
    },
    {
      "epoch": 0.9894109861019192,
      "grad_norm": 3.2850780487060547,
      "learning_rate": 2.7663730132182485e-09,
      "loss": 0.1484,
      "step": 1495
    },
    {
      "epoch": 0.9900727994705493,
      "grad_norm": 0.020512623712420464,
      "learning_rate": 2.431409683941732e-09,
      "loss": 0.0004,
      "step": 1496
    },
    {
      "epoch": 0.9907346128391793,
      "grad_norm": 0.0020420884247869253,
      "learning_rate": 2.118050118629089e-09,
      "loss": 0.0001,
      "step": 1497
    },
    {
      "epoch": 0.9913964262078094,
      "grad_norm": 0.04949253425002098,
      "learning_rate": 1.8262956718884117e-09,
      "loss": 0.001,
      "step": 1498
    },
    {
      "epoch": 0.9920582395764395,
      "grad_norm": 0.04606476426124573,
      "learning_rate": 1.5561476049325009e-09,
      "loss": 0.0008,
      "step": 1499
    },
    {
      "epoch": 0.9927200529450695,
      "grad_norm": 0.014043363742530346,
      "learning_rate": 1.3076070855710943e-09,
      "loss": 0.0002,
      "step": 1500
    },
    {
      "epoch": 0.9933818663136995,
      "grad_norm": 0.4595082402229309,
      "learning_rate": 1.0806751882092014e-09,
      "loss": 0.0087,
      "step": 1501
    },
    {
      "epoch": 0.9940436796823295,
      "grad_norm": 1.557692527770996,
      "learning_rate": 8.753528938409972e-10,
      "loss": 0.0241,
      "step": 1502
    },
    {
      "epoch": 0.9947054930509597,
      "grad_norm": 0.0032205567695200443,
      "learning_rate": 6.916410900442705e-10,
      "loss": 0.0001,
      "step": 1503
    },
    {
      "epoch": 0.9953673064195897,
      "grad_norm": 0.006213679909706116,
      "learning_rate": 5.295405709787594e-10,
      "loss": 0.0001,
      "step": 1504
    },
    {
      "epoch": 0.9960291197882197,
      "grad_norm": 8.739147186279297,
      "learning_rate": 3.890520373817097e-10,
      "loss": 0.4826,
      "step": 1505
    },
    {
      "epoch": 0.9966909331568498,
      "grad_norm": 0.023265207186341286,
      "learning_rate": 2.7017609656454504e-10,
      "loss": 0.0004,
      "step": 1506
    },
    {
      "epoch": 0.9973527465254798,
      "grad_norm": 0.004805080126971006,
      "learning_rate": 1.7291326241064555e-10,
      "loss": 0.0001,
      "step": 1507
    },
    {
      "epoch": 0.9980145598941098,
      "grad_norm": 1.5013024806976318,
      "learning_rate": 9.726395537312805e-11,
      "loss": 0.2351,
      "step": 1508
    },
    {
      "epoch": 0.99867637326274,
      "grad_norm": 0.0005419576773419976,
      "learning_rate": 4.3228502473180446e-11,
      "loss": 0.0,
      "step": 1509
    },
    {
      "epoch": 0.99933818663137,
      "grad_norm": 0.0809386819601059,
      "learning_rate": 1.080713729784133e-11,
      "loss": 0.0014,
      "step": 1510
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.9816365242004395,
      "learning_rate": 0.0,
      "loss": 0.2087,
      "step": 1511
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.34523809523809523,
      "eval_loss": 0.060016244649887085,
      "eval_runtime": 744.0164,
      "eval_samples_per_second": 0.226,
      "eval_steps_per_second": 0.226,
      "step": 1511
    }
  ],
  "logging_steps": 1,
  "max_steps": 1511,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.66702577632555e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
